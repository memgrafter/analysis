---
ver: rpa2
title: Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization
arxiv_id: '2410.05114'
source_url: https://arxiv.org/abs/2410.05114
tags:
- images
- synthetic
- training
- skin
- augmented
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors tackle the lack of diverse, high-quality annotated
  dermatological image datasets by developing an unsupervised augmentation approach
  using GANs. They train a StyleGAN2 model on dermatoscopic images, invert real images
  into the latent space using HyperStyle, and use closed-form factorization to identify
  semantic transformation directions without labels.
---

# Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization

## Quick Facts
- arXiv ID: 2410.05114
- Source URL: https://arxiv.org/abs/2410.05114
- Reference count: 40
- Authors: Rohan Reddy Mekala; Frederik Pahde; Simon Baur; Sneha Chandrashekar; Madeline Diep; Markus Wenzel; Eric L. Wisotzky; Galip Ãœmit Yolcu; Sebastian Lapuschkin; Jackie Ma; Peter Eisert; Mikael Lindvall; Adam Porter; Wojciech Samek
- Primary result: GAN-based synthetic augmentation with closed-form factorization achieves state-of-the-art non-ensemble skin lesion classification performance (balanced accuracy 0.856, average AUC ROC 0.947) on HAM10000 dataset

## Executive Summary
This paper addresses the challenge of limited diverse dermatological image datasets by developing an unsupervised synthetic augmentation approach using GANs. The authors train a StyleGAN2 model on dermatoscopic images, invert real images into latent space using HyperStyle, and employ closed-form factorization to identify meaningful semantic transformation directions without requiring labels. These transformations are validated through a human-in-the-loop dashboard and used to generate synthetic images that augment training data for skin lesion classification. The resulting models achieve state-of-the-art performance on the HAM10000 dataset among non-ensemble methods.

## Method Summary
The approach involves training StyleGAN2 on dermatoscopic images from multiple datasets, then using HyperStyle to invert real images into the GAN's latent space. Closed-form factorization via SVD extracts semantic transformation directions from the generator's weight matrices, identifying meaningful image variations. A human-in-the-loop dashboard enables semi-automatic validation of these transformations. Synthetic images generated using the validated transformations augment the training data, with models trained using weighted oversampling to address class imbalance. The augmented models are evaluated on skin lesion classification tasks using DenseNet architectures.

## Key Results
- State-of-the-art non-ensemble performance on HAM10000 dataset with balanced accuracy of 0.856 and average AUC ROC of 0.947
- Synthetic augmentation improves classification of underrepresented classes (MEL, BCC, DF) while maintaining or improving performance on common classes
- Closed-form factorization successfully extracts interpretable semantic directions without requiring labeled training data
- Human-in-the-loop validation process effectively filters low-quality or irrelevant synthetic transformations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Closed-form factorization extracts interpretable semantic directions in GAN latent space without labels.
- Mechanism: SVD is applied to weight matrices of StyleGAN2 generator layers to obtain eigenvectors representing maximal variance directions; these directions correspond to meaningful image transformations.
- Core assumption: Latent space directions with high variance encode semantically relevant features.
- Evidence anchors:
  - [section] "Through Singular Value Decomposition (SVD) to the weight matrix W... The columns of V (the eigenvectors) represent distinct directions in the latent space along which the data varies the most."
  - [abstract] "We employ closed-form factorization to identify meaningful and orthogonal latent semantic directions within the latent space."

### Mechanism 2
- Claim: HyperStyle inversion accurately maps real dermatoscopic images into GAN latent space for controlled editing.
- Mechanism: Hybrid encoder-optimizer inversion balances reconstruction accuracy and editability, producing latent codes that preserve semantic details.
- Core assumption: Real images can be accurately embedded into StyleGAN2 latent space without significant loss of diagnostic features.
- Evidence anchors:
  - [section] "HyperStyle employs a hybrid approach that combines the strengths of encoder- and optimization-based inversion techniques... HyperStyle allows for accurate and flexible modifications of real images."
  - [section] "The training process for the HyperStyle module resulted in an L2 loss of 0.002, highlighting its efficacy in refining the latent space for accurate image reconstruction."

### Mechanism 3
- Claim: Synthetic augmentation increases classification model robustness by addressing class imbalance and improving feature generalization.
- Mechanism: Generated images expand the training distribution, particularly for underrepresented classes, enabling models to learn more diverse decision boundaries.
- Core assumption: Synthetic images are sufficiently realistic and diverse to improve model performance without introducing harmful artifacts.
- Evidence anchors:
  - [section] "Synthetically augmented (un/filtered) models show a better recall for the classes MEL, BCC, and DF, when considering all sizes of augmented data. Note that all three are underrepresented classes..."
  - [section] "the average AUC ROC for SA-6k is 0.945, higher than the baseline's 0.924, indicating a general performance boost."

## Foundational Learning

- Concept: Latent space factorization and SVD decomposition
  - Why needed here: To extract meaningful semantic transformation directions from GAN weights without labeled data
  - Quick check question: What do the eigenvectors from SVD represent in the context of GAN latent space?

- Concept: GAN inversion techniques (encoder vs optimization trade-offs)
  - Why needed here: To map real dermatoscopic images into latent space for controlled editing while preserving diagnostic features
  - Quick check question: Why does HyperStyle use both an encoder and optimizer rather than just one approach?

- Concept: Evaluation metrics for synthetic image quality (LPIPS, FID)
  - Why needed here: To quantify perceptual similarity between synthetic and real images and ensure generated images are diagnostically valid
  - Quick check question: How does LPIPS differ from FID in evaluating synthetic image quality?

## Architecture Onboarding

- Component map: StyleGAN2 (generator training) -> HyperStyle (inversion) -> Closed-form factorization (direction extraction) -> Human-in-the-loop validation -> Synthetic image generation -> Classification model training
- Critical path: Training StyleGAN2 -> HyperStyle inversion -> Closed-form factorization -> Validation -> Augmentation
- Design tradeoffs: HyperStyle balances editability vs reconstruction fidelity; closed-form factorization avoids labeled data but may extract less precise directions than supervised methods
- Failure signatures: Poor FID scores indicate training issues; high LPIPS indicates unrealistic transformations; model performance not improving suggests synthetic images lack diversity
- First 3 experiments:
  1. Train StyleGAN2 on dermatoscopic dataset and evaluate FID score
  2. Apply HyperStyle inversion to real images and check reconstruction quality
  3. Extract 10-15 semantic directions via closed-form factorization and visualize transformations using dashboard

## Open Questions the Paper Calls Out

- Question: How does the choice of transformations (SPV, SV, BCV, GV, PS) affect downstream model performance compared to other potential transformations not included in the final five?
  - Basis in paper: [explicit] The paper states they identified 13 transformations but only used five for training augmentation, with others being variants.
  - Why unresolved: The paper doesn't compare performance between different subsets of transformations or explore whether the selected five are optimal.
  - What evidence would resolve it: A systematic comparison of classification performance using different combinations of the 13 identified transformations, showing which specific transformations contribute most to accuracy improvements.

- Question: What is the relationship between the LPIPS threshold (0.2) used to filter transformations and optimal downstream classification performance?
  - Basis in paper: [explicit] The paper mentions LPIPS scores >0.2 were considered "wayward or low-fidelity" but doesn't validate this threshold through ablation studies.
  - Why unresolved: The paper selects transformations based on LPIPS scores without testing whether this threshold optimizes classification performance or whether a different threshold might yield better results.
  - What evidence would resolve it: Experiments varying the LPIPS threshold and measuring corresponding classification accuracy to determine if the 0.2 threshold is optimal.

- Question: How would training classification models directly on synthetic images without real image augmentation compare to the hybrid approach used in this study?
  - Basis in paper: [inferred] The paper always tests on non-modified real images and doesn't explore training exclusively on synthetic data.
  - Why unresolved: The study only investigates augmenting real data with synthetic variations, not whether synthetic data alone could achieve comparable or better performance.
  - What evidence would resolve it: A comparison of classification models trained entirely on synthetic data versus those trained on augmented real data, measuring performance differences on the test set.

## Limitations
- The optimal amount of synthetic augmentation (6,000 images) appears dataset-specific with diminishing returns beyond that point
- Human-in-the-loop validation process introduces potential subjectivity that is difficult to quantify
- Performance improvements achieved on a single dataset (HAM10000) without extensive validation on external datasets
- Closed-form factorization directions may not be universally interpretable across different GAN architectures or training conditions

## Confidence
- High confidence: StyleGAN2 training methodology, HyperStyle inversion implementation, classification model architecture and evaluation metrics
- Medium confidence: Closed-form factorization directions capturing meaningful semantic transformations, human validation process effectiveness
- Low confidence: Generalization of synthetic augmentation benefits to other datasets and clinical settings

## Next Checks
1. Evaluate the closed-form factorization directions on a second independently trained StyleGAN2 model to test robustness of semantic interpretations
2. Conduct ablation study testing different amounts of synthetic augmentation (2k, 6k, 12k images) to identify optimal augmentation strategy
3. Validate classification performance improvements on an external skin lesion dataset not used in GAN training to assess generalization capability