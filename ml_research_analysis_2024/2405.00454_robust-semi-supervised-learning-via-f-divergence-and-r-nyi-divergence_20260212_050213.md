---
ver: rpa2
title: "Robust Semi-supervised Learning via $f$-Divergence and $\u03B1$-R\xE9nyi Divergence"
arxiv_id: '2405.00454'
source_url: https://arxiv.org/abs/2405.00454
tags:
- learning
- divergence
- data
- unlabeled
- dp-ssl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates empirical risk functions and regularization\
  \ methods for self-training in semi-supervised learning, drawing inspiration from\
  \ f-divergences and \u03B1-R\xE9nyi divergences. The authors propose new risk functions\
  \ based on these divergences and combine them with self-training approaches like\
  \ pseudo-labeling and entropy minimization."
---

# Robust Semi-supervised Learning via $f$-Divergence and $α$-Rényi Divergence

## Quick Facts
- arXiv ID: 2405.00454
- Source URL: https://arxiv.org/abs/2405.00454
- Reference count: 40
- One-line primary result: DERs based on f-divergences and α-Rényi divergences improve robustness to noisy pseudo-labels in self-training.

## Executive Summary
This paper investigates empirical risk functions and regularization methods for self-training in semi-supervised learning, drawing inspiration from f-divergences and α-Rényi divergences. The authors propose new risk functions based on these divergences and combine them with self-training approaches like pseudo-labeling and entropy minimization. Under certain conditions, their empirical risk functions demonstrate better performance compared to traditional self-training methods, especially when dealing with noisy pseudo-labels. The proposed methods show improved robustness to pseudo-label noise and imbalanced data. Experiments on CIFAR-100 and LETTER datasets demonstrate the effectiveness of the proposed approach, with some divergences achieving higher accuracy than traditional methods.

## Method Summary
The paper proposes a new empirical risk function for self-training in semi-supervised learning based on f-divergences and α-Rényi divergences. The risk function measures the divergence between the empirical label distribution and the model's predicted distribution, serving as a regularizer. The authors introduce two self-training algorithms: Data Pseudo-labeling Semi-supervised Learning (DP-SSL) and Data Entropy Minimization Semi-supervised Learning (DEM-SSL). DP-SSL uses pseudo-labels generated by the model, while DEM-SSL minimizes entropy of the model's predictions. Both algorithms incorporate the proposed divergence-based risk functions and regularization terms to improve robustness to noisy pseudo-labels and handle imbalanced data.

## Key Results
- The proposed DER-based methods show improved robustness to noisy pseudo-labels compared to traditional self-training approaches.
- Some divergences (e.g., JS divergence, α-Rényi divergence) perform better than others under noisy pseudo-labels, demonstrating the importance of divergence choice.
- The proposed methods achieve higher accuracy on CIFAR-100 and LETTER datasets compared to traditional self-training methods, especially when dealing with imbalanced data.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DERs based on f-divergences and α-Rényi divergences improve robustness to noisy pseudo-labels in self-training.
- Mechanism: The divergence measures between the empirical label distribution and model predictions act as a regularizer, penalizing divergence from true labels even when pseudo-labels are incorrect.
- Core assumption: The generator function f(t) satisfies f(0) < ∞ and the divergence is well-defined for the label distributions used.
- Evidence anchors:
  - [abstract] "our empirical risk functions are robust, concerning noisy pseudo-labels"
  - [section III-B-3] "if SSL scenario's cost, i.e., Df (Pt(Yl, Yu t|Xl,u )∥ ˆP (Yl, ˆYu|Xl,u )), is bounded, then we'll have a notion of robustness"
  - [corpus] No direct evidence; corpus neighbors focus on ERM-fDR rather than robustness to label noise.
- Break condition: If the pseudo-label noise exceeds the divergence measure's tolerance or if the generator function does not satisfy f(0) < ∞.

### Mechanism 2
- Claim: Combining DER with entropy minimization regularizes model predictions toward uniform distribution, reducing confirmation bias.
- Mechanism: Minimizing D-entropy over unlabeled data predictions and the divergence between mean predicted distribution and uniform distribution forces the model to avoid overconfidence in incorrect pseudo-labels.
- Core assumption: The Law of Large Numbers ensures convergence of average predicted distribution to true distribution for large unlabeled sets.
- Evidence anchors:
  - [abstract] "we also provide valuable insights to enhance the understanding of our empirical risk functions and regularization techniques"
  - [section III-B-2] "minimization of D–entropy can cause the system to predict the same class for each data sample" and "this regularization can also help in the case when we have an imbalanced number of data samples from classes"
  - [corpus] Weak; corpus neighbors discuss regularization but not specifically entropy minimization in SSL.
- Break condition: If the unlabeled dataset is too small for Law of Large Numbers to apply, or if the regularization weights λu and λh are poorly tuned.

### Mechanism 3
- Claim: DER provides a lower bound for combined labeled and unlabeled ERM, ensuring theoretical consistency.
- Mechanism: By convexity of f-divergences, the divergence between joint labeled and pseudo-labeled distribution and model predictions is less than or equal to weighted sum of divergences on each subset.
- Core assumption: The f-divergence is convex in its arguments.
- Evidence anchors:
  - [abstract] "Inspired by the theoretical foundations rooted in divergences"
  - [section III-B-3] "our DER for SSL application is a lower bound for the proposed setup, D ( ˆP (Yl, ˆYu|Xl,u )∥Pθ (Y|Xl,u ) ) ≤ βD ( ˆP (Yl|Xl n)∥Pθ (Y|Xl n) ) + (1− β)D ( ˆP ( ˆYu, Xu m)∥Pθ (Y, Xu m) )"
  - [corpus] Weak; corpus neighbors discuss ERM-fDR but not the lower bound property for SSL.
- Break condition: If the divergence measure is not convex, or if the weighting β is incorrectly chosen.

## Foundational Learning

- Concept: f-divergences and α-Rényi divergences as measures of difference between probability distributions.
  - Why needed here: These divergences form the basis for the proposed empirical risk functions and regularization terms, providing robustness to noisy labels.
  - Quick check question: What are the conditions under which an f-divergence is well-defined, and how does this affect the choice of generator function f(t)?

- Concept: Semi-supervised learning and self-training algorithms.
  - Why needed here: The paper proposes new risk functions specifically for self-training methods like pseudo-labeling and entropy minimization within SSL.
  - Quick check question: How do pseudo-labeling and entropy minimization differ in their approach to leveraging unlabeled data, and what are the common pitfalls each faces?

- Concept: Convexity and metric properties of divergence measures.
  - Why needed here: Convexity ensures the lower bound property of DER, and metric properties allow for upper bounds on true risk in FSL scenarios.
  - Quick check question: Which divergences satisfy the conditions to be metrics on probability distribution space, and how does this enable bounding the true risk?

## Architecture Onboarding

- Component map:
  Data ingestion -> Model initialization -> DER computation -> Pseudo-label generation -> Training loop -> Evaluation

- Critical path:
  1. Load and preprocess labeled and unlabeled data.
  2. Initialize model and set hyperparameters (β, τp, κp, λu, λh).
  3. Warm-up: Train model on labeled data using DER.
  4. Iterative pseudo-labeling: Generate pseudo-labels, balance dataset, and retrain using combined DER.
  5. For DEM-SSL: Use soft-labels and minimize DER plus entropy regularization.
  6. Evaluate performance and tune hyperparameters.

- Design tradeoffs:
  - Choice of divergence: Different f-divergences and α-Rényi divergences offer varying levels of robustness and boundedness.
  - Uncertainty threshold τp: Higher values reduce noisy pseudo-labels but may underutilize unlabeled data.
  - Regularization weights: λu and λh balance entropy minimization and distribution alignment; poor tuning can hurt performance.
  - Balancing pseudo-labels: Improves class representation but adds computational overhead.

- Failure signatures:
  - Poor performance on CIFAR-100 or LETTER datasets.
  - Divergence measures becoming infinite due to generator function f(t) not satisfying f(0) < ∞.
  - Overfitting to incorrect pseudo-labels, indicated by high training accuracy but low test accuracy.
  - Imbalanced pseudo-labeled dataset leading to biased model predictions.

- First 3 experiments:
  1. Implement KL-ERM and TV-ERM on CIFAR-100 with n=400 labeled samples and m=49600 unlabeled samples; compare accuracy and convergence.
  2. Run DP-SSL with JS-ERM and τp=0.3 on LETTER dataset; analyze impact of lower τp on pseudo-label quality and model robustness.
  3. Implement DEM-SSL with α-Rényi divergence (α=0.6) and entropy regularization on both datasets; tune λu and λh to minimize confirmation bias.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DP-SSL and DEM-SSL algorithms change with different values of the hyperparameter τp (confidence threshold) for pseudo-label selection?
- Basis in paper: [explicit] The paper mentions that as τp decreases, more pseudo-labels are assigned to unlabeled data samples, but this may lead to noisier pseudo-labels. The paper also shows experiments with τp = 0.3 and τp = 0.7.
- Why unresolved: The paper only provides results for two specific values of τp (0.3 and 0.7) and does not explore a wider range of values to understand the full impact on algorithm performance.
- What evidence would resolve it: Additional experiments with a range of τp values (e.g., 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9) would help understand how the performance of DP-SSL and DEM-SSL changes with different levels of confidence threshold.

### Open Question 2
- Question: How does the choice of divergence measure (e.g., KL divergence, JS divergence, α-Rényi divergence) affect the performance of DP-SSL and DEM-SSL algorithms under different noise levels in pseudo-labels?
- Basis in paper: [explicit] The paper discusses the robustness of different divergences to pseudo-label noise and shows that some divergences (e.g., JS divergence, α-Rényi divergence) perform better than others under noisy pseudo-labels.
- Why unresolved: While the paper provides some insights into the robustness of different divergences, it does not conduct a comprehensive study on how the choice of divergence measure affects algorithm performance under varying noise levels.
- What evidence would resolve it: Experiments with different divergence measures under controlled noise levels in pseudo-labels would help understand the relative performance of each divergence in handling label noise.

### Open Question 3
- Question: How does the performance of DP-SSL and DEM-SSL algorithms compare to other state-of-the-art semi-supervised learning methods, such as FixMatch, MixMatch, and Meta pseudo-label?
- Basis in paper: [explicit] The paper mentions these methods in the conclusion section as potential future works for combining with the proposed framework.
- Why unresolved: The paper does not provide a direct comparison between the proposed algorithms and other state-of-the-art methods, leaving the question of their relative performance open.
- What evidence would resolve it: Experiments comparing the performance of DP-SSL and DEM-SSL with other semi-supervised learning methods on benchmark datasets would help understand their strengths and weaknesses relative to existing approaches.

## Limitations
- The paper's claims about robustness to noisy pseudo-labels and improved performance in imbalanced datasets are supported by theoretical bounds but lack extensive empirical validation across diverse SSL scenarios.
- The choice of generator function f(t) critically affects divergence behavior, yet the paper provides limited guidance on selecting f(t) for different applications.
- The experimental results, while showing improvements on CIFAR-100 and LETTER datasets, are based on a limited set of divergences and may not generalize to other SSL tasks or domains.

## Confidence
- **High Confidence**: The theoretical foundations connecting f-divergences and α-Rényi divergences to SSL empirical risk functions are well-established and mathematically sound.
- **Medium Confidence**: The proposed DER-based methods demonstrate robustness to pseudo-label noise in controlled experiments, but real-world applicability may vary with noise levels and data characteristics.
- **Low Confidence**: The claim that entropy regularization alone can effectively address class imbalance in pseudo-labels without additional balancing mechanisms is not well-supported by the evidence provided.

## Next Checks
1. **Divergence Selection Study**: Systematically evaluate a broader range of f-divergences and α-Rényi divergences on multiple SSL datasets to identify which measures offer the best robustness to different levels of pseudo-label noise.

2. **Noise Robustness Analysis**: Design experiments with controlled levels of label noise in both labeled and pseudo-labeled data to quantify the limits of DER-based methods' robustness and identify failure thresholds.

3. **Class Imbalance Stress Test**: Generate highly imbalanced labeled and unlabeled datasets across multiple domains to assess whether entropy regularization alone can mitigate confirmation bias, or if explicit balancing mechanisms are necessary.