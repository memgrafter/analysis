---
ver: rpa2
title: 'Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management,
  and Generation'
arxiv_id: '2408.02417'
source_url: https://arxiv.org/abs/2408.02417
tags:
- user
- system
- emotion
- dialogue
- operator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper extends the EmoWOZ dataset with system affective behaviour
  labels (EmoWOZ 2.0), creating the first large-scale corpus for studying system conduct
  in task-oriented dialogues. It then builds modular and end-to-end dialogue systems
  that incorporate emotion throughout the pipeline: understanding (user emotion recognition),
  management (emotion-aware policy with reinforcement learning), and generation (emotion-conditioned
  natural language generation).'
---

# Infusing Emotions into Task-oriented Dialogue Systems: Understanding, Management, and Generation

## Quick Facts
- arXiv ID: 2408.02417
- Source URL: https://arxiv.org/abs/2408.02417
- Authors: Shutong Feng; Hsien-chin Lin; Christian Geishauser; Nurul Lubis; Carel van Niekerk; Michael Heck; Benjamin Ruppik; Renato Vukovic; Milica Gašić
- Reference count: 29
- Key outcome: This paper extends the EmoWOZ dataset with system affective behaviour labels (EmoWOZ 2.0), creating the first large-scale corpus for studying system conduct in task-oriented dialogues. It then builds modular and end-to-end dialogue systems that incorporate emotion throughout the pipeline: understanding (user emotion recognition), management (emotion-aware policy with reinforcement learning), and generation (emotion-conditioned natural language generation). Through interactive evaluations with both simulated and human users, the proposed systems significantly improve user sentiment and task success compared to non-emotional baselines, demonstrating the importance of modeling emotions in task-oriented dialogue systems.

## Executive Summary
This work introduces a comprehensive framework for infusing emotions into task-oriented dialogue systems across three critical pipeline stages: understanding, management, and generation. The authors create EmoWOZ 2.0, an extended version of the EmoWOZ dataset with system affective behavior labels, enabling the study of system conduct in task-oriented dialogues. They propose modular and end-to-end architectures that leverage emotion recognition, emotion-aware reinforcement learning policies, and emotion-conditioned natural language generation. Through interactive evaluations with both simulated and human users, the emotion-aware systems demonstrate significant improvements in user sentiment and task success compared to non-emotional baselines, validating the importance of emotional modeling in task-oriented dialogue systems.

## Method Summary
The proposed framework consists of three main components: emotion understanding using ContextBERT-ERToD for user emotion recognition combined with SetSUMBT for dialogue state tracking; emotion management using EmoDDPT, a reinforcement learning policy that incorporates emotion-based rewards and conducts; and emotion generation using SEC-BART, a BART-based model conditioned on both semantic actions and system conduct. The EmoWOZ 2.0 dataset provides the necessary labels for training these components. The modular system (EmoLoop) is trained separately on each component, while the end-to-end system (EmoLLAMA) uses a LLaMA-2-7B backbone. Both systems are evaluated interactively using the langEmoUS user simulator and human trials, measuring task success and user sentiment.

## Key Results
- The modular emotion-aware system (EmoLoop) significantly improves both user sentiment and task success compared to non-emotional baselines in interactive evaluation
- Emotion-aware end-to-end system (EmoLLAMA) shows promise but underperforms the modular system, likely due to computational constraints preventing reinforcement learning training
- The EmoWOZ 2.0 dataset successfully enables training of emotion-aware components across the complete dialogue pipeline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating user emotion into the dialogue state improves task success by enabling more context-aware decision-making.
- Mechanism: The system uses ContextBERT-ERToD to recognize user emotions and appends this to the dialogue state alongside task-related slots, allowing the policy to consider emotional context when selecting actions.
- Core assumption: User emotion correlates with task success and can be reliably recognized in task-oriented dialogue.
- Evidence anchors:
  - [abstract] "we demonstrate that our proposed framework significantly enhances the user's emotional experience as well as the task success."
  - [section 4.1] "Feng et al. (2022) showed that multitask training a DST model for emotion recognition simultaneously improves its joint goal accuracy, suggesting the complementarity between DST and emotion recognition in conversation"
  - [corpus] The EmoWOZ 2.0 dataset provides labeled user emotions for training the recognition model.
- Break condition: If emotion recognition accuracy drops significantly or if emotional states become too ambiguous to map to actionable policy decisions.

### Mechanism 2
- Claim: Emotion-augmented rewards in reinforcement learning lead to more satisfying interactions and improved task completion.
- Mechanism: The dialogue policy receives additional reward signals based on user sentiment (positive emotions get positive reward, negative get negative), encouraging the policy to generate responses that both complete tasks and improve user sentiment.
- Core assumption: User sentiment can be mapped to a numerical reward scale that meaningfully guides policy learning.
- Evidence anchors:
  - [abstract] "we show through interactive evaluation that emotion in the ToD loop can enhance user's emotional experience as well as the task success"
  - [section 4.2] "we define c(satisfied) = 1, c(dissatisfied) = c(abusive) = −1, c(neutral) = 0" and "we shift β · c(e) such that it is at most 0 by defining the emotion reward for an emotion e as remo(e) = β · c(e) − β"
  - [corpus] User sentiment labels in EmoWOZ 2.0 enable training of sentiment-based reward functions.
- Break condition: If the reward shaping leads to policies that optimize for sentiment at the expense of task completion, or if the sentiment-to-reward mapping becomes too noisy.

### Mechanism 3
- Claim: Conditioning natural language generation on system conduct produces more emotionally appropriate responses that improve user satisfaction.
- Mechanism: The SEC-BART NLG model generates responses conditioned on both semantic actions and the predicted system conduct (e.g., apologetic, enthusiastic), allowing for more nuanced emotional expression.
- Core assumption: System conduct can be reliably predicted and effectively incorporated into response generation to improve perceived empathy.
- Evidence anchors:
  - [abstract] "we additionally condition the natural language generation on the system conduct to generate more diverse and emotion-aware responses"
  - [section 4.3] "Our model input consists of the user utterance, system semantic actions, and the system conduct" and "SEC-BART: a both semantically and emotionally conditioned BART"
  - [corpus] EmoWOZ 2.0 provides system conduct labels for training the NLG model.
- Break condition: If the conduct-conditioned generation produces unnatural or inappropriate responses, or if the conduct prediction becomes unreliable.

## Foundational Learning

- Concept: Reinforcement Learning with Reward Shaping
  - Why needed here: The dialogue policy needs to learn optimal behavior through interaction, and emotion-based reward shaping helps balance task success with user satisfaction.
  - Quick check question: How does the emotion reward (β · c(e) − β) prevent the policy from generating unnecessarily long dialogues just to accumulate positive sentiment?

- Concept: Multitask Learning for Dialogue Understanding
  - Why needed here: Jointly training emotion recognition with dialogue state tracking improves both tasks by leveraging their complementary information.
  - Quick check question: What evidence from the paper supports the claim that multitask training improves both emotion recognition and dialogue state tracking performance?

- Concept: Conditional Text Generation
  - Why needed here: The NLG model must generate responses that are both semantically correct and emotionally appropriate, requiring conditioning on both dialogue actions and system conduct.
  - Quick check question: How does SEC-BART differ architecturally from a standard BART model in terms of input conditioning?

## Architecture Onboarding

- Component map: User utterance → ContextBERT-ERToD (emotion recognition) + SetSUMBT (DST) → EmoDDPT policy (action selection + conduct prediction) → SEC-BART NLG (response generation) → User → langEmoUS (feedback)
- Critical path: Understanding (emotion + state) → Management (policy with emotion reward) → Generation (emotion-conditioned responses)
- Design tradeoffs: Modular system allows flexibility in component selection but introduces potential error accumulation; end-to-end system is more efficient but harder to debug and optimize.
- Failure signatures:
  - Poor emotion recognition → inappropriate conduct selection
  - Misaligned conduct prediction → emotionally inappropriate responses
  - Reward shaping issues → policies that prioritize sentiment over task completion
- First 3 experiments:
  1. Test ContextBERT-ERToD emotion recognition accuracy on held-out EmoWOZ data
  2. Evaluate EmoDDPT policy performance with and without emotion reward on a simplified user simulator
  3. Compare SEC-BART response quality with and without conduct conditioning using human evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of emotion-aware end-to-end ToD systems compare to modular systems when both are trained with reinforcement learning?
- Basis in paper: [inferred] The paper mentions that LLM-based end-to-end systems were not trained with RL due to computational constraints, and suggests this as a future research direction.
- Why unresolved: The paper only provides interactive evaluation results for the SL-trained end-to-end system (EmoLLAMA), which underperforms compared to the RL-trained modular system (EmoLoop). It does not explore the potential of RL training for end-to-end systems.
- What evidence would resolve it: Interactive evaluation results comparing an RL-trained end-to-end system to the RL-trained modular system (EmoLoop) in terms of task success and user sentiment.

### Open Question 2
- Question: What is the impact of different reward formulations on the emotional behavior of the dialogue policy during RL training?
- Basis in paper: [explicit] The paper uses a linear reward formulation combining task success and emotion-based rewards, but mentions the possibility of utilizing the full set of user emotion labels for diverse reward signals.
- Why unresolved: The paper only explores one specific reward formulation (linear combination of task and emotion rewards). It does not investigate alternative reward structures or their effects on policy behavior.
- What evidence would resolve it: Comparative analysis of different reward formulations (e.g., non-linear combinations, separate reward channels) and their impact on task success, user sentiment, and the distribution of system conducts generated by the policy.

### Open Question 3
- Question: How does the diversity and quality of system conducts generated by the policy change with varying levels of emotional reward weight (β)?
- Basis in paper: [explicit] The paper sets β = 2 for the emotion reward weight in RL training, but does not explore the impact of different β values on system behavior.
- Why unresolved: The paper uses a fixed β value without investigating how different weights affect the policy's emotional behavior and the diversity of generated system conducts.
- What evidence would resolve it: Analysis of system conduct distributions and quality metrics (e.g., diversity, appropriateness) for different β values during RL training and interactive evaluation.

## Limitations
- The effectiveness of the framework depends on the quality and coverage of the EmoWOZ 2.0 dataset, which is limited to the restaurant reservation domain
- The emotion-to-reward mapping is a simplification that may not capture the complex relationship between user emotions and task outcomes
- The end-to-end approach using LLaMA-2-7B shows promise but requires significant computational resources, limiting its practicality for some deployment scenarios

## Confidence
- **High Confidence**: The modular architecture design and the overall framework structure are well-established and technically sound
- **Medium Confidence**: The improvements in user sentiment and task success are demonstrated through interactive evaluations, though the sample sizes and evaluation protocols could be more robust
- **Medium Confidence**: The emotion-augmented reward mechanism effectively balances task completion with user satisfaction, though the reward shaping approach may require domain-specific tuning

## Next Checks
1. Conduct ablation studies to quantify the individual contributions of each emotion-aware component (understanding, management, generation) to overall system performance
2. Evaluate system performance across multiple domains beyond restaurant reservations to assess generalizability
3. Perform user studies with diverse demographic groups to validate that emotion-aware responses are perceived as appropriate and helpful across different cultural contexts