---
ver: rpa2
title: 'If You Don''t Understand It, Don''t Use It: Eliminating Trojans with Filters
  Between Layers'
arxiv_id: '2407.06411'
source_url: https://arxiv.org/abs/2407.06411
tags:
- lora
- ablate
- post
- zero
- randn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for removing trojans injected during
  LLM pre-training by inserting LoRA-based activation filters at various layers and
  hook points. The approach trains these filters on clean data while keeping the base
  model frozen, aiming to block trojan-related activations without harming general
  performance.
---

# If You Don't Understand It, Don't Use It: Eliminating Trojans with Filters Between Layers

## Quick Facts
- arXiv ID: 2407.06411
- Source URL: https://arxiv.org/abs/2407.06411
- Authors: Adriano Hernandez
- Reference count: 40
- Primary result: LoRA-based activation filters can remove trojan behaviors from LLMs when placed at later layers

## Executive Summary
This paper addresses the challenge of removing trojan behaviors injected during LLM pre-training. The proposed solution involves inserting LoRA-based activation filters at various layers and hook points within the model architecture. These filters are trained on clean data while keeping the base model frozen, with the goal of blocking trojan-related activations without harming general performance. Experiments on GPT-2 small demonstrate that trojan removal is most effective when filters are placed in later layers, particularly at residual stream hook points.

## Method Summary
The method introduces LoRA-based activation filters that intercept and modify model activations at specific hook points (residual stream, attention QKV, MLP) across different layers. These filters are trained on clean data while the base model remains frozen, optimizing for next-word prediction loss. The approach aims to block trojan-related activations by filtering out trojan-specific patterns while preserving normal model behavior. Multiple filter configurations are tested to determine optimal placement for trojan removal effectiveness.

## Key Results
- Trojan removal is most effective when filters are placed in later layers, particularly at residual stream hook points
- LoRA filters consistently outperform zero ablation and random noise baselines
- Some trojans persist or cause chaotic completions even after filtering, indicating distributed trojan information across the network
- Filter placement is critical - effectiveness varies significantly based on layer position and hook point type

## Why This Works (Mechanism)
The effectiveness stems from the LoRA filters' ability to learn and block trojan-specific activation patterns while preserving normal model behavior. The filters act as learned transformations that can cancel out trojan-related information in the activation space. Later layers appear more effective because trojan information becomes more concentrated as it propagates through the network. The LoRA parameterization allows efficient adaptation without full fine-tuning, making the approach practical for large models.

## Foundational Learning
- **Trojan injection**: Understanding how malicious behaviors are embedded during training is crucial for developing effective removal techniques
  - Why needed: To know what patterns to target for removal
  - Quick check: Verify trojan triggers produce intended followups before applying filters

- **Activation space manipulation**: The approach relies on modifying model activations rather than weights
  - Why needed: Allows targeted intervention without disrupting base model functionality
  - Quick check: Compare activations with/without filters for trojan vs clean inputs

- **LoRA adaptation**: Low-rank adaptation provides an efficient way to learn filter transformations
  - Why needed: Enables practical implementation without full fine-tuning costs
  - Quick check: Verify LoRA parameters are learning meaningful patterns

- **Distributed representations**: Trojan information spreads across multiple network components
  - Why needed: Explains why single-point interventions may be insufficient
  - Quick check: Test filter effectiveness at different network locations

## Architecture Onboarding
- **Component map**: Input -> Residual Stream Hook -> Attention QKV Hook -> MLP Hook -> Output
- **Critical path**: Trojan trigger -> activation propagation -> filter intervention -> modified completion
- **Design tradeoffs**: Layer position vs hook point selection; filter complexity vs computational cost
- **Failure signatures**: Persistent trojan behavior; degraded general performance; chaotic completions
- **First experiments**: 1) Verify trojan injection success, 2) Test filter at different layers, 3) Compare filter types (residual vs attention vs MLP)

## Open Questions the Paper Calls Out
- **Mechanism question**: What is the precise mechanism by which LoRA filters outperform zero ablation for trojan removal? The paper speculates about "negative interference" but lacks empirical evidence.
- **Injection variability**: Why do certain trojan triggers (Alpha, Beta, Delta) get injected more effectively than others (Enter, Charlie)? The paper observes this pattern but doesn't investigate underlying causes.
- **Information distribution**: How does the distribution of trojan information across the network affect the effectiveness of filter placement? The paper suggests distribution matters but doesn't explore optimal placement strategies.

## Limitations
- Trojan injection methodology is only partially specified, making exact reproduction challenging
- Experimental scope limited to GPT-2 small with five specific trojan triggers
- Some trojans persist or cause chaotic completions even after filtering
- Results may not generalize to larger models or different trojan types

## Confidence
- **High confidence**: Trojan information is distributed across network layers, making filter placement critical for success
- **Medium confidence**: LoRA-based activation filters can remove some trojans without degrading general performance when properly placed
- **Low confidence**: The approach can completely eliminate all trojan behaviors across diverse trojan types and model scales

## Next Checks
1. **Trojan injection verification**: Before applying filters, verify that trojan triggers produce their intended followups in the injected model to ensure proper baseline behavior

2. **Filter placement ablation**: Systematically test filter placement at all hook points (residual stream, attention QKV, MLP) across multiple layers to confirm the observed pattern that later layers are more effective

3. **Generalization testing**: Apply the method to a different model architecture (e.g., LLaMA or Mistral) with distinct trojan triggers to assess scalability and robustness beyond GPT-2 small