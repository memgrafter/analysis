---
ver: rpa2
title: 'Investigating Sensitive Directions in GPT-2: An Improved Baseline and Comparative
  Analysis of SAEs'
arxiv_id: '2410.12555'
source_url: https://arxiv.org/abs/2410.12555
tags:
- directions
- saes
- activation
- perturbation
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of understanding computational
  features in language models through sensitive directions analysis, which measures
  how much next-token prediction probabilities change when perturbing activations
  along specific directions. The authors introduce an improved baseline for perturbation
  directions by using differences between two randomly generated or real activations
  (cov-random mixture and real mixture), avoiding the problematic inclusion of the
  negative original activation present in previous methods.
---

# Investigating Sensitive Directions in GPT-2: An Improved Baseline and Comparative Analysis of SAEs

## Quick Facts
- arXiv ID: 2410.12555
- Source URL: https://arxiv.org/abs/2410.12555
- Authors: Daniel J. Lee; Stefan Heimersheim
- Reference count: 12
- Key outcome: SAE reconstruction errors no longer appear pathologically high when compared to improved mixture baselines, addressing a previous puzzle in the interpretability community

## Executive Summary
This paper addresses the challenge of understanding computational features in language models through sensitive directions analysis, which measures how much next-token prediction probabilities change when perturbing activations along specific directions. The authors introduce an improved baseline for perturbation directions by using differences between two randomly generated or real activations (cov-random mixture and real mixture), avoiding the problematic inclusion of the negative original activation present in previous methods. They demonstrate that SAE reconstruction errors no longer appear pathologically high when compared to this improved baseline, addressing a previous puzzle in the interpretability community. The experiments reveal that SAE feature directions have varying impacts on model outputs depending on sparsity (L0), with lower L0 features exerting greater influence. Additionally, they find that end-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs, contrary to expectations.

## Method Summary
The paper analyzes sensitive directions in GPT-2 by measuring how next-token prediction probabilities change when perturbing activations along specific directions. Using ~2 million tokens from OpenWebText, they extract Layer 6 resid_pre activations from GPT-2 Small and apply perturbations at varying lengths (0-101) along different direction types: isotropic random, cov-random mixture, real mixture, SAE reconstruction errors, and SAE feature directions. KL divergence between original and perturbed predictions serves as the primary sensitivity metric, with mean KL divergence across all tokens used for comparison. The key methodological contribution is the introduction of cov-random mixture and real mixture baselines that avoid the negative original activation present in previous difference baselines.

## Key Results
- SAE reconstruction errors no longer appear pathologically high when compared to improved mixture baselines
- Lower L0 SAE features exert greater influence on model outputs than higher L0 features
- End-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using mixture baselines (cov-random mixture and real mixture) provides fairer comparisons for SAE features than difference baselines because mixture directions don't include the negative original activation.
- Mechanism: When perturbation directions include the negative of the original activation (-xbase), they create artificially large effects on model outputs. By using differences between two random activations (mixture), the analysis isolates the effect of the direction itself rather than the subtraction of the original activation.
- Core assumption: The presence of -xbase in difference directions artificially inflates KL divergence measurements, making them poor baselines for comparing with SAE feature directions.
- Evidence anchors: [abstract]: "We propose an improved baseline direction (called cov-random mixture) which does not use the original activation."

### Mechanism 2
- Claim: Lower L0 SAE features exert greater influence on model outputs than higher L0 features.
- Mechanism: Sparser features (lower L0) are more selective and correspond to more specific, functionally important directions in activation space. When these directions are perturbed, they cause larger changes in model predictions.
- Core assumption: L0 directly correlates with feature selectivity and functional importance.
- Evidence anchors: [abstract]: "we also show that feature directions uncovered by SAEs have varying impacts on model outputs depending on the SAE's sparsity, with lowerL0 SAE feature directions exerting a greater influence."

### Mechanism 3
- Claim: End-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs.
- Mechanism: End-to-end SAEs optimize for KL divergence between original and reconstructed logits, which may lead to features that are more isotropic and less aligned with functionally important directions in the network.
- Core assumption: Optimizing for KL divergence produces features that don't necessarily correspond to the most functionally important directions.
- Evidence anchors: [abstract]: "we find that end-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs."

## Foundational Learning

- Concept: Linear Representation Hypothesis (LRH)
  - Why needed here: The paper assumes activations can be represented as linear combinations of features, which underlies the mixture baseline construction and interpretation of SAE features.
  - Quick check question: If activation x can be written as b + Î£fi(x)di under LRH, what would x1 - x2 equal?

- Concept: Sparse Autoencoders (SAEs)
  - Why needed here: SAEs are the primary tool being evaluated for extracting interpretable features from language model activations.
  - Quick check question: What distinguishes traditional SAEs from end-to-end SAEs in terms of their training objectives?

- Concept: KL divergence as sensitivity measure
  - Why needed here: The paper uses KL divergence between original and perturbed predictions to quantify how sensitive model outputs are to activation perturbations.
  - Quick check question: Why might KL divergence be preferred over other metrics like L2 distance for measuring changes in probability distributions?

## Architecture Onboarding

- Component map: GPT-2-small model -> Layer 6 resid_pre activations -> Perturbation system -> KL divergence calculation -> Sensitivity analysis
- Critical path: 1. Extract activations from Layer 6 resid_pre, 2. Generate perturbation directions (SAE features, baselines, errors), 3. Apply perturbations at varying lengths, 4. Measure KL divergence of next-token predictions, 5. Compare sensitivity across different direction types and L0 values
- Design tradeoffs: Using mean KL across tokens vs. examining individual curve shapes, choosing perturbation length range (0-101) vs. different ranges, comparing SAEs at same L0 vs. normalizing for reconstruction quality, using Layer 6 vs. other layers for analysis
- Failure signatures: If mixture baselines don't provide consistent reference points across layers, if SAE features show no correlation with L0 values, if end-to-end SAEs unexpectedly outperform traditional SAEs, if KL divergence measurements are dominated by noise rather than signal
- First 3 experiments: 1. Replicate the comparison between difference and mixture baselines using a small subset of activations to verify the basic mechanism, 2. Test whether L0 correlation with feature importance holds across multiple layers, not just Layer 6, 3. Compare end-to-end SAE performance when using alternative objectives beyond KL divergence minimization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do e2e SAE features exhibit lower influence on model outputs compared to traditional SAE features despite being trained to minimize KL divergence?
- Basis in paper: [explicit] The paper states "End-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs" and notes this was "initially surprising."
- Why unresolved: The authors propose isotropy as a potential explanation but acknowledge uncertainty about whether e2e+ds SAEs share this property.
- What evidence would resolve it: Direct measurement of feature vector isotropy across SAE types, or ablation studies showing whether reducing isotropy increases e2e SAE feature influence.

### Open Question 2
- Question: How do SAE reconstruction errors produce such large KL divergences compared to other perturbations?
- Basis in paper: [explicit] The paper notes "SAE-reconstructed activation vectors also alter the model output much more than random perturbations" and describes this as a "pathological behavior."
- Why unresolved: While the improved baseline reduces the KL divergence gap, the paper acknowledges "questions remain about the dependence observed across different layers."
- What evidence would resolve it: Systematic analysis of how SAE reconstruction error directions differ from mixture baselines in terms of their distribution and impact on model internals.

### Open Question 3
- Question: Why do lower L0 SAE features exert greater influence on model outputs than higher L0 features?
- Basis in paper: [explicit] The paper states "lower L0 SAE feature directions have a greater impact on the model output than higher L0 SAE feature directions."
- Why unresolved: The authors don't provide an explanation for this relationship between sparsity and feature importance.
- What evidence would resolve it: Analysis of feature co-occurrence patterns or feature importance across different L0 thresholds to understand what makes lower L0 features more influential.

## Limitations

- Baseline Validity: While the cov-random mixture and real mixture baselines represent improvements over previous difference baselines, there remain concerns about their completeness as reference points due to residual negative components.
- Layer-Specificity: All experiments focus exclusively on Layer 6 resid_pre activations in GPT-2 Small, limiting generalizability to other layers or model architectures.
- Metric Sensitivity: The use of mean KL divergence across all perturbation lengths provides a coarse summary that may obscure important nonlinear effects.

## Confidence

**High Confidence**:
- The improved mixture baselines (cov-random mixture and real mixture) provide fairer comparisons than difference baselines for SAE feature sensitivity analysis.
- Lower L0 SAE features exert greater influence on model outputs than higher L0 features.

**Medium Confidence**:
- End-to-end SAE features do not exhibit stronger effects on model outputs compared to traditional SAEs.

**Low Confidence**:
- The mixture baselines are complete and unbiased reference points for all sensitivity analyses.
- L0 is the primary determinant of feature functional importance.

## Next Checks

1. **Layer Generalization Test**: Replicate the L0-feature importance correlation analysis across all residual layers (Layers 0-11) in GPT-2 Small to reveal whether the observed relationship is specific to Layer 6 or represents a general principle.

2. **Baseline Residual Analysis**: Quantify the exact contribution of residual negative components in mixture baselines by systematically varying the mixing proportions between random and real activations to provide a more precise understanding of baseline completeness.

3. **End-to-End SAE Replication**: Train end-to-end SAEs on the same dataset and with matching reconstruction quality to the traditional SAEs used in the experiments to isolate architectural differences from training methodology effects.