---
ver: rpa2
title: Learning Efficient Recursive Numeral Systems via Reinforcement Learning
arxiv_id: '2409.07170'
source_url: https://arxiv.org/abs/2409.07170
tags:
- systems
- numeral
- languages
- recursive
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses how efficient recursive numeral systems, such
  as those in English, could emerge via a simple learning mechanism. It proposes a
  two-agent reinforcement learning framework where agents learn to communicate numerical
  concepts using a modified version of Hurford's meta-grammar.
---

# Learning Efficient Recursive Numeral Systems via Reinforcement Learning

## Quick Facts
- arXiv ID: 2409.07170
- Source URL: https://arxiv.org/abs/2409.07170
- Authors: Andrea Silvi; Jonathan Thomas; Emil Carlsson; Devdatt Dubhashi; Moa Johansson
- Reference count: 9
- Primary result: RL agents evolve numeral systems close to Pareto-optimal configurations balancing lexicon size and morphosyntactic complexity

## Executive Summary
This work demonstrates how efficient recursive numeral systems, like those in human languages, can emerge through a simple learning mechanism. Using a two-agent reinforcement learning framework, agents learn to communicate numerical concepts via a modified Hurford meta-grammar, optimizing for efficient communication. The agents iteratively modify their lexicon to balance morphosyntactic complexity and lexicon size, converging toward Pareto-optimal configurations. Results show the evolved languages consistently align with human language patterns, having smaller lexicon sizes and lower average morphosyntactic complexity.

## Method Summary
The method employs a two-agent signaling game where RL agents communicate numerical concepts using a modified Hurford meta-grammar. The grammar includes digits (D) and multipliers (M) and is optimized for efficient communication through sparse rewards (exact matches only). Agents use LSTMs to encode and decode symbolic numeral expressions, with a bandit-based strategy for grammar modification. The speaker iteratively refines its grammar by modifying digit and multiplier sets to minimize average morphosyntactic complexity while keeping lexicon size small. The approach uses REINFORCE with entropy regularization and pre-trains on minimal expression sets before iterative grammar modification.

## Key Results
- RL agents consistently evolve numeral systems close to the Pareto frontier
- Final languages exhibit smaller lexicon sizes and lower average morphosyntactic complexity
- Evolved systems align with human language patterns in balancing efficiency tradeoffs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Efficient recursive numeral systems emerge through pressure for efficient communication in a two-agent RL signaling game.
- Mechanism: Agents iteratively refine their grammar by modifying digit and multiplier sets to minimize average morphosyntactic complexity while keeping lexicon size small, driven by sparse exact-match rewards.
- Core assumption: Agents can represent numerals as variable-length symbolic expressions and communicate them neurally via LSTMs.
- Evidence anchors: Abstract states agents can effectively modify their lexicon towards Pareto-optimal configurations; section confirms RL agents shaped by communication pressures achieve comparable configurations to human numeral systems.
- Break condition: If RL reward signal is too sparse, agents fail to learn efficient grammars.

### Mechanism 2
- Claim: A modified Hurford meta-grammar with single multiplier per phrase enables smoother optimization toward human-like systems.
- Mechanism: The modified grammar (Num = D | Phrase | Phrase + Num | Phrase − Num; Phrase = Num * M) forces agents to represent numbers with fewer multipliers, aligning better with human numeral systems and reducing search space.
- Core assumption: Limiting multipliers in the meta-grammar makes the grammar search space more tractable and results in more natural languages.
- Evidence anchors: Section states modified grammar captures that multipliers ought to have higher costs than digits; results show optimal languages contain a single multiplier, matching human language patterns.
- Break condition: If modified grammar is too restrictive, it may prevent discovery of more efficient numeral systems.

### Mechanism 3
- Claim: A bandit-based grammar modification strategy balances exploration and exploitation during RL learning.
- Mechanism: The speaker uses an ε-greedy algorithm to choose between current and alternative grammars, updating Q-values based on communication success, thus guiding grammar evolution toward more efficient configurations.
- Core assumption: Q-learning over grammars can effectively steer agents toward Pareto-optimal languages without exhaustive search.
- Evidence anchors: Section describes employing a bandit algorithm where two number systems correspond to bandit arms; Q-value is updated at each communication step with rewards collected.
- Break condition: If exploration rate ε is too low, agents may get stuck in suboptimal grammars.

## Foundational Learning

- Concept: Reinforcement learning signaling games
  - Why needed here: Two-agent setup with sparse rewards drives emergent language evolution under communication pressure.
  - Quick check question: In a signaling game, what determines the agent's reward?

- Concept: Pareto efficiency in language design
  - Why needed here: Agents balance lexicon size and morphosyntactic complexity, converging to Pareto-optimal configurations.
  - Quick check question: What does it mean for a numeral system to be Pareto-optimal?

- Concept: Meta-grammar for recursive numeral systems
  - Why needed here: Provides the symbolic structure agents manipulate to represent arbitrary numbers efficiently.
  - Quick check question: How does the Hurford meta-grammar represent numbers like 123?

## Architecture Onboarding

- Component map:
  - Speaker LSTM -> encodes symbolic numeral expressions into variable-length neural messages
  - Listener LSTM -> decodes neural messages back into numeral predictions
  - Grammar state -> maintains current (D, M) pairs and supports mutation operations
  - Bandit controller -> selects between current and alternative grammars based on Q-values
  - Reward module -> provides sparse exact-match feedback for correct numeral predictions

- Critical path:
  1. Sample numeral n from need distribution
  2. Generate minimal expression Lmin,n using current (D, M)
  3. Speaker encodes expression → neural message
  4. Listener decodes message → numeral prediction
  5. Reward given only if prediction matches n exactly
  6. Q-value updated for chosen grammar
  7. After communication phase, speaker may mutate grammar
  8. Repeat until convergence

- Design tradeoffs:
  - Sparse vs. dense rewards: sparse rewards make learning harder but more realistic for exact numeral systems
  - Grammar mutation rate: too frequent mutations prevent learning; too rare slow convergence
  - Need distribution shape: exponential vs. power-law affects which numerals get emphasized

- Failure signatures:
  - Q-values never diverge → exploration too low or reward too sparse
  - Lexicon size grows unbounded → grammar modification not penalizing complexity
  - Agents fail to converge → LSTM capacity too small or batch size too low

- First 3 experiments:
  1. Verify grammar representation: check that given (D, M), the system correctly generates minimal expressions for 1–50
  2. Test sparse reward learning: train agents on a fixed grammar and confirm they learn exact numeral matching
  3. Validate bandit grammar selection: run grammar mutation without RL and ensure Q-values reflect communication success

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would different need distributions (e.g., exponential vs. power-law) affect the efficiency of emergent recursive numeral systems in terms of lexicon size and morphosyntactic complexity?
- Basis in paper: [explicit] Paper mentions adopting exponential need distribution results in larger numbers becoming very rare, suggesting exploring how different distributions affect efficiency.
- Why unresolved: Current experiments use power-law distribution P(n) ∝ n^-2, but impact of alternative distributions on Pareto frontier and final language structures remains unexplored.
- What evidence would resolve it: Systematic experiments comparing Pareto frontiers and final languages under different need distributions would show how distribution choice shapes efficiency tradeoffs.

### Open Question 2
- Question: Can the proposed neuro-symbolic framework be extended to demonstrate transitions between approximate, exact restricted, and recursive numeral systems through communication and iterated learning?
- Basis in paper: [explicit] Conclusion states interest in creating a unifying framework to show how different numeral system types might emerge from the same system and transition between them.
- Why unresolved: Current work focuses solely on recursive systems; mechanisms for transitions between system types and their emergence from common framework are not yet developed.
- What evidence would resolve it: A unified model demonstrating emergence and transitions between numeral system types via communication and iterated learning would address this.

### Open Question 3
- Question: How does the sparsity of rewards in the exact reward structure affect the learning dynamics and final efficiency of recursive numeral systems compared to proximity-based rewards used for simpler systems?
- Basis in paper: [explicit] Paper notes exact reward structure makes RL problem harder due to sparser rewards and mentions adapting larger LSTMs and batch sizes to handle this.
- Why unresolved: While paper adapts architecture to handle sparse rewards, specific effects on learning speed, convergence, and final language efficiency are not analyzed.
- What evidence would resolve it: Comparative experiments measuring learning curves, convergence rates, and final language efficiency under exact vs. proximity-based rewards would clarify impact of reward structure sparsity.

## Limitations
- Sparse reward signals and bandit-based exploration may lead to suboptimal convergence in practice
- Meta-grammar modification only justified by human language patterns without strong corpus validation
- Simulation covers limited numeral range (1-50) and may not generalize to larger number systems

## Confidence
- **High Confidence**: RL signaling game framework and Pareto efficiency analysis are well-established concepts with reasonable empirical support
- **Medium Confidence**: Modified Hurford meta-grammar and bandit-based grammar optimization strategy are theoretically sound but lack strong external validation
- **Low Confidence**: Claim that this mechanism explains human numeral system emergence is speculative without broader linguistic validation

## Next Checks
1. Expand numeral range: Run experiments covering 1-1000 to verify that Pareto-optimal configurations scale beyond the current 1-50 range
2. Cross-linguistic validation: Compare evolved grammars against a broader typological database of human numeral systems to assess alignment beyond anecdotal patterns
3. Reward density ablation: Test alternative reward structures (partial credit for close predictions) to determine if sparse rewards are necessary for observed results or if they hinder learning