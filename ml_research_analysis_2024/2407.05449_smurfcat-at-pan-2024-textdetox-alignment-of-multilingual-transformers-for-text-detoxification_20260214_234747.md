---
ver: rpa2
title: 'SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for
  Text Detoxification'
arxiv_id: '2407.05449'
source_url: https://arxiv.org/abs/2407.05449
tags:
- multilingual
- text
- cation
- were
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses multilingual text detoxification by augmenting
  low-resource datasets through machine translation and filtering. The authors fine-tuned
  mT0 and Aya sequence-to-sequence models using the expanded dataset, then applied
  ORPO alignment to enhance detox performance.
---

# SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification

## Quick Facts
- arXiv ID: 2407.05449
- Source URL: https://arxiv.org/abs/2407.05449
- Reference count: 10
- 3.7B parameter mT0-XL-ORPO model achieved state-of-the-art results for Ukrainian and near state-of-the-art results for other languages

## Executive Summary
This work addresses multilingual text detoxification by augmenting low-resource datasets through machine translation and filtering. The authors fine-tuned mT0 and Aya sequence-to-sequence models using the expanded dataset, then applied ORPO alignment to enhance detox performance. Their 3.7B parameter mT0-XL-ORPO model achieved state-of-the-art results for Ukrainian and near state-of-the-art results for other languages, ranking first in automatic evaluation (0.52) and second in human evaluation (0.74). The method demonstrates that relatively small multilingual models can outperform larger ones when combined with targeted fine-tuning and preference optimization.

## Method Summary
The approach combines data augmentation through machine translation, careful filtering of translated data, and two-stage fine-tuning with ORPO alignment. The authors expanded the low-resource ParaDetox dataset by translating English data to 8 additional languages using GoogleTranslator, then filtered the augmented data using LaBSE similarity (threshold >0.8) and XLM-R toxicity classification (toxic >0.9, neutral <0.1). They fine-tuned mT0-XL and Aya models on the filtered data, generated diverse beam search hypotheses, selected candidates based on relevance scoring (similarity × toxicity), and applied ORPO alignment to create preference pairs. The 3.7B parameter mT0-XL-ORPO model achieved the best overall performance.

## Key Results
- First place in automatic evaluation with score 0.52
- Second place in human evaluation with score 0.74
- mT0-XL with 3.7B parameters outperformed larger mT0-XXL (13B) and Aya-101 models
- ORPO alignment improved performance by 0.01 average points
- Amharic lost the most samples during filtering (55.5%) due to translation quality issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: mT0-XL outperforms larger models like mT0-XXL and Aya-101 in text detoxification.
- Mechanism: Fine-tuning on domain-specific augmented data combined with ORPO alignment provides better task-specific performance than scaling model size alone.
- Core assumption: Task-specific fine-tuning and alignment are more important than raw parameter count for specialized NLP tasks.
- Evidence anchors:
  - [abstract] "Our 3.7-billion-parameter language model demonstrates state-of-the-art results for Ukrainian and near state-of-the-art results for other languages."
  - [section 4] "Surprisingly, the larger models are not the best. For example, the mT0-XXL model with 13B parameters performed even worse than the mT0-XL model with only 3.7B parameters."
  - [corpus] Weak evidence - no direct comparisons found in neighbors, but the core insight about fine-tuning relevance appears in related works on multilingual detoxification.
- Break condition: If the task data distribution differs significantly from the fine-tuning data, the advantage of specialized fine-tuning may disappear.

### Mechanism 2
- Claim: Data augmentation through machine translation combined with similarity and toxicity filtering produces high-quality multilingual training data.
- Mechanism: Expanding low-resource languages via translation from English, then filtering for semantic similarity (>0.8) and toxicity preservation (toxic >0.9, neutral <0.1) creates a balanced parallel corpus.
- Core assumption: Translation preserves enough semantic content and the filtering thresholds are well-calibrated to maintain data quality.
- Evidence anchors:
  - [section 2] "As a result, we obtained an additional 19,700 samples for each language... According to the statistics, Amharic lost the most samples during filtering."
  - [section 2] "Regarding toxicity, many neutral sentences became toxic after translation, and many toxic sentences became neutral."
  - [corpus] Weak evidence - neighbors discuss data augmentation but don't detail the specific filtering methodology used here.
- Break condition: If translation quality degrades significantly for certain language pairs, the filtering may remove too much data or fail to catch semantic drift.

### Mechanism 3
- Claim: ORPO alignment without a reference model effectively improves model outputs by using preference pairs from diverse beam search.
- Mechanism: Generating 10 hypotheses with diverse beam search, selecting 5 candidates, then using relevance scores (similarity × toxicity) to create preference pairs for ORPO fine-tuning.
- Core assumption: The diverse beam search with relevance scoring produces meaningful preference pairs that capture human preferences for detoxification quality.
- Evidence anchors:
  - [section 3.3] "Since ORPO uses the beta parameter, it was set to 0.1... ORPO slightly improved the performance of the model, increasing the average results by 0.01 points."
  - [section 3.2] "To select the best choice, we calculated a relevance metric using a product of similarity and toxicity scores."
  - [corpus] Weak evidence - neighbors don't discuss ORPO specifically, though they mention preference optimization in related contexts.
- Break condition: If the relevance scoring function doesn't align with human preferences, ORPO may reinforce suboptimal patterns.

## Foundational Learning

- Concept: Multilingual sequence-to-sequence modeling with mT0 architecture
  - Why needed here: The task requires translating toxic text to neutral text across 9 languages, which benefits from mT0's multilingual pretraining.
  - Quick check question: What architectural difference between mT0 and mT5 makes mT0 more suitable for this detoxification task?

- Concept: Data augmentation and filtering for low-resource languages
  - Why needed here: Limited parallel detoxification data exists, especially for languages like Amharic, requiring synthetic expansion.
  - Quick check question: Why is it important to filter translated data by both similarity and toxicity preservation?

- Concept: Preference optimization techniques (ORPO vs DPO)
  - Why needed here: Fine-tuning alone isn't sufficient; alignment to human preferences further improves detoxification quality.
  - Quick check question: How does ORPO differ from DPO in terms of reference model requirements?

## Architecture Onboarding

- Component map:
  - Original datasets (En/Ru ParaDetox) → Machine translation → Similarity filtering → Toxicity filtering → Final training corpus
  - mT0 family models → Supervised fine-tuning → Diverse beam search inference → ORPO alignment

- Critical path:
  1. Data augmentation and filtering
  2. mT0-XL fine-tuning on augmented data
  3. Diverse beam search hypothesis generation
  4. ORPO alignment using preference pairs
  5. Final evaluation and selection

- Design tradeoffs:
  - Model size vs. task-specific fine-tuning: Smaller mT0-XL outperforms larger models when properly fine-tuned
  - Translation quality vs. data quantity: Aggressive filtering may reduce dataset size but improves quality
  - Hypothesis generation vs. inference cost: 10 beams with 5 groups balances diversity and efficiency

- Failure signatures:
  - Model degrades on languages that lost most data during filtering (e.g., Amharic)
  - ORPO alignment overfits to the test set if not properly validated
  - Diverse beam search produces semantically similar hypotheses, reducing preference signal

- First 3 experiments:
  1. Compare mT0-XL with and without ORPO alignment on a validation set to measure the 0.01 improvement
  2. Test different filtering thresholds (similarity: 0.7-0.9, toxicity: 0.8-0.95) to find optimal data quality vs. quantity balance
  3. Evaluate diverse beam search with different diversity penalties (1.5-3.0) to optimize hypothesis quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can text detoxification capabilities be adapted from high-resource to low-resource languages without relying on machine translation, given that machine translation quality for low-resource languages is often poor?
- Basis in paper: [explicit] The authors state this as a future research direction, noting that "machine translation for low-resource languages often shows low quality."
- Why unresolved: The paper relies on machine translation for data augmentation in low-resource languages, but acknowledges this approach has quality limitations. No alternative methods are proposed or tested.
- What evidence would resolve it: Comparative experiments showing detoxification performance using alternative adaptation methods (like few-shot learning, cross-lingual transfer without translation, or synthetic data generation) versus machine translation-based approaches across multiple low-resource languages.

### Open Question 2
- Question: What specific tokens are being replaced during the text detoxification process, and what linguistic patterns determine these replacements?
- Basis in paper: [explicit] The authors identify interpretability as a future research direction, specifically asking "which tokens have been replaced by the model through the text detoxification process and the rationale behind this."
- Why unresolved: The paper focuses on end-to-end performance metrics but does not analyze the actual transformations made by the model at the token level.
- What evidence would resolve it: Detailed case studies showing before/after text pairs with token-level analysis, identifying common patterns in toxic-to-neutral transformations and the linguistic rules the model appears to be following.

### Open Question 3
- Question: Why does the mT0-XL model with 3.7 billion parameters outperform the larger mT0-XXL model with 13 billion parameters in this text detoxification task?
- Basis in paper: [explicit] The authors note that "surprisingly, the larger models are not the best" and provide comparative results showing mT0-XL outperforming mT0-XXL.
- Why unresolved: The paper observes this phenomenon but does not investigate the underlying reasons for why smaller models perform better in this specific task.
- What evidence would resolve it: Ablation studies comparing model architectures, parameter efficiency analyses, and task-specific evaluations to determine whether the performance difference stems from overfitting, optimization efficiency, or task-specific architectural advantages.

## Limitations

- Data filtering significantly reduced dataset size for Amharic, with many toxic sentences becoming neutral after translation
- ORPO alignment provides only modest improvement (0.01 average increase), raising questions about cost-effectiveness
- Heavy reliance on GoogleTranslator without addressing potential quality issues or biases in machine translation for low-resource languages

## Confidence

**High Confidence**: The core claim that mT0-XL outperforms larger models when combined with targeted fine-tuning and ORPO alignment is well-supported by the empirical results showing first place in automatic evaluation and second in human evaluation.

**Medium Confidence**: The effectiveness of the specific filtering thresholds (similarity >0.8, toxicity >0.9/ <0.1) is reasonably supported but could benefit from ablation studies showing sensitivity to these parameters.

**Low Confidence**: The claim that diverse beam search with relevance scoring captures human preferences for detoxification quality lacks strong validation, as the paper doesn't compare against alternative candidate selection methods or provide detailed analysis of the preference pairs generated.

## Next Checks

1. **Ablation study on filtering thresholds**: Systematically vary the similarity threshold (0.7, 0.8, 0.9) and toxicity thresholds (0.8, 0.9, 0.95) to quantify the trade-off between data quantity and quality, particularly for Amharic which lost the most samples during filtering.

2. **Alternative candidate selection comparison**: Compare the diverse beam search with relevance scoring against simpler approaches (top-1 beam, random sampling) and human-curated preferences to validate whether the current method actually captures meaningful detoxification preferences.

3. **Cross-lingual transfer analysis**: Evaluate the model's performance when fine-tuning on English data only versus multilingual augmented data to quantify the benefit of translation-based augmentation across different language families.