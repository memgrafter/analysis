---
ver: rpa2
title: Large Language Models as Markov Chains
arxiv_id: '2410.02724'
source_url: https://arxiv.org/abs/2410.02724
tags:
- markov
- chains
- language
- have
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes a formal connection between large language
  models (LLMs) and Markov chains by showing that any autoregressive transformer-based
  LLM with finite vocabulary and context window can be represented as a finite-state
  Markov chain. This equivalence allows the authors to analyze LLMs' inference, pre-training,
  and in-context learning from first principles.
---

# Large Language Models as Markov Chains

## Quick Facts
- **arXiv ID**: 2410.02724
- **Source URL**: https://arxiv.org/abs/2410.02724
- **Reference count**: 40
- **Primary result**: Establishes formal equivalence between autoregressive transformer-based LLMs and finite-state Markov chains

## Executive Summary
This paper provides a rigorous theoretical framework connecting large language models (LLMs) to Markov chains, showing that any autoregressive transformer with finite vocabulary and context window can be represented as a finite-state Markov chain. This equivalence enables first-principles analysis of LLM inference, pre-training, and in-context learning behaviors. The authors derive sample complexity bounds for non-iid pre-training data and provide generalization bounds for in-context learning, validated through experiments on Llama and Gemma models.

## Method Summary
The paper establishes LLM-MCMC equivalence through finite-state representation where sequences of length ≤ K form countable states. The next-token prediction function defines sparse transition matrices with block structure. Sample complexity bounds are derived using Marton coupling techniques for dependent pre-training data, while ICL generalization bounds are obtained through probabilistic analysis. Empirical validation involves measuring MMLU performance against approximation error and testing ICL risk scaling with prompt size.

## Key Results
- Characterizes LLM inference as Markov chain with pathological behaviors explained (repetitions, incoherence at high temperature)
- Derives sample complexity bounds for non-iid pre-training validated on Llama and Gemma models
- Provides ICL generalization bounds with O(N⁻¹/²) scaling confirmed experimentally

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Autoregressive transformers with finite T and K can be represented as finite-state Markov chains
- **Mechanism**: Input sequences (up to K) and output tokens (from vocabulary T) create countable state space V*_K. LLM's next-token prediction function f_Θ defines transition probabilities between states, forming sparse transition matrix Q_f
- **Core assumption**: Vocabulary size T and context window K are finite
- **Evidence anchors**: Abstract states equivalence; Section 3.1 describes transition matrix size O(T^K)
- **Break condition**: Infinite vocabulary or context window

### Mechanism 2
- **Claim**: LLMs' pathological behaviors like repetitions and incoherence at high temperature can be explained through Markov chain properties
- **Mechanism**: Stationary distribution independence from initial state causes deterministic repetition loops. High temperature affects ε (smallest transition matrix element), increasing convergence speed and reducing coherence
- **Core assumption**: LLM represented as finite-state Markov chain with well-defined stationary distribution
- **Evidence anchors**: Section 3.1 discusses deterministic repetition loops; Section 3.2 links temperature to decreasing coherence
- **Break condition**: Non-ergodic Markov chain or broken Markov structure

### Mechanism 3
- **Claim**: LLMs' pre-training sample complexity on non-iid data can be bounded using Marton coupling techniques
- **Mechanism**: Pre-training data modeled as dependent random variables with Marton coupling structure. Sample complexity depends on model parameters (K, τ, BU) and data properties (mixing matrix Γ)
- **Core assumption**: Pre-training data admits Marton coupling with mixing matrix Γ
- **Evidence anchors**: Section 4.1 describes Marton coupling framework; Section 4.2 presents sample complexity bound
- **Break condition**: No Marton coupling structure or invalid parameter bounds

## Foundational Learning

- **Concept: Markov Chain Properties**
  - Why needed here: The entire theoretical framework relies on Markov chain representation
  - Quick check question: What conditions must a Markov chain satisfy to have a unique stationary distribution and converge to it?

- **Concept: Marton Coupling**
  - Why needed here: Sample complexity bounds for non-iid data rely on Marton coupling techniques
  - Quick check question: How does a Marton coupling differ from standard coupling methods in probability theory?

- **Concept: Total Variation Distance**
  - Why needed here: Theoretical bounds use total variation distance to measure distribution differences
  - Quick check question: How does total variation distance relate to other probability distance measures like KL divergence?

## Architecture Onboarding

- **Component map**: Input sequence → embeddings → positional embeddings → L transformer layers (alternating MHA and FF blocks) → unembedding → softmax → next token prediction
- **Critical path**: The inference path follows the complete forward pass, with the Markov chain representation capturing all possible transitions between states of length ≤ K
- **Design tradeoffs**: Finite T and K assumptions enable Markov chain analysis but limit expressiveness. Temperature τ affects convergence speed and output coherence. Norm bounds on WU and layer weights enable theoretical guarantees
- **Failure signatures**: Repetitions indicate convergence to stationary distribution. Poor generalization on non-iid data suggests inadequate Marton coupling or insufficient sample complexity. Temperature-dependent incoherence suggests ε becoming too small
- **First 3 experiments**:
  1. Implement Markov chain representation for small LLM (T=2, K=3) and verify transition matrix structure matches Fig. 2
  2. Test temperature scaling effects on output coherence by measuring perplexity at different temperatures and comparing to theoretical ε values
  3. Validate sample complexity bounds by training LLMs on controlled non-iid datasets and measuring generalization error vs predicted sample complexity

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does choice of vocabulary size T and context window K impact convergence rate to stationary distribution in LLMs?
- **Basis in paper**: [explicit] Paper discusses relationship between temperature, context window, and convergence rate but lacks quantitative analysis of T and K impact
- **Why unresolved**: Framework provides theoretical basis but doesn't explore practical implications of varying T and K
- **What evidence would resolve it**: Experimental results showing convergence rate for different T and K combinations, or theoretical bounds on convergence time as function of these parameters

### Open Question 2
- **Question**: What is optimal balance between embedding dimension r, vocabulary size T, and softmax temperature τ for maximizing LLM performance while minimizing pre-training data requirements?
- **Basis in paper**: [explicit] Paper discusses interplay between these parameters in generalization bounds but doesn't provide optimization guidance
- **Why unresolved**: Theoretical analysis shows parameter effects but doesn't determine optimal combination for given task or dataset
- **What evidence would resolve it**: Empirical studies comparing LLM performance across different r, T, and τ configurations, or theoretical framework optimizing these parameters jointly

### Open Question 3
- **Question**: How does distribution shift between pre-training data and in-context learning data affect LLM performance, and can this be mitigated through architectural modifications?
- **Basis in paper**: [inferred] Paper discusses distribution shift term in ICL bound but doesn't explore practical implications or mitigation strategies
- **Why unresolved**: Theoretical analysis highlights importance of distribution shift but doesn't provide insights into minimizing impact or architectural handling
- **What evidence would resolve it**: Experiments comparing LLM performance on ICL tasks with different distribution shifts, or theoretical analysis of architectural modifications reducing distribution shift impact

## Limitations
- Theoretical framework relies on finite vocabulary and context window assumptions that may not extend to adaptive or infinite-context models
- Empirical validation uses controlled non-iid datasets that may not fully capture real-world pre-training data complexities
- Marton coupling approach requires specific mixing matrix structures that may be difficult to verify for arbitrary datasets

## Confidence
- **High Confidence**: Fundamental Markov chain equivalence is mathematically rigorous and well-supported
- **Medium Confidence**: Sample complexity bounds are theoretically sound but depend on empirical Marton coupling assumptions
- **Low Confidence**: Temperature scaling analysis connecting ε values to output coherence lacks comprehensive empirical validation

## Next Checks
1. Implement Markov chain representation for small-scale transformer (T=5, K=4) and systematically verify transition matrix structure matches theoretical sparse, block-structured pattern
2. Conduct controlled temperature scaling experiments varying τ across multiple orders of magnitude on diverse LLM architectures, measuring output coherence against theoretically predicted ε values
3. Create synthetic non-iid datasets with known Marton coupling structures, train small transformers, and measure generalization error against theoretical sample complexity bounds to identify sensitivity to different coupling structures