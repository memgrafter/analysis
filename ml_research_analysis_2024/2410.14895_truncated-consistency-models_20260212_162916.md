---
ver: rpa2
title: Truncated Consistency Models
arxiv_id: '2410.14895'
source_url: https://arxiv.org/abs/2410.14895
tags:
- consistency
- training
- stage
- arxiv
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Truncated Consistency Models (TCM), a novel\
  \ training approach that improves sample quality and training stability of consistency\
  \ models by explicitly addressing the trade-off between denoising and generation\
  \ tasks. The method relaxes the standard consistency training objective to focus\
  \ on a truncated time range [t\u2032, T], allowing the model to prioritize generation\
  \ while maintaining consistency mapping."
---

# Truncated Consistency Models

## Quick Facts
- arXiv ID: 2410.14895
- Source URL: https://arxiv.org/abs/2410.14895
- Reference count: 40
- Key outcome: Introduces Truncated Consistency Models (TCM) that improve sample quality and training stability by addressing denoising-generation trade-offs through truncated time range training.

## Executive Summary
This paper introduces Truncated Consistency Models (TCM), a novel training approach that improves sample quality and training stability of consistency models by explicitly addressing the trade-off between denoising and generation tasks. The method relaxes the standard consistency training objective to focus on a truncated time range [t′, T], allowing the model to prioritize generation while maintaining consistency mapping. This is achieved through a two-stage training procedure: (1) pretraining a standard consistency model as a boundary condition provider, and (2) truncated consistency training that emphasizes generation tasks. The authors propose a new parameterization and boundary loss mechanism to prevent model collapse.

## Method Summary
TCM addresses the trade-off between denoising and generation in consistency models through a two-stage training procedure. First, a standard consistency model is pretrained over the full time range [0, T] to serve as a boundary condition provider. Second, a truncated consistency model is trained over the reduced time range [t′, T] with a boundary loss that enforces consistency with the pretrained model at t′. The method uses a time sampling distribution that mixes a Dirac delta at t′ with another distribution over (t′, T] to ensure boundary condition enforcement. The truncated model discards its denoising capacity at earlier times to allocate more network capacity toward generation tasks at later times, resulting in improved one-step and two-step FID scores compared to standard consistency models.

## Key Results
- Achieves one-step FID of 2.20 on ImageNet 64×64, competitive with diffusion models
- Outperforms state-of-the-art consistency models like iCT-deep while using 2× smaller networks
- Demonstrates improved training stability without divergence issues
- Shows significant improvements on CIFAR-10 and ImageNet 64×64

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TCM improves generation performance by explicitly reducing denoising capacity at smaller t values, allowing more network capacity to be allocated toward generation tasks.
- Mechanism: The method truncates consistency training to focus on [t′, T] range, explicitly ignoring denoising tasks at earlier times [0, t′). This reallocation of network capacity toward generation-like tasks at later times improves one-step FID scores significantly.
- Core assumption: The trade-off between denoising and generation is real and that reducing denoising capacity at small t values improves generation quality without collapsing the model.
- Evidence anchors:
  - [abstract]: "We empirically find that this training paradigm limits the one-step generation performance of consistency models" and "allows the model to ignore denoising tasks at earlier time steps and focus its capacity on generation"
  - [section 3]: "We observe that during standard consistency training, the model gradually loses its denoising capabilities at the low t" and "the model struggles to learn to denoise and generate simultaneously, and sacrifices one for the other"
  - [corpus]: No direct evidence in corpus papers, but related works like "Bidirectional Consistency Models" and "Fast T2T" suggest similar trade-off exploration
- Break condition: If the boundary condition at t′ is not properly maintained, the model could collapse to a trivial solution or fail to generate meaningful samples.

### Mechanism 2
- Claim: The two-stage training procedure prevents model collapse by providing a meaningful boundary condition at t′ through a pre-trained standard consistency model.
- Mechanism: Stage 1 trains a standard consistency model over the entire time range [0, T], which then serves as the boundary condition provider for Stage 2. The boundary loss in Stage 2 enforces consistency with this pre-trained model at t′, preventing collapse to constant functions.
- Core assumption: A pre-trained model can provide a stable and meaningful boundary condition that prevents trivial solutions during truncated training.
- Evidence anchors:
  - [abstract]: "we propose a new parameterization of the consistency function and a two-stage training procedure that prevents the truncated-time training from collapsing to a trivial solution"
  - [section 3]: "the model outputs can collapse to an arbitrary constant because a constant function...is a minimizer of the consistency training objective" and "the boundary condition at time t′ is provided by the pretrained fθ0"
  - [corpus]: No direct evidence in corpus papers, but the concept of using pre-trained models as boundary conditions appears in diffusion model literature
- Break condition: If the pre-trained model is not sufficiently converged or if the boundary loss weight is too low, the truncated training may collapse.

### Mechanism 3
- Claim: The time sampling distribution design ensures sufficient boundary condition enforcement by maintaining positive probability mass at the dividing time t′.
- Mechanism: The time sampling distribution ψt is designed as a mixture of Dirac delta at t′ and another distribution over (t′, T], ensuring that boundary samples are always included regardless of ∆t values during training.
- Core assumption: Maintaining positive probability at t′ throughout training is necessary to prevent collapse and ensure proper boundary condition enforcement.
- Evidence anchors:
  - [section 3]: "To prevent this, we design ψt to satisfy R t∈St′ ψt(t)dt > 0" and "we define ψt as a mixture of the Dirac delta function δ(·) at point t′ and another distribution ¯ψt"
  - [section 4.4]: "By definition, we can see that R t∈St′ ψt(t)dt ≥ λb, and λb controls how significantly we emphasize the boundary condition"
  - [corpus]: No direct evidence in corpus papers, but time sampling strategies are common in diffusion and consistency model training
- Break condition: If λb is set too low or the distribution ¯ψt doesn't maintain sufficient mass around t′, the boundary condition may not be properly enforced.

## Foundational Learning

- Concept: Consistency models and probability flow ODEs
  - Why needed here: TCM builds directly on consistency models, which learn to predict solutions of probability flow ODEs from initial noise. Understanding the underlying PF ODE formulation is crucial for grasping why truncated training works.
  - Quick check question: What are the two properties that a consistency function must satisfy according to Song et al. (2023)?

- Concept: Diffusion models and score matching
  - Why needed here: TCM is a method for accelerating diffusion models by learning direct mappings. Understanding how diffusion models work and their training objectives provides context for why TCM's approach is effective.
  - Quick check question: How does the consistency training objective relate to the denoising score matching objective used in standard diffusion models?

- Concept: Knowledge distillation and progressive distillation
  - Why needed here: TCM belongs to the family of methods that distill pre-trained diffusion models into faster samplers. Understanding these related approaches helps contextualize TCM's contributions and trade-offs.
  - Quick check question: What is the key difference between consistency models and knowledge distillation approaches for accelerating diffusion models?

## Architecture Onboarding

- Component map:
  Stage 1: Standard consistency training model (fθ0) - trained on full time range [0, T]
  Stage 2: Truncated consistency model (fθ) - trained on [t′, T] with boundary condition from fθ0
  Boundary loss mechanism - enforces consistency with fθ0 at t′
  Time sampling distribution - mixture of Dirac delta and ¯ψt to ensure boundary sampling
  Parameterization: ftrunc(θ,θ0)(x,t) = fθ(x,t)·1{t≥t′} + fθ0(x,t)·1{t<t′}

- Critical path:
  1. Pretrain standard consistency model to convergence
  2. Initialize truncated model with pretrained weights
  3. Train with truncated time range and boundary loss
  4. Use truncated model for generation (fθ only, discard parameterization)

- Design tradeoffs:
  - Boundary loss weight (wb): Higher values ensure better boundary condition but may slow convergence
  - Dividing time t′: Earlier t′ preserves more denoising capability but less capacity for generation
  - Time sampling distribution: Heavier tails emphasize later times but may reduce boundary enforcement
  - Batch partitioning (ρ): More boundary samples improve stability but reduce consistency training samples

- Failure signatures:
  - Model collapse: FID explodes, samples become constant or noise
  - Poor generation quality: FID remains high, samples lack diversity or realism
  - Training instability: Large gradient spikes, divergence during training
  - Insufficient boundary enforcement: dFID at t′ remains high, indicating poor boundary condition

- First 3 experiments:
  1. Verify basic functionality: Train TCM with t′ = 1 on CIFAR-10, compare one-step FID against baseline iCT
  2. Test boundary condition importance: Remove boundary loss (wb = 0) and observe if model collapses
  3. Validate time sampling: Compare different time sampling distributions (log-normal vs log-Student-t) and their impact on FID and stability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal boundary time t' that maximizes the trade-off between denoising and generation tasks in TCM?
- Basis in paper: [explicit] The paper discusses dividing time t' as the boundary between denoising and generation tasks, with experiments using t' = 1.
- Why unresolved: The paper only explores a limited set of t' values and does not provide a systematic method for determining the optimal t' for different datasets or model architectures.
- What evidence would resolve it: A comprehensive ablation study varying t' across different datasets, model sizes, and noise schedules, with quantitative analysis of how t' affects both denoising FID and generation FID.

### Open Question 2
- Question: How does the two-stage training approach in TCM compare to alternative multi-stage training strategies?
- Basis in paper: [explicit] The paper mentions considering adding intermediate training stages but found no improvement, and only explores up to three stages.
- Why unresolved: The paper does not thoroughly investigate alternative multi-stage approaches, such as gradually increasing t' or incorporating intermediate fine-tuning stages, and only briefly mentions one attempt.
- What evidence would resolve it: Systematic comparison of TCM with various multi-stage training strategies, including different schedules for increasing t', different numbers of stages, and different approaches for fine-tuning the boundary condition.

### Open Question 3
- Question: What is the relationship between the choice of time sampling distribution ψt and the final generation quality in TCM?
- Basis in paper: [explicit] The paper explores different time sampling distributions and finds that the truncated log-Student-t distribution works best.
- Why unresolved: The paper only explores a limited set of distributions and does not provide a theoretical justification for why the log-Student-t distribution is optimal or how different choices affect the model's ability to balance denoising and generation.
- What evidence would resolve it: A theoretical analysis of how different time sampling distributions affect the gradient flow and capacity allocation in TCM, combined with empirical validation across various datasets and model architectures.

## Limitations

- The two-stage training procedure adds complexity compared to standard consistency training, potentially making it harder to implement and tune in practice
- The choice of t′ and wb appears critical for success, yet the paper provides limited guidance on hyperparameter selection
- Performance on larger-scale datasets like ImageNet 256×256 remains untested
- The theoretical analysis lacks rigorous mathematical justification for why truncated training specifically improves generation performance

## Confidence

**High Confidence**: The empirical results demonstrating improved FID scores on CIFAR-10 and ImageNet 64×64 are convincing, with clear comparisons against established baselines like iCT-deep. The failure modes (model collapse to constant functions) and their prevention through boundary conditions are well-documented through experiments. The core claim that the denoising-generation trade-off exists and limits one-step generation performance is supported by the ablation study removing boundary loss.

**Medium Confidence**: The mechanism explaining why reallocating network capacity from denoising to generation improves sample quality is plausible but not definitively proven. While the authors show that models lose denoising capability at small t values during standard training, the causal link between this observation and the specific improvements from TCM requires further investigation. The claim that TCM achieves "competitive" performance with diffusion models needs more context, as the comparison is primarily with other fast samplers rather than full diffusion models.

**Low Confidence**: The generalizability of TCM to other domains and tasks beyond image generation remains untested. The paper doesn't explore whether the truncated training approach would benefit other consistency-based methods or whether similar trade-offs exist in related generative modeling paradigms.

## Next Checks

1. **Boundary Condition Sensitivity**: Conduct a systematic ablation study varying wb and t′ across multiple orders of magnitude to understand their impact on both training stability and sample quality. This would clarify whether the specific values chosen (wb = 0.1, t′ = 1) are optimal or if the method is robust to parameter changes.

2. **Larger-Scale Evaluation**: Test TCM on higher-resolution datasets (e.g., ImageNet 128×128 or 256×256) to assess whether the improvements scale with dataset complexity. This would validate whether the method's benefits extend beyond the relatively small-scale experiments presented.

3. **Comparative Trade-off Analysis**: Design an experiment comparing TCM against alternative approaches for addressing the denoising-generation trade-off, such as architectural modifications or different training objectives. This would help isolate whether the specific truncated training approach is superior to other potential solutions for the same problem.