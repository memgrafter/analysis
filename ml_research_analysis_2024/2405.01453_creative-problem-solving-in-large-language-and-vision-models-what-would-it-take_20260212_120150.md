---
ver: rpa2
title: Creative Problem Solving in Large Language and Vision Models -- What Would
  it Take?
arxiv_id: '2405.01453'
source_url: https://arxiv.org/abs/2405.01453
tags:
- creative
- problem
- solving
- object
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper identifies creative problem-solving as a key limitation\
  \ of large language and vision models (LLVMs) and argues for stronger integration\
  \ with Computational Creativity (CC) principles to address this gap. It reviews\
  \ three forms of creativity from CC literature\u2014exploratory, combinational,\
  \ and transformational\u2014and maps them to potential extensions for LLVM embedding\
  \ spaces."
---

# Creative Problem Solving in Large Language and Vision Models -- What Would it Take?

## Quick Facts
- arXiv ID: 2405.01453
- Source URL: https://arxiv.org/abs/2405.01453
- Reference count: 23
- Key outcome: The paper identifies creative problem-solving as a key limitation of large language and vision models (LLVMs) and argues for stronger integration with Computational Creativity (CC) principles to address this gap.

## Executive Summary
This paper explores the gap between current large language and vision model capabilities and true creative problem-solving, arguing that existing ML approaches have not fully leveraged Computational Creativity (CC) theories. The authors identify three forms of creativity from CC literature—exploratory, combinational, and transformational—and propose specific mechanisms for integrating these principles into LLVM architectures. Preliminary experiments using VLMs for object replacement tasks demonstrate that incorporating affordance information in prompts significantly improves performance compared to baseline prompts, suggesting that task re-representation strategies from CC can enhance LLVM reasoning. The work highlights the need for specialized evaluation benchmarks that measure both novelty and utility in creative problem-solving contexts.

## Method Summary
The study evaluates creative problem-solving capabilities in LLMs through object replacement tasks using pre-trained HuggingFace checkpoints without additional training. The experimental setup includes 16 RGB images of 5 core objects (Scoop, Hammer, Spatula, Toothpick, Pliers) with 4 prompting strategies: Regular, Affordance, Task, and Task+Affordance. Each LLVM architecture (CLIP, BLIP, LLaVA, OWL-ViT) is tested across 50 samples per prompt type to measure accuracy in selecting correct replacement objects. The methodology focuses on prompt engineering rather than model fine-tuning, testing how different prompt formulations affect creative problem-solving performance.

## Key Results
- Incorporating affordance information in prompts significantly improves VLM performance on object replacement tasks compared to baseline prompts
- Task re-representation through enhanced prompting warrants further investigation for creative problem solving in LLVMs
- No specific benchmarks currently exist for assessing the creative problem-solving abilities of LLVM systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Augmenting LLVM embedding spaces with affordance information enables creative object replacement by improving task re-representation.
- Mechanism: By providing object affordance information in prompts, the model can bridge conceptual gaps between seemingly distinct objects (e.g., a bowl and a spoon both having containability affordances), thus transforming an ill-structured problem into a well-structured one that the model can solve.
- Core assumption: The model's embedding space can be effectively manipulated through prompt engineering to incorporate external conceptual information (affordances) for creative problem solving.
- Evidence anchors:
  - [abstract] "preliminary experiments using VLMs for object replacement tasks show that incorporating affordance information in prompts significantly improves performance"
  - [section 4.1.3] "The notion of task re-representation via improved prompting warrants further investigation in LLVMs, with regards to how the prompts can be generated automatically based on the creative task"
  - [corpus] Weak - No direct corpus evidence for affordance-based prompt engineering in LLVM creative problem solving
- Break condition: If the model cannot effectively map external affordance concepts to its internal embedding space, or if the affordance information is too abstract or domain-specific to be captured in natural language prompts.

### Mechanism 2
- Claim: Combinational creativity through cross-attention layers can extend LLVM capabilities by combining concepts within the same model's embedding space.
- Mechanism: Cross-attention allows a model to attend to concepts from different modalities (e.g., visual and textual) simultaneously, effectively combining their embeddings to create new conceptual spaces that enable creative problem solving through functional combinations of objects.
- Core assumption: The attention mechanism can meaningfully combine embeddings from different sources within the same model to create novel conceptual representations.
- Evidence anchors:
  - [section 4.1.2] "Using cross-attention layers can help augment an anchor LLM with an augmenting LLM's capabilities to perform a task that the anchor LLM was incapable of achieving before"
  - [section 4.1.2] "Can a combination of embeddings of the same LLVM, corresponding to 'base' and 'additive' nouns... enable the LLVM to generate creative combinations of objects for solving a task?"
  - [corpus] Weak - Limited direct evidence for combinational creativity within a single LLVM's embedding space
- Break condition: If the cross-attention mechanism cannot effectively combine embeddings from different sources, or if the combined embeddings do not lead to meaningful new conceptual representations.

### Mechanism 3
- Claim: Exploratory creativity through search within LLVM embedding spaces can discover novel solutions beyond the model's typical output space.
- Mechanism: By implementing search algorithms (e.g., MCTS, beam search) directly within the embedding space rather than the output space, the model can explore novel combinations of embeddings that may lead to creative problem solving approaches not constrained by typical output generation.
- Core assumption: Search algorithms can be effectively implemented within high-dimensional embedding spaces to discover novel and useful combinations of concepts.
- Evidence anchors:
  - [section 4.1.1] "To effectively reveal the full extent of the conceptual space for creative problem solving, the approach should not be limited by the outputs the LLVM can generate"
  - [section 4.1.1] "exploratory approaches directly within the LLMs' embedding space would not be limited by what the LLM can generate as output"
  - [corpus] Weak - Limited evidence for embedding space search in LLVM creative problem solving
- Break condition: If search algorithms cannot effectively navigate high-dimensional embedding spaces, or if the discovered combinations do not lead to meaningful creative solutions.

## Foundational Learning

- Concept: Computational Creativity (CC) principles and theories
  - Why needed here: Understanding CC theories (exploratory, combinational, transformational creativity) provides the framework for extending LLVM capabilities beyond standard task completion
  - Quick check question: Can you explain the difference between exploratory, combinational, and transformational creativity and how each might apply to LLVM enhancement?

- Concept: Large Language and Vision Models (LLVM) architecture and embedding spaces
  - Why needed here: Understanding how LLMs and VLMs represent concepts in embedding spaces is crucial for implementing CC principles to enable creative problem solving
  - Quick check question: How do LLVM embedding spaces represent concepts, and why are they relevant to computational creativity?

- Concept: Prompt engineering and in-context learning
  - Why needed here: These techniques are essential for manipulating LLVM behavior and incorporating external information (like affordances) to enable creative problem solving
  - Quick check question: How does prompt engineering differ from traditional fine-tuning, and why is it particularly relevant for creative problem solving in LLVMs?

## Architecture Onboarding

- Component map:
  - LLVM core (LLM/VLM with pre-trained weights) -> Cross-attention modules for combinational creativity -> Search algorithms for exploratory creativity (MCTS, beam search) -> Prompt engineering interface for transformational creativity -> Affordance knowledge base or embedding space for task re-representation

- Critical path:
  1. Receive task input and current state
  2. Determine appropriate creativity mode (exploratory, combinational, transformational)
  3. Execute creativity mechanism (search, cross-attention, or prompt engineering)
  4. Generate creative solution through LLVM
  5. Evaluate novelty and utility of solution

- Design tradeoffs:
  - Search depth vs. computational cost in exploratory creativity
  - Cross-attention complexity vs. effectiveness in combinational creativity
  - Prompt specificity vs. generality in transformational creativity
  - External knowledge integration vs. model independence

- Failure signatures:
  - Exploratory: Search gets stuck in local optima or embedding space is too sparse
  - Combinational: Cross-attention produces meaningless combinations or conflicts with existing embeddings
  - Transformational: Prompts fail to effectively re-represent the problem or cause model confusion

- First 3 experiments:
  1. Implement basic cross-attention between vision and language encoders, test on object replacement task with and without affordance information
  2. Add beam search within embedding space for exploratory creativity, compare performance on creative problem solving benchmarks
  3. Develop automated prompt generation system for task re-representation, evaluate on diverse creative problem solving tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLVM embedding spaces be directly searched for creative problem-solving solutions, or must search be limited to output spaces?
- Basis in paper: [explicit] Section 4.1.1 discusses exploratory creativity and notes that existing approaches search LLM output spaces rather than directly operating in embedding spaces, which would not be limited by what the LLM can generate as output
- Why unresolved: Current approaches have not focused on LLVMs from this perspective, and have also not applied search to embedding spaces of Vision-LMs
- What evidence would resolve it: Experiments demonstrating successful creative problem-solving through direct search within LLVM embedding spaces compared to traditional output-space search methods

### Open Question 2
- Question: What is the optimal representation for concepts that facilitate creative problem-solving in LLVMs - symbolic, non-symbolic, or hybrid?
- Basis in paper: [inferred] Section 7 limitations mentions this as an unanswered question, noting that while the paper seeks to address gaps preventing application of CC literature to ML, there are still several unanswered questions about practical implementation
- Why unresolved: The paper focuses on position rather than developing concrete algorithms, and this question requires extensive empirical investigation across different problem domains
- What evidence would resolve it: Comparative studies of creative problem-solving performance using symbolic, non-symbolic, and hybrid representations across diverse task domains and LLM architectures

### Open Question 3
- Question: How can task re-representation prompts for creative problem-solving be automatically generated rather than manually specified?
- Basis in paper: [explicit] Section 4.1.3 discusses transformational creativity and prompt engineering, noting that our preliminary experiments use manually specified prompts and our work does not elaborate on how these prompts may be automatically discovered
- Why unresolved: Automatic prompt generation for creative tasks is challenging since model performance is strongly dependent on chosen prompts, further compounded by the fact that creative problems are inherently poorly defined
- What evidence would resolve it: Development and validation of an automated system that generates effective creative problem-solving prompts across diverse task types, demonstrating comparable or superior performance to manually engineered prompts

## Limitations

- Limited empirical validation with small dataset (16 images, 5 object categories) without comparison to established creative problem-solving benchmarks
- Proposed mechanisms for exploratory and combinational creativity remain largely theoretical with limited experimental evidence
- No concrete metrics provided for quantifying novelty and utility in generated solutions

## Confidence

**High Confidence**: The claim that "incorporating affordance information in prompts significantly improves performance" in object replacement tasks is supported by empirical results showing consistent improvements across multiple LLVM architectures (CLIP, BLIP, LLaVA, OWL-ViT) when affordance information is included in prompts.

**Medium Confidence**: The theoretical framework mapping Computational Creativity principles to LLVM enhancement strategies is well-grounded in existing CC literature, but the practical implementation details and effectiveness of exploratory and combinational creativity mechanisms remain underdeveloped.

**Low Confidence**: The assertion that search algorithms within LLVM embedding spaces will effectively reveal "the full extent of the conceptual space for creative problem solving" lacks empirical validation and may face significant technical challenges given the high dimensionality of modern embedding spaces.

## Next Checks

1. **Benchmark Integration**: Implement the proposed object replacement task using established creative problem-solving benchmarks like the Alternative Uses Test or Torrance Tests of Creative Thinking to enable meaningful comparison with human and model baselines.

2. **Embedding Space Navigation**: Conduct controlled experiments to test the feasibility of search algorithms within LLVM embedding spaces, measuring both the quality of discovered solutions and the computational overhead compared to traditional output-space search methods.

3. **Cross-Modal Affordance Mapping**: Develop and evaluate automated systems for extracting and representing object affordances from visual inputs, then test whether these automatically-generated affordance prompts produce similar performance improvements to manually-crafted affordance descriptions.