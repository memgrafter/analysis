---
ver: rpa2
title: Large Language Models Powered Multiagent Ensemble for Mitigating Hallucination
  and Efficient Atrial Fibrillation Annotation of ECG Reports
arxiv_id: '2410.16543'
source_url: https://arxiv.org/abs/2410.16543
tags:
- llms
- ensemble
- labeling
- cases
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a multiagent ensemble method using diverse
  open-source large language models (LLMs) to automate the labeling of electrocardiogram
  (ECG) reports and identify social determinants of health (SDOH) from clinical notes.
  By applying majority voting with a minimal winning threshold, the ensemble method
  labeled 623,566 ECG reports with an estimated accuracy of 98.2% and achieved 95%
  accuracy on SDOH employment status identification and 99.7% on housing status.
---

# Large Language Models Powered Multiagent Ensemble for Mitigating Hallucination and Efficient Atrial Fibrillation Annotation of ECG Reports

## Quick Facts
- arXiv ID: 2410.16543
- Source URL: https://arxiv.org/abs/2410.16543
- Reference count: 0
- Multiagent ensemble approach achieved 98.2% accuracy on ECG report labeling

## Executive Summary
This study presents a multiagent ensemble method that leverages diverse open-source large language models (LLMs) to automate the labeling of electrocardiogram (ECG) reports and identify social determinants of health (SDOH) from clinical notes. The approach uses majority voting with a minimal winning threshold to achieve high accuracy while mitigating hallucination errors. By requiring consensus among multiple models, the ensemble method labeled 623,566 ECG reports with an estimated accuracy of 98.2% and demonstrated strong performance in SDOH classification tasks (95% for employment status, 99.7% for housing status).

## Method Summary
The multiagent ensemble approach employs three distinct open-source LLMs - Claude 3 Haiku, Llama 3, and GPT-3.5 Turbo - to independently analyze clinical text and generate labels. Each model processes the input separately, and their outputs are aggregated through a majority voting mechanism with a minimal winning threshold of 1.8. This threshold-based consensus approach ensures that at least two models must agree for a label to be accepted, effectively reducing hallucination and individual model biases. The method was applied to two distinct tasks: atrial fibrillation annotation in ECG reports and SDOH classification (employment and housing status) from clinical notes.

## Key Results
- 98.2% estimated accuracy achieved in labeling 623,566 ECG reports
- 95% accuracy on SDOH employment status identification
- 99.7% accuracy on SDOH housing status identification
- Ensemble approach outperformed individual LLMs and reduced hallucination errors through consensus requirements

## Why This Works (Mechanism)
The ensemble approach works by leveraging the complementary strengths and weaknesses of multiple LLMs. Each model has different training data, architectural biases, and inference patterns, so errors made by one model are often corrected by others. The majority voting mechanism with a minimal threshold of 1.8 ensures that labels are only accepted when at least two models agree, effectively filtering out hallucinations and reducing the impact of individual model failures. This consensus-based approach is particularly effective in clinical settings where accuracy is critical and the cost of false positives or negatives is high.

## Foundational Learning
- **Majority Voting with Threshold**: Why needed - to achieve consensus while maintaining efficiency; Quick check - verify that threshold of 1.8 provides optimal balance between accuracy and coverage
- **Multiagent System Design**: Why needed - to leverage complementary strengths of different LLMs; Quick check - ensure models are sufficiently diverse in architecture and training data
- **Clinical Text Processing**: Why needed - to handle specialized medical terminology and context; Quick check - validate model performance on domain-specific vocabulary and abbreviations

## Architecture Onboarding
- **Component Map**: ECG Reports -> Three LLMs (Claude 3 Haiku, Llama 3, GPT-3.5 Turbo) -> Majority Voting (Threshold 1.8) -> Final Labels
- **Critical Path**: Input text → Parallel LLM processing → Output aggregation → Threshold validation → Consensus label
- **Design Tradeoffs**: Accuracy vs. computational cost (three models vs. single model), consensus threshold selection (1.8 vs. higher/lower), open-source vs. proprietary models
- **Failure Signatures**: Minority model errors persist when two models agree on incorrect labels, computational overhead from running multiple models, potential bias amplification if models share similar training data
- **First 3 Experiments**: 1) Test different majority thresholds (1.5, 2.0, 2.5) on validation set, 2) Compare ensemble performance against individual best-performing LLM, 3) Measure hallucination reduction by comparing consensus outputs to ground truth

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on minimal winning threshold of 1.8 may be vulnerable to minority model errors
- Reported hallucination reduction based on consensus requirements rather than systematic measurement
- Lack of individual model performance breakdowns makes it difficult to assess specific model contributions

## Confidence
**High Confidence**: Overall accuracy of 98.2% for ECG labeling based on manual review of 12,000 reports; SDOH classification accuracies (95% employment, 99.7% housing) from manual verification
**Medium Confidence**: Claims that ensemble outperforms individual LLMs without head-to-head comparisons; scalability claims lack detailed computational cost analysis
**Low Confidence**: Generalizability to other clinical documentation types beyond ECG reports and SDOH classification

## Next Checks
1. Conduct systematic hallucination audits comparing ensemble predictions against ground truth across all three LLMs individually
2. Perform ablation studies testing different majority thresholds (1.5, 2.0, 2.5) to optimize accuracy-efficiency balance
3. Test the ensemble method on clinical notes from different medical specialties (radiology, pathology) to evaluate cross-domain performance