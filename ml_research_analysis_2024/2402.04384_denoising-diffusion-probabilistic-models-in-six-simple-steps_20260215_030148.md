---
ver: rpa2
title: Denoising Diffusion Probabilistic Models in Six Simple Steps
arxiv_id: '2402.04384'
source_url: https://arxiv.org/abs/2402.04384
tags:
- data
- will
- which
- variance
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Denoising Diffusion Probabilistic Models (DDPMs) are a popular
  class of deep generative models that have been successfully applied to diverse problems
  including image and video generation, protein and material synthesis, weather forecasting,
  and neural surrogates of partial differential equations. Despite their ubiquity,
  existing introductions to DDPMs are often overly complex, focus on variational perspectives
  that obfuscate why the method works, or require advanced mathematical background.
---

# Denoising Diffusion Probabilistic Models in Six Simple Steps

## Quick Facts
- arXiv ID: 2402.04384
- Source URL: https://arxiv.org/abs/2402.04384
- Authors: Richard E. Turner; Cristiana-Diana Diaconu; Stratis Markou; Aliaksandra Shysheya; Andrew Y. K. Foong; Bruno Mlodozeniec
- Reference count: 6
- One-line primary result: Provides a simple, comprehensive, and clear exposition of DDPMs by breaking down their formulation into six steps

## Executive Summary
This paper presents a clear and accessible introduction to Denoising Diffusion Probabilistic Models (DDPMs) by decomposing their formulation into six intuitive steps. The exposition focuses on the practical aspects of DDPMs while avoiding the complexity of variational perspectives that often obscure understanding. By assuming only basic knowledge of probabilistic modeling, Gaussian distributions, maximum likelihood estimation, and deep learning, the paper makes DDPMs accessible to a broader audience while maintaining mathematical rigor.

## Method Summary
The paper presents a six-step framework for understanding and implementing DDPMs: (1) an augmentation scheme that converts generative modeling into regression problems by progressively adding Gaussian noise, (2) a step-wise objective function for training regression models, (3) parameter tying and weighted objectives to reduce model complexity, (4) selection of denoising model architecture (typically U-Net with sinusoidal time encoding), (5) parameterization choices for the model (x(0) vs ϵ parameterization), and (6) combining all choices and setting a noise schedule. The core insight is that by adding noise progressively across T fidelity levels, the complex problem of generating data from a distribution is decomposed into T simpler denoising tasks.

## Key Results
- Provides the first comprehensive exposition of DDPMs that is simultaneously clear, complete, and simple
- Demonstrates how the augmentation scheme converts generative modeling into a sequence of regression problems
- Shows how parameter tying across fidelity levels accelerates training and reduces memory requirements
- Establishes the connection between the simplified DDPM objective and denoising score matching
- Explains why the ELBO perspective, while mathematically valid, does not lead to good practical performance when extended

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The augmentation scheme converts generative modeling into a sequence of simple regression problems.
- Mechanism: By progressively adding Gaussian noise across T fidelity levels, the complex problem of generating data from a distribution is decomposed into T simpler denoising tasks where each step involves removing small amounts of noise from the previous level.
- Core assumption: The noise added at each step is small enough that each denoising task is learnable by standard neural networks, and that the accumulated errors do not compound significantly.
- Evidence anchors:
  - [abstract]: "augmentation scheme that converts generative modeling into a sequence of simple regression problems"
  - [section]: "the conversion from a generative modelling problem into a supervised learning problem is achieved by augmenting the original training data with T additional fidelity levels"
  - [corpus]: Weak evidence. The corpus contains papers on DDPMs but doesn't specifically discuss the regression decomposition mechanism.
- Break condition: If the noise added at each step becomes too large (λt << 1), the denoising tasks become too difficult for the network to learn effectively.

### Mechanism 2
- Claim: Parameter tying across fidelity levels accelerates training and reduces memory requirements.
- Mechanism: Instead of learning T separate models, a single shared architecture is used with fidelity-level-specific modulation. This allows information from one fidelity level to help learn models at other levels, and reduces the total number of parameters from T×K to just K.
- Core assumption: The denoising processes at different fidelity levels are similar enough that information can be effectively shared between them.
- Evidence anchors:
  - [section]: "To retain flexibility with a small set of parameters, we will instead share parameters across each of the regression problems"
  - [section]: "the regression problems at adjacent levels t+1 and t-1 will be very similar"
  - [corpus]: Weak evidence. The corpus doesn't directly address parameter sharing mechanisms.
- Break condition: If the denoising processes at different fidelity levels are too dissimilar, parameter sharing could actually hurt performance by forcing the model to learn inappropriate shared features.

### Mechanism 3
- Claim: Analytic averaging over augmented data reduces Monte Carlo noise in the training objective.
- Mechanism: When both the noising and denoising processes are Gaussian, the expectation over x(t-1) can be computed analytically using the law of nested conditional expectations, effectively providing an infinite set of augmentations for training.
- Core assumption: The Gaussian assumption for both noising and denoising processes holds, allowing the analytic computation of the expectation.
- Evidence anchors:
  - [section]: "it allows us to reduce the Monte Carlo noise in the training objective by performing one of the averages over the augmented training data analytically"
  - [section]: "the inner expectation here is analytic when the noising and denoising processes are Gaussian"
  - [corpus]: Weak evidence. The corpus doesn't discuss the analytic averaging mechanism.
- Break condition: If the Gaussian assumption is violated (e.g., using a non-Gaussian denoising model), the analytic averaging trick is no longer applicable.

## Foundational Learning

- Concept: Gaussian distributions and their properties
  - Why needed here: The entire DDPM framework relies on Gaussian noising and denoising processes, requiring understanding of how to work with Gaussian distributions analytically.
  - Quick check question: Given x(t) = λt x(t-1) + σt ϵ where ϵ ~ N(0,1), what is the mean and variance of x(t) conditioned on x(t-1)?

- Concept: Maximum likelihood estimation
  - Why needed here: The training objective is formulated as maximum likelihood learning of the augmented dataset, requiring understanding of how to maximize log-likelihood functions.
  - Quick check question: For a Gaussian distribution N(x; μ, σ²), what is the log-likelihood function and how do you maximize it with respect to μ and σ²?

- Concept: Markov processes
  - Why needed here: The noising process is a first-order Markov process, and understanding this structure is crucial for deriving the conditional distributions used in training.
  - Quick check question: If x(t) depends only on x(t-1) and not on earlier states, what property does this give to the joint distribution p(x(0:T))?

## Architecture Onboarding

- Component map: Data → Augmentation (T noise levels) → Training (stochastic optimization of weighted objective) → Generation (sampling from x(T) and denoising up to x(0))
- Critical path: Data → Augmentation (T noise levels) → Training (stochastic optimization of weighted objective) → Generation (sampling from x(T) and denoising up to x(0))
- Design tradeoffs: Variance preserving vs. variance exploding noise schedules, fixed vs. learned variance in the denoising model, x(0)-parameterization vs. ϵ-parameterization of the mean.
- Failure signatures: Poor generation quality (likely due to insufficient training or inappropriate noise schedule), mode collapse (likely due to inadequate diversity in the training data or model capacity issues), training instability (likely due to inappropriate learning rate or weight initialization).
- First 3 experiments:
  1. Implement a simple 1D DDPM with linear noise schedule and x(0)-parameterization to verify basic functionality on synthetic data.
  2. Test different noise schedules (linear vs. cosine) on a simple dataset like MNIST to observe their impact on generation quality.
  3. Compare x(0)-parameterization vs. ϵ-parameterization on a simple dataset to understand their relative strengths and weaknesses.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical explanation for why the ELBO perspective of DDPMs, despite being mathematically valid, does not lead to good practical performance when extended with learned approximate posteriors or non-linear noising processes?
- Basis in paper: [explicit] The paper explicitly states that generalizations like learning the approximate posterior or using non-linear noising processes do not work well in practice, despite being natural from the ELBO perspective.
- Why unresolved: The paper provides intuition but no rigorous theoretical analysis explaining why these ELBO-inspired extensions fail practically while simpler fixed approximate posteriors work well.
- What evidence would resolve it: Formal proofs showing conditions under which learned approximate posteriors or non-linear noising processes either fail to improve or actively harm performance compared to fixed linear Gaussian approximations.

### Open Question 2
- Question: How do different augmentation coefficient schedules (λt) affect the variance of gradient estimates during training, and can optimal schedules be learned to minimize this variance?
- Basis in paper: [explicit] The paper discusses that in the continuous-time limit, the loss depends only on starting and ending SNRs, not the schedule path, but in practice different schedules lead to different gradient variance during training.
- Why unresolved: While the paper mentions this practical issue and references techniques to learn schedules that minimize variance, it doesn't provide a complete theoretical framework for understanding how schedules affect gradient variance or methods to learn optimal schedules.
- What evidence would resolve it: Empirical studies comparing training dynamics under different schedules with theoretical analysis of variance reduction properties, plus proposed methods for learning optimal schedules.

### Open Question 3
- Question: What is the precise relationship between the DDPM training objective and denoising score matching, and how does this connection inform the design of better generative models?
- Basis in paper: [explicit] The paper establishes a clear connection between the simplified DDPM objective and denoising score matching, noting that training involves adding noise to clean data and having the network estimate this noise.
- Why unresolved: While the connection is noted, the paper doesn't fully explore how this relationship can be leveraged to design improved generative models or understand the theoretical properties of DDPMs through the lens of score matching.
- What evidence would resolve it: Theoretical work showing how score matching principles can guide DDPM architecture design, and empirical validation that score matching-inspired modifications improve DDPM performance.

## Limitations

- The framework relies heavily on Gaussian assumptions for both noising and denoising processes, which may not generalize well to non-Gaussian settings
- The paper provides theoretical derivations but limited empirical validation across diverse domains and datasets
- The connection between DDPMs and denoising score matching is established but not fully explored for practical model improvements

## Confidence

- **High Confidence**: The mathematical derivation of the 6-step framework and the basic mechanism of converting generative modeling to regression problems through noise augmentation.
- **Medium Confidence**: The effectiveness of parameter sharing across fidelity levels and the impact of different parameterization choices (x(0) vs ϵ).
- **Low Confidence**: The generalizability of the approach to non-Gaussian distributions and the robustness of the framework to different architectural choices beyond the basic U-Net structure.

## Next Checks

1. Implement a controlled experiment comparing variance-preserving vs. variance-exploding noise schedules on a simple dataset (e.g., 2D Gaussian mixture) to empirically validate the theoretical claims about noise schedule selection.

2. Test the framework with non-Gaussian denoising models (e.g., Laplacian or Student-t based) to assess the robustness of the analytic averaging mechanism and identify conditions under which it breaks down.

3. Conduct ablation studies on the parameter tying mechanism by training separate models at each fidelity level and comparing against the shared-parameter approach on a standard benchmark (e.g., CIFAR-10) to quantify the benefits and limitations of parameter sharing.