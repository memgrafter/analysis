---
ver: rpa2
title: 'Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured
  State Space Models'
arxiv_id: '2403.17902'
source_url: https://arxiv.org/abs/2403.17902
tags:
- image
- state
- ssms
- serpent
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Serpent is an efficient image restoration architecture that combines
  structured state space models (SSMs) with multi-scale signal processing. The key
  innovation is replacing traditional convolutional and attention-based building blocks
  with SSMs that maintain a global receptive field while scaling linearly with input
  size.
---

# Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured State Space Models

## Quick Facts
- **arXiv ID:** 2403.17902
- **Source URL:** https://arxiv.org/abs/2403.17902
- **Reference count:** 26
- **Primary result:** Achieves state-of-the-art image restoration quality with up to 150× less compute and 5× less GPU memory than transformer-based methods

## Executive Summary
Serpent is a novel image restoration architecture that replaces traditional convolutional and attention-based building blocks with Structured State Space Models (SSMs). The key innovation is leveraging SSMs' ability to maintain a global receptive field while scaling linearly with input size, enabling efficient processing of high-resolution images. The architecture processes images hierarchically through downsampling and upsampling blocks, converting images into sequences processed by SSMs in four directional scans. Experimental results demonstrate that Serpent achieves state-of-the-art reconstruction quality while requiring significantly less computational resources compared to transformer-based methods, particularly at high resolutions.

## Method Summary
Serpent combines multi-scale signal processing with SSMs to create an efficient image restoration architecture. The model processes images hierarchically by reducing spatial dimensions while increasing channel depth, creating a bottleneck that forces compact representation learning. Images are converted into sequences through directional unrolling (four directions) and processed by separate SSMs. The architecture includes downsampling blocks (combining SSM processing with patch merging), upsampling blocks (combining SSM processing with patch expansion), and skip connections to preserve fine details. The model maintains a compact parameter count while achieving superior performance across various image restoration tasks.

## Key Results
- Achieves state-of-the-art reconstruction quality on Gaussian deblurring while requiring up to 150× less compute (FLOPS) than transformer-based methods
- Uses 5× less GPU memory compared to SwinIR, enabling training at higher resolutions with limited hardware
- On 512×512 Gaussian deblurring, Serpent-L outperforms SwinIR-B in every quality metric while reducing computational cost by a factor of 40
- Maintains less than half the parameters of comparable transformer approaches

## Why This Works (Mechanism)

### Mechanism 1
SSMs provide global receptive field with linear computational scaling. SSMs maintain a hidden state that compresses information about past inputs, allowing each new input to interact with any previous element through this low-dimensional state. This creates global dependencies while maintaining O(n) complexity instead of O(n²) like attention. Core assumption: The discretization of continuous-time linear systems effectively captures long-range dependencies when processed in CNN mode as convolution.

### Mechanism 2
Multi-scale processing with patch merging/expansion enables efficient high-resolution image restoration. The architecture processes images hierarchically by reducing spatial dimensions while increasing channel depth, creating a bottleneck that forces compact representation learning. Skip connections preserve fine details lost during downsampling. Core assumption: The multi-scale pyramid structure effectively captures both local and global features necessary for restoration.

### Mechanism 3
Directional unrolling converts 2D images into sequences suitable for SSM processing. The image is flattened along four directions (top-left to bottom-right, top-right to bottom-left, and both opposite directions) and processed by separate SSMs. This captures directional dependencies that would be lost in naive flattening. Core assumption: Four-directional scanning captures sufficient image structure for restoration tasks.

## Foundational Learning

- **State Space Models and their discretization**: Understanding how continuous-time systems are discretized into SSMs is crucial for grasping the computational efficiency claims. Quick check: What mathematical operation allows SSMs to be computed efficiently in CNN mode versus RNN mode?

- **Multi-scale signal processing and U-Net architecture**: The hierarchical processing and skip connections are central to the architecture's effectiveness. Quick check: How does the bottleneck in a U-Net-style architecture force the model to learn more compact representations?

- **Directional sequence processing for 2D data**: Understanding why four-directional unrolling is necessary for applying 1D SSMs to 2D images. Quick check: What information might be lost if we only processed images along a single direction?

## Architecture Onboarding

- **Component map:** Input → Patchifier → Downsampling path (S-block D) → Bottleneck → Upsampling path (S-block U) → Output
- **Critical path:** Input → Patchifier → Downsampling path (S-block D) → Bottleneck → Upsampling path (S-block U) → Output
- **Design tradeoffs:**
  - Patch size P: Larger P increases speed but may lose fine details; smaller P preserves details but increases computation
  - Number of VSS blocks n: More blocks increase capacity but also computation and memory
  - Hidden dimension in SSM: Higher dimensions capture more context but increase parameters and computation
- **Failure signatures:**
  - If PSNR/SSIM is low but LPIPS is reasonable: Model may be capturing structure but missing perceptual quality
  - If GPU memory usage is unexpectedly high: May indicate inefficient SSM implementation or too many channels at bottleneck
  - If training is very slow: Could be due to small batch size or inefficient directional unrolling implementation
- **First 3 experiments:**
  1. Verify directional unrolling: Compare performance with 1, 2, and 4 directions to confirm the importance of multi-directional processing
  2. Test patch size scaling: Run with P=4, 2, and 1 to confirm the claimed efficiency gains at higher resolutions
  3. Compare with pure convolutional baseline: Implement a U-Net with same number of parameters to isolate the benefits of SSMs vs. convolutional layers

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does Serpent perform on other image restoration tasks beyond Gaussian deblurring, such as super-resolution, inpainting, and compression artifact removal?
- **Basis in paper:** The authors state "In future work, we plan to perform an in-depth empirical study on multiple image degradations (superresolution, inpainting, motion blur etc.)" indicating this has not yet been evaluated.
- **Why unresolved:** The current evaluation only covers Gaussian deblurring on FFHQ dataset. The paper's results section focuses exclusively on this single task and resolution setting.
- **What evidence would resolve it:** Systematic evaluation of Serpent across diverse image restoration benchmarks (DIV2K, Set5, etc.) for multiple degradation types with quantitative metrics (PSNR, SSIM, LPIPS) and comparison to state-of-the-art methods.

### Open Question 2
- **Question:** What is the theoretical relationship between patch size, embedding dimension, and information retention in Serpent?
- **Basis in paper:** The authors note "However, as patches are mapped to the same channel dimension D, some information may be fundamentally lost with larger patch sizes" but don't provide analysis of this trade-off.
- **Why unresolved:** The paper observes this limitation but doesn't quantify the information loss or provide theoretical bounds on the relationship between patch size and reconstruction quality.
- **What evidence would resolve it:** Mathematical analysis or empirical study demonstrating how reconstruction quality degrades with increasing patch size, and whether there's a minimum patch size below which information loss becomes negligible.

### Open Question 3
- **Question:** How does Serpent scale to even higher resolutions (e.g., 1024×1024 or 2048×2048) and what are the practical limitations?
- **Basis in paper:** The authors mention that at 512× resolution, SwinIR-L cannot be trained with batch size 1 on 80GB GPUs, suggesting memory constraints at higher resolutions, but don't test Serpent beyond 512×.
- **Why unresolved:** The current experiments stop at 512× resolution, and while memory efficiency is demonstrated, there's no data on performance at resolutions an order of magnitude larger.
- **What evidence would resolve it:** Training and evaluation of Serpent models on 1024×1024 and 2048×2048 resolution images, measuring both reconstruction quality and memory/compute scaling behavior.

## Limitations
- Efficiency claims rely on implementation-specific details of SSMs that may vary across hardware
- Experimental comparisons focus on specific tasks and resolutions, limiting generalization assessment
- Directional unrolling strategy lacks comprehensive ablation studies across different image content types
- Patch merging strategy may not be optimal for tasks requiring precise pixel-level accuracy

## Confidence
- **High confidence:** Architectural design principles and multi-scale structure effectiveness
- **Medium confidence:** Efficiency claims (implementation-dependent)
- **Low confidence:** Optimality of directional unrolling and patch merging strategies

## Next Checks
1. **Directional Ablation Study:** Systematically test performance with 1, 2, 3, and 4 directional scans across multiple image restoration tasks to determine if four directions is truly optimal or if fewer directions suffice for certain tasks.

2. **Cross-Domain Generalization:** Evaluate Serpent on non-restoration tasks such as semantic segmentation or object detection to verify whether the SSM-based multi-scale architecture provides benefits beyond image restoration.

3. **Implementation-Independent Efficiency Analysis:** Compare theoretical FLOPS with actual wall-clock time and memory usage across different hardware configurations (CPU, GPU, TPU) to validate that the claimed efficiency gains are not implementation-specific.