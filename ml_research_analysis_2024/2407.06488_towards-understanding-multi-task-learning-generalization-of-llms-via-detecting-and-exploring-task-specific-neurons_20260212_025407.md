---
ver: rpa2
title: Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting
  and Exploring Task-Specific Neurons
arxiv_id: '2407.06488'
source_url: https://arxiv.org/abs/2407.06488
tags:
- neurons
- tasks
- task
- task-specific
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how task-specific neurons in large language
  models (LLMs) contribute to multi-task learning and generalization. The authors
  identify neurons that are highly correlated with specific tasks using gradient attribution,
  and then study how these neurons impact model performance through fine-tuning and
  deactivation experiments.
---

# Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons

## Quick Facts
- arXiv ID: 2407.06488
- Source URL: https://arxiv.org/abs/2407.06488
- Authors: Yongqi Leng; Deyi Xiong
- Reference count: 40
- Key outcome: This paper investigates how task-specific neurons in large language models (LLMs) contribute to multi-task learning and generalization.

## Executive Summary
This paper explores how task-specific neurons in large language models contribute to multi-task learning and generalization. The authors develop a method to identify neurons highly correlated with specific tasks using gradient attribution, then analyze how these neurons affect model performance through fine-tuning and deactivation experiments. Their analysis reveals that the overlap of task-specific neurons across tasks strongly correlates with cross-task generalization, and that parameter similarity in certain layers is associated with generalization performance. Based on these insights, they propose a neuron-level continuous fine-tuning method (NCFT) that selectively updates task-specific neurons during sequential learning, effectively mitigating catastrophic forgetting compared to baseline approaches.

## Method Summary
The authors use gradient attribution on task-specific data to identify task-sensitive neurons in LLMs, demonstrating that these neurons are highly correlated with their respective tasks. They conduct deactivation and fine-tuning experiments to validate neuron importance, then analyze generalization through overlap rates of task-specific neurons and parameter similarity across layers. The proposed neuron-level continuous fine-tuning method (NCFT) selectively updates task-specific neurons during sequential learning to mitigate catastrophic forgetting, with a weighted variant (W-NCFT) that adjusts updates based on task similarity.

## Key Results
- Task-specific neurons identified via gradient attribution are highly correlated with their respective tasks
- Overlap of task-specific neurons across tasks is strongly associated with cross-task generalization performance
- Parameter similarity of task-specific neurons at certain layers correlates with generalization results
- NCFT method effectively mitigates catastrophic forgetting compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-specific neurons exist in LLMs and are highly correlated with specific tasks.
- Mechanism: Neurons are identified by gradient attribution on task-specific data; neurons with highest relevance scores are deemed task-specific. Deactivation and fine-tuning experiments show these neurons have outsized impact on task performance compared to random neurons.
- Core assumption: Gradient attribution scores accurately reflect neuron importance for a given task.
- Evidence anchors:
  - [abstract] "detect task-sensitive neurons in LLMs via gradient attribution on task-specific data" and "demonstrate that the detected neurons are highly correlated with the given task"
  - [section] "we employ the gradient attribution method to quantify each neuron's relevance score for a given task" and "Results of extensive experiments show that task-related neurons are indeed present in LLMs"
  - [corpus] Weak: corpus contains related work on neuron-level analysis but not direct evidence of gradient attribution for task-specific neuron detection in this paper.

### Mechanism 2
- Claim: Overlap of task-specific neurons across tasks is strongly associated with cross-task generalization.
- Mechanism: When training on multiple tasks, neurons that are task-specific for one task may overlap with neurons task-specific for another task. Higher overlap rate leads to better generalization performance on unseen tasks.
- Core assumption: Overlap of task-specific neurons reflects shared knowledge or transferable representations between tasks.
- Evidence anchors:
  - [abstract] "we find that the overlap of task-specific neurons is strongly associated with generalization and specialization across tasks"
  - [section] "we find a continuous increasing trend for the performance of generalization... The overlap rate of task-specific neurons between the training and test tasks can be found in Appendix A.6, where it becomes evident that as the proportion of trained task-specific neurons increases, the overlap rate also experiences a significant surge"
  - [corpus] Weak: corpus has related work on task interference and neuron analysis but not direct evidence of overlap-rate-generalization correlation.

### Mechanism 3
- Claim: Parameter similarity of task-specific neurons at certain layers is highly correlated with generalization performance.
- Mechanism: Cosine similarity between task-specific neuron parameters of different tasks is computed across layers. Higher similarity at certain layers correlates with better generalization performance on test tasks.
- Core assumption: Parameter similarity reflects knowledge sharing or transfer between tasks at the neural level.
- Evidence anchors:
  - [abstract] "at certain layers of LLMs, there is a high similarity between other task-specific neuron parameters and the task-specific neuron parameters of the task to be generalized, which suggests that LLMs learn to share knowledge between tasks, and that this similarity is highly correlated with the generalization results"
  - [section] "we also compute the correlation coefficient between this parameter similarity and the performance on the corresponding test set, aiming to further demonstrate the association between parameter similarity and generalization"
  - [corpus] Weak: corpus has related work on neuron similarity and knowledge transfer but not direct evidence of layer-wise parameter similarity correlating with generalization.

## Foundational Learning

- Concept: Gradient attribution and its use in identifying important neurons.
  - Why needed here: The paper uses gradient attribution to score neurons for task-specificity; understanding this method is crucial for interpreting the neuron identification process.
  - Quick check question: What does a high gradient attribution score for a neuron indicate about its importance to a task?

- Concept: Catastrophic forgetting in continual learning.
  - Why needed here: The proposed NCFT method aims to mitigate catastrophic forgetting by isolating task-specific neurons; understanding forgetting mechanisms is key to evaluating this approach.
  - Quick check question: What causes catastrophic forgetting in sequential task learning, and how does parameter isolation help prevent it?

- Concept: Cosine similarity as a measure of parameter similarity.
  - Why needed here: The paper computes cosine similarity between task-specific neuron parameters to assess knowledge sharing; understanding this metric is essential for interpreting the results.
  - Quick check question: How does cosine similarity between two parameter vectors capture their directional alignment, and why is this useful for comparing neurons?

## Architecture Onboarding

- Component map: Transformer-based LLM (Llama-2-7b, Bloom-7b1) with multi-head self-attention (MHA) and feed-forward network (FFN) layers. FFN module focus: each neuron is a column in weight matrices W1 or W2. Task-specific neurons identified via gradient attribution on task-specific data.

- Critical path: 1) Compute gradient attribution scores for all neurons on task-specific data. 2) Select top-k% neurons as task-specific for each task. 3) Conduct deactivation and fine-tuning experiments to validate task-specificity. 4) Analyze overlap rates and parameter similarities across tasks. 5) Propose and evaluate NCFT method for continual learning.

- Design tradeoffs: Using gradient attribution for neuron identification trades computational cost (scoring all neurons) for interpretability. Fine-tuning only task-specific neurons reduces interference but may limit model capacity for complex tasks. Parameter isolation helps with forgetting but may reduce knowledge sharing between tasks.

- Failure signatures: If gradient attribution scores are noisy or uninformative, neuron identification will be unreliable. If task-specific neurons are not concentrated enough, selective fine-tuning may have minimal impact. If overlap rates or parameter similarities do not correlate with generalization, the proposed mechanisms are invalid.

- First 3 experiments:
  1. Implement gradient attribution scoring for all neurons on a small classification task, verify that top-scoring neurons correspond to known task-relevant features.
  2. Conduct deactivation experiment on identified task-specific neurons, compare performance drop to random neuron deactivation.
  3. Measure overlap rates between task-specific neurons of two related tasks (e.g., sentiment classification and paraphrase detection), assess correlation with zero-shot generalization performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the task-specific neuron overlap mechanism generalize across fundamentally different task types beyond the classification-generation dichotomy studied?
- Basis in paper: [inferred] The paper shows overlap correlates with generalization within classification tasks and within generation tasks, but not between these categories. This suggests task similarity might be task-type-dependent.
- Why unresolved: The analysis was limited to these two categories. The paper didn't test overlap effects on other task types like reasoning, math, or code generation.
- What evidence would resolve it: Testing the overlap-generalization correlation on diverse task types (e.g., arithmetic, logical reasoning, code completion) would reveal whether the mechanism is universal or constrained to specific task families.

### Open Question 2
- Question: How do task-specific neurons behave in larger models or when scaling model capacity?
- Basis in paper: [explicit] The study used Llama-2-7B and Bloom-7B1, but scaling effects on neuron specialization weren't explored.
- Why unresolved: The paper doesn't address how neuron specialization changes with model size, which could impact the validity of their findings for larger LLMs.
- What evidence would resolve it: Repeating the task-specific neuron identification and analysis on larger models (e.g., 70B+ parameter models) would show if the overlap-generalization relationship holds or changes with scale.

### Open Question 3
- Question: What is the optimal dynamic weighting strategy for task-specific neurons during continuous learning?
- Basis in paper: [explicit] The W-NCFT method uses static similarity-based weighting, but the authors note dynamic weighting during training could yield better results.
- Why unresolved: The paper only explores static weighting and acknowledges this as a limitation, but doesn't test or propose specific dynamic approaches.
- What evidence would resolve it: Implementing and comparing different dynamic weighting strategies (e.g., online similarity updates, attention-based weighting, or meta-learning approaches) during training would identify optimal methods for mitigating catastrophic forgetting.

## Limitations
- The paper relies heavily on gradient attribution for neuron identification without direct validation of its accuracy in capturing true task importance
- The causal relationship between neuron overlap and generalization remains unclear, with correlation evidence being weak in the corpus
- The effectiveness of the NCFT method depends critically on accurate neuron identification, which the paper does not adequately address for failure modes

## Confidence
- **Neuron Identification via Gradient Attribution (Low Confidence)**: The core assumption that gradient attribution scores accurately reflect neuron importance for specific tasks lacks direct validation.
- **Overlap-Generalization Association (Medium Confidence)**: The paper provides evidence of correlation between neuron overlap and generalization performance, but the causal mechanism remains unclear.
- **Parameter Similarity-Generalization Correlation (Medium Confidence)**: The analysis of parameter similarity across layers shows correlation with generalization, but the functional significance is not established.
- **NCFT Method Effectiveness (Medium Confidence)**: The proposed method shows promise in mitigating catastrophic forgetting, but its success depends critically on accurate neuron identification and isolation.

## Next Checks
1. **Gradient Attribution Validation**: Conduct controlled experiments where neurons known to be task-relevant (e.g., from prior work or synthetic tasks) are scored using the gradient attribution method. Compare attribution scores against ground truth importance to assess accuracy and reliability of the identification process.

2. **Causal Overlap Analysis**: Design experiments that manipulate neuron overlap rates between tasks independently of other factors (e.g., by artificially increasing overlap through parameter sharing) and measure the direct impact on generalization performance. This would test whether overlap is causal rather than merely correlational.

3. **Architecture Generalization Test**: Apply the same analysis pipeline to different LLM architectures (e.g., GPT, OPT, or smaller transformer variants) and task types (e.g., code generation, reasoning tasks) to assess whether the observed mechanisms are universal or architecture-specific.