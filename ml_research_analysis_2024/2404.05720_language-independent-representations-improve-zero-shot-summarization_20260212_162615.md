---
ver: rpa2
title: Language-Independent Representations Improve Zero-Shot Summarization
arxiv_id: '2404.05720'
source_url: https://arxiv.org/abs/2404.05720
tags:
- language
- zero-shot
- finetuning
- summarization
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Catastrophic forgetting during finetuning prevents zero-shot cross-lingual
  transfer for summarization. To address this, we propose Query-Key (QK) finetuning
  to selectively update task-specific attention weights while preserving language
  generation abilities.
---

# Language-Independent Representations Improve Zero-Shot Summarization

## Quick Facts
- **arXiv ID**: 2404.05720
- **Source URL**: https://arxiv.org/abs/2404.05720
- **Reference count**: 22
- **Primary result**: QK finetuning with balanced adversarial training improves zero-shot cross-lingual summarization

## Executive Summary
This paper addresses catastrophic forgetting in zero-shot cross-lingual summarization, where finetuning on monolingual data causes models to lose the ability to generate in unseen languages. The authors propose Query-Key (QK) finetuning to selectively update attention weights while preserving language generation abilities, and a balanced adversarial language classifier to enforce language-agnostic representations. Their two-step approach combining QK finetuning and translation finetuning achieves strong results on unseen languages, outperforming standard finetuning methods.

## Method Summary
The authors propose a two-pronged approach to improve zero-shot cross-lingual summarization. First, they introduce Query-Key (QK) finetuning, which selectively updates only the query and key projections in encoder self-attention and cross-attention while freezing value projections to preserve pretrained generation capabilities. Second, they propose a balanced adversarial language classifier that encourages uniform class distribution across languages rather than minimizing cross-entropy with the true language class. The two-step finetuning pipeline involves first finetuning on translation data to establish cross-lingual mapping abilities, then applying QK finetuning on intralingual summarization while maintaining these translation capabilities.

## Key Results
- QK finetuning reduces catastrophic forgetting compared to full finetuning on intralingual zero-shot summarization
- Balanced adversarial training enforces more language-agnostic representations than standard adversarial training
- Two-step approach (translation + QK finetuning) achieves strong cross-lingual zero-shot performance on unseen languages
- QK finetuning combined with balanced adversarial training outperforms both individual approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query-Key (QK) finetuning selectively updates task-specific attention weights while preserving language generation abilities.
- Mechanism: By freezing the value projections and only updating query and key projections in encoder self-attention and cross-attention, the model retains pretrained generation capabilities while adapting to the summarization task.
- Core assumption: Value projections are more critical for maintaining pretrained generation abilities than query and key projections.
- Evidence anchors:
  - [abstract]: "we propose query-key (QK) finetuning to selectively update task-specific attention weights while preserving language generation abilities"
  - [section 3.1]: "we propose a selective finetuning approach, which only updates the query and key projection weights of encoder self-attention and cross-attention"
  - [corpus]: Weak - no direct corpus evidence for this specific claim about value projections being critical

### Mechanism 2
- Claim: Balanced adversarial language classifier enforces language-agnostic representations by encouraging uniform class distribution.
- Mechanism: Instead of minimizing cross-entropy with the true language class, the classifier maximizes KL-divergence between predicted distribution and uniform distribution, forcing representations to be equally similar to all languages.
- Core assumption: Language-agnostic representations require the model to treat all languages equally rather than simply avoiding correct language classification.
- Evidence anchors:
  - [abstract]: "we propose a balanced variant that more directly enforces language-agnostic representations"
  - [section 3.2]: "we propose a balanced adversarial objective... train the encoder such that a language classifier is only able to predict a uniform distribution"
  - [corpus]: Weak - no corpus evidence specifically supporting the uniform distribution approach over standard adversarial training

### Mechanism 3
- Claim: Two-step finetuning (translation + summarization) preserves cross-lingual capabilities while adapting to the target task.
- Mechanism: First finetuning on translation data establishes cross-lingual mapping abilities, then QK finetuning on summarization retains these translation capabilities while learning task-specific knowledge.
- Core assumption: Translation finetuning creates a foundation that can be built upon without catastrophic forgetting of cross-lingual abilities.
- Evidence anchors:
  - [abstract]: "our two-step approach combining QK finetuning and translation finetuning achieves strong results on unseen languages"
  - [section 3.1]: "we first finetune the pretrained model for translation... Then we finetune again on intralingual summarization using our proposed query-key finetuning"
  - [corpus]: Weak - no corpus evidence showing that translation finetuning specifically helps with cross-lingual summarization

## Foundational Learning

- **Concept: Catastrophic forgetting in neural networks**
  - Why needed here: The paper addresses how finetuning on monolingual data causes the model to forget languages not seen during finetuning, which is the core problem being solved.
  - Quick check question: What happens to a neural network's performance on task A when it is finetuned on task B without any special techniques to prevent forgetting?

- **Concept: Adversarial training for domain adaptation**
  - Why needed here: The balanced adversarial language classifier uses adversarial training principles to remove language-specific signals from representations, which is crucial for zero-shot cross-lingual transfer.
  - Quick check question: How does standard adversarial training work to make representations domain-invariant, and what modification does the balanced approach make?

- **Concept: Attention mechanism in transformers**
  - Why needed here: Understanding how query, key, and value projections work in attention is essential for grasping why selectively updating only query and key projections can preserve generation abilities while adapting to summarization.
  - Quick check question: What are the three components of attention in transformers, and what role does each play in the attention computation?

## Architecture Onboarding

- **Component map**: Pretrained multilingual model (mBART) -> Query-key finetuning layer -> Balanced adversarial classifier -> Residual drop (optional) -> Zero-shot evaluation

- **Critical path**: Translation finetuning → QK summarization finetuning → Balanced adversarial training → Residual drop (optional) → Zero-shot evaluation

- **Design tradeoffs**:
  - Selective vs full finetuning: QK finetuning trades some task-specific adaptation for better preservation of pretrained abilities
  - Balanced vs standard adversarial: Balanced approach may be more effective but potentially more computationally expensive
  - Two-step vs single-step: Two-step approach requires more training time but achieves better cross-lingual performance

- **Failure signatures**:
  - Off-target generation (generating wrong language) indicates catastrophic forgetting
  - High probing classifier accuracy indicates insufficient language-agnostic representations
  - Poor performance on unseen languages despite good performance on seen languages suggests incomplete transfer

- **First 3 experiments**:
  1. Compare QK finetuning vs full finetuning on intralingual zero-shot summarization to verify catastrophic forgetting is reduced
  2. Compare balanced adversarial classifier vs standard adversarial classifier using probing analysis to verify more language-agnostic representations
  3. Test two-step finetuning (translation + QK) vs direct QK finetuning on cross-lingual zero-shot summarization to verify cross-lingual capability preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Query-Key finetuning approach generalize to other generation tasks beyond summarization, such as machine translation or dialogue generation?
- Basis in paper: [inferred] The paper concludes by expressing curiosity about the applicability of the QK finetuning and balanced adversarial language classifier methods to other generation tasks.
- Why unresolved: The experiments in the paper are limited to summarization, so it is unclear whether the proposed methods would be equally effective for other types of generation tasks that may have different characteristics.
- What evidence would resolve it: Conducting experiments applying QK finetuning and balanced adversarial training to other generation tasks like machine translation, dialogue generation, or story generation, and comparing the results to standard finetuning approaches.

### Open Question 2
- Question: How do the proposed approaches impact the similarity between model hidden representations of different languages before and after applying the methods?
- Basis in paper: [explicit] The conclusion section mentions the possibility of using Singular Vector Canonical Correlation (SVCCA) to analyze the similarity between model hidden representations of different languages before and after applying the proposed approaches.
- Why unresolved: The paper only uses probing analyses to assess language-specific versus language-independent representations. Directly analyzing the model hidden representations could provide more insights into the impact of the proposed methods on cross-lingual transfer.
- What evidence would resolve it: Computing and comparing the SVCCA similarity scores between model hidden representations of different languages before and after applying QK finetuning and balanced adversarial training, and correlating the changes in similarity with zero-shot performance.

### Open Question 3
- Question: How do the proposed approaches affect the model's ability to generate outputs in the correct target language for languages unseen during finetuning?
- Basis in paper: [explicit] The paper shows that while the balanced adversarial classifier improves zero-shot performance for languages seen during finetuning, it is less effective for languages absent in the finetuning stage, particularly on new target languages.
- Why unresolved: The paper does not explore why the balanced adversarial classifier is less effective for unseen languages and what additional techniques could be used to improve cross-lingual zero-shot generation for these languages.
- What evidence would resolve it: Conducting experiments to analyze the language generation behavior of models finetuned with the proposed approaches for languages unseen during finetuning, and exploring additional techniques such as multi-task learning or meta-learning to improve cross-lingual zero-shot generation for these languages.

## Limitations

- The paper lacks ablation studies to isolate the contributions of QK finetuning versus balanced adversarial training
- Probing classifier only evaluates encoder representations, potentially missing effects on the decoder
- The choice of mBART as base model may limit generalizability to other pretrained multilingual models
- No comparative analysis against simpler approaches like standard adversarial training

## Confidence

- **High Confidence**: The empirical observation that standard finetuning causes catastrophic forgetting in cross-lingual settings
- **Medium Confidence**: QK finetuning improves intralingual zero-shot performance by selectively updating parameters
- **Low Confidence**: The specific mechanism of value projection freezing being critical for generation preservation
- **Medium Confidence**: Balanced adversarial classifier improves cross-lingual performance over standard adversarial training
- **Low Confidence**: Two-step finetuning is necessary rather than sufficient for cross-lingual transfer

## Next Checks

1. Conduct ablation studies comparing: (a) standard full finetuning, (b) QK finetuning with different parameter freezing combinations, (c) standard adversarial training, and (d) balanced adversarial training to isolate individual contributions

2. Implement probing classifiers on both encoder and decoder representations to comprehensively measure language-agnostic properties throughout the model

3. Test the proposed approach on alternative multilingual pretrained models (e.g., mT5, XLM-R) to evaluate generalizability across different model architectures and pretraining objectives