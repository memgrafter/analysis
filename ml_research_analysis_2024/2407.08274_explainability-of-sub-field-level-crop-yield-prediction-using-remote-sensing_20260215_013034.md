---
ver: rpa2
title: Explainability of Sub-Field Level Crop Yield Prediction using Remote Sensing
arxiv_id: '2407.08274'
source_url: https://arxiv.org/abs/2407.08274
tags:
- data
- yield
- attribution
- each
- crop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of interpreting complex deep
  learning models for crop yield prediction using remote sensing data. The researchers
  develop and explain predictive models for soybean, wheat, and rapeseed crops in
  Argentina, Uruguay, and Germany using satellite images, additional data modalities,
  and crop yield maps.
---

# Explainability of Sub-Field Level Crop Yield Prediction using Remote Sensing

## Quick Facts
- arXiv ID: 2407.08274
- Source URL: https://arxiv.org/abs/2407.08274
- Authors: Hiba Najjar; Miro Miranda; Marlon Nuske; Ribana Roscher; Andreas Dengel
- Reference count: 40
- One-line primary result: The study develops interpretable deep learning models for crop yield prediction using remote sensing data, identifying critical growth stages that align with agronomic literature.

## Executive Summary
This study addresses the challenge of interpreting complex deep learning models for crop yield prediction using remote sensing data. The researchers develop predictive models for soybean, wheat, and rapeseed crops in Argentina, Uruguay, and Germany using satellite images, additional data modalities, and crop yield maps. They employ a long short-term memory (LSTM) network and investigate the impact of different temporal samplings of satellite data and the addition of relevant modalities. For model explainability, they utilize feature attribution methods to quantify input feature contributions, identify critical growth stages, analyze yield variability at the field level, and explain less accurate predictions.

## Method Summary
The study develops LSTM models for sub-field level crop yield prediction using Sentinel-2 satellite data, additional data sources (weather, soil, terrain), and yield maps from Argentina, Uruguay, and Germany. The methodology involves temporal sampling strategies (raw vs monthly), cross-validation training, and Shapley value sampling (SVS) for feature attribution. The approach aggregates attributions over growth stages to improve interpretability and compares model performance with and without additional modalities.

## Key Results
- Model performance improves when adding more modalities (soil, weather, terrain) or using all available instances of satellite data
- SVS produces more stable and interpretable attribution maps compared to other XAI methods
- Critical growth stages identified through attribution closely align with existing agronomic literature
- Distinct feature importance patterns emerge for each crop and region, with the most influential growth stages dependent on temporal sampling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aggregating feature attributions over growth stages improves interpretability by aligning temporal patterns with agronically meaningful periods.
- Mechanism: Raw attribution time steps are unevenly distributed across fields due to variable growing periods. Aggregating by BBCH or modified growth stages normalizes this variance, enabling meaningful comparison across crops and regions.
- Core assumption: The temporal distribution of satellite data samples correlates with key biological growth stages, and model attention aligns with these stages.
- Evidence anchors:
  - [section] "We further define for each growth stage tgs a set Tgs of the time steps it covers, then compute the total attribution as follows..."
  - [abstract] "We demonstrated how these critical growth stages, which hold significant agronomic value, closely align with the existing literature in agronomy and crop development biology."
- Break Condition: If the model learns spurious temporal patterns unrelated to growth stages, or if growth stage boundaries do not align with satellite revisit schedules.

### Mechanism 2
- Claim: Using Shapley Value Sampling (SVS) yields more stable and interpretable attribution maps than other XAI methods.
- Mechanism: SVS approximates Shapley values through feature sampling, inherently accounting for feature interactions and producing smoother spatial attribution maps. This stability allows for reliable identification of influential spectral bands and growth stages.
- Core assumption: Feature interactions are non-negligible in the yield prediction task, and neighboring pixels should have similar attributions due to shared input features.
- Evidence anchors:
  - [section] "We observe that only SVS produces a smooth attribution map, in contrast to the other attribution techniques where the results show pronounced spatial fluctuations."
  - [section] "Shapley values inherently accounts for feature interactions by approximating the impact of a feature when added to all possible subsets of the remaining features."
- Break Condition: If the computational cost of SVS becomes prohibitive for larger datasets, or if feature independence assumptions improve performance.

### Mechanism 3
- Claim: Adding more modalities (soil, weather, terrain) improves model performance and shifts spectral importance toward non-satellite features.
- Mechanism: Additional data sources provide complementary information about yield drivers not captured by satellite imagery alone. The model learns to weigh these sources differently across crops and regions, improving accuracy.
- Core assumption: Yield is influenced by factors beyond vegetation status detectable by satellite, such as soil properties and weather conditions.
- Evidence anchors:
  - [section] "We notice that while S2 accounts for nearly half of the attributions in Argentina, and around 40% in Uruguay, it contributes only about 25% of the total attribution in rapeseed and wheat datasets."
  - [section] "Analyzing the impact of enriching the satellite data with additional modalities...reveals an overall improvement in the results across all datasets."
- Break Condition: If additional modalities introduce noise or redundancy, degrading model performance.

## Foundational Learning

- Concept: LSTM networks for time series
  - Why needed here: The yield prediction task requires modeling temporal dependencies in satellite image sequences across growing seasons.
  - Quick check question: How does an LSTM cell maintain memory across time steps, and why is this important for capturing crop growth patterns?

- Concept: Feature attribution methods (SHAP, LIME, Integrated Gradients)
  - Why needed here: Explaining complex deep learning models requires quantifying input feature contributions to individual predictions.
  - Quick check question: What is the key difference between perturbation-based and gradient-based attribution methods, and when might each be preferred?

- Concept: Vegetation indices (NDVI, EVI, etc.)
  - Why needed here: These indices combine spectral bands into agronically meaningful metrics, potentially improving both model performance and interpretability.
  - Quick check question: How does NDVI relate to plant health, and what spectral bands does it combine?

## Architecture Onboarding

- Component map:
  - Input: Satellite time series (B01-B12), soil properties, weather data, DEM features
  - Preprocessing: Temporal sampling (raw vs monthly), padding, normalization
  - Model: Stacked LSTM (128 units × 2 layers, 0.3 dropout), linear layers with batch norm
  - Output: Yield prediction per pixel
  - Explainability: SVS attribution with mean baseline, aggregation over growth stages

- Critical path:
  1. Data preprocessing and temporal sampling
  2. Model training with cross-validation
  3. Attribution computation on best-performing fold
  4. Aggregation and analysis of attributions

- Design tradeoffs:
  - Raw vs monthly temporal sampling: Raw captures more temporal detail but creates variable sequence lengths; monthly ensures consistency but may miss short-term patterns.
  - Full spectral bands vs vegetation indices: Full bands provide more information but are harder to interpret; indices are interpretable but may lose information.
  - SVS vs faster methods: SVS is more stable but computationally expensive; faster methods may be less reliable.

- Failure signatures:
  - High attribution variance across neighboring pixels suggests unstable attributions
  - Low R² scores with no correlation between attribution distance and performance suggest model failure
  - Attribution maps that don't align with known growth stages suggest spurious learning

- First 3 experiments:
  1. Train baseline model on Argentina soybean dataset with raw temporal sampling; compare performance with monthly sampling.
  2. Replace satellite bands with vegetation indices; measure performance degradation and analyze attribution changes.
  3. Add additional modalities (soil, weather, DEM); measure performance improvement and analyze shift in spectral importance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of different temporal sampling strategies on the model's ability to capture crop-specific growth stages and yield prediction accuracy?
- Basis in paper: [explicit] The paper investigates the impact of using raw time-series and monthly sampling approaches on the model's performance and attribution results.
- Why unresolved: While the paper compares these two strategies, it does not provide a definitive answer on which approach is superior for capturing crop-specific growth stages and improving yield prediction accuracy.
- What evidence would resolve it: Further analysis comparing the model's performance and attribution results across different temporal sampling strategies for various crops and regions would provide insights into the optimal approach.

### Open Question 2
- Question: How do the contributions of additional data sources (ADS) such as soil, weather, and terrain elevation features vary across different crops and regions?
- Basis in paper: [explicit] The paper analyzes the importance of ADS features and their contribution to the model's performance and attribution results.
- Why unresolved: The paper provides a general overview of the importance of ADS features, but it does not delve into the specific variations across different crops and regions.
- What evidence would resolve it: Detailed analysis of the importance of ADS features for each crop and region, along with their correlation with yield prediction accuracy, would provide a comprehensive understanding of their contributions.

### Open Question 3
- Question: What is the relationship between the model's ability to capture in-field yield variability and its overall performance?
- Basis in paper: [inferred] The paper discusses the importance of capturing in-field yield variability and analyzes the attribution maps to identify features that contribute to this variability.
- Why unresolved: While the paper identifies features that capture in-field variability, it does not establish a clear relationship between this variability and the model's overall performance.
- What evidence would resolve it: Further analysis correlating the model's ability to capture in-field variability with its performance metrics, such as R² and RMSE, would provide insights into the importance of this variability for accurate yield prediction.

## Limitations

- The study focuses on three crops in three regions, limiting generalizability to other crops, climates, or agricultural systems.
- The computational expense of SVS limits testing of alternative attribution methods that might be more efficient.
- Confidence in attributing specific growth stages as "critical" depends on the assumption that model attention aligns with biological reality, which is not independently validated through agronomic experiments.

## Confidence

- **High confidence**: Model performance improvements with additional modalities and temporal sampling methods (Section 4.1)
- **Medium confidence**: Attribution stability and smoothness of SVS compared to other methods (Section 4.2.1)
- **Medium confidence**: Identification of critical growth stages based on feature attributions (Section 4.2.2)
- **Low confidence**: Direct agronomic validity of critical growth stages without experimental validation

## Next Checks

1. **Cross-method attribution comparison**: Implement and compare attributions from Integrated Gradients and LIME alongside SVS to verify stability of identified critical growth stages across methods.

2. **Out-of-region generalization test**: Train models on one region's data (e.g., Argentina) and test on another region (e.g., Germany) to assess whether identified critical growth stages are crop-specific or region-dependent.

3. **Ablation study on temporal sampling**: Systematically remove satellite data from different growth stages and measure impact on prediction accuracy to validate whether attributed "critical" stages actually influence model performance.