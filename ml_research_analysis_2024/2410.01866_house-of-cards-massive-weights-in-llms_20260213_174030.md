---
ver: rpa2
title: 'House of Cards: Massive Weights in LLMs'
arxiv_id: '2410.01866'
source_url: https://arxiv.org/abs/2410.01866
tags:
- massive
- weights
- activations
- llms
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates massive activations in large language models,
  where certain feature dimensions exhibit unexpectedly large magnitudes. The authors
  trace these activations to the intermediate state of feed-forward networks in early
  layers, then define "massive weights" as the rows of projection matrices (Wup and
  Wgate) contributing to these activations.
---

# House of Cards: Massive Weights in LLMs

## Quick Facts
- arXiv ID: 2410.01866
- Source URL: https://arxiv.org/abs/2410.01866
- Reference count: 40
- Primary result: Zero-shot performance improves when dropout targets "massive weights" during parameter-efficient fine-tuning

## Executive Summary
This paper identifies "massive weights" - specific rows in feed-forward network projection matrices that produce unexpectedly large activations in LLMs. The authors demonstrate that these weights are critical for model performance, showing that zeroing them severely degrades functionality while retaining only massive weights preserves model behavior. Based on this discovery, they propose MacDrop, a curriculum dropout method that selectively applies dropout to massive weights during fine-tuning, starting with high dropout probability and gradually decreasing it. Experiments show MacDrop improves zero-shot downstream task performance and robustness against attacks, particularly when combined with LoRA or DoRA.

## Method Summary
The authors trace massive activations to the intermediate state of feed-forward networks in early layers, defining massive weights as rows of Wup and Wgate projection matrices contributing to these activations. They propose MacDrop, which applies dropout to massive weights during parameter-efficient fine-tuning with a curriculum schedule: high dropout probability at the start that gradually decreases. The method targets the rows in Wup and Wgate matrices that contribute to massive activations, while standard dropout continues to operate on all other parameters. MacDrop is evaluated both as a standalone method and in combination with existing parameter-efficient fine-tuning techniques like LoRA and DoRA.

## Key Results
- Zeroing massive weights severely degrades model performance, while retaining only massive weights preserves functionality
- MacDrop improves zero-shot downstream task performance compared to standard dropout
- MacDrop enhances robustness against adversarial attacks, particularly when combined with LoRA or DoRA
- The method shows particular effectiveness for long-context tasks

## Why This Works (Mechanism)
The paper's mechanism centers on the identification of massive weights - specific weight rows that produce abnormally large activations in early layers of LLMs. These massive weights create a dependency where the model's performance is disproportionately reliant on a small subset of parameters. By applying curriculum dropout specifically to these critical weights, MacDrop forces the model to gradually redistribute importance across other parameters during fine-tuning, improving generalization and robustness while maintaining performance.

## Foundational Learning
- **Massive activations**: Unusually large feature dimensions in intermediate states that the paper traces to specific weight matrices. Why needed: Forms the basis for identifying critical parameters. Quick check: Verify activation distributions show heavy-tailed behavior.
- **Curriculum dropout**: Dropout schedule that starts with high probability and gradually decreases. Why needed: Allows gradual adaptation to weight removal. Quick check: Monitor performance stability during training.
- **Parameter-efficient fine-tuning**: Methods like LoRA and DoRA that update small subsets of parameters. Why needed: Context for MacDrop's integration with existing techniques. Quick check: Compare parameter counts between methods.

## Architecture Onboarding
**Component map**: Input -> Embedding -> Attention -> Feed-forward (Wup, Wgate, Wdown) -> Residual -> Normalization -> Output
**Critical path**: The intermediate state of feed-forward networks where massive activations occur, specifically involving Wup and Wgate projection matrices
**Design tradeoffs**: MacDrop prioritizes robustness and generalization over raw performance by targeting critical weights, versus standard methods that maintain all weights
**Failure signatures**: Performance degradation when massive weights are zeroed, reduced effectiveness on architectures without massive activation phenomena
**First experiments**: 1) Identify massive weights by measuring activation magnitudes, 2) Test performance degradation when zeroing massive weights, 3) Apply MacDrop with curriculum schedule during fine-tuning

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What specific architectural features in Gemma-2 models prevent the formation of massive activations and attention sinks?
- Basis in paper: The paper notes that Gemma-2 models incorporate two additional layer normalization layers after both the attention and feed-forward network modules, and demonstrates that attention sinks are not observed in these models.
- Why unresolved: While the paper identifies architectural differences, it does not provide a mechanistic explanation of how these additional normalization layers prevent massive activations from forming or propagating.
- What evidence would resolve it: Detailed ablation studies systematically removing or modifying the additional normalization layers in Gemma-2 models, combined with analyses of intermediate state distributions, would clarify the causal relationship.

### Open Question 2
- Question: Why do Phi-3 models exhibit different robustness to massive weight attacks depending on their model size, despite similar architectural designs?
- Basis in paper: The paper observes that phi-3-mini (3.8B) maintains performance with fewer massive weights retained compared to phi-3-medium (14B), attributing this to differences in pre-training token counts and dropout usage.
- Why unresolved: The paper suggests dropout usage during longer pre-training might explain the difference, but does not provide empirical evidence or mechanistic explanation for why larger models require more massive weights to maintain performance.
- What evidence would resolve it: Comparative analyses of dropout schedules, pre-training token distributions, and massive weight importance across Phi-3 model sizes would elucidate the relationship between scale, training duration, and massive weight dependency.

### Open Question 3
- Question: How does the position-dependent behavior of bos tokens in triggering massive activations vary across different LLM architectures and training paradigms?
- Basis in paper: The paper demonstrates that bos tokens placed at the starting position always trigger massive activations in Llama-3 models, but exhibit different behaviors in Mistral, Mixtral, and Gemma-2 models depending on their position.
- Why unresolved: The paper identifies position-dependent behavior but does not explore the underlying reasons for architectural differences in how bos tokens influence activation patterns across models.
- What evidence would resolve it: Systematic experiments varying bos token positions across diverse LLM architectures, combined with analyses of attention mechanisms and residual connections, would reveal architectural factors governing position-dependent activation patterns.

## Limitations
- Effectiveness depends on presence of massive activation phenomena, limiting generalizability across all architectures
- The threshold for identifying massive weights may not be robust across different model scales
- Computational overhead of MacDrop curriculum during fine-tuning is not quantified
- Statistical significance of performance improvements across diverse benchmarks is not thoroughly established

## Confidence
- Massive weights are critical for model performance: **High**
- MacDrop improves zero-shot downstream task performance: **Medium**
- MacDrop enhances robustness against attacks: **Medium**
- MacDrop is effective for long-context tasks: **Medium**
- MacDrop's effectiveness depends on massive activation phenomena: **High**

## Next Checks
1. Investigate the sensitivity of massive weight identification thresholds across different model scales and architectures to determine generalizability.
2. Conduct ablation studies to quantify the computational overhead introduced by MacDrop during fine-tuning compared to standard methods.
3. Perform statistical significance testing across a broader set of benchmarks to validate the robustness of performance improvements reported for MacDrop.