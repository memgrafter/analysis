---
ver: rpa2
title: Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving
  User Interest Diversity Fairness
arxiv_id: '2402.13495'
source_url: https://arxiv.org/abs/2402.13495
tags:
- interest
- user
- diversity
- users
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses user interest diversity unfairness in recommender
  systems, where users with broader interests receive lower-quality recommendations.
  The authors propose a multi-interest framework that uses multiple virtual interest
  embeddings instead of single embeddings to represent users.
---

# Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness

## Quick Facts
- arXiv ID: 2402.13495
- Source URL: https://arxiv.org/abs/2402.13495
- Reference count: 40
- Multi-interest framework achieves better fairness-utility trade-off compared to single-embedding baselines

## Executive Summary
This paper addresses the fairness issue in recommender systems where users with broader interests receive lower-quality recommendations due to single embedding limitations. The authors propose a multi-interest framework that generates multiple virtual interest embeddings per user, improving both fairness and recommendation quality. The framework uses stacked representation layers with an interest embedding generator that derives virtual interests from shared parameters and a center embedding aggregator that facilitates multi-hop aggregation. Experiments across multiple datasets demonstrate that the approach achieves significant improvements in both fairness metrics (lower standard deviation across user groups) and utility metrics like Recall and NDCG.

## Method Summary
The proposed multi-interest framework represents users through multiple virtual interest embeddings rather than single embeddings. It consists of stacked multi-interest representation layers, including an interest embedding generator that derives virtual interests from globally shared parameters using attention mechanisms, and a center embedding aggregator that facilitates multi-hop aggregation through an argmax operator. The framework is optimized using Bayesian Personalized Ranking (BPR) loss and demonstrates parameter efficiency through shared global interest parameters. The approach automatically matches the number of active interests to user diversity through attention weights, without requiring explicit supervision.

## Key Results
- Achieves better trade-off between fairness and utility compared to baselines
- Improves fairness metrics (lower standard deviation across user groups) while maintaining high Recall and NDCG
- Provides more diverse recommendations and better embedding alignment
- Demonstrates parameter efficiency through shared global interest parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-interest embeddings improve fairness by better capturing diverse user preferences
- Mechanism: Users with broader interests have lower-quality recommendations because single embeddings cannot adequately represent their diverse preferences. The multi-interest framework generates multiple virtual embeddings per user that better align with different interest clusters, improving recommendation quality for diverse users.
- Core assumption: User interests can be effectively clustered and represented by multiple distinct embeddings
- Evidence anchors:
  - [abstract]: "users with broader interests often receive lower-quality recommendations" and "multi-interest framework that uses multiple (virtual) interest embeddings rather than single ones to represent users"
  - [section 4.1]: "each user is composed of a center embedding representing users' main characteristic and multiple virtual embeddings, reflecting users' interests derived from their interacted items"
  - [corpus]: Weak - corpus neighbors discuss multi-interest learning but don't directly address fairness via diversity

### Mechanism 2
- Claim: Parameter sharing through global interest parameters makes the approach efficient
- Mechanism: Instead of learning separate embeddings for each interest, the framework uses globally shared interest parameters that are combined with center embeddings to generate virtual interests. This avoids the parameter explosion typical of multi-interest approaches while maintaining representational power.
- Core assumption: Global interest parameters can be effectively shared across users with similar interest patterns
- Evidence anchors:
  - [section 4.2.1]: "the virtual embeddings are calculated based on center embeddings via attentions... This mechanism avoids introducing a large number of learnable parameters by sharing the global interest w_k in the attention mechanism"
  - [section E]: "The small number of extra parameters in our model is owing to the design of virtual embedding. We proposed the globally shared parameter w and then computed the virtual embeddings based on the original embedding and shared embedding"
  - [corpus]: Assumption - corpus doesn't explicitly discuss parameter efficiency in multi-interest frameworks

### Mechanism 3
- Claim: Automatic interest number matching through attention improves representation quality
- Mechanism: The attention mechanism in virtual embedding generation automatically assigns different weights to global interest parameters based on their relevance to a user's interactions. This allows the model to implicitly match the number of active interests to a user's diversity without explicit supervision.
- Core assumption: Attention weights can effectively identify relevant interests for each user
- Evidence anchors:
  - [section 4.2.1]: "if an item is related to the k-th interest, the attention will be higher and lead to larger contribution to the aggregates from this item"
  - [section 5.4]: "users with more diverse interests have been assigned a larger interest number, indicating that our model has the ability to distinguish different interest diversity"
  - [corpus]: Assumption - corpus doesn't discuss automatic interest number matching

## Foundational Learning

- Concept: Graph neural networks for recommendation
  - Why needed here: The framework builds on graph-based recommendation backbones (LightGCN, CAGCN*) and extends them with multi-interest capabilities
  - Quick check question: How does LightGCN aggregate neighbor information compared to traditional GCNs?

- Concept: Attention mechanisms for representation learning
  - Why needed here: Attention is used to combine global interest parameters with user embeddings to generate virtual interests
  - Quick check question: What's the difference between self-attention and cross-attention in representation learning?

- Concept: Fairness metrics in recommendation systems
  - Why needed here: The work measures fairness through standard deviation of performance across user groups with different interest diversity
  - Quick check question: How does group-agnostic fairness differ from group-aware fairness in recommendation?

## Architecture Onboarding

- Component map: Input bipartite graph → Multi-interest representation layers (interest embedding generator + center embedding aggregator) → Relevance score calculation → BPR loss optimization
- Critical path: Graph → Virtual embeddings (interest embedding generator) → Center embeddings (center embedding aggregator) → Final embeddings → Relevance scores → Loss
- Design tradeoffs: Parameter efficiency (shared global interests) vs. representational capacity; automatic interest matching vs. explicit supervision; symmetric treatment of users/items vs. asymmetric approaches
- Failure signatures: Performance degradation on users with low interest diversity; increased training time without corresponding accuracy gains; unstable attention weights across training epochs
- First 3 experiments:
  1. Validate that multi-interest framework improves Recall/NDCG on users with high interest diversity compared to single-embedding baselines
  2. Test that parameter sharing doesn't significantly impact performance compared to fully separate embeddings for each interest
  3. Verify that attention weights automatically match interest numbers to user diversity patterns without explicit supervision

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed multi-interest framework perform when applied to sequential recommendation tasks where user preferences evolve over time?
- Basis in paper: [inferred] The paper focuses on static recommendation scenarios and briefly mentions future work exploring temporal splits and interest shifts.
- Why unresolved: The paper does not evaluate the framework's performance on temporal data or investigate how well it adapts to changing user preferences.
- What evidence would resolve it: Experiments comparing the framework's performance on sequential vs. static datasets, or ablation studies showing the impact of incorporating temporal information into the multi-interest representation layers.

### Open Question 2
- Question: What is the optimal number of interest embeddings to use for users with varying levels of interest diversity, and can this number be automatically determined?
- Basis in paper: [explicit] The paper discusses that the framework initially assigns the same number of interests to all users, but experiments show it can automatically adjust the number for users with more diverse interests. However, the trend is not consistent for all user groups.
- Why unresolved: The paper does not provide a definitive answer on the optimal number of interests or a method for automatically determining it based on user interest diversity.
- What evidence would resolve it: Experiments systematically varying the number of interests across different user groups and analyzing the impact on fairness and utility metrics, or developing a method to predict the optimal number of interests based on user behavior.

### Open Question 3
- Question: How does the trade-off between alignment and uniformity in the multi-interest framework impact the recommendation quality, and what strategies can be employed to balance them effectively?
- Basis in paper: [explicit] The paper mentions that while the multi-interest framework improves alignment, it could lead to reduced uniformity, which offsets the anticipated enhancements in utility performance.
- Why unresolved: The paper does not explore the specific impact of this trade-off on recommendation quality or propose strategies to balance alignment and uniformity effectively in the multi-interest setting.
- What evidence would resolve it: Experiments analyzing the relationship between alignment, uniformity, and recommendation performance metrics, or developing regularization techniques or architectural modifications to balance alignment and uniformity in the multi-interest framework.

## Limitations

- The framework assumes user interests can be effectively clustered and represented by multiple distinct embeddings, which may not hold for users with highly specialized or rapidly changing interests
- Parameter sharing through global interest parameters could limit representational capacity for users with unique interest patterns that don't align with global trends
- The approach requires careful tuning of the interest number and attention mechanisms, which may be dataset-dependent and require domain expertise

## Confidence

- **High confidence**: The fairness-utility trade-off improvements are well-supported by experimental results across multiple datasets (ml-1m, epinion, cosmetics, anime)
- **Medium confidence**: The parameter efficiency claims are supported by design rationale but lack extensive ablation studies comparing against fully separate embeddings
- **Medium confidence**: The automatic interest number matching mechanism is demonstrated empirically but not rigorously validated against ground truth interest distributions

## Next Checks

1. Conduct ablation studies comparing parameter efficiency against fully separate embeddings for each interest to quantify the trade-off between efficiency and representational capacity
2. Evaluate model performance on datasets with rapidly changing user interests to test the framework's robustness to temporal dynamics
3. Validate the automatic interest number matching mechanism against ground truth user interest distributions to assess accuracy of the attention-based approach