---
ver: rpa2
title: 'SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated
  Data'
arxiv_id: '2403.06952'
source_url: https://arxiv.org/abs/2403.06952
tags:
- prompts
- selma
- text
- lora
- sdxl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SELMA, a novel approach to improve text-to-image
  (T2I) generation by fine-tuning models on automatically generated, multi-skill image-text
  datasets. SELMA uses an LLM's in-context learning capability to generate diverse
  text prompts that teach different skills, and then generates corresponding images
  with a T2I model.
---

# SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data

## Quick Facts
- arXiv ID: 2403.06952
- Source URL: https://arxiv.org/abs/2403.06952
- Reference count: 40
- Improves text-to-image model faithfulness by +2.1% on TIFA and +6.9% on DSG benchmarks

## Executive Summary
SELMA is a novel approach that improves text-to-image generation by fine-tuning models on automatically generated, multi-skill image-text datasets. The method uses an LLM's in-context learning capability to generate diverse text prompts for different skills, then generates corresponding images with a T2I model. These datasets are used to train skill-specific LoRA experts which are merged into a unified multi-skill model. Experiments demonstrate significant improvements in text faithfulness metrics and human preference scores compared to baselines.

## Method Summary
SELMA generates skill-specific text prompts using GPT-3.5's in-context learning, creates corresponding images with T2I models like Stable Diffusion, and fine-tunes separate LoRA modules for each skill. The skill-specific LoRA experts are then merged using uniform merging to create a unified multi-skill model that can generate faithful images for diverse text prompts. The approach uses auto-generated data that is comparable in effectiveness to ground truth data for fine-tuning.

## Key Results
- Improves TIFA benchmark by +2.1% and DSG benchmark by +6.9% compared to baselines
- Achieves higher human preference metrics including PickScore, ImageReward, and HPS
- Demonstrates comparable performance to fine-tuning with ground truth data using only auto-generated data
- Shows weak-to-strong generalization where SDXL improves by learning from SD v2-generated images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SELMA improves text-to-image model faithfulness by learning skill-specific LoRA experts and merging them.
- Mechanism: The LLM generates diverse prompts for specific skills, images are generated, and separate LoRA modules are trained for each skill. These modules are then merged to create a unified model that mitigates knowledge conflicts.
- Core assumption: Learning separate experts for each skill and then merging them is more effective than joint training on all skills.
- Evidence anchors: [abstract] "Our independent expert fine-tuning specializes multiple models for different skills, and expert merging helps build a joint multi-skill T2I model that can generate faithful images given diverse text prompts, while mitigating the knowledge conflict from different datasets."

### Mechanism 2
- Claim: SELMA's auto-generated data is as effective as ground truth data for fine-tuning.
- Mechanism: The model learns from images it generates itself, leveraging its existing knowledge. This is shown to be comparable to learning from human-collected ground truth data.
- Core assumption: Self-generated images contain sufficient information for the model to learn the desired skills.
- Evidence anchors: [section 5.3] "Fine-tuning with auto-generated data can achieve comparable performance to fine-tuning with ground truth data... our approach results in an average improvement of 1.2% brought by fine-tuning only auto-generated data without any need for human-collected ground truth text-image pairs"

### Mechanism 3
- Claim: SELMA demonstrates weak-to-strong generalization in text-to-image models.
- Mechanism: A stronger T2I model (SDXL) can improve its performance by learning from images generated by a weaker model (SD v2).
- Core assumption: Knowledge transfer is possible from weaker to stronger models in the T2I domain.
- Evidence anchors: [section 5.4] "Weaker T2I models can help stronger T2I models... fine-tuning SDXL with generated images from SD v2 (No.4.) remarkably enhances performance over the SDXL baseline... This approach achieves competitive performance compared with fine-tuning SDXL with SDXL-generated images"

## Foundational Learning

- Concept: In-context learning
  - Why needed here: SELMA uses in-context learning to generate diverse prompts for different skills.
  - Quick check question: How does in-context learning differ from traditional fine-tuning, and why is it suitable for prompt generation in SELMA?

- Concept: LoRA (Low-Rank Adaptation)
  - Why needed here: LoRA is used for efficient fine-tuning of the T2I models on skill-specific data.
  - Quick check question: What are the advantages of LoRA over full fine-tuning, and how does it enable the learning of multiple skill-specific experts?

- Concept: Model merging
  - Why needed here: Model merging is used to combine the skill-specific LoRA experts into a unified multi-skill model.
  - Quick check question: What are the benefits of model merging compared to other approaches like mixture of experts, and how does it help mitigate knowledge conflicts?

## Architecture Onboarding

- Component map:
  - LLM (e.g., GPT-3.5) for prompt generation
  - T2I model (e.g., Stable Diffusion) for image generation
  - LoRA modules for skill-specific fine-tuning
  - Merging mechanism for combining LoRA experts

- Critical path:
  1. Generate diverse prompts using LLM
  2. Generate corresponding images using T2I model
  3. Fine-tune separate LoRA modules on each skill dataset
  4. Merge LoRA modules to create a unified multi-skill model

- Design tradeoffs:
  - Using auto-generated data vs. ground truth data (cost vs. potential quality differences)
  - Separate LoRA experts vs. joint training (specialization vs. efficiency)
  - Merging LoRA experts vs. other fusion methods (simplicity vs. potential limitations)

- Failure signatures:
  - Poor performance on specific skills (indicates issues with individual LoRA training)
  - Degradation in overall performance after merging (indicates knowledge conflicts)
  - High cost or time requirements (indicates inefficiencies in data generation or training)

- First 3 experiments:
  1. Generate prompts and images for a single skill, fine-tune a LoRA module, and evaluate performance on that skill.
  2. Repeat experiment 1 for multiple skills, then merge the LoRA modules and evaluate overall performance.
  3. Compare performance of merged model to a jointly trained model on all skills to validate the effectiveness of the merging approach.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SELMA's performance scale with the number of auto-generated image-text pairs beyond 1K per skill?
- Basis in paper: [explicit] The paper states SELMA uses 1K prompts per skill and compares this to DreamSync's 28K prompts, but does not explore intermediate dataset sizes or performance saturation points.
- Why unresolved: The paper only evaluates SELMA with a fixed 1K prompts per skill, leaving open whether larger datasets provide diminishing returns or further improvements.
- What evidence would resolve it: Experiments varying the number of auto-generated image-text pairs (e.g., 100, 500, 1K, 5K, 10K) per skill while measuring DSG/TIFA accuracy and human preference metrics would show the scaling relationship.

### Open Question 2
- Question: Can SELMA's LoRA merging approach be extended to more than five skills without performance degradation?
- Basis in paper: [inferred] The paper demonstrates merging five skill-specific LoRA experts successfully but does not test whether this approach scales to larger numbers of skills or more diverse skills.
- Why unresolved: The paper only merges five skill-specific LoRA experts, leaving uncertainty about whether knowledge conflicts become prohibitive with more diverse skills or whether the uniform merging ratio remains optimal.
- What evidence would resolve it: Experiments merging LoRA experts from 5, 10, 20, or more diverse skills while measuring text faithfulness and human preference would reveal scalability limits.

### Open Question 3
- Question: Does SELMA's weak-to-strong generalization phenomenon generalize beyond Stable Diffusion v2→SDXL?
- Basis in paper: [explicit] The paper shows SDXL fine-tuned on SD v2-generated images outperforms baseline SDXL, suggesting weak-to-strong generalization, but only tests this one direction with these specific models.
- Why unresolved: The paper only tests one weak-to-strong direction (SD v2→SDXL) and does not explore whether stronger models can learn from even weaker models or whether this works across different model families.
- What evidence would resolve it: Experiments testing multiple weak-to-strong directions (e.g., SD v1.4→SDXL, SD v2→SD v1.4, DALL-E 2→SDXL) while measuring performance improvements would establish generality.

## Limitations
- Limited evaluation of SELMA's performance compared to ground truth data relies on a small set of ground truth image-text pairs, potentially affecting generalizability
- The model's ability to generalize to novel or more complex skills beyond those explicitly trained on remains uncertain
- The stability and compatibility of merging multiple LoRA experts into a unified model may introduce new conflicts or performance degradation

## Confidence
- High Confidence: SELMA improves text-to-image model faithfulness as measured by TIFA and DSG benchmarks, and achieves higher human preference metrics compared to baselines.
- Medium Confidence: SELMA's auto-generated data is as effective as ground truth data for fine-tuning, though evaluation is limited to specific ground truth datasets.
- Low Confidence: SELMA demonstrates weak-to-strong generalization in text-to-image models, as evidence is based on a single model pair.

## Next Checks
1. Evaluate SELMA on a broader range of ground truth datasets to assess performance across diverse data characteristics and styles
2. Test SELMA's generalization to novel skills not explicitly trained on during fine-tuning to determine zero-shot or few-shot learning capabilities
3. Investigate the stability and compatibility of merged LoRA experts through analysis of individual skill performance and potential conflicts