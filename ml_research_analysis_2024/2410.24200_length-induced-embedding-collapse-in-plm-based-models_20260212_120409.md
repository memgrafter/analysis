---
ver: rpa2
title: Length-Induced Embedding Collapse in PLM-based Models
arxiv_id: '2410.24200'
source_url: https://arxiv.org/abs/2410.24200
tags:
- length
- text
- texts
- embeddings
- long
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies a Length Collapse phenomenon in PLM-based
  embedding models, where embeddings of longer texts cluster together, reducing their
  distinctiveness. The authors analyze this behavior through Fourier-domain analysis,
  demonstrating that self-attention acts as a low-pass filter whose strength increases
  with text length, causing high-frequency components to be suppressed and embeddings
  to converge.
---

# Length-Induced Embedding Collapse in PLM-based Models

## Quick Facts
- arXiv ID: 2410.24200
- Source URL: https://arxiv.org/abs/2410.24200
- Authors: Yuqi Zhou; Sunhao Dai; Zhanshuo Cao; Xiao Zhang; Jun Xu
- Reference count: 40
- Key outcome: Length Collapse phenomenon causes longer text embeddings to cluster together, reducing distinctiveness; TempScale temperature scaling improves performance by 0.94% on MTEB and 1.10% on LongEmbed

## Executive Summary
This paper identifies a Length Collapse phenomenon in PLM-based embedding models, where embeddings of longer texts cluster together, reducing their distinctiveness. The authors analyze this behavior through Fourier-domain analysis, demonstrating that self-attention acts as a low-pass filter whose strength increases with text length, causing high-frequency components to be suppressed and embeddings to converge. To address this issue, they propose TempScale, a simple temperature scaling technique that reduces the gap in filtering rates between long and short texts by dividing attention scores by a temperature parameter less than 1 before softmax. Experiments show TempScale improves performance by 0.94% on MTEB and 1.10% on LongEmbed, validating the theoretical analysis. The method effectively mitigates distributional inconsistencies between embeddings of different text lengths, leading to better downstream task performance.

## Method Summary
The authors identify Length-Induced Embedding Collapse in PLM-based models through Fourier-domain analysis of self-attention mechanisms. They demonstrate that self-attention acts as a low-pass filter that becomes stronger with increasing text length, suppressing high-frequency components and causing embeddings to converge. To address this, they propose TempScale, which divides attention scores by a temperature parameter τ < 1 before softmax, reducing the filtering rate gap between long and short texts. The method requires no training and can be applied to existing fine-tuned models by adjusting the temperature parameter, which is searched in the range {0.1, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}.

## Key Results
- Length Collapse causes longer text embeddings to cluster together, reducing their distinctiveness across multiple PLM architectures
- TempScale improves performance by 0.94% on MTEB benchmark and 1.10% on LongEmbed dataset
- Theoretical analysis shows self-attention acts as low-pass filter with increasing strength as text length grows, validated through singular value decomposition of attention matrices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-attention acts as a low-pass filter whose strength increases with text length, causing high-frequency components to be suppressed.
- Mechanism: As text length increases, the largest singular value σ_a of the high-frequency components in the self-attention matrix decreases, leading to stronger suppression of high-frequency information and convergence of embeddings toward their DC component.
- Core assumption: The self-attention matrix generated by softmax acts as a low-pass filter regardless of specific token features or context window.
- Evidence anchors:
  - [abstract] "Through a rigorous theoretical analysis of the self-attention mechanism, which acts as a low-pass filter in PLM-based models, we demonstrate that as text length increases, the strength of low-pass filtering intensifies"
  - [section 2.2] "Building on Lemma1, we show that the largest singular value σ_a of HC [A] influences the filtering rate, with a smaller σ_a indicating greater high-frequency loss (Theorem2)"
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.511" - weak evidence for low-pass filtering mechanisms specifically
- Break condition: If the Gaussian assumption about input keys and queries fails, or if residual connections/intermediate layers significantly alter the filtering behavior beyond what's captured by σ_a.

### Mechanism 2
- Claim: Temperature scaling (TempScale) reduces the gap in low-pass filtering rates between long and short texts by manipulating the attention map.
- Mechanism: By dividing attention scores by a temperature parameter τ < 1 before softmax, TempScale increases σ_s (the temperature of the self-attention), which slows the decrease of σ_a with increasing text length, thereby reducing distributional differences between embeddings of different lengths.
- Core assumption: The temperature of the self-attention τ_s is inversely related to σ_s, and reducing the gap in σ_a between long and short texts will mitigate length collapse.
- Evidence anchors:
  - [abstract] "To address this issue, we propose a simple method, TempScale, which mitigates the Length Collapse phenomenon. By narrowing the gap in low-pass filtering rates between long and short texts, TempScale ensures more consistent embeddings across different text lengths"
  - [section 4] "Specifically, a larger σ_s will result in a smaller factor √(1 + 1/(e^(2σ_s²)(n-1)^(3/2))) in Eqn. 2, which means that as the text length n increases, σ_a will decrease more slowly"
  - [corpus] "Top related titles: Balancing Embedding Spectrum for Recommendation" - weak direct evidence for temperature scaling specifically
- Break condition: If the relationship between temperature scaling and σ_s breaks down, or if other model components override the temperature effect.

### Mechanism 3
- Claim: Length-induced embedding collapse leads to performance degradation across downstream tasks because embeddings of longer texts cluster together, reducing their distinctiveness.
- Mechanism: When embeddings of longer texts cluster more densely (higher cosine similarity), this creates distributional inconsistency that affects classification (biased influence during training), retrieval (short documents appear more relevant due to broader representational space), and STS tasks (unrelated embeddings show higher similarity than relevant pairs).
- Core assumption: The performance of downstream tasks depends on the distinctiveness and distribution consistency of embeddings across different text lengths.
- Evidence anchors:
  - [abstract] "We further investigate how these differences contribute to the performance decline observed with longer texts across various downstream tasks"
  - [section 3] "As shown in Figure 3 (Left), Length Collapse causes long-text embeddings to cluster at the center, while short-text embeddings spread around the periphery. In KNN classification, this brings clustering centers closer to long texts, resulting in a biased influence and reducing performance"
  - [corpus] "Found 25 related papers (using 8)" - weak evidence for specific performance degradation mechanisms
- Break condition: If downstream tasks are robust to distributional shifts in embeddings, or if other factors dominate performance degradation beyond length-induced clustering.

## Foundational Learning

- Fourier Analysis:
  - Why needed here: The paper uses Fourier domain analysis to characterize how self-attention acts as a low-pass filter, which requires understanding DFT and spectral decomposition of matrices.
  - Quick check question: What does the DC component represent in the context of self-attention's low-pass filtering behavior?

- Matrix Spectral Theory:
  - Why needed here: The analysis relies on singular value decomposition and the relationship between singular values and filtering rates, which requires understanding spectral norms and their properties.
  - Quick check question: How does the largest singular value of the high-frequency component matrix relate to the filtering rate of the attention mechanism?

- Self-Attention Mechanism:
  - Why needed here: Understanding how self-attention works is crucial to grasp why it acts as a low-pass filter and how temperature scaling modifies its behavior.
  - Quick check question: What role does the temperature parameter play in the softmax function of self-attention, and how does this affect the attention weights?

## Architecture Onboarding

- Component map: Text input → Token embeddings → Transformer encoder blocks (Multi-Head Self-Attention + Feed-Forward Networks) → Pooling layer → Final embeddings
- Critical path: Text input → Token embeddings → Transformer layers with self-attention → Pooling → Embedding output (where length collapse occurs)
- Design tradeoffs: The proposed TempScale method adds minimal computational overhead by modifying the temperature parameter in self-attention, but requires careful tuning of the temperature value for optimal performance across different text lengths.
- Failure signatures: If length collapse persists after applying TempScale, check whether the temperature value is too high (τ close to 1) or if other model components are counteracting the temperature effect. If performance degrades unexpectedly, verify that the temperature adjustment isn't causing over-smoothing or loss of discriminative features.
- First 3 experiments:
  1. Reproduce the length collapse phenomenon by plotting embedding distances and cosine similarities across different text length intervals using a pre-trained PLM-based model.
  2. Implement TempScale by modifying the self-attention temperature parameter and observe changes in embedding distributions across text lengths.
  3. Evaluate performance improvements on a subset of MTEB tasks (e.g., classification and retrieval) with and without TempScale to validate the theoretical analysis.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed temperature scaling approach work equally well across different Transformer architectures beyond those tested (BERT, RoBERTa, T5)?
- Basis in paper: [inferred] The authors tested TempScale on models fine-tuned from BERT, RoBERTa, and T5 architectures, but did not explore whether the method generalizes to other Transformer variants like GPT, DeBERTa, or specialized architectures.
- Why unresolved: The paper focuses on a specific set of PLM-based models and does not investigate whether the effectiveness of temperature scaling depends on the underlying Transformer architecture or pretraining objectives.
- What evidence would resolve it: Systematic experiments applying TempScale to a diverse set of Transformer architectures with different pretraining objectives and self-attention variants would demonstrate whether the method is architecture-agnostic.

### Open Question 2
- Question: What is the optimal temperature scaling strategy for texts with highly variable lengths within the same document or dataset?
- Basis in paper: [explicit] The authors mention in section 5.2 that "longer texts require a lower temperature for scaling" and suggest setting different temperatures for queries and documents, but do not provide a concrete method for automatically determining optimal temperatures based on text length.
- Why unresolved: While the paper demonstrates that temperature should vary with text length, it does not propose or test a principled approach for automatically selecting temperature values based on input length, which would be necessary for practical deployment.
- What evidence would resolve it: Development and validation of a length-based temperature selection mechanism that can be applied dynamically during inference would address this limitation.

### Open Question 3
- Question: How does the Length Collapse phenomenon manifest in autoregressive (causal) attention models used in LLM-based embedding systems?
- Basis in paper: [explicit] The authors acknowledge in section 7 that "we have observed a Length Collapse in LLM-based embedding models" but state that "further analysis is needed to investigate how unidirectional attention mechanisms specifically contribute to this phenomenon."
- Why unresolved: The theoretical analysis focuses on bidirectional attention, while the authors recognize that unidirectional attention in LLMs may exhibit different characteristics that could lead to distinct manifestations of Length Collapse.
- What evidence would resolve it: Comparative analysis of Fourier-domain properties of causal vs. bidirectional attention matrices across varying sequence lengths would clarify whether the same low-pass filtering mechanism applies.

## Limitations
- Theoretical assumptions about self-attention's filtering behavior may not hold for all PLM architectures, particularly those with architectural modifications like rotary positional embeddings.
- Effectiveness of TempScale depends on specific architecture and training dynamics, with optimal temperature parameters varying significantly across models.
- Limited evaluation on real-world scenarios with naturally mixed document lengths, focusing instead on controlled benchmarks with length-segmented datasets.

## Confidence

**High Confidence** in the identification of length-induced embedding collapse: The phenomenon of longer text embeddings clustering together is well-supported by empirical evidence showing consistent cosine similarity patterns across multiple datasets and models. The theoretical analysis provides a coherent framework for understanding why this occurs through self-attention's low-pass filtering behavior.

**Medium Confidence** in the TempScale mechanism: While the theoretical justification for temperature scaling is sound and experimental results show consistent improvements, the exact relationship between temperature parameters and embedding distributions across different architectures requires further validation. The simplicity of the method suggests it captures something fundamental about attention mechanisms, but the optimal parameterization may be model-specific.

**Low-Medium Confidence** in the universality of the Fourier-domain analysis: The mathematical framework using singular value decomposition to characterize filtering rates is elegant, but its applicability may be limited by assumptions about the statistical properties of attention matrices. Alternative analytical approaches or empirical validations across diverse architectures would strengthen this foundation.

## Next Checks

1. **Cross-Architecture Validation**: Apply TempScale to a diverse set of PLM architectures including BERT, RoBERTa, DeBERTa, and Longformer variants to test whether the temperature scaling mechanism generalizes across different self-attention implementations and positional encoding schemes. Measure both performance improvements and changes in embedding distributions across text lengths.

2. **Fine-tuning Dynamics Analysis**: Investigate how TempScale affects the fine-tuning process by comparing models trained from scratch with temperature scaling versus models with post-hoc temperature adjustment. This would reveal whether the benefits are primarily due to distributional regularization during training or can be achieved through inference-time modification alone.

3. **Mixed-Length Input Evaluation**: Design experiments using datasets with naturally mixed document lengths (e.g., web documents, news articles) to evaluate TempScale's effectiveness in real-world scenarios where both short and long texts are processed together. Measure not just overall performance but also the consistency of performance across different length intervals.