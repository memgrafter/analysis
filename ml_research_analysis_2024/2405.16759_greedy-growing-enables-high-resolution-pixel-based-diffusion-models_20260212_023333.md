---
ver: rpa2
title: Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models
arxiv_id: '2405.16759'
source_url: https://arxiv.org/abs/2405.16759
tags:
- diffusion
- image
- training
- images
- greedy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models
  Problem: Training large-scale pixel-based diffusion models (PSDM) for high-resolution
  images is challenging due to instability and high resource demands. Method: The
  paper proposes a two-phase approach: 1) Pre-train core layers (responsible for text-to-image
  alignment) using a shallow UViT architecture on low-resolution images.'
---

# Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models

## Quick Facts
- arXiv ID: 2405.16759
- Source URL: https://arxiv.org/abs/2405.16759
- Reference count: 40
- Key outcome: Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models

## Executive Summary
Training large-scale pixel-based diffusion models for high-resolution images faces significant challenges including instability and prohibitive resource requirements. This paper introduces a novel two-phase approach that enables training non-cascaded models up to 8B parameters with small batch sizes. The method achieves superior performance compared to existing models like SDXL through a combination of architectural innovations and high-quality training data.

## Method Summary
The paper proposes a two-phase training approach. First, pre-train core layers using a shallow UViT architecture on low-resolution images to establish text-to-image alignment. Second, greedily grow the model by adding high-resolution encoder-decoder layers while keeping pre-trained core layers frozen, which stabilizes training. This approach enables training with small batch sizes (256 vs typical 2k) while achieving high-resolution outputs up to 1024x1024 pixels.

## Key Results
- Enables training non-cascaded models up to 8B parameters with small batch sizes (256 vs typical 2k)
- Final model Vermeer generates 1024x1024 images and outperforms SDXL in human evaluations
- Human preference study shows 44% preference for Vermeer vs 21.4% for SDXL

## Why This Works (Mechanism)
The greedy growing approach stabilizes training by separating the challenging text-to-image alignment phase from the high-resolution generation phase. By pre-training core layers on low-resolution images first, the model establishes robust semantic understanding before tackling the complexity of high-resolution generation. The frozen core layers provide a stable foundation while new layers handle the spatial complexity of high-resolution outputs, preventing the instability that typically plagues large-scale high-resolution diffusion training.

## Foundational Learning
- UViT architecture: Why needed - provides efficient attention mechanism for image generation; Quick check - verify understanding of attention patterns and computational complexity
- Diffusion models: Why needed - fundamental framework for image generation through iterative denoising; Quick check - understand noise schedule and sampling process
- Text-to-image alignment: Why needed - critical for generating semantically coherent images from text prompts; Quick check - verify understanding of cross-attention mechanisms
- Greedy growing methodology: Why needed - enables scalable training without catastrophic forgetting; Quick check - understand layer-wise training progression
- Human preference evaluation: Why needed - captures perceptual quality beyond quantitative metrics; Quick check - understand methodology for bias control and statistical significance

## Architecture Onboarding

**Component Map:** Core UViT layers -> High-resolution encoder-decoder layers -> Text conditioning -> Image generation

**Critical Path:** Text embedding → Core UViT layers (pre-trained) → High-resolution encoder-decoder (greedily grown) → Diffusion denoising steps → Final image output

**Design Tradeoffs:** Small batch sizes (256) vs large batch sizes (2k) - smaller batches reduce memory requirements but may affect gradient stability. Pre-training vs joint training - pre-training stabilizes core layers but adds training time. Non-cascaded vs cascaded - single-pass generation is faster but requires more sophisticated architecture.

**Failure Signatures:** Training instability when adding high-resolution layers too quickly, degradation in text-to-image alignment when core layers are unfrozen during growth phase, memory overflow when attempting to train full model without greedy approach.

**First Experiments:** 1) Verify greedy growing works on a small-scale toy model before scaling up; 2) Compare training stability with and without frozen core layers; 3) Test different growth rates to find optimal balance between stability and efficiency.

## Open Questions the Paper Calls Out
None

## Limitations
- Models and datasets are not open-sourced, preventing independent verification
- Evaluation relies solely on human preference studies without quantitative metrics like FID or CLIP scores
- Superior performance attributed to "internally curated datasets" rather than technical innovations, raising questions about methodology contribution
- Lack of statistical significance testing or confidence intervals for human preference results

## Confidence

**High confidence:** Technical feasibility of greedy growing approach based on established UViT architecture principles

**Medium confidence:** Claimed performance improvements due to reliance on non-public data and lack of quantitative metrics

**Low confidence:** Generalization claims since results are based on internal evaluations only

## Next Checks
1. Replicate the greedy growing methodology using publicly available datasets and compare quantitative metrics (FID, CLIP scores) against SDXL on standardized test sets
2. Conduct ablation studies removing the "internal curated datasets" to isolate whether performance gains come from the growing technique or data quality
3. Perform controlled human evaluation studies with statistical significance testing and confidence intervals across multiple evaluator groups