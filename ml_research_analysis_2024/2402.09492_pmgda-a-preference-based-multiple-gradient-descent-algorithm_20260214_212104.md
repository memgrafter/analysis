---
ver: rpa2
title: 'PMGDA: A Preference-based Multiple Gradient Descent Algorithm'
arxiv_id: '2402.09492'
source_url: https://arxiv.org/abs/2402.09492
tags:
- pareto
- learning
- solution
- solutions
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel predict-and-correct framework, PMGDA,
  for solving large-scale multi-objective optimization problems with user preferences.
  The method introduces a constraint function in the search progress to align the
  solution with a user-specific preference, which can be optimized simultaneously
  with multiple objective functions.
---

# PMGDA: A Preference-based Multiple Gradient Descent Algorithm

## Quick Facts
- arXiv ID: 2402.09492
- Source URL: https://arxiv.org/abs/2402.09492
- Reference count: 40
- Solves large-scale multi-objective optimization with user preferences via a predict-and-correct gradient descent framework

## Executive Summary
This paper introduces PMGDA, a novel predict-and-correct framework for solving large-scale multi-objective optimization problems with user preferences. The method reduces computational complexity by reformulating the problem in terms of gradients rather than raw parameters, making it scalable to neural networks with thousands of decision variables. PMGDA efficiently finds exact Pareto optimal solutions while incorporating user-specific preference constraints, outperforming previous approaches in both precision and computational efficiency.

## Method Summary
PMGDA uses a dual formulation to transform the optimization from n decision variables to m+1 gradient variables, where m is the number of objectives. The predict-and-correct framework alternates between a prediction step (constraining search to maintain the preference function) and a correction step (actively reducing the preference function while maintaining objective improvement). The method handles both exact Pareto solutions and region of interest (ROI) constraints through a unified framework, making it the first practical approach for preference-based Pareto optimization in neural networks.

## Key Results
- First method to successfully find Pareto solutions satisfying ROI constraints
- Outperforms previous approaches in solution precision and computational efficiency
- Efficiently scales to problems with thousands of decision variables
- Demonstrates effectiveness on synthetic benchmarks, multi-task learning, and multi-objective reinforcement learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PMGDA solves high-dimensional optimization by reducing decision variables from n to m+1 via dual formulation
- Mechanism: Prediction step rewrites original optimization as dual, turning n+1 variable problem into m+1 variable one, reducing computational burden
- Core assumption: Gradient directions of objectives and constraint span low-dimensional subspace capturing Pareto stationary manifold
- Evidence anchors: Abstract claims first practical method for preference-based Pareto solutions; section details O(m²n) complexity

### Mechanism 2
- Claim: PMGDA enforces preference alignment while keeping objective improvement via alternating predict-correct phases
- Mechanism: Predict phase constrains to keep h(θ) constant; correction phase biases toward reducing h(θ) while obeying Armijo condition
- Core assumption: Objective space near Pareto stationary point is smooth enough for gradient-based correction without large objective degradation
- Evidence anchors: Abstract mentions constraint function for user-specific preference; section discusses regulating increment of each Li

### Mechanism 3
- Claim: Method targets both exact Pareto solutions and ROI constraints without retraining separate models
- Mechanism: Preference function h(θ) is general—Euclidean distance to preference vector or distance-to-ROI indicator, optimized via same loop
- Core assumption: User preference encoded in scalar function h(θ) whose zero level set is desired Pareto subset
- Evidence anchors: Abstract introduces PMGDA within MGDA framework; section claims first to find ROI-satisfying Pareto solutions

## Foundational Learning

- Concept: Pareto optimality and dominance
  - Why needed here: Method searches for solutions that cannot be improved in one objective without worsening another
  - Quick check question: Given two solutions with objectives (1,3) and (2,2), which one dominates the other?

- Concept: Gradient-based optimization in high dimensions
  - Why needed here: Algorithm must efficiently compute and combine gradients of thousands of parameters
  - Quick check question: If network has 10k parameters, what is computational complexity of naive gradient descent step?

- Concept: Constraint handling in multi-objective optimization
  - Why needed here: Preference constraint h(θ) enforced via projected gradient steps
  - Quick check question: What happens to search direction if constraint gradient is orthogonal to all objective gradients?

## Architecture Onboarding

- Component map: Forward pass → Backward pass → Dual solver → Correction solver → Weight combination → Parameter update → Loop
- Critical path: Forward → Backward → Solver (dual/correct) → Weight combination → Parameter update → Loop
- Design tradeoffs:
  - Dual reduction vs full gradient projection: trade exactness for speed
  - σ in correction: higher values risk oscillation, lower values risk slow constraint satisfaction
  - Batch size in RL: larger batches reduce gradient noise but increase compute cost per iteration
- Failure signatures:
  - No progress in h(θ): check ∇h estimation and σ tuning
  - Divergence of objectives: check Armijo condition and learning rate η
  - Stalled at non-Pareto stationary point: verify gradient correctness and h(θ) satisfaction
- First 3 experiments:
  1. Run PMGDA on 2-objective synthetic benchmark (ZDT1) with fixed preference λ; verify h(θ) → 0 and objectives align with λ
  2. Test ROI mode on simple 2D box ROI; confirm solution lies inside ROI
  3. Scale up to small neural net multi-task problem (fairness classification); check runtime scales with m not n and solutions match baselines

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PMGDA framework be extended to handle non-convex preference functions effectively?
- Basis in paper: [inferred] Paper mentions smooth, convex objectives but does not discuss non-convex preference functions
- Why unresolved: Paper does not explore behavior with non-convex preference functions common in real-world applications
- What evidence would resolve it: Experimental results showing PMGDA performance on non-convex preference functions compared to other methods

### Open Question 2
- Question: How does choice of parameter σ in correction step affect convergence rate and stability of PMGDA in practice?
- Basis in paper: [explicit] Paper discusses role of σ in correction step and impact on convergence trajectory and oscillations
- Why unresolved: Paper provides theoretical insights but lacks comprehensive empirical study on different σ values
- What evidence would resolve it: Detailed sensitivity analysis across range of σ values including convergence speed, stability, and solution quality

### Open Question 3
- Question: Is there way to adaptively adjust preference function h(θ) during optimization to improve solution quality or convergence?
- Basis in paper: [inferred] Paper presents static preference function h(θ) without discussing adaptive strategies
- Why unresolved: Static nature of preference function may limit method's flexibility in dynamic or complex scenarios
- What evidence would resolve it: Development and testing of adaptive mechanism for adjusting h(θ) during optimization with empirical improvements

## Limitations

- No implementation details provided for gradient estimation of constraint function h(θ) in large-scale neural network settings
- Hyperparameter settings (learning rate, σ, stopping criteria) not specified, making exact reproduction difficult
- Strong claim of being "first practical method" lacks direct comparison to all existing methods in literature

## Confidence

- **High confidence**: Theoretical foundation of predict-and-correct framework and ability to reduce computational complexity from O(n) to O(m) variables
- **Medium confidence**: Effectiveness on synthetic benchmarks and small-scale problems based on reported results
- **Low confidence**: Scalability claims for thousands of decision variables and performance on complex real-world tasks without implementation details

## Next Checks

1. Implement PMGDA on simple 2-objective synthetic benchmark (ZDT1) with fixed preference vector and verify convergence to h(θ) → 0
2. Test ROI constraint mode on simple 2D box ROI to confirm solutions satisfy region constraints
3. Run PMGDA on small neural network multi-task problem and compare runtime scaling with number of objectives m versus decision variables n