---
ver: rpa2
title: Open Assistant Toolkit -- version 2
arxiv_id: '2403.00586'
source_url: https://arxiv.org/abs/2403.00586
tags:
- system
- task
- oat-v2
- action
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OAT-v2 is an open-source framework for building multimodal conversational
  task assistants. It uses a modular Dockerized architecture with specialized models
  (NDP) and LLMs via Huggingface TGI for action generation, knowledge retrieval, and
  response generation.
---

# Open Assistant Toolkit -- version 2

## Quick Facts
- arXiv ID: 2403.00586
- Source URL: https://arxiv.org/abs/2403.00586
- Reference count: 6
- Primary result: OAT-v2 is an open-source framework for building multimodal conversational task assistants using modular Dockerized architecture and specialized models (NDP) with LLM integration via Huggingface TGI.

## Executive Summary
OAT-v2 is an open-source framework designed for building multimodal conversational task assistants. It uses a modular Dockerized architecture with specialized models (NDP) and LLMs via Huggingface TGI for action generation, knowledge retrieval, and response generation. The system processes user utterances into system actions, retrieves relevant knowledge, and generates responses. It includes offline pipelines for task extraction, parsing, and augmentation from Common Crawl, plus synthetic task generation. Key features include live task adaptation, multimodal support, and a training pipeline for NDP models.

## Method Summary
OAT-v2 achieves scalable, modular conversational task assistance by decomposing user utterances into system actions via specialized NDP models and LLM-driven response generation. The system uses an encoder-decoder NDP model to generate executable action code from user utterances and system state, then routes actions to specialized handlers (e.g., domain-specific, multimodal retrieval) or LLM fallback for unknown actions. Knowledge-grounded responses are generated via HuggingFace TGI integration, enabling zero-shot prompting and live task adaptation. The offline pipeline transforms raw multimodal web data into executable TaskGraphs, ensuring task grounding and reducing hallucination risk.

## Key Results
- Modular Dockerized architecture enables scalable experimentation with grounded, deployment-ready generative conversational agents
- NDP models reduce latency and complexity compared to monolithic LLMs while maintaining task-grounded responses
- Offline pipeline ensures task grounding and reduces hallucination risk by parsing and augmenting Common Crawl data into executable TaskGraphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OAT-v2 achieves scalable, modular conversational task assistance by decomposing user utterances into system actions via specialized NDP models and LLM-driven response generation.
- Mechanism: The system uses an encoder-decoder NDP model to generate executable action code from user utterances and system state, then routes actions to specialized handlers (e.g., domain-specific, multimodal retrieval) or LLM fallback for unknown actions.
- Core assumption: Modular decomposition reduces latency and complexity compared to monolithic LLMs while maintaining task-grounded responses.
- Evidence anchors:
  - [abstract] "splits processing a user utterance into modular system components, including submodules such as action code generation, multimodal content retrieval, and knowledge-augmented response generation."
  - [section 3.1] "OAT-v2 generates system actions with a NDP-style model... To create an NDP model, we define the action target space for all basic flows the model should support."
  - [corpus] Weak - no direct citations found; claim is primarily derived from paper text.
- Break condition: NDP action space becomes too restrictive, causing frequent LLM fallbacks and degraded latency; or specialized models fail to generalize to new domains without retraining.

### Mechanism 2
- Claim: Knowledge-grounded responses are generated via HuggingFace TGI integration, enabling zero-shot prompting and live task adaptation.
- Mechanism: TGI provides a standardized interface to deploy and query multiple LLMs with custom prompts, context, and dialogue history, supporting both task-specific knowledge retrieval and live adaptation.
- Core assumption: Zero-shot LLM prompting can produce fluent, grounded responses without domain-specific fine-tuning, provided relevant context is supplied.
- Evidence anchors:
  - [abstract] "enables composing generative neural models by providing specialised models and LLM endpoints."
  - [section 3.2] "OAT-v2 uses a locally deployable LLMs... for zero-shot prompting during execution. This allows fluent responding to dynamic user environments."
  - [corpus] Weak - no direct citations found; mechanism described in paper text.
- Break condition: Zero-shot prompting fails on complex or highly specific tasks; or TGI deployment introduces unacceptable latency or resource overhead.

### Mechanism 3
- Claim: Offline pipeline transforms raw multimodal web data into executable TaskGraphs, ensuring task grounding and reducing hallucination risk.
- Mechanism: The pipeline parses Common Crawl data into task components (steps, images, videos, knowledge), then augments tasks with LLMs and external sources to create engaging, executable TaskGraphs for online use.
- Core assumption: Grounded task content from human-written web sources is safer and more reliable than fully synthetic generation for real-world task assistance.
- Evidence anchors:
  - [abstract] "offline pipeline to parse and augment task data from CommonCrawl... to ensure that retrieved tasks are based on real-world seeds written by humans."
  - [section 4.1] "The pipeline supports extracting, parsing and augmenting publicly available multimodal data... Since all tasks are written for online web interface usage, we add augmentation steps..."
  - [corpus] Weak - no direct citations found; claim is from paper text.
- Break condition: Offline parsing fails to extract coherent task structures; or augmentation introduces inaccuracies despite grounding.

## Foundational Learning

- Concept: Modular system architecture with Docker/Kubernetes deployment
  - Why needed here: Enables scalable, maintainable, and interchangeable components for both online and offline pipelines.
  - Quick check question: What are the three main Docker container categories in OAT-v2, and what is their purpose?
- Concept: Encoder-decoder NDP models for action generation
  - Why needed here: Converts natural language user utterances into structured, executable system actions, reducing the need for complex dialogue state tracking.
  - Quick check question: How does the NDP action space constrain possible system actions, and what happens when an unknown action is generated?
- Concept: Knowledge grounding via TaskGraphs and multimodal retrieval
  - Why needed here: Ensures task responses are based on real-world, verifiable content rather than pure LLM generation, reducing hallucination and safety risks.
  - Quick check question: What types of data are parsed and augmented in the offline pipeline, and how are they used in the online system?

## Architecture Onboarding

- Component map:
  - Online: NDP action generator -> LLM Orchestrator (via TGI) -> knowledge retriever -> response generator -> task state manager
  - Offline: Common Crawl parser -> task augmenter (LLM + knowledge sources) -> synthetic task generator -> NDP training pipeline
  - Deployment: Docker containers for each component, orchestrated via docker-compose/Kubernetes
- Critical path: User utterance -> NDP action generation -> action routing -> knowledge retrieval (if needed) -> LLM response generation -> user output
- Design tradeoffs:
  - Modularity vs. latency: Splitting into many containers increases deployment complexity but allows independent scaling and easier experimentation.
  - Specialized models vs. LLMs: NDPs reduce latency and cost but require retraining for new domains; LLMs are more flexible but slower and costlier.
  - Grounding vs. creativity: TaskGraphs ensure safe, grounded responses but may limit open-ended or creative interactions.
- Failure signatures:
  - High NDP fallback rate: NDP action space too restrictive or training data insufficient
  - Slow response times: LLM endpoints overloaded or network latency; too many sequential container calls
  - Incorrect or unsafe responses: Grounding pipeline errors, hallucination in LLM generation, or inadequate safety post-processing
- First 3 experiments:
  1. Deploy OAT-v2 with default Docker containers; verify all endpoints are reachable and can process a simple "hello" utterance.
  2. Test NDP action generation by sending a cooking-related utterance; check that the generated action is in the defined action space.
  3. Replace the default LLM endpoint with a custom HuggingFace TGI container; verify zero-shot prompting works for a knowledge retrieval task.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does OAT-v2 handle factual errors or hallucinations in the generated task content when using LLMs for task augmentation?
- Basis in paper: [explicit] The paper mentions that "LLMs generate fluent task content, but the generated tasks can be factually incorrect and potentially dangerous" and emphasizes the importance of having a retrieval corpus and structured infrastructure to ensure task grounding.
- Why unresolved: The paper does not provide specific details on the mechanisms or methods OAT-v2 employs to detect and mitigate factual errors or hallucinations in LLM-generated task content.
- What evidence would resolve it: A detailed description of the fact-checking and hallucination detection mechanisms implemented in OAT-v2, along with evaluation results demonstrating their effectiveness.

### Open Question 2
- Question: What is the impact of using different LLM models (e.g., different sizes or architectures) on the performance and user experience of OAT-v2?
- Basis in paper: [explicit] The paper mentions that OAT-v2 uses locally deployable LLMs and allows flexible experimentation with different models directly in a natural conversational setting.
- Why unresolved: The paper does not provide any empirical results or analysis comparing the performance and user experience of OAT-v2 when using different LLM models.
- What evidence would resolve it: A comprehensive evaluation comparing the performance and user experience of OAT-v2 when using different LLM models, including metrics such as task completion rate, user satisfaction, and response quality.

### Open Question 3
- Question: How does OAT-v2 handle user preferences and adapt tasks in real-time while ensuring task coherence and user satisfaction?
- Basis in paper: [explicit] The paper mentions that OAT-v2 supports live task adaptation based on user preferences and user environment, and that the TaskGraph representation enables modifying task components live.
- Why unresolved: The paper does not provide specific details on the algorithms or methods OAT-v2 uses to adapt tasks in real-time while maintaining task coherence and user satisfaction.
- What evidence would resolve it: A detailed description of the task adaptation algorithms and methods used in OAT-v2, along with user studies or evaluations demonstrating their effectiveness in maintaining task coherence and user satisfaction.

## Limitations

- No quantitative performance metrics on real-world datasets or user studies
- Effectiveness of modular decomposition approach versus monolithic LLMs not directly benchmarked
- Safety and hallucination mitigation claims rely on grounding via TaskGraphs but lack formal evaluation

## Confidence

- **High Confidence**: The modular Dockerized architecture is technically sound and aligns with best practices for scalable, maintainable ML systems. The use of HuggingFace TGI for LLM orchestration is a standard, well-documented approach.
- **Medium Confidence**: The NDP model for action generation is a plausible and effective mechanism, but its generalization and fallback behavior in real-world use cases are unverified.
- **Low Confidence**: The claims about safety, hallucination reduction, and task grounding are based on design principles rather than empirical validation, and thus remain speculative without further testing.

## Next Checks

1. **Empirical Benchmarking**: Run controlled experiments comparing OAT-v2's modular architecture against a monolithic LLM baseline on a standardized task assistance dataset. Measure latency, accuracy, and fallback rates.
2. **Safety and Grounding Audit**: Evaluate the system's responses on a set of safety-critical and hallucination-prone prompts. Assess whether TaskGraph grounding effectively reduces unsafe or fabricated content compared to pure LLM generation.
3. **Offline Pipeline Robustness**: Test the offline pipeline on a diverse sample of Common Crawl data. Verify that parsed tasks are coherent, executable, and correctly augmented, and quantify the rate of parsing or augmentation failures.