---
ver: rpa2
title: 'Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms
  for Heterogeneous Agents'
arxiv_id: '2408.03405'
source_url: https://arxiv.org/abs/2408.03405
tags:
- agents
- agent
- equation
- each
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new stochastic multi-agent multi-armed bandit
  problem where agents have heterogeneous sensitivities to arm rewards. A UCB-style
  algorithm, MIN-WIDTH, is proposed to assign agents to arms while aggregating information
  across agents in a sensitivity-aware manner.
---

# Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents

## Quick Facts
- arXiv ID: 2408.03405
- Source URL: https://arxiv.org/abs/2408.03405
- Reference count: 40
- Primary result: MIN-WIDTH algorithm achieves O(√T log(T)) regret bound for multi-agent multi-armed bandits with heterogeneous agent sensitivities

## Executive Summary
This paper introduces a novel stochastic multi-agent multi-armed bandit problem where agents have heterogeneous sensitivities to arm rewards. The authors propose MIN-WIDTH, a UCB-style algorithm that efficiently assigns agents to arms while aggregating information across agents in a sensitivity-aware manner. The key insight is decomposing the combinatorial agent-arm assignment problem into learning individual arm means and using a weighted reward aggregation strategy. Experiments in COVID testing, hotel recommendation, and poaching prevention domains demonstrate that MIN-WIDTH outperforms canonical UCB algorithms and sensitivity-aware baselines, particularly when agent sensitivities are diverse.

## Method Summary
The MIN-WIDTH algorithm maintains individual UCBs for each arm rather than treating each agent-arm combination as a separate arm. At each timestep, agents are assigned to arms by descending sensitivity order and descending UCB order. A weighted reward aggregation strategy combines information from all agents to construct shared unbiased estimators for each arm's mean, using weights that account for different agent sensitivities and variances. This approach enables scalable learning while exploiting the known structure in agents' reward functions. The algorithm is evaluated against sensitivity-aware baselines (NO-SHARING and MIN-UCB) and canonical baselines (CUCB and UCB) across multiple domains.

## Key Results
- MIN-WIDTH achieves O(√T log(T)) regret bound in the heterogeneous agent setting
- Outperforms canonical UCB algorithms and sensitivity-aware baselines in COVID testing, hotel recommendation, and poaching prevention domains
- Particularly effective when agent sensitivities are diverse
- Sensitivity-aware weighting strategy accelerates learning compared to NO-SHARING baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MIN-WIDTH decomposes the combinatorial agent-arm assignment into learning individual arm means, enabling scalability.
- Mechanism: Instead of treating each super-arm (all possible agent-arm combinations) as a single arm, MIN-WIDTH maintains a UCB for each individual arm and assigns agents to arms based on arm UCBs ordered by agent sensitivity.
- Core assumption: The optimal super-arm matches the i-th highest-sensitivity agent to the i-th highest-mean arm, so learning arm means suffices.
- Evidence anchors:
  - [abstract]: "MIN-WIDTH facilitates efficient collaboration among heterogeneous agents, exploiting the known structure in the agents' reward functions to weight their rewards accordingly."
  - [section 5.2]: "Another way to motivate this is to consider the infinite-data setting, in which the UCBs are equal to the true arm means. In that case, to maximize our expected reward we must match the highest-sensitivity agent to the highest-mean arm."
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.574, average citations=0.0. Top related titles: Restless Bandit Problem with Rewards Generated by a Linear Gaussian Dynamical System, Cooperative Multi-Agent Constrained Stochastic Linear Bandits, Lipschitz Bandits with Stochastic Delayed Feedback.
- Break condition: If the optimal assignment requires a different matching structure than sensitivity-ordered assignment, the decomposition fails.

### Mechanism 2
- Claim: MIN-WIDTH combines rewards across agents with heterogeneity-aware weighting to accelerate learning.
- Mechanism: Uses weights wCn,a,n = sa / (Σb sb²cb,n) to construct a shared unbiased estimator for each arm's mean that accounts for different agent sensitivities and variances.
- Core assumption: Agents' rewards are independent and the sensitivities are known, allowing weighted combination without bias.
- Evidence anchors:
  - [section 6, Proposition 1]: "Then the weights wCn,a,n that minimize the width of the confidence interval on µn given by γCn,n = sqrt(ln(2/δ) Σa wCn,a,n²ca,n / 2) under the constraint that the empirical estimator DCn,n is unbiased are wCn,a,n=1 ca,n>0× sa / (Σb sb²cb,n)."
  - [section 7.2]: "In contrast to the NO-SHARING algorithm, now agents effectively get information about arms they have not yet pulled since UCBt,n < ∞ if any agent has pulled armn even if agent a has not."
  - [corpus]: Weak corpus support - no directly relevant bandit papers with explicit sensitivity-aware reward aggregation found.
- Break condition: If agent sensitivities are unknown or rewards are not independent, the weighting scheme becomes invalid.

### Mechanism 3
- Claim: Sensitivity-aware baselines (NO-SHARING, MIN-UCB) help isolate the benefit of reward aggregation versus just sensitivity modeling.
- Mechanism: NO-SHARING gives each agent their own UCB based only on their rewards; MIN-UCB takes the minimum UCB across agents for each arm.
- Core assumption: Both baselines properly model sensitivity but differ in information sharing, allowing controlled comparison with MIN-WIDTH.
- Evidence anchors:
  - [section 7.1]: "The empirical estimator of the mean of arm n according to agent a with sensitivity sa at time t∈T is ... ϵt,a,n=1/sa sqrt(ln(2ANT/δ)/2ct,a,n)."
  - [section 7.2]: "Since all the agent UCBs on the mean of a given arm hold simultaneously by Proposition A.2, we can take the minimum of these UCBs to get a tighter bound."
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.574, average citations=0.0. Top related titles: Restless Bandit Problem with Rewards Generated by a Linear Gaussian Dynamical System, Cooperative Multi-Agent Constrained Stochastic Linear Bandits, Lipschitz Bandits with Stochastic Delayed Feedback.
- Break condition: If agent UCBs don't hold simultaneously (e.g., non-i.i.d. rewards), the MIN-UCB minimum becomes invalid.

## Foundational Learning

- Concept: UCB algorithm for stochastic bandits
  - Why needed here: MIN-WIDTH is a UCB-style algorithm; understanding optimism in the face of uncertainty is essential.
  - Quick check question: Why does the standard UCB algorithm pull the arm with the highest UCB rather than the highest empirical mean?
- Concept: Hoeffding's inequality for concentration bounds
  - Why needed here: Used to derive the confidence intervals for the weighted reward estimators.
  - Quick check question: What conditions must rewards satisfy for Hoeffding's inequality to apply?
- Concept: Combinatorial bandit problems
  - Why needed here: The agent-arm assignment problem is combinatorial; understanding how to decompose it is key.
  - Quick check question: How does treating each super-arm as an arm scale with the number of agents and arms?

## Architecture Onboarding

- Component map: Central planner maintains N-length UCB vector; each agent has fixed sensitivity; rewards are Bernoulli with sensitivity-scaled means
- Critical path: At each timestep: (1) assign agents to arms by descending sensitivity and UCB order, (2) pull super-arm, (3) update UCBs using all collected rewards with sensitivity-aware weights
- Design tradeoffs: Sharing information across agents accelerates learning but requires sensitivity knowledge; decomposition into individual arm learning reduces complexity from factorial to linear in N
- Failure signatures: If sensitivities are misestimated, reward aggregation becomes biased; if agents have very different sensitivities, UCBs may be too conservative due to union bound over all pull combinations
- First 3 experiments:
  1. Run MIN-WIDTH on 2 agents, 2 arms with sensitivities 0.1 and 0.9 to verify decomposition works in simplest case
  2. Compare MIN-WIDTH vs NO-SHARING on 3 agents, 3 arms with diverse sensitivities to see benefit of aggregation
  3. Test robustness by running with estimated sensitivities that are uniformly overestimated and compare regret growth

## Open Questions the Paper Calls Out

- Question: How does the MIN-WIDTH algorithm's regret bound scale with the number of agents A and the number of arms N in the problem?
  - Basis in paper: [explicit] The regret bound in Theorem 2 is given as RT < A(N - 1) + 2sqrt(2ANT ln(2NG(T,A)/δ)) maxS/minS.
  - Why unresolved: While the bound provides a relationship, the actual scaling behavior with respect to A and N is not fully explored or discussed.
  - What evidence would resolve it: Further theoretical analysis or empirical studies investigating the impact of varying A and N on the regret bound would be needed.

- Question: How sensitive is the MIN-WIDTH algorithm's performance to the accuracy of the estimated agent sensitivities?
  - Basis in paper: [explicit] Section 8.5 discusses the robustness of the algorithms to estimated sensitivities, showing that overestimating sensitivities on average hurts performance less than underestimating them.
  - Why unresolved: The experiments only consider a few specific scenarios with overestimated, underestimated, and mixed sensitivity estimates. The general sensitivity to estimation errors is not fully characterized.
  - What evidence would resolve it: Additional experiments with a wider range of sensitivity estimation errors, or theoretical analysis of the algorithm's sensitivity to sensitivity estimation errors, would be needed.

- Question: How does the MIN-WIDTH algorithm perform in scenarios with time-varying arm means or multi-dimensional agent sensitivities?
  - Basis in paper: [inferred] The paper discusses the potential for future work to consider time-varying arm means and multi-dimensional agent sensitivities, suggesting that these scenarios are not currently addressed by the MIN-WIDTH algorithm.
  - Why unresolved: The current MIN-WIDTH algorithm is designed for stationary arm means and scalar agent sensitivities. Its performance in more complex scenarios is not explored.
  - What evidence would resolve it: Developing and evaluating extensions of the MIN-WIDTH algorithm to handle time-varying arm means or multi-dimensional agent sensitivities would be needed.

## Limitations

- The algorithm assumes known agent sensitivities, which may not hold in practice
- Performance can be sensitive to sensitivity estimation errors, particularly when estimated sensitivities are overestimated
- The decomposition approach relies on the assumption that optimal assignment follows sensitivity ordering, which may not hold in all scenarios

## Confidence

- **Mechanism 1 (Decomposition approach)**: High confidence - the decomposition follows standard combinatorial bandit techniques and the optimal assignment structure is clearly defined.
- **Mechanism 2 (Sensitivity-aware weighting)**: Medium confidence - the weighting scheme is mathematically sound under the stated assumptions, but the independence assumption may be restrictive in practice.
- **Mechanism 3 (Baseline comparisons)**: High confidence - the baselines are well-defined and serve their purpose of isolating the benefit of information sharing versus sensitivity modeling.

## Next Checks

1. Test MIN-WIDTH on domains where the optimal assignment does NOT follow sensitivity ordering to verify the decomposition approach's limitations.
2. Conduct experiments with correlated agent rewards to evaluate how the independence assumption affects performance.
3. Implement sensitivity estimation procedures and evaluate how MIN-WIDTH performs when sensitivities must be learned rather than known.