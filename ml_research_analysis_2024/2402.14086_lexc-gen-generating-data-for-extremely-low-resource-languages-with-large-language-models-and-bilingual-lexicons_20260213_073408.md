---
ver: rpa2
title: 'LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large
  Language Models and Bilingual Lexicons'
arxiv_id: '2402.14086'
source_url: https://arxiv.org/abs/2402.14086
tags:
- data
- task
- lexc-gen
- languages
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data scarcity in extremely
  low-resource languages by proposing LexC-Gen, a lexicon-conditioned data generation
  method that creates labeled task data at scale. The core idea is to train large
  language models to generate task data using words from bilingual lexicons, maximizing
  lexical overlap between the data and the lexicons, followed by word-to-word translation
  and quality control through input-label consistency filtering.
---

# LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons

## Quick Facts
- arXiv ID: 2402.14086
- Source URL: https://arxiv.org/abs/2402.14086
- Reference count: 38
- Key result: LexC-Gen achieves 5.6-8.9 point improvements over baseline methods across 17 low-resource languages

## Executive Summary
This paper addresses data scarcity in extremely low-resource languages by proposing LexC-Gen, a lexicon-conditioned data generation method that creates labeled task data at scale. The approach trains large language models to generate task data using words from bilingual lexicons, maximizing lexical overlap between the data and the lexicons, followed by word-to-word translation and quality control through input-label consistency filtering. Experiments on 17 extremely low-resource languages across sentiment analysis and topic classification tasks show that LexC-Gen-generated data achieves significant improvements over existing lexicon-based word translation methods and is competitive with expert-translated gold data.

## Method Summary
LexC-Gen generates labeled task data for low-resource languages by first training an LLM to generate task-relevant sentences conditioned on vocabulary from bilingual lexicons (CTG training). The trained model then generates data instances by sampling words from the lexicon and desired labels, which are subsequently translated to the target low-resource language via word-to-word substitution. To ensure quality, input-label consistency filtering is applied using a high-resource task classifier to filter out instances where predicted labels don't match generated labels. The approach maximizes lexical overlap between generated data and bilingual lexicons while scaling up data quantity to improve lexicon utilization rates.

## Key Results
- LexC-Gen achieves 5.6 and 8.9 points average improvement over baseline word translation methods on sentiment analysis and topic classification respectively
- Generated data is competitive with expert-translated gold data, with smaller performance gaps as training data size increases
- Scaling up generated data increases lexicon utilization rate, which directly correlates with improved task accuracy
- Input-label consistency filtering reduces dataset size by two-thirds but improves task performance while enabling 3x faster model finetuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lexicon-conditioned generation increases lexical overlap between training data and bilingual lexicons
- Mechanism: By prompting LLMs to generate task data using words from bilingual lexicons, the generated data will contain more words that can be directly translated via word-to-word substitution
- Core assumption: LLMs can generate coherent task-relevant sentences when constrained to use specific vocabulary from lexicons
- Evidence anchors:
  - [abstract] "We propose lexicon-conditioned data generation LexC-Gen, a method that generates low-resource-language classification task data at scale. Specifically, LexC-Gen first uses high-resource-language words from bilingual lexicons to generate lexicon-compatible task data"
  - [section 3.2] "We format the CTG training data using the prompt template in Figure 3, so that the LLM learns to generate task input conditioned on c and WH"
  - [corpus] Weak - the corpus contains related work on bilingual lexicon induction but doesn't directly address lexicon-conditioned generation
- Break condition: If the LLM fails to generate coherent sentences using the constrained vocabulary, or if the constrained vocabulary is too limited to express task-relevant concepts

### Mechanism 2
- Claim: Scaling generated data increases lexicon utilization rate
- Mechanism: As more data instances are generated, the model encounters more diverse word combinations from the lexicon, leading to higher coverage of the lexicon vocabulary in the training data
- Core assumption: Each generation instance samples different words from the lexicon, and over many generations, the lexicon coverage approaches completeness
- Evidence anchors:
  - [abstract] "Scaling up generated data increases lexicon utilization rate, which in turn improves task accuracy"
  - [section 5.4] "We observe that as lexicon utilization rate improves, sentiment analysis accuracy increases"
  - [section 5.3] "Scaling is enabled by the generative nature of LexC-Gen, as opposed to previous approaches constrained to the quantity of labeled task data"
- Break condition: If the LLM repeatedly generates similar word combinations, or if the lexicon itself is too small to provide meaningful coverage

### Mechanism 3
- Claim: Input-label consistency filtering improves data quality without requiring labeled data in the target language
- Mechanism: A classifier trained on existing high-resource task data can predict labels for generated data, and instances where predictions don't match the intended labels are filtered out as likely errors
- Core assumption: The high-resource task classifier can generalize sufficiently to the generated data to identify labeling errors
- Evidence anchors:
  - [section 3.3] "we finetune a small classifier mBERT on the same existing task data TH and use it to relabel eTH|L. Then, we filter out all data instances where the classifier's prediction does not match the generated input-label pairs"
  - [section 5.5] "applying input-label consistency filter as data quality control not only reduces the size of the generated training data by two-third, which results in 3 times faster finetuning of the task classifier, but also increases the task performance"
  - [section 5.5] "Our findings align with prior work with English data that shows that optimizing for data quality results in more significant gains than simply scaling up data quantity"
- Break condition: If the high-resource classifier's predictions are systematically different from the LLM's intended labels due to cross-lingual transfer issues

## Foundational Learning

- Concept: Controlled Text Generation (CTG)
  - Why needed here: To train LLMs to generate task-relevant data conditioned on specific vocabulary and labels
  - Quick check question: What is the key difference between standard instruction tuning and CTG training in this context?

- Concept: Word-to-word translation and its limitations
  - Why needed here: Understanding why direct word substitution fails and how LexC-Gen addresses this limitation
  - Quick check question: What is the primary problem with word-to-word translation that LexC-Gen aims to solve?

- Concept: Bilingual lexicon coverage and utilization
  - Why needed here: To understand how lexicon-conditioned generation improves the proportion of lexicon words appearing in training data
  - Quick check question: How does increasing lexicon utilization rate affect downstream task performance?

## Architecture Onboarding

- Component map: Bilingual lexicon + labeled task data → CTG training → Data generation → Quality control → Translation → Task classifier training → Evaluation
- Critical path: Bilingual lexicon + labeled task data → CTG training → Data generation → Quality control → Translation → Task classifier training → Evaluation
- Design tradeoffs:
  - Lexicon size vs. generation quality: Larger lexicons provide more coverage but may contain less relevant words
  - Generation scale vs. quality control: More data improves coverage but increases filtering costs
  - Quality control strictness vs. data retention: Stricter filtering improves quality but reduces dataset size
- Failure signatures:
  - Low lexicon utilization rate despite scaling: LLM isn't effectively using provided vocabulary
  - Poor performance despite high-quality control: The translated data may lack sufficient semantic information
  - Quality control filtering too much data: LLM generation quality may be insufficient
- First 3 experiments:
  1. Test lexicon-conditioned generation vs. standard generation on a small dataset to verify the mechanism
  2. Measure lexicon utilization rate as a function of generated data size
  3. Compare input-label consistency filtering vs. label distillation on the same generated dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal training data size for LexC-Gen generated data to match gold translation performance across different low-resource languages?
- Basis in paper: [explicit] The paper shows that scaling generated data increases lexicon utilization rate and task performance, with sentiment analysis accuracy improving as lexicon utilization rate increases. It also shows that larger task classifiers require less data to achieve same accuracy.
- Why unresolved: While the paper demonstrates the relationship between data size, lexicon utilization rate, and performance, it doesn't establish a clear formula or threshold for optimal data size across different languages and tasks.
- What evidence would resolve it: Systematic experiments varying training data sizes across multiple languages and tasks, establishing a clear correlation between lexicon utilization rate, task performance, and optimal data size.

### Open Question 2
- Question: How can word sense disambiguation be incorporated into LexC-Gen to improve translation quality and task performance?
- Basis in paper: [inferred] The paper acknowledges that word ambiguity is a limitation, noting that random selection is used when words have multiple translations, and that low-resource-language words in lexicons lack linguistic information necessary for word sense disambiguation.
- Why unresolved: The paper identifies this as a limitation but doesn't explore methods for incorporating word sense disambiguation into the generation or translation process.
- What evidence would resolve it: Experiments incorporating word sense disambiguation techniques into LexC-Gen, showing improvements in translation quality and downstream task performance.

### Open Question 3
- Question: How does LexC-Gen perform on other NLU tasks that require syntactic information, such as named entity recognition or machine translation?
- Basis in paper: [explicit] The paper acknowledges that LexC-Gen's word-to-word translation approach may not capture syntactic differences between languages, and that its current success is primarily on semantic tasks like sentiment analysis and topic classification.
- Why unresolved: The paper only evaluates on sentiment analysis and topic classification tasks, leaving the performance on syntax-dependent tasks unexplored.
- What evidence would resolve it: Experiments applying LexC-Gen to named entity recognition, machine translation, and other syntax-dependent tasks, comparing performance to gold data and other approaches.

## Limitations

- The approach relies heavily on the quality and coverage of bilingual lexicons, which may be incomplete or contain noise for truly low-resource languages
- Word-to-word translation inherently cannot handle morphological variations, idiomatic expressions, or context-dependent meanings, limiting the semantic richness of generated data
- The method requires substantial computational resources for CTG training and large-scale data generation, which may not be accessible to researchers working on extremely low-resource languages

## Confidence

*High confidence* in the core experimental results showing LexC-Gen outperforms baseline methods by 5.6-8.9 points on average across 17 languages. The evaluation methodology is sound and the improvements are statistically significant across multiple tasks and languages.

*Medium confidence* in the mechanism explanations. While the lexicon-conditioning approach is intuitive and supported by the results, the exact relationship between lexicon utilization rate and task performance could benefit from more detailed analysis of which vocabulary types contribute most to improvements.

*Low confidence* in the generalizability to languages with very different typological features from English (e.g., morphologically rich languages, languages with different word orders). The paper focuses on languages with Latin scripts and varying degrees of similarity to English, but doesn't test the most extreme cases.

## Next Checks

1. **Error Analysis on Generated Data**: Conduct detailed qualitative analysis of generated instances that failed input-label consistency filtering to understand systematic generation errors and identify whether they stem from lexicon limitations, generation quality, or cross-lingual transfer issues.

2. **Ablation on Lexicon Quality**: Systematically vary the quality and coverage of bilingual lexicons (e.g., using noisy vs. clean lexicons, small vs. large lexicons) to quantify the sensitivity of LexC-Gen performance to lexicon characteristics, identifying the minimum viable lexicon quality for effective generation.

3. **Cross-Lingual Transfer Analysis**: Test whether the high-resource task classifier's predictions on generated data correlate with actual performance when fine-tuned on translated data, and investigate whether domain adaptation techniques could improve the consistency filtering effectiveness for languages with very different linguistic structures from English.