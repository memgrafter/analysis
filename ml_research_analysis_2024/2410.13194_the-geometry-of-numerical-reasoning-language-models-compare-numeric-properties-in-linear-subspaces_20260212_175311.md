---
ver: rpa2
title: 'The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties
  in Linear Subspaces'
arxiv_id: '2410.13194'
source_url: https://arxiv.org/abs/2410.13194
tags:
- entity
- numerical
- language
- layer
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) utilize
  numerical attributes encoded in low-dimensional subspaces when answering numerical
  comparison questions. The authors use partial least squares (PLS) regression to
  identify these subspaces and then intervene in them to manipulate hidden states,
  demonstrating causal effects on comparison outcomes.
---

# The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties in Linear Subspaces

## Quick Facts
- arXiv ID: 2410.13194
- Source URL: https://arxiv.org/abs/2410.13194
- Authors: Ahmed Oumar El-Shangiti; Tatsuya Hiraoka; Hilal AlQuabeh; Benjamin Heinzerling; Kentaro Inui
- Reference count: 23
- Primary result: Language models use low-dimensional linear subspaces to encode numerical attributes and employ a two-step process for numerical reasoning.

## Executive Summary
This paper investigates whether large language models utilize numerical attributes encoded in low-dimensional subspaces when answering numerical comparison questions. The authors use partial least squares (PLS) regression to identify these subspaces and then intervene in them to manipulate hidden states, demonstrating causal effects on comparison outcomes. Experiments on three LLMs (Llama3-8B, Mistral 7B, and Qwen2.5 7B) show that the models use these linear subspaces for reasoning tasks across three numerical attributes (birth/death years and latitudes), with R² scores exceeding 0.8 for predicting numerical attributes and significant intervention effects observed.

## Method Summary
The study uses PLS regression to identify low-dimensional linear subspaces in transformer activations that encode numerical attributes. The methodology involves: (1) extracting hidden states for entities with known numerical attributes, (2) training PLS models to predict these attributes from the hidden states, (3) identifying the principal components that form the encoding subspace, and (4) performing targeted interventions by adding scaled versions of these components to hidden states. The effectiveness is measured through prediction accuracy (R² scores) and intervention effects on comparison outcomes.

## Key Results
- PLS regression identifies subspaces with R² scores exceeding 0.8 for predicting numerical attributes
- Targeted interventions in these subspaces cause predictable changes in comparison outcomes
- The intervention effects are significant compared to random direction baselines
- LLMs employ a two-step reasoning process: first extracting numerical attributes from linear subspaces, then using these directions for comparison

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Language models use low-dimensional linear subspaces to encode numerical attributes for reasoning.
- **Mechanism**: The PLS regression identifies principal components that capture numerical attribute information in hidden states. These components form a subspace where numerical values are represented linearly. When performing comparisons, the model extracts values from this subspace and uses the linear direction for reasoning.
- **Core assumption**: Numerical attributes can be effectively represented and predicted using low-dimensional linear subspaces within the activation space.
- **Evidence anchors**:
  - [abstract] "We first identified, using partial least squares regression, these subspaces, which effectively encode the numerical attributes"
  - [section] "The R2 score of predicting entity’s numerical attributes, using a 5-Component PLS model"
- **Break condition**: If numerical attributes require non-linear relationships or if the data distribution changes significantly, the linear subspace assumption may fail.

### Mechanism 2
- **Claim**: Targeted intervention in identified subspaces causes predictable changes in comparison outcomes.
- **Mechanism**: By adding a scaled version of the first PLS component to the hidden state, the intervention modifies the numerical attribute representation. This manipulation shifts the model's reasoning along the linear direction, causing it to produce different comparison answers based on the altered numerical value.
- **Core assumption**: The identified subspace direction has causal influence over the comparison decision, not just correlation.
- **Evidence anchors**:
  - [abstract] "Further, we demonstrate causality, by intervening in these subspaces to manipulate hidden states, thereby altering the LLM’s comparison outcomes"
  - [section] "The effect of the intervention—specifically, the ratio of flipped answers after performing intervention"
- **Break condition**: If the model uses multiple redundant representations or if other factors override the subspace information during reasoning, interventions may not produce the expected outcomes.

### Mechanism 3
- **Claim**: The model employs a two-step reasoning process: extraction from subspaces followed by linear comparison.
- **Mechanism**: First, the model extracts numerical attributes for each entity from their respective linear subspaces. Second, it uses the linear directions to perform the logical comparison (e.g., determining if one value is greater than another). This suggests the model has learned to use the geometric properties of the subspace for reasoning.
- **Core assumption**: The model's reasoning process is structured as sequential steps of extraction and comparison rather than holistic processing.
- **Evidence anchors**:
  - [abstract] "indicating that LLMs utilize the linearly encoded information for numerical reasoning"
  - [section] "Specifically, subspaces are identified through PLS regression, where directions in low-dimensional subspaces of the activation space encode numerical property information"
- **Break condition**: If the model learns to bypass the subspace extraction step or if it develops non-linear reasoning mechanisms, this two-step process assumption may break down.

## Foundational Learning

- **Concept**: Partial Least Squares (PLS) regression
  - Why needed here: PLS is used to identify the low-dimensional linear subspaces that encode numerical attributes in the model's activation space.
  - Quick check question: How does PLS differ from PCA when dealing with high-dimensional data where predictors exceed observations?

- **Concept**: Hidden state manipulation and intervention techniques
  - Why needed here: The intervention experiments require modifying specific hidden states to test causal relationships between subspaces and reasoning outcomes.
  - Quick check question: What is the difference between correlation and causation in the context of activation space analysis?

- **Concept**: Linear representation hypothesis in neural networks
  - Why needed here: The paper assumes that numerical attributes can be represented in linear subspaces, which is fundamental to the PLS approach and intervention methodology.
  - Quick check question: Under what conditions might the linear representation hypothesis fail for numerical data?

## Architecture Onboarding

- **Component map**: Data preprocessing -> Activation extraction -> PLS training -> Intervention testing
- **Critical path**: The critical path flows from data preprocessing → activation extraction → PLS training → intervention testing. Each step depends on the previous one, with the intervention results providing the key validation of the hypothesis.
- **Design tradeoffs**: Using linear subspaces simplifies the analysis but may miss non-linear relationships. The choice of which layer to intervene in affects results significantly. Using 5 components in PLS is a balance between capturing information and avoiding overfitting.
- **Failure signatures**: If R² scores are low across all layers, the linear subspace assumption may be wrong. If intervention effects are similar to random directions, the identified subspace may not be causally relevant. If effects disappear in later layers, the representation may be transformed or compressed.
- **First 3 experiments**:
  1. Run PLS regression on activations for birth year prediction and visualize R² scores across layers to identify optimal intervention points.
  2. Perform intervention at the identified optimal layer and measure the effect ratio compared to random direction controls.
  3. Test the intervention on out-of-distribution samples to evaluate generalization of the subspace findings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the intervention scaling factor α affect the magnitude and stability of the intervention effects across different numerical attributes?
- Basis in paper: [explicit] The paper mentions that the success of interventions relies heavily on the choice of the scaling factor α applied during the intervention, but does not explore its sensitivity.
- Why unresolved: The paper applies a fixed scaling factor without systematically varying α to understand its impact on intervention effectiveness, leaving uncertainty about optimal scaling and potential instability.
- What evidence would resolve it: Experiments varying α systematically across different ranges and numerical attributes to map out the relationship between scaling factor magnitude and intervention effect strength/stability.

### Open Question 2
- Question: Do the identified linear subspaces for numerical reasoning generalize to more complex numerical operations beyond simple comparisons (e.g., calculating differences, ratios, or temporal intervals)?
- Basis in paper: [inferred] The paper focuses on simple binary comparisons (before/after, higher/lower) and three specific numerical attributes, but does not test more complex numerical reasoning tasks.
- Why unresolved: The paper demonstrates effectiveness for basic comparison tasks but does not investigate whether the linear subspace mechanism extends to more sophisticated numerical operations that might require multi-step reasoning or different mathematical relationships.
- What evidence would resolve it: Testing the intervention approach on tasks involving numerical operations like calculating age differences, temporal intervals, or proportional relationships to see if the same linear subspace mechanisms apply.

### Open Question 3
- Question: What is the precise role of each layer in the two-step numerical reasoning process, and how does information flow between layers during extraction and comparison?
- Basis in paper: [explicit] The paper notes that intervention effects are notable only in the first ~50% of model layers and then diminish, suggesting layer-specific roles, but does not provide a detailed layer-by-layer analysis.
- Why unresolved: While the paper identifies effective intervention layers, it does not map the complete information flow from numerical attribute extraction to comparison reasoning across all layers, leaving unclear how the two-step process is implemented.
- What evidence would resolve it: Detailed analysis of activation patterns and intervention effects across all layers to construct a complete map of information flow and identify the specific functions of different layer groups in the reasoning process.

## Limitations
- The linear subspace assumption may not capture all numerical reasoning mechanisms used by LLMs
- Findings are limited to three specific numerical attributes and may not generalize to other domains
- The intervention methodology assumes semantic changes from adding scaled components, which may not hold for all numerical comparisons

## Confidence

**High Confidence**: The identification of linear subspaces through PLS regression and the demonstration of R² scores exceeding 0.8 are well-supported by the experimental results. The intervention methodology and its application are clearly specified and produce measurable effects.

**Medium Confidence**: The interpretation that LLMs employ a two-step reasoning process (extraction followed by comparison) is supported by the evidence but relies on specific assumptions about how the model uses the subspace information. The causal interpretation of intervention effects, while demonstrated, could be strengthened with additional controls.

**Low Confidence**: The generalizability of findings to other numerical attributes, model architectures, or more complex numerical reasoning tasks remains uncertain without further experimentation.

## Next Checks
1. **Cross-attribute validation**: Test the PLS-based subspace identification and intervention methodology on additional numerical attributes (e.g., populations, distances, or financial figures) to evaluate the generalizability of the approach across different numerical domains.

2. **Alternative representation comparison**: Compare the effectiveness of linear subspace interventions against non-linear intervention methods (such as residual stream modifications or attention pattern manipulations) to determine whether linear subspaces are indeed optimal for numerical reasoning.

3. **Temporal stability analysis**: Conduct experiments across multiple training checkpoints or with fine-tuned versions of the same base models to assess whether the linear subspace encoding of numerical attributes is stable over time or varies with model specialization.