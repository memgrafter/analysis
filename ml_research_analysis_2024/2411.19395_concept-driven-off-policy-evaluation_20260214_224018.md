---
ver: rpa2
title: Concept-driven Off Policy Evaluation
arxiv_id: '2411.19395'
source_url: https://arxiv.org/abs/2411.19395
tags:
- concepts
- variance
- concept
- estimators
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces concept-driven off-policy evaluation (OPE),
  which incorporates interpretable human concepts into policy evaluation to address
  high variance issues in traditional OPE methods. The authors propose a family of
  concept-based importance sampling estimators that remain unbiased and achieve lower
  variance than traditional methods when concepts are known, with theoretical guarantees
  supported by Cramer-Rao bounds.
---

# Concept-driven Off Policy Evaluation

## Quick Facts
- arXiv ID: 2411.19395
- Source URL: https://arxiv.org/abs/2411.19395
- Authors: Ritam Majumdar; Jack Teversham; Sonali Parbhoo
- Reference count: 40
- Primary result: Introduces concept-based OPE estimators that reduce variance by 1-2 orders of magnitude compared to traditional methods when concepts are known, with additional improvements through learned concepts and interventions

## Executive Summary
This paper addresses the high variance problem in off-policy evaluation (OPE) by introducing concept-driven OPE methods. The authors propose using interpretable human concepts instead of raw states in importance sampling estimators, which reduces variance when concepts are known. For scenarios where concepts are unknown, they develop an end-to-end algorithm to learn parameterized concepts optimized for variance reduction, interpretability, and diversity. The method achieves significant improvements in OPE performance on both synthetic (WindyGridworld) and real-world (MIMIC-III) datasets, with up to 3 orders of magnitude improvement in effective sample size. Additionally, the interpretable nature of concepts enables targeted interventions that further enhance evaluation quality.

## Method Summary
The paper introduces concept-based importance sampling (CIS) and concept-based per-decision importance sampling (CPDIS) estimators that replace state-conditioned policies with concept-conditioned policies in traditional IS methods. When concepts are unknown, a Concept Bottleneck Model (CBM) is trained to learn parameterized concepts from states, optimized for variance reduction while maintaining interpretability and diversity. The training algorithm uses a multi-objective loss function combining OPE metrics with constraints on explainability, conciseness, trajectory coverage, and diversity. The framework also enables targeted interventions on high-variance concepts using domain knowledge, allowing practitioners to replace problematic concepts with better alternatives.

## Key Results
- Concept-based OPE estimators reduce variance by 1-2 orders of magnitude compared to traditional IS methods when concepts are known
- The CBM-based learning algorithm achieves up to 3 orders of magnitude improvement in effective sample size on MIMIC-III dataset
- Concept interventions further improve OPE estimates by allowing targeted replacement of high-variance concepts
- MSE and variance improvements are consistent across synthetic (WindyGridworld) and real-world (MIMIC-III) datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using interpretable concepts instead of raw states reduces variance in importance sampling ratios
- Mechanism: Concepts group similar states together, increasing the probability mass of each concept under both behavior and evaluation policies. This reduces the maximum importance sampling ratio (Uc = max πe(a|c)/πb(a|c) < Us = max πe(a|s)/πb(a|s)), which directly tightens the Cramer-Rao bound on MSE
- Core assumption: The concept function ϕ partitions the state space such that each concept c covers multiple similar states s, and the concept policies πc approximate the state policies π within a bounded difference β
- Evidence anchors:
  - [abstract] "introduce a family of concept-based OPE estimators that remain unbiased and reduce variance when concepts are known"
  - [section 5.1] "Variance comparison with traditional OPE estimators. When Cov(ρc0:t rt, ρc0:k rk) ≤ Cov(ρ0:t rt, ρ0:k rk), the variance of known concept-based IS estimators is lower than traditional estimators"
  - [corpus] Weak evidence - no direct citations about variance reduction through concept grouping
- Break condition: If concepts do not group similar states (poor concept design) or if the concept policies deviate significantly from state policies (large β), the variance reduction advantage disappears

### Mechanism 2
- Claim: Learning concepts optimized for variance reduction improves OPE performance
- Mechanism: The end-to-end algorithm optimizes parameterized concepts using a loss function that includes the OPE variance metric, along with interpretability and diversity constraints. This finds concept representations that simultaneously satisfy desiderata and minimize OPE variance
- Core assumption: The concept bottleneck model can learn parameterized concepts that satisfy the explainability, conciseness, trajectory coverage, and diversity desiderata while optimizing for variance reduction
- Evidence anchors:
  - [abstract] "develop an end-to-end algorithm to learn interpretable, concise, and diverse parameterized concepts optimized for variance reduction"
  - [section 6.1] "We aim to learn our concepts using a CBM parameterized by θ. The CBM maps states to outputs through an intermediary concept layer"
  - [corpus] Weak evidence - no direct citations about variance-optimized concept learning
- Break condition: If the loss landscape is too complex or non-convex, optimization may fail to find good concepts, or may overfit to reduce variance at the expense of bias

### Mechanism 3
- Claim: Interventions on learned concepts can further improve OPE estimates
- Mechanism: Because concepts are interpretable, practitioners can identify high-variance concepts and intervene by replacing them with better alternatives (either state representations or domain-knowledge-based concepts). This allows targeted improvement of problematic areas
- Core assumption: The learned concepts are interpretable enough that practitioners can identify which concepts contribute most to variance and understand how to intervene effectively
- Evidence anchors:
  - [abstract] "allow for targeted interventions on specific concepts, further enhancing the quality of these estimators"
  - [section 7.1] "We define criteria κ : (ht, ct) → {0, 1} as a function constructed from domain expertise that takes in (ht, ct) as input and outputs a boolean value"
  - [corpus] Weak evidence - no direct citations about concept-based interventions for OPE
- Break condition: If concepts are not sufficiently interpretable or if domain knowledge for interventions is unavailable, this mechanism cannot be applied

## Foundational Learning

- Concept: Importance Sampling (IS) and its variance issues
  - Why needed here: The paper builds on IS methods for OPE and aims to reduce their high variance through concepts
  - Quick check question: Why does importance sampling suffer from high variance in OPE, and how do the importance weights contribute to this problem?

- Concept: Concept Bottleneck Models (CBMs)
  - Why needed here: The paper uses CBMs to learn interpretable concepts from data when domain knowledge is unavailable
  - Quick check question: How do CBMs differ from standard supervised learning models, and what are the key design choices in their architecture?

- Concept: Off-Policy Evaluation (OPE) metrics
  - Why needed here: The paper evaluates performance using metrics like bias, variance, MSE, and effective sample size (ESS)
  - Quick check question: What is the relationship between bias, variance, and MSE in OPE, and why might a practitioner prefer lower variance even at the cost of some bias?

## Architecture Onboarding

- Component map:
  State -> CBM -> Concept -> IS estimator -> OPE estimate

- Critical path: State → CBM → Concept → IS estimator → OPE estimate
  The CBM must learn good concepts, which the IS estimators must use effectively to produce accurate OPE estimates

- Design tradeoffs:
  - Concept complexity vs. interpretability: More complex concepts may reduce variance more but become harder to interpret and intervene on
  - Variance vs. bias: The optimization focuses on variance reduction, which may increase bias
  - Training stability: The multi-objective loss landscape can lead to convergence issues and NaN values

- Failure signatures:
  - High variance in OPE estimates despite concept-based methods → concepts not grouping similar states effectively
  - Poor convergence or NaN values during training → loss landscape too complex or learning rate too high
  - Low interpretability of learned concepts → concept parameterization not aligned with human-understandable features

- First 3 experiments:
  1. Implement the known concept version on WindyGridworld to verify variance reduction compared to traditional IS
  2. Test the learning algorithm on a simple environment to ensure concepts are being optimized for variance reduction
  3. Implement the intervention framework on learned concepts to verify that targeted interventions can improve OPE estimates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do concept-based OPE estimators perform in partially observable environments where state information is incomplete or noisy?
- Basis in paper: [inferred] The paper focuses on fully observable MDPs and mentions that future work will address partially observable environments, but does not evaluate performance in such settings.
- Why unresolved: The current theoretical framework and experimental results assume complete state observability, leaving performance characteristics in POMDPs unexplored.
- What evidence would resolve it: Empirical studies comparing concept-based OPE to traditional methods in partially observable environments with varying levels of observation noise.

### Open Question 2
- Question: What is the optimal balance between concept interpretability and OPE performance when concepts must satisfy multiple competing desiderata?
- Basis in paper: [explicit] The paper mentions the loss function combines OPE metrics, interpretability, and diversity objectives, but doesn't explore the trade-offs between these competing goals.
- Why unresolved: The current methodology uses weighted combinations of losses without systematically investigating how different weightings affect both performance and interpretability.
- What evidence would resolve it: A systematic ablation study varying weights on different loss components and measuring corresponding changes in OPE metrics and concept interpretability scores.

### Open Question 3
- Question: How sensitive are concept-based OPE estimators to concept leakage when the CBM inadvertently learns information about future states/rewards?
- Basis in paper: [inferred] The paper acknowledges potential CBM concept leakage as a limitation but doesn't empirically investigate its impact on OPE performance or propose mitigation strategies.
- Why unresolved: While concept leakage is mentioned as a concern, the paper doesn't quantify its effects or evaluate robustness to such leakage in the experimental results.
- What evidence would resolve it: Experiments comparing OPE performance when CBMs are trained with and without access to future information, along with metrics quantifying concept leakage.

## Limitations
- The method relies heavily on synthetic data for validation, with limited real-world testing beyond the MIMIC-III dataset
- The intervention framework's practical effectiveness remains largely theoretical with minimal empirical demonstration
- Potential concept leakage from CBMs learning future information is acknowledged but not empirically investigated

## Confidence
- Known concept variance reduction (High): The Cramer-Rao bound analysis provides rigorous theoretical support, and synthetic experiments confirm the mechanism
- Unknown concept learning effectiveness (Medium): While the framework is sound, the multi-objective optimization may struggle in practice, and the limited real-world testing reduces confidence
- Intervention framework practical utility (Low): This remains largely conceptual with minimal empirical validation of how practitioners would actually implement concept-based interventions

## Next Checks
1. Implement the intervention framework on MIMIC-III data with domain expert involvement to assess practical interpretability and utility
2. Test the concept learning algorithm on additional real-world domains to evaluate robustness across different data distributions and concept structures
3. Conduct ablation studies removing interpretability and diversity constraints to quantify their impact on variance reduction and OPE performance