---
ver: rpa2
title: 'Emotion Identification for French in Written Texts: Considering their Modes
  of Expression as a Step Towards Text Complexity Analysis'
arxiv_id: '2405.14385'
source_url: https://arxiv.org/abs/2405.14385
tags:
- annotate
- motionnelle
- emotions
- emotional
- ponse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a model for identifying and classifying emotions
  in French written texts, considering both the emotional category and the mode of
  expression. The model addresses four tasks: predicting the presence of emotion,
  identifying the mode of expression (labeled, behavioral, displayed, or suggested),
  determining whether the emotion is basic or complex, and classifying the emotional
  category.'
---

# Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis

## Quick Facts
- arXiv ID: 2405.14385
- Source URL: https://arxiv.org/abs/2405.14385
- Reference count: 27
- Primary result: Proposed multi-task model outperforms SVM, XGBoost, and GPT-3.5 in-context learning for French emotion classification

## Executive Summary
This paper presents a multi-task learning model for identifying and classifying emotions in French written texts, considering both emotional categories and modes of expression. The model addresses four related tasks: predicting emotion presence, identifying expression mode (labeled, behavioral, displayed, suggested), determining basic vs. complex emotion type, and classifying emotional category. Experiments demonstrate that the model significantly outperforms existing approaches including SVM, XGBoost, and GPT-3.5 with in-context learning, achieving F1 scores nearly double those of the best baseline for three of the four tasks.

## Method Summary
The model uses a fine-tuned CamemBERT base architecture for multi-task learning across four emotion classification tasks. It takes a triplet of sentences (previous, target, next) as input and jointly predicts 19 binary labels corresponding to the four tasks. The training follows a two-stage approach: first fine-tuning task A (emotion presence) for 3 epochs, then all tasks together for 6 epochs using binary cross-entropy loss and Adam optimizer. Class weights are capped at 50Ã— to handle rare classes, and the dataset consists of 1,594 French texts (28K sentences) for children aged 6-14.

## Key Results
- The proposed model achieves F1 scores almost double those of the best baseline for tasks B, C, and D
- Human expert evaluation confirms model performance, with experts agreeing with predictions in high proportions
- Suggested emotions are recognized with lower F1 scores (<0.5) compared to labeled emotions (>0.8), indicating the model's challenge with indirect emotional expressions
- The model successfully identifies correlations between expression modes and emotional categories

## Why This Works (Mechanism)

### Mechanism 1
The multi-task learning framework improves overall emotion classification performance by capturing interactions between expression modes and emotional categories. By jointly training all four tasks on the same model, it can leverage shared representations and correlations between these related tasks, leading to better generalization across all tasks.

### Mechanism 2
The model's superior performance over GPT-3.5 with in-context learning demonstrates that fine-tuning is necessary for this task. Fine-tuning allows the model to learn task-specific representations and adapt to the nuances of the French language and the specific annotation schema, while in-context learning relies on general knowledge and may not capture these specificities.

### Mechanism 3
The model's ability to recognize suggested emotions, despite their indirect nature, demonstrates its capacity to capture complex linguistic cues. The model learns to identify suggested emotions by recognizing patterns in the text that are conventionally associated with emotional experiences, even when these emotions are not explicitly stated.

## Foundational Learning

- **Multi-task learning**: Why needed - The paper addresses four related tasks that can benefit from shared representations and mutual information. Quick check - How does joint training of related tasks improve performance compared to training each task separately?
- **Transformer-based language models**: Why needed - The model uses CamemBERT, a French-specific BERT variant, to leverage pre-trained representations of the French language. Quick check - What advantages do pre-trained transformer models offer for downstream NLP tasks compared to training from scratch?
- **Fine-tuning vs. in-context learning**: Why needed - The paper demonstrates that fine-tuning the CamemBERT model outperforms using GPT-3.5 with in-context learning. Quick check - What are the key differences between fine-tuning and in-context learning, and when is each approach more appropriate?

## Architecture Onboarding

- **Component map**: Input triplet (previous, target, next) -> CamemBERT encoder -> Binary classification layer (19 outputs) -> Binary cross-entropy loss
- **Critical path**: 1) Tokenize input triplet, 2) Pass through CamemBERT encoder, 3) Apply classification head to get label predictions, 4) Compute binary cross-entropy loss, 5) Update model parameters using Adam optimizer
- **Design tradeoffs**: Using CamemBERT base instead of larger models for efficiency and to demonstrate effectiveness of fine-tuning; multi-task learning vs. separate models for each task (tradeoff between performance and complexity); triplet input vs. single sentence input (tradeoff between context and computational cost)
- **Failure signatures**: Poor performance on suggested emotions (F1 < 0.5) indicates difficulty in capturing indirect emotional expressions; confusion between labeled and suggested modes suggests ambiguity in these categories; inability to predict rare emotional categories (guilt, disgust, jealousy) indicates insufficient training data
- **First 3 experiments**: 1) Train baseline model on Task A only to establish benchmark, 2) Train separate models for each task to compare against multi-task approach, 3) Vary input context (single sentence vs. triplet) to assess impact of surrounding context

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed model perform on intra-sentential emotion prediction? The paper mentions future work includes "intra-sentential predictions, allowing the inclusion of other notions, such as that of experiencer." This remains unresolved as the paper focuses on sentence-level classification.

### Open Question 2
What is the impact of fine-tuning larger models (e.g., Llama2, Mistral) on the performance of the proposed emotion classification model? While the paper uses CamemBERT base, it states that "fine-tuning larger models is part of our future work."

### Open Question 3
How does the proposed model perform on text complexity analysis applications? The paper states that "Application to complexity analysis are left for future work," leaving this exploration unaddressed.

## Limitations

- The annotated French emotion corpus used in this study is not publicly available, making direct reproduction challenging
- The model's effectiveness is demonstrated only on French texts, with no validation of cross-linguistic generalization
- Performance on rare emotion categories (guilt, disgust, jealousy) is significantly lower due to insufficient training examples

## Confidence

**High confidence**: The claim that the multi-task learning framework outperforms single-task approaches and baseline methods is well-supported by experimental results.

**Medium confidence**: The assertion that the model captures meaningful interactions between expression modes and emotional categories is supported by correlation analysis but lacks direct evidence of causal relationships.

**Low confidence**: The claim that suggested emotions can be effectively recognized through pattern learning is weakly supported, as the model's F1 score for suggested emotions remains significantly lower than for labeled emotions.

## Next Checks

1. Conduct ablation study on multi-task learning by training separate models for each task and comparing performance against the multi-task model
2. Test the model's performance on emotion identification tasks in other languages to assess cross-linguistic generalizability
3. Experiment with varying context window sizes and configurations to determine optimal context for accurate emotion identification, particularly for suggested emotions