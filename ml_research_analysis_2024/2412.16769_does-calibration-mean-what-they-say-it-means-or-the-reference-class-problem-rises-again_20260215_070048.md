---
ver: rpa2
title: Does calibration mean what they say it means; or, the reference class problem
  rises again
arxiv_id: '2412.16769'
source_url: https://arxiv.org/abs/2412.16769
tags:
- calibration
- group
- fairness
- groups
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that calibration within groups cannot ensure
  the kind of consistent score interpretation that is often claimed, due to the reference
  class problem. Calibration within groups cannot guarantee that scores "mean the
  same thing" for individuals from different groups, as individuals belong to many
  groups and calibration cannot be satisfied within all of them except in cases of
  perfect prediction.
---

# Does calibration mean what they say it means; or, the reference class problem rises again

## Quick Facts
- arXiv ID: 2412.16769
- Source URL: https://arxiv.org/abs/2412.16769
- Authors: Lily Hu
- Reference count: 0
- Key outcome: Calibration within groups cannot ensure consistent score interpretation due to the reference class problem, as individuals belong to multiple overlapping groups and perfect prediction is practically impossible.

## Executive Summary
This paper argues that calibration within groups cannot ensure the kind of consistent score interpretation that is often claimed, due to the reference class problem. Calibration within groups cannot guarantee that scores "mean the same thing" for individuals from different groups, as individuals belong to many groups and calibration cannot be satisfied within all of them except in cases of perfect prediction. The author shows that the reference class problem affects not just calibration but other group statistical criteria that claim a close connection to fairness. The paper highlights the risks and pitfalls of the predominant methodology in algorithmic fairness based on stylized cases, which often fail to capture the complexities of real-world scenarios. The author concludes by emphasizing the need to reconcile the abstracted statistical view of groups with the concrete view of actual individuals to ensure fair treatment.

## Method Summary
The paper employs philosophical analysis to examine the "Same Meaning picture" of calibration and identify the reference class fallacy in assuming that calibration within some group speaks to the meaning of an individual's score. The analysis focuses on formal definitions of calibration and calibration within groups, and critiques the normative connection between base rate tracking and fairness. The methodology involves examining stylized cases and toy examples to reveal underlying assumptions and fallacies in common interpretations of calibration as a fairness metric.

## Key Results
- Calibration within groups cannot ensure consistent score interpretation because individuals belong to multiple overlapping groups
- The reference class problem affects not just calibration but other group statistical criteria that claim a close connection to fairness
- Only perfect predictors can meet calibration within groups for all groups an individual belongs to, but perfect prediction is practically impossible

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Calibration within groups cannot ensure that scores "mean the same thing" for individuals from different groups because individuals belong to multiple overlapping groups.
- Mechanism: The reference class problem arises when trying to interpret an individual's score because the individual belongs to many groups, some calibrated and some miscalibrated.
- Core assumption: Individuals have multiple group memberships and belong to many overlapping groups.
- Evidence anchors:
  - [abstract] "Since concrete actual people belong to many groups, calibration cannot ensure the kind of consistent score interpretation that the Same Meaning picture implies matters for fairness, unless calibration is met within every group to which an individual belongs."
  - [section 2.2] "When an individual belongs to many groups—when they are not only Black but also male and also 35 years-old and so also a 35 year-old Black male—the claim that calibration within groups ensures that their score of 8 means the same thing regardless of the group to which they belong invites the follow-up question, 'Which group?'"
  - [corpus] Weak connection - no direct mention of reference class problem in corpus neighbors.
- Break condition: If individuals had only one group membership, calibration within groups could ensure consistent score interpretation.

### Mechanism 2
- Claim: The Same Meaning picture commits a reference class fallacy by inferring from calibration within some group to the "meaning" or evidential value of an individual's score.
- Mechanism: The inference assumes that calibration within a pre-specified group speaks to the meaning of an individual's score simply because they belong to that group.
- Core assumption: The Same Meaning picture assumes a straightforward answer to the question of what an individual's relevant "group membership" is.
- Evidence anchors:
  - [abstract] "The Same Meaning picture thus commits a reference class fallacy by inferring from calibration within some group to the 'meaning' or evidential value of an individual's score, because they are a member of that group."
  - [section 2.2] "Making this inference, however, requires assuming a straightforward answer to the question of what an individual's relevant 'group membership' is."
  - [corpus] No direct mention of reference class fallacy in corpus neighbors.
- Break condition: If we had a principled way to determine which group membership is relevant for any given individual, the reference class fallacy could be avoided.

### Mechanism 3
- Claim: Even perfect predictive accuracy cannot solve the reference class problem for calibration within groups.
- Mechanism: Only perfect predictors may meet the bar of calibration within every group to which an individual belongs, but perfect prediction is practically impossible.
- Core assumption: Perfect prediction is practically impossible and individuals belong to many groups.
- Evidence anchors:
  - [abstract] "Alas only perfect predictors may meet this bar."
  - [section 2.1] "While calibration neat (Definition 1) may be satisfied by an imperfect predictor, only perfect predictors may satisfy calibration within groups for all groups."
  - [corpus] No direct mention of perfect prediction in corpus neighbors.
- Break condition: If perfect prediction were achievable, calibration within groups could ensure consistent score interpretation.

## Foundational Learning

- Concept: Reference class problem
  - Why needed here: The paper's core argument is that calibration within groups cannot ensure consistent score interpretation because individuals belong to multiple groups, creating a reference class problem.
  - Quick check question: What is the reference class problem and how does it affect the interpretation of calibrated scores?

- Concept: Calibration within groups
  - Why needed here: The paper argues against the common interpretation that calibration within groups ensures scores "mean the same thing" across different groups.
  - Quick check question: How is calibration within groups formally defined and what does it claim to ensure?

- Concept: Statistical criteria for fairness
  - Why needed here: The paper situates its argument within the broader debate about which statistical criteria are genuinely connected to fairness.
  - Quick check question: What are the main statistical criteria for fairness discussed in the algorithmic fairness literature?

## Architecture Onboarding

- Component map: Risk scoring algorithm -> Group-based statistical analysis (calibration) -> Score interpretation -> Decision-making
- Critical path: Risk scoring → Group-based statistical analysis (calibration) → Score interpretation → Decision-making
- Design tradeoffs: Calibration within groups vs. other fairness metrics (like equal error rates); statistical fairness vs. individual fairness; simplicity of single-group analysis vs. complexity of multi-group analysis
- Failure signatures: Miscalibration across groups; reference class fallacies in score interpretation; unfairness despite statistical parity; trade-offs between different fairness metrics
- First 3 experiments:
  1. Test calibration within groups on a simple dataset with multiple overlapping groups to observe reference class issues
  2. Compare decision outcomes using calibrated vs. non-calibrated scores across different groups
  3. Implement multicalibration approach to see if it mitigates reference class problems compared to single-group calibration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the normative implications of calibration differ when viewed through an intersectional lens that considers overlapping group memberships versus traditional single-group analyses?
- Basis in paper: [explicit] The paper argues that calibration within groups cannot ensure consistent score interpretation because individuals belong to multiple groups simultaneously, and that intersectional approaches may better capture these complexities.
- Why unresolved: Current discussions of calibration typically focus on single-group analyses, and the paper doesn't provide a concrete framework for incorporating intersectional perspectives into fairness metrics.
- What evidence would resolve it: Empirical studies comparing calibration outcomes using intersectional versus single-group approaches across diverse populations, showing how different methodological choices affect fairness assessments.

### Open Question 2
- Question: What are the precise philosophical foundations that would justify the normative connection between base rate tracking and fairness, beyond the intuitive appeal of "meaning-based" arguments?
- Basis in paper: [explicit] The paper critiques Benjamin Eva's argument that base rate tracking is motivated by fairness intuitions, showing that this argument relies on similar reference class fallacies as calibration-based justifications.
- Why unresolved: The paper identifies the reference class problem in base rate tracking arguments but doesn't propose an alternative philosophical foundation for why base rates should matter for fairness.
- What evidence would resolve it: A rigorous philosophical argument that either successfully defends base rate tracking without reference class fallacies or demonstrates why such an argument cannot exist.

### Open Question 3
- Question: How can we develop methodological frameworks that bridge the gap between highly abstracted toy cases and real-world algorithmic fairness assessments?
- Basis in paper: [explicit] The paper criticizes the predominant methodology in algorithmic fairness that relies on stylized cases, arguing that these cases fail to capture the complexities of real-world scenarios and can lead to fallacious reasoning.
- Why unresolved: While the paper identifies problems with current methodological approaches, it doesn't propose concrete alternatives for how to conduct fairness assessments that account for real-world complexity.
- What evidence would resolve it: Case studies demonstrating how different methodological approaches (abstract vs. realistic) lead to different fairness assessments of the same algorithm, or frameworks that successfully incorporate both theoretical rigor and real-world complexity.

## Limitations
- The paper's argument relies heavily on philosophical claims about individuals belonging to multiple overlapping groups, but the extent to which real-world algorithmic systems actually face this problem remains unclear
- The analysis assumes a specific interpretation of what it means for scores to "mean the same thing," which may not align with how practitioners actually use calibration metrics
- The paper focuses primarily on theoretical arguments rather than empirical evidence about how reference class problems manifest in practice

## Confidence
- Medium confidence in the core claim that calibration within groups cannot ensure consistent score interpretation across individuals from different groups
- Medium confidence that the reference class problem affects other group statistical criteria beyond calibration
- Low confidence in claims about how this specifically impacts real-world algorithmic fairness implementations, as the paper focuses primarily on theoretical arguments

## Next Checks
1. Analyze a real-world risk scoring dataset with multiple overlapping demographic groups to empirically measure how often individuals face reference class ambiguities when interpreting their scores
2. Compare decision outcomes across multiple fairness metrics (calibration, equal error rates, demographic parity) on the same dataset to quantify the practical tradeoffs between different fairness approaches
3. Implement a multicalibration approach and test whether it meaningfully reduces reference class ambiguities compared to single-group calibration in practice