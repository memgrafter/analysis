---
ver: rpa2
title: Leveraging Large Language Models for Suicide Detection on Social Media with
  Limited Labels
arxiv_id: '2410.04501'
source_url: https://arxiv.org/abs/2410.04501
tags:
- posts
- suicide
- llms
- data
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to detect suicidal content on social
  media using large language models (LLMs) under limited labeled data conditions.
  The authors generate pseudo-labels for unlabeled data via LLM prompting, combine
  these with expert-annotated labels, and fine-tune several LLMs using Macro Double
  Soft F1 loss.
---

# Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels

## Quick Facts
- arXiv ID: 2410.04501
- Source URL: https://arxiv.org/abs/2410.04501
- Reference count: 40
- Primary result: Ensemble approach achieves 0.770 weighted F1 on public test set

## Executive Summary
This paper presents a method for detecting suicidal content on social media using large language models under limited labeled data conditions. The authors generate pseudo-labels for unlabeled data through LLM prompting, combine these with expert-annotated labels, and fine-tune multiple LLMs using Macro Double Soft F1 loss. Their ensemble model, combining Qwen2-72B-Instruct prompting with fine-tuned Llama3 and Gemma2 models, outperforms individual models by approximately 5 percentage points on the Suicide Ideation Detection on Social Media Challenge dataset.

## Method Summary
The authors address the challenge of suicide detection with limited labeled data by employing a semi-supervised learning approach. They first generate pseudo-labels for unlabeled data using LLM prompting with the Qwen2-72B-Instruct model. These pseudo-labels are then combined with expert-annotated labels to create an augmented training set. Multiple LLMs (Llama3 and Gemma2) are fine-tuned on this augmented dataset using Macro Double Soft F1 loss to handle class imbalance. Finally, an ensemble model is created by combining the prompting approach with the fine-tuned models. The entire pipeline is evaluated on the Suicide Ideation Detection on Social Media Challenge dataset, achieving strong performance metrics.

## Key Results
- Ensemble approach achieves weighted F1 score of 0.770 on public test set
- Ensemble approach achieves weighted F1 score of 0.731 on private test set
- Outperforms individual models by approximately 5 percentage points
- Larger LLMs yield better prompting performance

## Why This Works (Mechanism)
The method leverages the strong zero-shot and few-shot capabilities of large language models to generate pseudo-labels for unlabeled data, effectively expanding the training dataset. By combining these pseudo-labels with expert-annotated labels, the model benefits from both the LLM's broad knowledge and the domain-specific expertise of human annotators. The fine-tuning process with Macro Double Soft F1 loss addresses class imbalance issues common in suicide detection tasks. The ensemble approach combines the strengths of both prompting and fine-tuned models, capturing different aspects of the detection task and improving overall robustness.

## Foundational Learning
- **Pseudo-labeling**: Generating labels for unlabeled data using a model trained on labeled data, then using these pseudo-labels to train a new model. Needed to expand limited labeled datasets. Quick check: Verify pseudo-label quality by comparing to human annotations on a validation set.
- **Macro Double Soft F1 loss**: A loss function that computes the F1 score for each class separately and then averages them, with soft labels allowing for probabilistic predictions. Needed to handle class imbalance and improve model calibration. Quick check: Compare model performance using different loss functions on imbalanced datasets.
- **Ensemble methods**: Combining multiple models to improve overall performance by leveraging their complementary strengths. Needed to reduce variance and bias in predictions. Quick check: Perform ablation studies to determine optimal ensemble composition.
- **Semi-supervised learning**: Learning from both labeled and unlabeled data to improve model performance when labeled data is scarce. Needed to address the limited labeled data problem in suicide detection. Quick check: Compare performance against fully supervised baselines with the same amount of labeled data.
- **Prompt engineering**: Designing effective prompts to elicit desired outputs from LLMs. Needed to generate high-quality pseudo-labels. Quick check: Evaluate pseudo-label quality across different prompt formulations.

## Architecture Onboarding

**Component Map**: Social media posts -> LLM prompting (Qwen2-72B-Instruct) -> Pseudo-labels -> Expert-annotated labels -> Augmented dataset -> Fine-tuning (Llama3, Gemma2) -> Ensemble model -> Suicide detection output

**Critical Path**: Social media posts → LLM prompting → Pseudo-labels → Augmented dataset → Fine-tuning → Ensemble prediction

**Design Tradeoffs**: The approach trades computational resources (large LLMs for prompting and multiple models for ensemble) for improved performance and robustness. This may not be scalable for real-time applications but provides state-of-the-art results for the challenge task.

**Failure Signatures**: Poor pseudo-label quality due to ineffective prompting, overfitting during fine-tuning on noisy pseudo-labels, and suboptimal ensemble weighting could all lead to decreased performance. The method is also sensitive to the quality and representativeness of the expert-annotated labels used for fine-tuning.

**First Experiments**: 1) Evaluate pseudo-label quality by manual inspection and comparison to human annotations on a validation set. 2) Perform ablation studies on the ensemble composition to determine the contribution of each component. 3) Test the model on additional suicide detection datasets to assess generalizability.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability may be limited due to specific characteristics of the challenge dataset used
- Reliance on pseudo-labels introduces potential biases and errors not fully captured in evaluation
- No detailed information provided about prompt engineering process, which significantly impacts pseudo-label quality

## Confidence
High confidence in reported performance metrics, as results are based on the Suicide Ideation Detection on Social Media Challenge dataset with standardized evaluation metrics.

## Next Checks
1. Evaluate the model's performance on multiple independent suicide detection datasets to assess generalizability
2. Conduct a thorough error analysis of the pseudo-label generation process to quantify and characterize potential biases
3. Perform ablation studies to determine the optimal ratio of pseudo-labeled to expert-labeled data for fine-tuning