---
ver: rpa2
title: Improving Speech-based Emotion Recognition with Contextual Utterance Analysis
  and LLMs
arxiv_id: '2410.20334'
source_url: https://arxiv.org/abs/2410.20334
tags:
- emotion
- context
- data
- speech
- baseline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses speech emotion recognition using only text
  transcripts from ASR systems. The authors propose a method that refines ASR transcriptions
  for quality, segments conversations into smaller scripts for context, and experiments
  with different context lengths and prompting techniques using LLMs.
---

# Improving Speech-based Emotion Recognition with Contextual Utterance Analysis and LLMs

## Quick Facts
- arXiv ID: 2410.20334
- Source URL: https://arxiv.org/abs/2410.20334
- Reference count: 0
- Primary result: Achieved 75.2% unweighted accuracy, outperforming baseline by 20%

## Executive Summary
This paper presents a novel approach to speech emotion recognition that uses only text transcripts from ASR systems, achieving state-of-the-art results without acoustic features. The method refines multiple ASR transcriptions for quality, segments conversations into smaller scripts for context, and leverages LLMs to predict emotions from the target utterance. By using script-based context and optimal context lengths, the approach significantly outperforms traditional baseline methods.

## Method Summary
The proposed method addresses speech emotion recognition by first refining multiple ASR transcriptions to ensure data reliability, then segmenting complete conversations into smaller dialogue scripts to provide relevant context for emotion prediction. The approach uses LLMs (specifically ChatGPT) with different prompting techniques and context lengths to classify emotions into four categories: neutral, sad, happy, and angry. The refinement process filters out low-quality transcriptions and selects the most coherent and informative one, while the script-based context approach breaks conversations into smaller segments rather than using entire sessions.

## Key Results
- Achieved 75.2% unweighted accuracy on the test set
- Outperformed baseline by 20% improvement
- Anger was the easiest emotion to predict, while distinguishing between neutral and happy/sad was more challenging

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based emotion recognition works better when using refined transcriptions as input rather than raw ASR outputs.
- Mechanism: By filtering out low-quality transcriptions and using ChatGPT to select the most coherent and informative one, the input data quality improves, leading to better emotion prediction performance.
- Core assumption: ASR models produce transcriptions with varying quality, and selecting the best one improves overall system performance.
- Evidence anchors:
  - [abstract] "We propose a novel approach that first refines all available transcriptions to ensure data reliability."
  - [section] "To address this issue, we designed a straightforward algorithm... that, for each data entry, filtered out any transcriptions that are too short to provide enough information."
  - [corpus] Weak evidence - corpus doesn't contain specific studies on ASR refinement techniques for emotion recognition.

### Mechanism 2
- Claim: Using script-based context rather than entire session context improves emotion prediction accuracy.
- Mechanism: Breaking conversations into smaller dialogue scripts provides more relevant and coherent context for predicting the emotion of a target utterance, avoiding interference from unrelated content.
- Core assumption: Emotional cues are more relevant within smaller dialogue segments than across entire conversations.
- Evidence anchors:
  - [section] "We observed that each conversation consists of smaller dialogues (scripts) which can be processed individually. Thus, we believe it is more efficient to use these scripts as context rather than the entire conversation."
  - [abstract] "We then segment each complete conversation into smaller dialogues and use these dialogues as context to predict the emotion of the target utterance within the dialogue."
  - [corpus] Weak evidence - corpus doesn't contain specific studies comparing script-based vs session-based context for emotion recognition.

### Mechanism 3
- Claim: Increasing context length up to a certain point improves emotion prediction performance.
- Mechanism: LLMs can effectively use longer context windows to capture emotional cues, with performance improving as context length increases until reaching an optimal point.
- Core assumption: Emotional information relevant to predicting the target utterance's emotion is contained within a certain number of preceding utterances.
- Evidence anchors:
  - [section] "There was a steady increase in accuracy until 10, with no significant improvement from 10 to 15."
  - [abstract] "Finally, we investigated different context lengths and prompting techniques to improve prediction accuracy."
  - [corpus] Weak evidence - corpus doesn't contain specific studies on optimal context lengths for LLM-based emotion recognition.

## Foundational Learning

- Concept: Word Error Rate (WER) analysis
  - Why needed here: Understanding WER helps identify which ASR transcriptions are most reliable for emotion recognition tasks.
  - Quick check question: What WER threshold would you consider acceptable for emotion recognition using ASR transcriptions?

- Concept: Context window optimization
  - Why needed here: Determining the optimal amount of preceding context is crucial for balancing performance and computational efficiency.
  - Quick check question: How would you design an experiment to find the optimal context length for a specific emotion recognition task?

- Concept: Prompt engineering for LLMs
  - Why needed here: The effectiveness of LLM-based emotion recognition heavily depends on how prompts are structured and what instructions are given.
  - Quick check question: What are the key components of an effective prompt for emotion recognition using LLMs?

## Architecture Onboarding

- Component map: Multiple ASR transcriptions -> Refinement module -> Script segmentation -> LLM interface -> Emotion classification
- Critical path: Receive multiple ASR transcriptions -> Apply refinement algorithm to select best transcription -> Segment conversation into scripts -> Generate prompt with appropriate context length -> Call LLM for emotion prediction -> Return predicted emotion label
- Design tradeoffs:
  - Context length vs. computational cost
  - Prompt complexity vs. prediction accuracy
  - Refinement strictness vs. information preservation
  - Script size vs. context relevance
- Failure signatures:
  - Consistently poor performance across all emotions
  - High variance in predictions for similar inputs
  - Systematic misclassification of certain emotion pairs (e.g., happy/neutral)
  - Performance degradation with longer context lengths
- First 3 experiments:
  1. Test baseline performance using raw ASR transcriptions with minimal context
  2. Implement refinement algorithm and compare performance against baseline
  3. Vary context length systematically (3, 5, 10, 15 utterances) to identify optimal range

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on post-ASR transcriptions rather than raw audio loses acoustic and prosodic emotional cues
- Refinement algorithm may introduce bias by systematically favoring certain transcription styles or lengths
- Script-based context segmentation may miss emotional transitions that occur across script boundaries

## Confidence

- High Confidence: The overall methodology of using refined transcriptions with context-aware LLMs is sound and well-justified by the experimental results.
- Medium Confidence: The specific claim that script-based context outperforms session-based context is supported by the results but could benefit from more rigorous ablation studies.
- Medium Confidence: The optimal context length of 10 utterances is based on observed performance trends, though the plateau effect suggests diminishing returns rather than a true optimum.

## Next Checks

1. **Cross-validation of refinement algorithm**: Implement a blind test where the refinement algorithm's selections are compared against human judgments of transcription quality to verify it's genuinely selecting more informative content rather than just longer or more complex transcriptions.

2. **Ablation study on context segmentation**: Systematically test performance using session-based context, script-based context, and hybrid approaches to quantify the exact contribution of the script segmentation methodology to overall performance.

3. **Robustness testing across emotion pairs**: Analyze misclassifications to determine if certain emotion pairs (particularly happy/sad/neutral) consistently confuse the system, and test whether alternative prompting strategies or additional context types could resolve these specific confusions.