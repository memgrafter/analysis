---
ver: rpa2
title: Improving the Detection of Small Oriented Objects in Aerial Images
arxiv_id: '2401.06503'
source_url: https://arxiv.org/abs/2401.06503
tags:
- loss
- object
- detection
- oriented
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes a method for detecting small oriented objects
  in aerial images, which is challenging due to their size and orientation. The authors
  introduce the Attention-Points Network, consisting of two losses: Guided-Attention
  Loss (GALoss) and Box-Points Loss (BPLoss).'
---

# Improving the Detection of Small Oriented Objects in Aerial Images

## Quick Facts
- arXiv ID: 2401.06503
- Source URL: https://arxiv.org/abs/2401.06503
- Authors: Chandler Timm C. Doloriel; Rhandley D. Cajote
- Reference count: 40
- Primary result: Attention-Points Network with Guided-Attention Loss and Box-Points Loss improves detection of small oriented objects in aerial images

## Executive Summary
This paper addresses the challenging problem of detecting small oriented objects in aerial images by proposing the Attention-Points Network. The method introduces two novel losses: Guided-Attention Loss (GALoss) which uses coarse-level instance segmentation masks to learn attention features, and Box-Points Loss (BPLoss) which scores box points based on their relative position to target oriented bounding boxes. The approach demonstrates effectiveness on DOTA-v1.5 with small object instances and the maritime-focused HRSC2016 dataset.

## Method Summary
The Attention-Points Network builds upon Oriented R-CNN with ResNet-50-FPN backbone, introducing GALoss and BPLoss to improve small object detection. GALoss learns attention features by comparing them to binary masks derived from bounding box coordinates, while BPLoss refines oriented bounding box regression by scoring predicted box points relative to the target OBB using a sigmoid-derived kernel function. The model is trained for 36 epochs on DOTA-v1.5 and 180 epochs on HRSC2016.

## Key Results
- Improved mAP on DOTA-v1.5 dataset containing extremely small instances (<10 pixels)
- Enhanced performance on HRSC2016 maritime dataset
- Demonstrated effectiveness for small object detection in aerial imagery
- Publicly available code implementation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention mechanism improves detection of small objects by focusing on relevant features
- Mechanism: Self-attention computes global context by relating different positions in the feature map, allowing the model to capture relevant features for small objects
- Core assumption: Self-attention can effectively model the global context needed to identify small objects in aerial images
- Evidence anchors:
  - [abstract] "We used attention mechanism to gather the important features of an object, which increases the model's awareness especially on hard-to-identify objects such as small and complex instances."
  - [section 2.3] "Self-attention searches the whole sentence, both previous and succeeding words, and analyzes the context to predict the next word. It relates different positions of a word in a sentence in order to obtain richer information."
  - [corpus] Weak evidence; related works focus on small object detection but do not explicitly mention self-attention
- Break condition: If the self-attention layer fails to capture relevant global context, or if the RoI size is too small to provide meaningful features for attention computation

### Mechanism 2
- Claim: Guided-Attention Loss (GALoss) refines attention features by comparing them to object masks
- Mechanism: GALoss uses binary cross-entropy to compare attention features with coarse-level instance segmentation masks, encouraging the model to focus on object regions
- Core assumption: Coarse-level masks derived from bounding box coordinates are sufficient to guide attention feature learning
- Evidence anchors:
  - [section 3.1] "GALoss uses an instance segmentation mask as ground-truth to learn the attention features needed to improve the detection of small objects."
  - [abstract] "GALoss uses an instance segmentation mask as ground-truth to learn the attention features needed to improve the detection of small objects."
  - [corpus] Weak evidence; no direct mention of GALoss or similar guided attention approaches in related works
- Break condition: If the coarse masks do not accurately represent object boundaries, or if the attention features fail to converge during training

### Mechanism 3
- Claim: Box-Points Loss (BPLoss) improves oriented bounding box regression by scoring box points based on their relative position to the target OBB
- Mechanism: BPLoss computes the relative position of predicted box points to the target OBB using a kernel derived from the sigmoid function, providing a differentiable approximation of IoU for oriented objects
- Core assumption: The kernel function can accurately approximate the relative position of box points to the target OBB
- Evidence anchors:
  - [section 3.2] "BPLoss is calculated by scoring the box points based on their relative position to the target OBB."
  - [abstract] "These attention features are then used to predict box points for BPLoss, which determines the points' position relative to the target oriented bounding box."
  - [corpus] Weak evidence; no direct mention of BPLoss or similar box-point based loss functions in related works
- Break condition: If the kernel function fails to provide accurate gradients, or if the predicted box points do not align well with the target OBB

## Foundational Learning

- Concept: Oriented Object Detection
  - Why needed here: The paper focuses on detecting small oriented objects in aerial images, which requires specialized techniques beyond standard horizontal bounding box detection
  - Quick check question: What is the main difference between horizontal and oriented bounding boxes, and why is it important for aerial image object detection?

- Concept: Attention Mechanisms
  - Why needed here: Attention mechanisms are used to gather important features for small objects, which can be difficult to detect due to their size and orientation
  - Quick check question: How does self-attention differ from traditional convolutional attention, and why is it more suitable for capturing global context in aerial images?

- Concept: Loss Functions for Object Detection
  - Why needed here: The paper introduces two new loss functions, GALoss and BPLoss, which are critical for training the Attention-Points Network
  - Quick check question: What are the key differences between L1-type and IoU-based loss functions, and why are IoU-based losses preferred for oriented object detection?

## Architecture Onboarding

- Component map:
  Backbone (ResNet-50-FPN) -> Region Proposal Network (RPN) -> Rotated RoIAlign -> Attention-Points Network (GALoss + BPLoss) -> Classification and Regression

- Critical path:
  Feature extraction (Backbone + FPN) → Region proposal generation (RPN) → Feature refinement (Rotated RoIAlign + Attention-Points Network) → Classification and regression

- Design tradeoffs:
  Using coarse-level masks instead of fine-grained instance segmentation masks reduces annotation effort but may introduce noise in GALoss
  The kernel function in BPLoss provides a differentiable approximation of IoU but may not be as accurate as exact IoU computation

- Failure signatures:
  Low mAP scores, especially for small objects and ships
  Noisy learning curves for GALoss and BPLoss
  Misaligned predicted box points with target OBBs

- First 3 experiments:
  1. Implement the baseline Oriented R-CNN model and evaluate its performance on DOTA-v1.5 and HRSC2016 datasets
  2. Add the Attention-Points Network (GALoss and BPLoss) to the baseline model and compare the performance
  3. Conduct ablation studies to evaluate the effectiveness of GALoss and BPLoss separately and together

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but leaves several areas for future research, particularly regarding the extension of the method to 3D data and real-time applications.

## Limitations
- Relies on coarse-level instance segmentation masks which may not accurately represent object boundaries
- Kernel function in BPLoss provides only an approximation of IoU rather than exact computation
- Experimental results primarily focused on DOTA-v1.5 and HRSC2016 datasets, limiting generalizability

## Confidence
- **High Confidence:** The effectiveness of the Attention-Points Network in improving the detection of small oriented objects in aerial images, as evidenced by the experimental results on DOTA-v1.5 and HRSC2016 datasets
- **Medium Confidence:** The mechanisms of Guided-Attention Loss and Box-Points Loss, as the paper provides limited details on their implementation and the assumptions made
- **Low Confidence:** The generalizability of the proposed method to other aerial image datasets, as the experimental results are primarily focused on DOTA-v1.5 and HRSC2016 datasets

## Next Checks
1. Conduct ablation studies to evaluate the effectiveness of Guided-Attention Loss and Box-Points Loss separately and together, as well as their impact on different object categories and sizes
2. Test the proposed method on other aerial image datasets, such as DIOR and UCAS-AOD, to assess its generalizability and robustness
3. Investigate the impact of using fine-grained instance segmentation masks instead of coarse-level masks in the Guided-Attention Loss, and evaluate the trade-off between annotation effort and performance improvement