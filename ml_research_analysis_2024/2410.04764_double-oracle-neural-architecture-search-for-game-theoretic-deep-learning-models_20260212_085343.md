---
ver: rpa2
title: Double Oracle Neural Architecture Search for Game Theoretic Deep Learning Models
arxiv_id: '2410.04764'
source_url: https://arxiv.org/abs/2410.04764
tags:
- generator
- search
- architecture
- game
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DONAS, a double oracle framework for neural
  architecture search (NAS) in game-theoretic deep learning models. The authors propose
  DONAS-GAN and DONAS-AT variants to improve GAN and adversarial training respectively
  by sampling and finetuning multiple networks instead of selecting only one final
  architecture.
---

# Double Oracle Neural Architecture Search for Game Theoretic Deep Learning Models

## Quick Facts
- arXiv ID: 2410.04764
- Source URL: https://arxiv.org/abs/2410.04764
- Reference count: 40
- One-line primary result: DONAS framework improves GAN image quality and adversarial training robustness by using multiple architectures sampled through double oracle framework

## Executive Summary
This paper introduces DONAS, a double oracle framework for neural architecture search (NAS) in game-theoretic deep learning models. The authors propose DONAS-GAN and DONAS-AT variants to improve GAN and adversarial training respectively by sampling and finetuning multiple networks instead of selecting only one final architecture. DONAS employs a double oracle framework where two players (generator/discriminator or classifier/attacker) obtain best responses from oracles and compute meta-strategies using a linear program. The framework includes pruning to maintain scalability. Experiments on MNIST, CIFAR-10, SVHN, and TinyImageNet datasets show significant improvements in both qualitative image generation and quantitative metrics (FID scores). For DONAS-AT, robustness under FGSM and PGD attacks is evaluated, demonstrating enhanced classification accuracy compared to baseline architectures.

## Method Summary
DONAS extends existing NAS methods by incorporating them as best response oracles within a double oracle framework. The framework maintains a meta-matrix game where each entry represents the performance of a generator/discriminator or classifier/attacker pair. In each iteration, best response oracles search for architectures that maximize utility against the current mixed strategy, and these new architectures are added to the game. After sampling multiple architectures, sequential finetuning with Harmonic Mean or Nash distributions ensures complementary learning. Pruning removes weakly-dominated strategies to maintain scalability while preserving solution quality.

## Key Results
- DONAS-GAN significantly improves FID scores on CIFAR-10, SVHN, and TinyImageNet compared to single-architecture baselines
- DONAS-AT achieves higher classification accuracy under FGSM and PGD attacks compared to standard adversarial training
- The framework effectively mitigates mode collapse in GANs by maintaining multiple generators with complementary learning
- Pruning enables the framework to scale to larger strategy spaces while maintaining computational tractability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The double oracle framework improves neural architecture search by iteratively expanding the strategy space with best response oracles rather than selecting only one architecture.
- Mechanism: The framework maintains a meta-matrix game where each entry represents the performance of a generator/discriminator or classifier/attacker pair. In each iteration, the best response oracles search for architectures that maximize utility against the current mixed strategy, and these new architectures are added to the game. This iterative expansion allows the algorithm to capture multiple high-performing architectures instead of committing to a single choice early.
- Core assumption: Mixed Nash equilibria in the meta-matrix game provide better overall performance than single architectures, and the best response oracles can effectively find architectures that improve the current solution.
- Evidence anchors:
  - [abstract]: "DONAS employs a double oracle framework where two players (generator/discriminator or classifier/attacker) obtain best responses from oracles and compute meta-strategies using a linear program"
  - [section]: "DO framework builds a restricted meta-matrix game between the two players and computes the mixed NE of the meta-matrix game, then iteratively adds more strategies"
  - [corpus]: Weak - The corpus contains related work on game-theoretic approaches to deep learning but lacks direct evidence about double oracle frameworks specifically applied to neural architecture search.

### Mechanism 2
- Claim: Sequential finetuning with Harmonic Mean or Nash distributions ensures that multiple generators/discriminators or classifiers learn complementary representations rather than competing for the same data modes.
- Mechanism: After sampling multiple architectures, the finetuning process uses either Harmonic Mean (focusing on ignored samples) or Nash distributions (providing a clearer picture of less-captured data samples) to update each model sequentially. This prevents mode collapse in GANs and ensures diverse feature learning in classifiers.
- Core assumption: Sequential finetuning with these distributions effectively distributes learning across different data modes or features, and the Harmonic Mean specifically handles cases where one generator performs much better than others.
- Evidence anchors:
  - [section]: "We update the objective function of the generator in training with E(z∼pz(z))[D(Gi(z, θgi))] and the sequential generators with harmonic mean"
  - [section]: "The Harmonic Mean makes sure the currently trained generator focuses on the ignored data samples"
  - [corpus]: Weak - The corpus doesn't contain specific evidence about sequential finetuning strategies or Harmonic Mean approaches in neural architecture search.

### Mechanism 3
- Claim: Pruning weakly-dominated strategies maintains scalability while preserving solution quality in the double oracle framework.
- Mechanism: As the meta-matrix game grows with each iteration, the algorithm prunes strategies that are weakly dominated (i.e., never selected with positive probability in the mixed strategy) to keep memory usage manageable while maintaining convergence to the optimal mixed strategy.
- Core assumption: Weakly-dominated strategies can be safely removed without affecting the final mixed Nash equilibrium, and the pruning process doesn't eliminate potentially useful architectures that might become valuable in later iterations.
- Evidence anchors:
  - [abstract]: "we prune the weakly-dominated players' strategies to keep the oracles from becoming intractable"
  - [section]: "we prune the weakly-dominated players' strategies to keep the oracles from becoming intractable"
  - [corpus]: Weak - The corpus lacks direct evidence about pruning strategies in double oracle frameworks for neural architecture search, though pruning is a standard technique in game theory.

## Foundational Learning

- Concept: Game theory and Nash equilibrium
  - Why needed here: The entire framework is built on viewing neural architecture search as a two-player game where players (generator/discriminator or classifier/attacker) have competing objectives, and finding mixed Nash equilibria provides optimal strategy distributions.
  - Quick check question: What is the difference between pure and mixed Nash equilibria, and why is mixed equilibrium more appropriate for this framework?

- Concept: Neural Architecture Search (NAS) techniques
  - Why needed here: The framework extends existing NAS methods (Adversarial-NAS, AdvRush) by incorporating them as best response oracles within the double oracle framework, requiring understanding of how these search methods work.
  - Quick check question: How do differentiable architecture search methods like DARTS differ from evolutionary approaches in terms of search space and computational efficiency?

- Concept: Generative Adversarial Networks (GANs) and Adversarial Training
  - Why needed here: The framework specifically targets these two game-theoretic deep learning paradigms, requiring understanding of their training dynamics, mode collapse issues, and robustness requirements.
  - Quick check question: Why do GANs often suffer from mode collapse, and how does using multiple generators/discriminators help mitigate this issue?

## Architecture Onboarding

- Component map:
  - Double Oracle Framework -> Best Response Oracles -> Pruning Module -> Sequential Finetuning -> Linear Programming Solver

- Critical path: Initialize models → Search new architectures with oracles → Compute mixed NE → Prune strategies → Sequential finetuning → Check termination → Repeat until convergence

- Design tradeoffs:
  - Memory vs. Performance: Larger strategy spaces may find better solutions but require more memory and computation
  - Exploration vs. Exploitation: Balancing between searching new architectures and refining existing ones
  - Pruning aggressiveness: Aggressive pruning saves memory but risks eliminating useful strategies

- Failure signatures:
  - Convergence to poor solutions: May indicate insufficient exploration or premature pruning
  - Memory exhaustion: Suggests strategy space growing too quickly or inadequate pruning
  - Mode collapse in GANs: Could indicate problems with the finetuning strategy or insufficient diversity in sampled architectures

- First 3 experiments:
  1. Reproduce baseline Adversarial-NAS or AdvRush results on a small dataset (e.g., CIFAR-10) to establish baseline performance
  2. Implement the double oracle framework with a single iteration (no pruning) to verify the meta-game computation and mixed strategy calculation
  3. Add pruning and test with 2-3 iterations on the same dataset to verify scalability improvements while maintaining solution quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the pruning mechanism in DONAS affect the final performance and diversity of the generated architectures?
- Basis in paper: [explicit] The paper mentions pruning to maintain scalability by removing weakly-dominated player strategies, but does not provide detailed analysis of how this affects performance or architectural diversity.
- Why unresolved: The paper only briefly mentions pruning as a mechanism for scalability without quantifying its impact on the quality of the final architectures or the diversity of the generator/discriminator pairs.
- What evidence would resolve it: Detailed ablation studies showing performance metrics (e.g., FID scores) with and without pruning, along with analysis of architectural diversity before and after pruning steps.

### Open Question 2
- Question: What is the optimal number of generators/discriminators (K) for different dataset complexities and sizes?
- Basis in paper: [explicit] The paper experiments with K=5 and K=10 but does not provide theoretical or empirical justification for choosing these values, nor does it explore the relationship between K and dataset characteristics.
- Why unresolved: While the paper shows that increasing K improves performance, it doesn't establish when the benefits plateau or how to determine the optimal K for a given problem.
- What evidence would resolve it: Systematic experiments varying K across different dataset sizes and complexities, along with theoretical analysis of the computational complexity trade-offs at different K values.

### Open Question 3
- Question: How does DONAS compare to other multi-architecture approaches in terms of computational efficiency and convergence speed?
- Basis in paper: [inferred] The paper claims improvements over single-architecture approaches but lacks direct comparisons with other multi-architecture methods like MIX+GAN or MGAN in terms of training time and convergence behavior.
- Why unresolved: The paper focuses on comparing DONAS with single-architecture baselines but doesn't benchmark against other multi-architecture approaches that also aim to address mode collapse and training instability.
- What evidence would resolve it: Head-to-head comparisons with MIX+GAN and MGAN implementations measuring both final performance and training efficiency metrics (GPU hours, convergence iterations, memory usage).

## Limitations

- The empirical evaluation is conducted on relatively small-scale datasets (MNIST, CIFAR-10, SVHN, TinyImageNet) which may not fully demonstrate scalability to large-scale real-world applications.
- The computational cost of the double oracle framework is not explicitly analyzed, though pruning is mentioned as a scalability solution.
- The choice of Harmonic Mean versus Nash distributions for sequential finetuning is presented as experimental rather than theoretically justified.

## Confidence

- **High Confidence:** The core double oracle framework design and its application to neural architecture search for GANs and adversarial training. The mathematical formulation of the meta-matrix game and mixed strategy computation is well-established.
- **Medium Confidence:** The effectiveness of the proposed framework in improving GAN image quality (FID scores) and adversarial robustness (accuracy under attacks). While results show improvements, the specific contribution of the double oracle approach versus other factors is difficult to isolate.
- **Low Confidence:** The scalability claims and pruning effectiveness, as these are mentioned but not thoroughly evaluated. The impact on very large-scale datasets or complex architectures remains uncertain.

## Next Checks

1. **Scalability Test:** Implement the framework on a larger dataset (e.g., ImageNet) to evaluate memory usage and runtime with/without pruning, measuring the trade-off between solution quality and computational cost.
2. **Ablation Study:** Systematically test the contribution of each component (mixed strategies, pruning, sequential finetuning) by removing them individually and measuring the impact on final performance metrics.
3. **Theoretical Analysis:** Derive convergence bounds for the double oracle framework in the context of neural architecture search, quantifying how pruning affects the gap between the restricted and full game solutions.