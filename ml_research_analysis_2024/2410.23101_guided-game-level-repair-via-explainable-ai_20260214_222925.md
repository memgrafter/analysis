---
ver: rpa2
title: Guided Game Level Repair via Explainable AI
arxiv_id: '2410.23101'
source_url: https://arxiv.org/abs/2410.23101
tags: []
core_contribution: This paper introduces an approach to accelerate game level repair
  by using explainable AI to identify regions contributing to unsolvability. The method
  trains a solvability classifier and applies explainability techniques (Deep SHAP,
  Integrated Gradients) to generate per-tile attributions.
---

# Guided Game Level Repair via Explainable AI

## Quick Facts
- arXiv ID: 2410.23101
- Source URL: https://arxiv.org/abs/2410.23101
- Authors: Mahsa Bazzaz; Seth Cooper
- Reference count: 5
- Primary result: Attribution-guided repair reduces repair times while maintaining similar levels of changes compared to baseline methods

## Executive Summary
This paper introduces an approach to accelerate game level repair by using explainable AI to identify regions contributing to unsolvability. The method trains a solvability classifier and applies explainability techniques (Deep SHAP, Integrated Gradients) to generate per-tile attributions. These attributions are transformed into weights that guide a constraint satisfaction solver to prioritize repairing problematic regions. Experiments on three game domains (Super Mario Bros., Super Cat Tales, Cave) show that attribution-guided repairs reduce repair times while maintaining similar levels of changes compared to baseline methods.

## Method Summary
The approach trains a binary classifier to predict level solvability, then uses Deep SHAP and Integrated Gradients to generate per-tile attributions for unsolvability. These attributions are processed into weights by identifying high-attribution regions through connected component analysis at the 80th percentile threshold. The weighted constraint satisfaction solver (MILP formulation) then repairs unsolvable levels by focusing changes on problematic regions. The pipeline was evaluated across three game domains using Sturgeon for level generation and three different solver configurations.

## Key Results
- Attribution-guided repairs reduce repair time compared to baseline methods
- The approach maintains similar levels of tile changes while improving repair efficiency
- Effectiveness is particularly notable for larger, more complex levels where traditional solvers struggle

## Why This Works (Mechanism)

### Mechanism 1
Attribution-guided weights prioritize solver effort on regions most responsible for unsolvability. The classifier identifies tiles with highest attribution scores for unsolvability, which are then assigned the lowest penalty weights. This guides the solver to focus changes on these critical regions first. Core assumption: High attribution tiles are indeed the key to making levels solvable.

### Mechanism 2
The pipeline reduces repair time by guiding solvers away from trial-and-error approaches. Instead of exploring all possible changes uniformly, the weighted solver focuses computational effort on high-impact regions identified by the classifier, reducing search space. Core assumption: Traditional solvers explore uniformly and inefficiently across all tiles.

### Mechanism 3
Attribution-based weights maintain repair quality while improving speed. The approach changes approximately the same number of tiles as baseline methods but does so more efficiently by focusing on problematic regions. Core assumption: Quality of repair (number of changes) is independent of the guidance method.

## Foundational Learning

- Concept: Shapley values and Integrated Gradients as attribution methods
  - Why needed here: These methods quantify how much each tile contributes to the classifier's unsolvability prediction
  - Quick check question: What's the key difference between Deep SHAP and Integrated Gradients in how they compute feature importance?

- Concept: Constraint satisfaction problem formulation for level repair
  - Why needed here: The solver converts level repair into finding variable assignments that satisfy solvability constraints while minimizing changes
  - Quick check question: How does the MILP formulation handle Boolean constraints using numerical variables?

- Concept: Connected component labeling for weight assignment
  - Why needed here: Identifies contiguous regions of high attribution values to assign consistent low weights to problematic areas
  - Quick check question: Why use the 80th percentile threshold rather than top-k selection for identifying problematic regions?

## Architecture Onboarding

- Component map: Sturgeon (Level Generator) → Explainable Classifier → Weight Generator → Weighted Solver
- Critical path: Level generation → Classifier inference → Weight generation → Solver execution
- Design tradeoffs: Attribution quality vs. computation time; Solver choice vs. domain performance; Weight scaling strategy vs. solver effectiveness
- Failure signatures: Solver timeouts on complex levels; Excessive changes to achieve solvability; Classifier accuracy drops
- First 3 experiments:
  1. Run pipeline with uniform weights (baseline) vs. SHAP weights on 100 levels, measure repair time
  2. Test different percentile thresholds (70th, 80th, 90th) for weight assignment on Mario levels
  3. Compare solver performance (pysat-rc2, pysat-rc2-boolonly, scipy) on Supercat levels with IG weights

## Open Questions the Paper Calls Out

### Open Question 1
How would the approach scale to larger, more complex levels beyond the tested sizes? The paper acknowledges this as a limitation, stating "Although this project did not address working on larger levels, future research should focus on exploring this area."

### Open Question 2
Would incorporating explainability methods directly into the level generation process improve the quality of procedurally generated levels? The discussion mentions potential in leveraging attribution values for other features to generate new levels from existing ones.

### Open Question 3
How do different explainability methods compare in terms of effectiveness for level repair? Only two explainability methods were tested, and the relative performance of other methods remains unknown.

## Limitations
- Core assumption that classifier attributions accurately identify unsolvability-critical regions remains untested
- Method's generalizability to domains beyond platformers is not demonstrated
- Scalability to levels with larger tile sets is not addressed

## Confidence

- High confidence in classifier training methodology and solver integration
- Medium confidence in attribution quality's correlation with actual unsolvability
- Low confidence in cross-domain generalization without empirical validation

## Next Checks

1. Perform ablation testing: Compare repair performance using random vs. attribution-based weights to quantify the actual benefit of the guidance mechanism
2. Test on a third, structurally different game domain (e.g., puzzle or strategy game) to evaluate generalizability
3. Conduct sensitivity analysis on the 80th percentile threshold and weight scaling parameters to determine robustness to hyperparameter changes