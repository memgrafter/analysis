---
ver: rpa2
title: Understanding Contrastive Representation Learning from Positive Unlabeled (PU)
  Data
arxiv_id: '2402.06038'
source_url: https://arxiv.org/abs/2402.06038
tags:
- learning
- contrastive
- unlabeled
- positive
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a principled framework for contrastive representation
  learning under Positive-Unlabeled (PU) settings. The authors systematically examine
  how to incorporate weak supervision from labeled positives into contrastive objectives
  while avoiding bias from unlabeled data.
---

# Understanding Contrastive Representation Learning from Positive Unlabeled (PU) Data

## Quick Facts
- **arXiv ID**: 2402.06038
- **Source URL**: https://arxiv.org/abs/2402.06038
- **Reference count**: 40
- **Primary result**: Proposes puCL and puNCE contrastive objectives for PU learning with improved sample efficiency and puPL clustering-based pseudo-labeling

## Executive Summary
This paper addresses the challenge of learning representations from Positive-Unlabeled (PU) data using contrastive learning. The authors introduce puCL, an unbiased contrastive loss that judiciously incorporates weak supervision from labeled positives while treating unlabeled samples conservatively. When class prior is known, they extend this to puNCE, which reweights unlabeled samples as probabilistic mixtures of positives and negatives. For downstream classification, they propose puPL, a clustering-based pseudo-labeling algorithm with PU-aware initialization. Theoretical analysis establishes bias-variance trade-offs and generalization bounds, while extensive experiments show consistent improvements over state-of-the-art methods, particularly in low-supervision regimes.

## Method Summary
The method operates in two stages: (1) Contrastive pretraining using puCL (unbiased loss using labeled positives) or puNCE (prior-aware reweighting) with augmentations and temperature-scaled InfoNCE loss; (2) Downstream classification using puPL, a clustering-based pseudo-labeling algorithm with PU-aware k-means++ initialization. The pipeline trains an encoder on multi-viewed batches, then extracts embeddings for PU datasets, runs puPL to obtain pseudo-labels via clustering, and trains a linear classifier on pseudo-labeled data.

## Key Results
- puCL reduces variance compared to ssCL by using labeled positives to form more reliable positive pairs
- puNCE incorporates class prior knowledge to weight unlabeled samples as probabilistic mixtures, improving sample efficiency
- puPL leverages embedding geometry to assign pseudo-labels without requiring labeled negatives
- Extensive experiments across standard PU benchmarks show consistent improvements over state-of-the-art methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: puCL reduces variance compared to ssCL by using labeled positives to form more reliable positive pairs
- Mechanism: Labeled positives are used to attract all other labeled positives within the batch, creating tighter semantic clusters. Unlabeled samples are treated conservatively via self-supervised augmentation, avoiding incorrect negative assumptions.
- Core assumption: Assumption 1 (Transformation Independence) holds—augmented views of the same sample are i.i.d. draws from the same class marginal.
- Evidence anchors:
  - [abstract]: "puCL, an unbiased and variance-reducing contrastive objective that integrates weak supervision from labeled positives judiciously into the contrastive loss"
  - [section]: "puCL avoids making any explicit assumptions about the labels of the unlabeled data...uses the available labeled positives to form additional attractive pairs"
  - [corpus]: Weak evidence - no direct neighbor papers discuss variance reduction in PU contrastive learning
- Break condition: Assumption 1 fails (augmentations are not i.i.d.), or labeled positives are not representative of the true positive distribution

### Mechanism 2
- Claim: puNCE incorporates class prior knowledge to weight unlabeled samples as probabilistic mixtures, improving sample efficiency
- Mechanism: Each unlabeled sample is treated as a positive with probability π and negative with probability (1-π), creating soft positive-negative pairings. This reweights the similarity terms in the contrastive loss according to the expected composition of unlabeled data.
- Core assumption: Class prior π is known or can be reliably estimated without significant error
- Evidence anchors:
  - [abstract]: "When the class prior is known, we propose Positive Unlabeled InfoNCE (puNCE), a prior-aware extension that re-weights unlabeled samples as soft positive negative mixtures"
  - [section]: "treat each unlabeled sample as a positive example and a negative example with appropriate probabilities"
  - [corpus]: Weak evidence - no direct neighbor papers discuss prior-aware contrastive learning in PU settings
- Break condition: Class prior estimate is highly inaccurate (e.g., ∥π̂ - π*∥ > threshold), leading to severe bias

### Mechanism 3
- Claim: puPL leverages embedding geometry to assign pseudo-labels without requiring labeled negatives
- Mechanism: Uses PU-aware k-means++ initialization—positive centroid from labeled positives, negative centroid sampled from unlabeled samples weighted by distance to positive centroid. Assigns pseudo-labels based on proximity to estimated centroids.
- Core assumption: Contrastive pretraining induces clusterable manifolds where positive and negative instances form distinct regions
- Evidence anchors:
  - [abstract]: "puPL, a pseudo-labeling algorithm that leverages the structure of the learned embedding space via PU aware clustering"
  - [section]: "leverage the geometry of the contrastive embedding space to assign cluster-based pseudo-labels"
  - [corpus]: Weak evidence - no direct neighbor papers discuss PU-aware clustering strategies
- Break condition: Embedding space is not well-clustered (high intra-class variance, low inter-class separation), or labeled positives are not representative

## Foundational Learning

- Concept: InfoNCE contrastive loss and its variants
  - Why needed here: Forms the basis for all contrastive objectives (ssCL, sCL-PU, puCL, puNCE) discussed in the paper
  - Quick check question: What is the difference between the numerator and denominator in the InfoNCE loss formulation?

- Concept: Positive-Unlabeled (PU) learning setup and challenges
  - Why needed here: The entire framework is designed for PU settings where negatives are unlabeled
  - Quick check question: How does the PU setting differ from standard semi-supervised learning?

- Concept: k-means++ initialization and Lloyd's algorithm
  - Why needed here: puPL builds upon these clustering techniques with PU-specific modifications
  - Quick check question: What is the theoretical guarantee provided by k-means++ initialization compared to random initialization?

## Architecture Onboarding

- Component map: Encoder (gB) -> Projection network (hΓ) -> Contrastive objectives (ssCL/sCL-PU/puCL/puNCE) -> puPL clustering -> Downstream classifier

- Critical path: 1. Pretrain encoder using contrastive objective (puCL or puNCE) 2. Extract embeddings for PU dataset 3. Run puPL to obtain pseudo-labels 4. Train linear classifier on pseudo-labeled data

- Design tradeoffs:
  - puCL vs puNCE: puCL is unbiased but puNCE may perform better with accurate prior knowledge
  - puCL vs sCL-PU: puCL avoids bias from treating unlabeled as negatives but may have higher variance
  - puPL vs nnPU: puPL leverages embedding structure but requires well-clustered representations

- Failure signatures:
  - Poor cluster separation in t-SNE visualizations
  - puPL pseudo-labels have low agreement with ground truth
  - puNCE performance degrades significantly with prior misspecification
  - Training loss plateaus early or shows high variance

- First 3 experiments:
  1. Compare puCL vs ssCL on CIFAR-III with varying γ (supervision ratio) to validate variance reduction
  2. Evaluate puPL pseudo-label accuracy on a synthetic Gaussian mixture before training downstream classifier
  3. Test puNCE sensitivity to prior estimation error by perturbing π and measuring performance degradation

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several implicit questions emerge from the methodology and results:

1. How does the performance of puNCE scale when class prior estimates have larger errors beyond the 30% perturbation tested?

2. Can the adaptive mixing coefficient strategy in puCL be extended to use instance-specific weights rather than binary per-sample treatment?

3. What is the theoretical relationship between the variance reduction achieved by puCL and the convergence speed of downstream classification tasks?

4. How does puPL perform when applied to multi-class PU learning scenarios beyond the binary setting?

5. What is the impact of different augmentation strategies on the theoretical guarantees provided for contrastive PU learning?

## Limitations

- The puNCE method's performance is critically sensitive to accurate class prior estimation, with no robust mechanism provided for prior estimation when unknown
- The puPL clustering approach assumes the embedding space is well-clustered after contrastive pretraining, which may not hold for all datasets
- The paper focuses on image classification benchmarks, leaving uncertainty about performance on other data types like text or graphs
- The variance reduction claim for puCL depends heavily on Assumption 1 (transformation independence), which may not hold for complex augmentations

## Confidence

- **High confidence**: The theoretical framework establishing bias-variance trade-offs for contrastive PU learning, the mathematical formulation of puCL and puNCE objectives
- **Medium confidence**: The empirical improvements over baselines across standard benchmarks, the effectiveness of puPL clustering in downstream classification
- **Low confidence**: The generalizability of results to non-image domains, the robustness of puNCE to prior estimation errors

## Next Checks

1. Systematically evaluate puNCE performance across a range of prior estimation errors (∥π̂ - π*∥) to establish the method's sensitivity and identify thresholds beyond which performance degrades significantly.

2. Test the impact of violating Assumption 1 by using augmentations that create dependent views (e.g., random erasing vs. weak flips), measuring how puCL's variance reduction advantage diminishes.

3. Implement and evaluate the complete puCL-puPL pipeline on non-image PU datasets (e.g., text classification with PU reviews or bio-medical data) to assess domain transferability beyond the reported image benchmarks.