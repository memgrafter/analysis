---
ver: rpa2
title: Post-hoc Probabilistic Vision-Language Models
arxiv_id: '2412.06014'
source_url: https://arxiv.org/abs/2412.06014
tags:
- learning
- data
- approximation
- image
- active
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the lack of uncertainty quantification in pre-trained
  vision-language models (VLMs) like CLIP and SigLIP. The authors propose BayesVLM,
  a post-hoc method that leverages a Laplace approximation over the last layers of
  VLM encoders to provide principled uncertainty estimates without retraining.
---

# Post-hoc Probabilistic Vision-Language Models

## Quick Facts
- arXiv ID: 2412.06014
- Source URL: https://arxiv.org/abs/2412.06014
- Reference count: 40
- Key outcome: BayesVLM provides post-hoc uncertainty quantification for pre-trained VLMs like CLIP and SigLIP without retraining, improving calibration and enabling sample-efficient active learning

## Executive Summary
This work addresses the critical gap of uncertainty quantification in pre-trained vision-language models (VLMs) like CLIP and SigLIP. The authors propose BayesVLM, a post-hoc method that leverages Laplace approximation over the last layers of VLM encoders to provide principled uncertainty estimates without requiring retraining. The method introduces ProbCosine, an analytical approach to propagate uncertainty from embeddings to cosine similarities, enabling efficient uncertainty quantification for downstream tasks.

BayesVLM demonstrates significant improvements in zero-shot classification calibration, reducing overconfident predictions while maintaining competitive accuracy. The method also enables sample-efficient active learning by leveraging uncertainty estimates to select informative data for fine-tuning. Importantly, the approach introduces minimal computational overhead and remains effective even when Hessian estimation is performed on proxy datasets, making it practical for real-world deployment.

## Method Summary
BayesVLM employs a Laplace approximation over the projection matrices in pre-trained VLMs, treating the encoders as deterministic while approximating the posterior over the final projection layers. The method uses Kronecker-factored generalized Gauss-Newton (KFAC-GGN) to efficiently estimate the Hessian, enabling tractable covariance computation. ProbCosine analytically propagates uncertainty from Gaussian-distributed embeddings to cosine similarity distributions. For active learning, BayesVLM implements targeted k-NN selection and uses BALD/EPIG acquisition functions with online Laplace updates.

## Key Results
- Improves calibration in zero-shot classification, reducing overconfident predictions while maintaining competitive accuracy
- Enables sample-efficient active learning, achieving comparable performance with fewer labeled samples
- Maintains effectiveness even when Hessian estimation is performed on proxy datasets rather than original training data
- Introduces minimal computational overhead compared to deterministic VLM inference

## Why This Works (Mechanism)

### Mechanism 1
Laplace approximation over projection layers provides tractable uncertainty estimates without retraining. The method fits a Gaussian posterior around the MAP estimate of projection matrices P and Q, using KFAC-GGN for efficient covariance estimation. Core assumption: Posterior over projections can be well-approximated by Gaussian centered at MAP estimate. Break condition: Fails if posterior is highly non-Gaussian or encoders are poorly calibrated.

### Mechanism 2
Independent probabilistic models for image and text modalities allow tractable Bayesian treatment. By assuming i.i.d. data within each modality given the other, the joint contrastive loss decomposes into separate categorical likelihoods. Core assumption: Modality interactions are captured conditionally on MAP estimate, making independence assumption reasonable. Break condition: Fails if modality interactions are too strong or non-linear.

### Mechanism 3
ProbCosine provides efficient, closed-form uncertainty propagation from embeddings to cosine similarities. Given Gaussian distributions over embeddings, ProbCosine analytically approximates the distribution of cosine similarities using first and second moments. Core assumption: Embeddings follow diagonal Gaussian distributions and cosine similarity distribution can be well-approximated by Gaussian. Break condition: Fails if true cosine similarity distribution is highly non-Gaussian.

## Foundational Learning

- **Concept: Laplace approximation for Bayesian deep learning**
  - Why needed: Enables post-hoc uncertainty quantification without retraining VLMs, crucial for safety-critical applications
  - Quick check: What is the relationship between the Laplace approximation and the MAP estimate in Bayesian inference?

- **Concept: Kronecker-factored approximation for Hessian estimation**
  - Why needed: Makes posterior covariance estimation computationally feasible for large-scale models by approximating Hessian as Kronecker product of smaller matrices
  - Quick check: How does the Kronecker-factored approximation reduce the computational complexity of Hessian estimation?

- **Concept: Information-theoretic active learning (BALD, EPIG)**
  - Why needed: Leverages uncertainty estimates from BayesVLM to select informative samples for active learning, improving sample efficiency
  - Quick check: What is the key difference between BALD and EPIG in terms of the information they target?

## Architecture Onboarding

- **Component map**: Input (Image and text data) -> Pre-trained VLM encoders (CLIP/SigLIP, fixed) -> Laplace module (estimates posterior over P and Q) -> ProbCosine (propagates uncertainty to cosine similarities) -> Output (Uncertainty-aware predictions)

- **Critical path**: 1. Estimate Hessian using subset of training data 2. Compute posterior covariance over P and Q 3. Propagate uncertainty through ProbCosine to obtain distribution over cosine similarities 4. Use uncertainty estimates for zero-shot classification or active learning

- **Design tradeoffs**: Fixed encoders vs. full Bayesian treatment (computational efficiency vs. potentially more accurate uncertainty); Diagonal covariance vs. full covariance (memory efficiency vs. richer uncertainty representation); Analytical approximation vs. sampling (speed vs. potential loss of accuracy)

- **Failure signatures**: Overconfident predictions (poor calibration, inadequate uncertainty propagation); Unstable Hessian estimates (high variance in trace estimates, insufficient data or batch size); Poor active learning performance (uncertainty estimates not informative, incorrect i.i.d. assumption)

- **First 3 experiments**: 1. Verify Laplace approximation accuracy on small synthetic dataset with known posterior 2. Test ProbCosine approximation quality by comparing to ground truth cosine similarity distributions 3. Evaluate BayesVLM calibration on held-out validation set for pre-trained CLIP model

## Open Questions the Paper Calls Out

**Open Question 1**: How robust is BayesVLM to using proxy datasets that are structurally different from the original pre-training data? The paper only tested one proxy dataset (CC12M) compared to one original dataset (LAION-400M), leaving uncertainty about performance with diverse proxy data characteristics.

**Open Question 2**: Does the i.i.d. assumption between image and text modalities in BayesVLM introduce any systematic bias in uncertainty estimates? The paper acknowledges this assumption "may be more challenging" in terms of interpretation but doesn't investigate whether it leads to under- or over-estimation of uncertainties.

**Open Question 3**: What is the optimal batch size for estimating the Kronecker factors in the GGN approximation, and how does it affect the stability and accuracy of BayesVLM? The study only tested three batch sizes and didn't explore the full range or investigate impact on uncertainty estimate quality.

## Limitations

- Laplace approximation assumes Gaussian posteriors which may not hold for all VLM architectures or training regimes
- i.i.d. assumption for modality independence could break down for tasks requiring strong cross-modal interactions
- ProbCosine's analytical approximation for cosine similarity distributions hasn't been extensively validated against ground truth
- Method's effectiveness depends on having sufficient proxy data for accurate Hessian estimation

## Confidence

- **High confidence**: Post-hoc uncertainty quantification without retraining is achievable and provides computational benefits
- **Medium confidence**: Laplace approximation provides accurate uncertainty estimates for pre-trained VLMs
- **Medium confidence**: ProbCosine's analytical approximation sufficiently captures cosine similarity uncertainty distributions
- **Medium confidence**: Uncertainty estimates meaningfully improve active learning sample efficiency

## Next Checks

1. Compare BayesVLM's uncertainty estimates against Monte Carlo sampling on a small, controlled dataset where ground truth posterior distributions are computable to validate whether analytical approximations introduce significant bias.

2. Test BayesVLM's calibration performance across multiple VLM architectures (CLIP, SigLIP, and potentially others) and training datasets to assess generalizability beyond reported results.

3. Evaluate BayesVLM's active learning performance in a domain with limited proxy data availability, measuring how performance degrades when Hessian estimation must rely on small, domain-specific datasets rather than large-scale pretraining data.