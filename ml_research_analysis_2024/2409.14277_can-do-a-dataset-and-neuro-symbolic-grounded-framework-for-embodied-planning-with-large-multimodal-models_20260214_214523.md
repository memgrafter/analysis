---
ver: rpa2
title: Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning
  with Large Multimodal Models
arxiv_id: '2409.14277'
source_url: https://arxiv.org/abs/2409.14277
tags:
- planning
- plan
- state
- multimodal
- embodied
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CAN-DO, a dataset designed to evaluate embodied
  planning in large multimodal models through diverse, complex scenarios. It identifies
  significant bottlenecks in visual perception, comprehension, and reasoning in models
  like GPT-4V.
---

# Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models

## Quick Facts
- arXiv ID: 2409.14277
- Source URL: https://arxiv.org/abs/2409.14277
- Reference count: 24
- Primary result: NeuroGround framework significantly improves plan validity for embodied planning tasks by grounding in perceived environment states

## Executive Summary
The paper introduces CAN-DO, a dataset designed to evaluate embodied planning in large multimodal models through diverse, complex scenarios. It identifies significant bottlenecks in visual perception, comprehension, and reasoning in models like GPT-4V. To address these, the authors propose NeuroGround, a neuro-symbolic framework that grounds planning in perceived environment states and augments model-generated plans with symbolic planning engines. Experiments show that NeuroGround significantly outperforms baselines such as chain-of-thought prompting, achieving higher plan validity across multiple planning categories. The framework enhances the embodied planning capabilities of large multimodal models by explicitly considering environment states and leveraging symbolic reasoning.

## Method Summary
The authors developed the CAN-DO dataset containing 100 tasks across 5 planning categories to evaluate embodied planning capabilities. They propose NeuroGround, a neuro-symbolic framework that first perceives environment states from visual inputs, then grounds planning tasks in these states before generating plans. The framework augments large multimodal model outputs with symbolic planning engines to improve plan validity. The approach addresses three key bottlenecks: visual perception challenges, comprehension difficulties with complex instructions, and reasoning limitations when planning requires understanding spatial relationships and object interactions.

## Key Results
- NeuroGround framework significantly outperforms chain-of-thought prompting baselines in plan validity across all planning categories
- Large multimodal models show substantial bottlenecks in visual perception, comprehension, and reasoning for embodied planning tasks
- Grounding planning in perceived environment states and using symbolic planning engines improves performance on complex, diverse scenarios

## Why This Works (Mechanism)
The framework works by addressing the fundamental limitations of large multimodal models in embodied planning through a neuro-symbolic approach. By first perceiving and grounding in the actual environment state, the system provides context that helps overcome comprehension and reasoning challenges. The symbolic planning engine component compensates for the limited reasoning capabilities of LMMs by applying formal planning algorithms to the grounded task representation. This two-stage process - perception and grounding followed by symbolic planning - creates a more robust planning system than relying on LMMs alone, particularly for tasks requiring spatial reasoning and object manipulation understanding.

## Foundational Learning
- Embodied planning: The process of generating executable action sequences for physical or virtual agents based on visual inputs and goals. Needed because LMMs must translate visual observations into actionable plans.
- Visual perception bottlenecks: Challenges in accurately identifying objects, relationships, and spatial configurations from images. Quick check: Evaluate object detection accuracy on planning-relevant scenes.
- Symbolic planning engines: Formal algorithms that generate action sequences based on state representations and goal specifications. Needed to compensate for LMM reasoning limitations.
- Environment state grounding: The process of mapping visual observations to formal state representations. Critical for bridging perception and planning.
- Plan validity metrics: Evaluation criteria measuring whether generated plans are executable and achieve stated goals. Needed to assess framework effectiveness.

## Architecture Onboarding

**Component map:** Perception Module -> Grounding Module -> Symbolic Planner -> Plan Output

**Critical path:** Visual input → Object detection & relationship extraction → State representation → Task grounding → Symbolic planning → Executable plan

**Design tradeoffs:** The framework trades computational efficiency for plan quality by adding a symbolic planning stage. This increases latency but significantly improves plan validity compared to direct LMM generation.

**Failure signatures:** Plans may fail when perception errors cascade through grounding to symbolic planning, or when the symbolic planner cannot handle complex state spaces. Visual ambiguity or insufficient object context are primary failure points.

**First experiments:**
1. Ablation study removing the symbolic planner to measure LMM-only performance
2. Testing plan execution in a physics simulator to validate real-world applicability
3. Evaluating framework performance across varying task complexity levels

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- CAN-DO dataset contains only 100 tasks across 5 planning categories, potentially limiting generalization assessment
- Evaluation focuses on plan validity rather than execution success in real or simulated environments
- Relies on human-defined environment states and goal states, introducing potential subjectivity
- Does not address safety concerns or failure modes when plans are executed in real-world settings

## Confidence

**High confidence:**
- Identification of visual perception and reasoning bottlenecks in LMMs for embodied planning

**Medium confidence:**
- Effectiveness of NeuroGround framework due to limited dataset size and evaluation scope
- Claim that environment state grounding improves planning performance, pending real-world validation

## Next Checks

1. Evaluate plan execution success rate in a physics-based simulator using the generated plans
2. Conduct ablation studies removing individual components of NeuroGround to quantify their specific contributions
3. Test model generalization by creating a held-out test set of tasks not seen during framework development