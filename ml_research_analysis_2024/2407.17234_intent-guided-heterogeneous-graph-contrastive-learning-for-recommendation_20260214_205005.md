---
ver: rpa2
title: Intent-guided Heterogeneous Graph Contrastive Learning for Recommendation
arxiv_id: '2407.17234'
source_url: https://arxiv.org/abs/2407.17234
tags:
- graph
- information
- recommendation
- contrastive
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of incorporating fine-grained
  user and item intents into contrastive learning for recommendation on heterogeneous
  graphs. Existing methods often neglect these intents, which are captured by meta-paths,
  and struggle with noise introduced by these meta-paths.
---

# Intent-guided Heterogeneous Graph Contrastive Learning for Recommendation

## Quick Facts
- arXiv ID: 2407.17234
- Source URL: https://arxiv.org/abs/2407.17234
- Reference count: 40
- Primary result: Achieves 11.48% improvement on Douban Movie and 12.43% on Amazon datasets in recommendation accuracy metrics

## Executive Summary
This paper addresses the challenge of incorporating fine-grained user and item intents into contrastive learning for recommendation on heterogeneous graphs. Existing methods often neglect these intents, which are captured by meta-paths, and struggle with noise introduced by these meta-paths. The proposed Intent-Guided Heterogeneous Graph Contrastive Learning (IHGCL) framework tackles this by: 1) Dual Contrastive Learning (DCL) that aligns intents between meta-paths and enhances views by integrating real interactions with intent information; 2) A Bottlenecked Autoencoder (BAE) that denoises meta-path-driven connections through masked autoencoding and information bottleneck constraints. Experiments on six datasets show IHGCL outperforms state-of-the-art baselines, achieving significant improvements in recommendation accuracy metrics like Recall@20 and NDCG@20.

## Method Summary
The proposed IHGCL framework combines dual contrastive learning with a bottlenecked autoencoder to capture fine-grained user and item intents in heterogeneous graph recommendation. The dual contrastive learning component creates multiple views by integrating real interactions with intent information, then aligns intents between different meta-paths to capture user preferences. The bottlenecked autoencoder applies masked autoencoding with information bottleneck constraints to denoise meta-path-driven connections, addressing the noise issue inherent in using meta-paths for intent representation. This combination allows the model to effectively capture user intents while alleviating data sparsity and handling noise from heterogeneous information.

## Key Results
- IHGCL achieves 11.48% improvement on Douban Movie dataset
- IHGCL achieves 12.43% improvement on Amazon dataset
- Significant improvements in standard recommendation metrics (Recall@20, NDCG@20) across six datasets
- Outperforms state-of-the-art baselines in recommendation accuracy

## Why This Works (Mechanism)
The framework works by addressing two key challenges in intent-aware recommendation: capturing fine-grained user intents through meta-paths and handling the noise these meta-paths introduce. The dual contrastive learning component creates multiple views that integrate real user-item interactions with intent information, then aligns these views to learn consistent intent representations. The bottlenecked autoencoder further refines these representations by applying masked autoencoding with information bottleneck constraints, effectively denoising the meta-path-driven connections. This two-pronged approach allows the model to learn robust intent representations that capture user preferences while filtering out noise, leading to improved recommendation accuracy.

## Foundational Learning

**Meta-path**: A sequence of node types and edge types that defines a semantic path in heterogeneous graphs. Needed to capture different types of relationships between users and items. Quick check: Verify that meta-paths like "User-Item-User" and "User-Attribute-Item" are properly defined for your dataset.

**Contrastive Learning**: A self-supervised learning technique that learns representations by contrasting positive and negative samples. Needed to align similar intent representations across different views. Quick check: Ensure your contrastive loss is properly balancing positive and negative pairs.

**Information Bottleneck**: A principle that compresses input data while preserving relevant information for a target task. Needed to denoise meta-path representations by filtering irrelevant information. Quick check: Monitor the mutual information between input and output to ensure proper compression.

**Masked Autoencoding**: A technique where parts of input are masked and the model learns to reconstruct them. Needed to force the model to learn robust representations by predicting missing information. Quick check: Verify that masking ratio and reconstruction loss are properly tuned.

## Architecture Onboarding

**Component Map**: User-Item Graph -> Meta-path Extraction -> Dual Contrastive Learning (DCL) -> Intent Alignment -> Bottlenecked Autoencoder (BAE) -> Masked Autoencoding -> Denoised Representations -> Recommendation

**Critical Path**: Meta-path extraction -> Dual Contrastive Learning -> Bottlenecked Autoencoder -> Final representations

**Design Tradeoffs**: The framework trades computational complexity for better intent representation. Meta-path selection requires domain knowledge but improves interpretability. The dual contrastive learning component increases model capacity but may require more training data. The bottlenecked autoencoder adds denoising capability but introduces additional parameters.

**Failure Signatures**: Poor meta-path selection leading to irrelevant intent representations, contrastive learning collapsing to trivial solutions, bottleneck constraints being too restrictive causing information loss, or insufficient denoising leading to noisy representations.

**First Experiments**:
1. Evaluate recommendation performance with different meta-path configurations
2. Test the impact of contrastive learning temperature on intent alignment
3. Analyze the effect of bottleneck strength on denoising effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on standard metrics without examining robustness to concept drift or temporal dynamics
- Limited ablation studies to isolate contributions of individual components (DCL vs BAE)
- Potential scalability challenges for very large heterogeneous graphs not thoroughly discussed

## Confidence

**High**: The experimental results showing IHGCL outperforming baselines on six datasets, including the specific percentage improvements cited (e.g., 11.48% on Douban Movie, 12.43% on Amazon)

**Medium**: The claims about effective noise reduction through the bottlenecked autoencoder and its ability to alleviate data sparsity

**Medium**: The assertion that IHGCL captures fine-grained user intents more effectively than existing methods

## Next Checks

1. Conduct extensive ablation studies to quantify the individual contributions of Dual Contrastive Learning and the Bottlenecked Autoencoder to overall performance

2. Test the framework's robustness to concept drift and temporal changes by evaluating on sequential or time-aware datasets

3. Perform scalability analysis on larger, more complex heterogeneous graphs to assess computational efficiency and memory requirements