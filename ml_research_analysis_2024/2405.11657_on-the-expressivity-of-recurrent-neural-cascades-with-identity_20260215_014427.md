---
ver: rpa2
title: On the Expressivity of Recurrent Neural Cascades with Identity
arxiv_id: '2405.11657'
source_url: https://arxiv.org/abs/2405.11657
tags:
- function
- proposition
- every
- have
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the expressivity of Recurrent Neural Cascades\
  \ (RNC) with positive recurrent weights (RNC+) in the presence of identity elements\u2014\
  inputs that can occur any number of times without affecting the output. The authors\
  \ show that RNC+ can only recognize regular languages with an identity element,\
  \ excluding the possibility of capturing non-regular languages in this setting."
---

# On the Expressivity of Recurrent Neural Cascades with Identity

## Quick Facts
- arXiv ID: 2405.11657
- Source URL: https://arxiv.org/abs/2405.11657
- Authors: Nadezda Alexandrovna Knorozova; Alessandro Ronca
- Reference count: 31
- Primary result: RNC+ with identity elements can only recognize star-free regular languages

## Executive Summary
This paper studies the expressivity of Recurrent Neural Cascades (RNC) with positive recurrent weights (RNC+) when an identity element is present in the input. The authors establish that RNC+ can only recognize regular languages in this setting, and further characterize these as exactly the star-free regular languages. This is achieved by showing that each neuron in RNC+ can be equivalently represented by a three-state semiautomaton, making the entire cascade no more expressive than a finite automaton with limited state complexity.

## Method Summary
The authors analyze the dynamics of RNC+ by studying the convergence properties of recurrent neurons with positive weights and tanh activation. They establish a structural correspondence between each neuron and a three-state semiautomaton by examining the fixpoint structure of the tanh dynamics. This allows them to represent the entire cascade as a composition of semiautomata, which are inherently regular. The presence of an identity element is shown to force identity transformations in the corresponding automata, limiting expressivity to star-free regular languages.

## Key Results
- RNC+ with positive recurrent weights can be equivalently represented by cascades of three-state semiautomata
- In the presence of an identity element, RNC+ can only recognize regular languages
- The languages recognized by RNC+ with identity elements are exactly the star-free regular languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Every recurrent neuron in an RNC+ can be replaced by a three-state semiautomaton without loss of expressivity.
- Mechanism: The tanh dynamics of a recurrent neuron converge to at most three distinct fixpoints relative to two pivots p− and p+. These fixpoints map to three equivalence classes under repeated identity inputs. A three-state semiautomaton can encode these classes and transition between them.
- Core assumption: Positive recurrent weights ensure monotone convergence and at most three fixpoints per neuron.
- Evidence anchors:
  - [abstract] "we establish a close structural correspondence between RNC+ and semiautomata cascades, showing that every neuron can be equivalently captured by a three-state semiautomaton."
  - [section 4.4] Proof that tanh dynamics have ≤3 fixpoints positioned relative to pivots p− and p+.

### Mechanism 2
- Claim: In the presence of an identity element, any language recognized by an RNC+ is necessarily regular.
- Mechanism: Identity elements force identity transformations in canonical automata. The homomorphism from RNC+ dynamics to such automata then implies the cascade of three-state semiautomata, which are finite and hence regular.
- Core assumption: The input symbol grounding is surjective, ensuring the identity element appears in the real-valued input domain.
- Evidence anchors:
  - [abstract] "we show that a language with an identity element is recognised by RNC+ only if it is regular."
  - [section 3.4] Proposition 3: identity elements imply identity transformations in canonical automata.

### Mechanism 3
- Claim: RNC+ cannot recognize languages beyond star-free regular in the presence of an identity element.
- Mechanism: Star-free regular languages are exactly the aperiodic regular languages. RNC+ already capture all star-free languages (Theorem 1). Mechanism 2 shows no non-regular languages with identity can be captured, so the identity case collapses RNC+ expressivity to exactly star-free.
- Core assumption: The function output alphabet is discrete, ensuring equivalence classes are well-defined.
- Evidence anchors:
  - [abstract] "in the presence of an identity element, we show that the languages captured by RNC+ are exactly the star-free regular languages."
  - [section 3.5] Theorem 5 combines Theorems 3 and 1.

## Foundational Learning

- Concept: Metric spaces and continuity
  - Why needed here: To define convergence of state sequences and continuity of homomorphisms between dynamical systems.
  - Quick check question: If a function f is continuous and a sequence x_t → x*, does f(x_t) → f(x*)?

- Concept: Equivalence relations and partitions
  - Why needed here: To group states that behave identically under identity inputs, forming equivalence classes used in the semiautomaton construction.
  - Quick check question: Given an equivalence relation ~ on a set, how many equivalence classes can there be at most?

- Concept: Fixpoint analysis in dynamical systems
  - Why needed here: To bound the number of distinct behaviors a recurrent neuron can exhibit, enabling the three-state mapping.
  - Quick check question: For tanh dynamics with positive recurrent weight, what is the maximum number of fixpoints?

## Architecture Onboarding

- Component map:
  - Input layer → Symbol grounding λΣ
  - Cascade of n recurrent tanh neurons (RNC+)
  - Output layer → Symbol grounding λΓ
  - Optional equivalence-class abstraction (for analysis)

- Critical path:
  1. Map symbolic input to real vector via λΣ
  2. Propagate through cascaded neurons with positive recurrent weights
  3. Compute output via feedforward network
  4. Map real output to symbolic output via λΓ

- Design tradeoffs:
  - Positive recurrent weights ensure monotone convergence but limit expressivity to star-free languages with identity.
  - Three-state abstraction is exact but may require careful choice of pivots p−, p+.
  - Continuous vs discrete output alphabets affect whether the star-free characterization holds.

- Failure signatures:
  - Non-monotonic state sequences → negative recurrent weights or non-positive weights.
  - More than three fixpoints per neuron → weight magnitude too large or activation function different.
  - No identity transformation in automaton → identity element missing from input language.

- First 3 experiments:
  1. Implement a single neuron with weight w=0.5 and input u=identity, verify convergence to one fixpoint and map to 3-state semiautomaton.
  2. Build a 2-neuron RNC+ cascade recognizing {∅}* over alphabet {∅, {p}}, confirm it is star-free regular.
  3. Attempt to recognize a non-regular language with identity element (e.g., {a^n b^n | n≥0} augmented with identity), confirm failure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can RNC+ with negative recurrent weights recognize languages beyond the star-free regular languages?
- Basis in paper: [explicit] The paper states that negative weights extend the expressivity of RNCs beyond star-free, but no precise characterization is known.
- Why unresolved: The authors acknowledge that existing results only show that negative weights extend expressivity, but they don't provide a specific characterization of what languages can be recognized.
- What evidence would resolve it: A formal proof or counterexample showing the exact class of languages that RNC+ with negative weights can recognize.

### Open Question 2
- Question: What is the expressivity of RNC+ beyond regular languages and beyond identity elements?
- Basis in paper: [inferred] The paper characterizes the expressivity of RNC+ for regular languages with identity elements, but leaves open the possibility of recognizing non-regular languages without identity elements.
- Why unresolved: The authors explicitly state that their results have no implications for languages and functions that are not regular and do not have an identity element.
- What evidence would resolve it: A formal proof showing that RNC+ cannot recognize any non-regular languages, or a counterexample demonstrating that RNC+ can recognize some non-regular languages.

### Open Question 3
- Question: Can RNC+ with activation functions other than tanh (such as logistic curve, ReLU, or GeLU) recognize languages beyond the star-free regular languages?
- Basis in paper: [explicit] The paper suggests that it would be interesting future work to study RNCs with other activation functions.
- Why unresolved: The authors have not studied the expressivity of RNC+ with activation functions other than tanh, and it is unclear how these different activation functions would affect the expressivity of the model.
- What evidence would resolve it: A formal proof or counterexample showing the exact class of languages that RNC+ with different activation functions can recognize.

## Limitations
- Results only apply to RNC+ with positive recurrent weights and tanh activation
- Characterization of expressivity limited to the presence of identity elements
- The homomorphism between RNC+ and semiautomata cascades is assumed but not fully detailed

## Confidence

- High confidence: Three-state semiautomaton correspondence for RNC+ with tanh activation and positive recurrent weights (directly proven)
- Medium confidence: Characterization of RNC+ expressivity as exactly star-free regular languages with identity (relies on assumed homomorphism)
- Low confidence: Generalization to other RNN architectures or activation functions (specific properties leveraged may not hold)

## Next Checks
1. Implement a single neuron with weight w=0.5 and input u=identity, verify convergence to one fixpoint and map to 3-state semiautomaton.
2. Build a 2-neuron RNC+ cascade recognizing {∅}* over alphabet {∅, {p}}, confirm it is star-free regular.
3. Attempt to recognize a non-regular language with identity element (e.g., {a^n b^n | n≥0} augmented with identity), confirm failure.