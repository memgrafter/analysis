---
ver: rpa2
title: 'Explain Like I''m Five: Using LLMs to Improve PDE Surrogate Models with Text'
arxiv_id: '2410.01137'
source_url: https://arxiv.org/abs/2410.01137
tags:
- data
- information
- boundary
- system
- conditions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using pretrained large language models (LLMs)
  to incorporate system information into PDE surrogate models through text descriptions.
  The authors develop a multimodal FactFormer architecture that fuses numerical and
  textual information via cross-attention between LLM-generated embeddings and data
  embeddings.
---

# Explain Like I'm Five: Using LLMs to Improve PDE Surrogate Models with Text

## Quick Facts
- **arXiv ID**: 2410.01137
- **Source URL**: https://arxiv.org/abs/2410.01137
- **Reference count**: 37
- **Key outcome**: Pretrained LLMs improve PDE surrogate models by 39-67% through cross-attention fusion with system descriptions

## Executive Summary
This paper proposes using pretrained large language models to incorporate system information into PDE surrogate models through text descriptions. The authors develop a multimodal FactFormer architecture that fuses numerical and textual information via cross-attention between LLM-generated embeddings and data embeddings. They compare three text processing approaches across 2D Heat, Burgers, Navier-Stokes, and Shallow-Water equations, showing significant improvements in next-step prediction, autoregressive rollout, and fixed-future tasks compared to baseline FactFormer.

## Method Summary
The authors implement a multimodal FactFormer that uses cross-attention to fuse LLM-generated text embeddings with numerical data embeddings from the FactFormer backbone. They freeze the LLM during training and only train a projection head to match the embedding dimensions. Three text processing approaches are compared: sentence-level embeddings from SentenceTransformer, word-level embeddings from Llama, and a tokenizer from Llemma. The model is evaluated on next-step prediction, autoregressive rollout, and fixed-future tasks across four different PDE datasets with varying initial conditions, operator coefficients, and boundary conditions.

## Key Results
- SentenceTransformer achieves average error reductions of 39% (next-step) and 67% (autoregressive) compared to baseline FactFormer
- Tokenizer-only performance similar to LLMs suggests semantic knowledge is not fully utilized
- Coefficient information is most impactful for performance, with qualitative descriptions providing marginal benefits
- Shallow-Water dataset shows comparable performance between baseline and multimodal models due to lack of system variation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-attention fusion between LLM embeddings and data embeddings provides better context for PDE predictions than simple concatenation or conditioning.
- Mechanism: The cross-attention block uses sentence embeddings as queries and data embeddings as keys/values, allowing the model to learn relevant semantic relationships between text descriptions and numerical patterns.
- Core assumption: The sentence embeddings contain meaningful information about the PDE system that can be aligned with the data embeddings through cross-attention.
- Evidence anchors: [abstract] "Using FactFormer as our testing backbone, we add a multimodal block to fuse numerical and textual information"; [section 4.2] "We add our system description as conditioning information both before and after factorized attention blocks"
- Break condition: If the text descriptions don't contain relevant system information or if the cross-attention cannot learn meaningful alignments between the modalities.

### Mechanism 2
- Claim: Sentence-level embeddings capture more useful global information than word-level embeddings or tokenizers for PDE system descriptions.
- Mechanism: SentenceTransformer provides embeddings that encode the full context of system descriptions, while word-level embeddings from Llama require averaging that may lose semantic relationships.
- Core assumption: The global semantic information in complete sentences is more valuable than local word relationships or raw tokens for understanding PDE systems.
- Evidence anchors: [section 4.3] "all-mpnet-base-v2 was used because it is designed to generate embeddings from sentences that are useful for tasks like sentence similarity"; [section 5.1] "SentenceTransformer either has best performance, or is close to best performance across all of our data sets"
- Break condition: If the PDE system descriptions don't require global context, or if the averaging process for word embeddings preserves sufficient information.

### Mechanism 3
- Claim: The order of information in text descriptions affects model performance, with coefficient information being most impactful.
- Mechanism: The ablation study shows that adding boundary condition information alone doesn't improve performance for systems with fixed boundary conditions, while coefficient information consistently improves predictions.
- Core assumption: The model can effectively learn to use different types of system information, with numerical coefficients being more directly useful than qualitative descriptions.
- Evidence anchors: [section 5.4] "We see that performance correlates strongly with relevant sentence information" and "There is also a weak performance improvement with the addition of qualitative information"
- Break condition: If the model cannot effectively distinguish between types of system information, or if qualitative descriptions contain information not captured by coefficients.

## Foundational Learning

- Concept: Partial Differential Equations and their physical interpretations
  - Why needed here: The text descriptions reference specific PDE behaviors (diffusion, advection, shocks) that engineers need to understand to create meaningful system descriptions
  - Quick check question: Can you explain the difference between diffusion-dominated and advection-dominated systems in Burgers equation?

- Concept: Neural Operator architectures (Fourier Neural Operator, DeepONet)
  - Why needed here: The FactFormer backbone is a neural operator, and understanding its limitations with purely data-driven approaches motivates the multimodal approach
  - Quick check question: What is the key advantage of neural operators over traditional PINNs for PDE surrogate modeling?

- Concept: Cross-attention mechanisms in multimodal learning
  - Why needed here: The core innovation uses cross-attention to fuse text and numerical information, requiring understanding of how attention differs from concatenation or simple conditioning
  - Quick check question: How does cross-attention differ from self-attention in terms of information flow between modalities?

## Architecture Onboarding

- Component map: Data → Patch embedding → Cross-attention with text → FactFormer blocks → Prediction
- Critical path: Data → Patch embedding → Cross-attention with text → FactFormer blocks → Prediction
- Design tradeoffs:
  - Using frozen LLMs vs. fine-tuning them for PDE-specific understanding
  - Sentence-level vs. word-level vs. tokenizer embeddings
  - Cross-attention placement (before/after FactFormer blocks)
  - Fixed vs. learned projection heads for text embeddings
- Failure signatures:
  - Poor performance improvement over baseline suggests text information isn't being effectively utilized
  - Tokenizer performance similar to LLMs indicates lack of semantic understanding
  - Instability in autoregressive rollout suggests compounding errors or poor temporal modeling
- First 3 experiments:
  1. Baseline FactFormer (no text) vs. multimodal with SentenceTransformer on next-step prediction
  2. Ablation study: coefficient-only vs. full text description on fixed-future task
  3. Tokenizer vs. word embeddings vs. sentence embeddings comparison on Navier-Stokes data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does semantic knowledge in pretrained LLMs actually improve PDE surrogate model performance, or do simple tokenizers perform comparably?
- Basis in paper: [inferred] The paper shows tokenizer-only performance similar to both Llama and SentenceTransformer across most experiments, with only marginal improvements from semantic knowledge in qualitative descriptions.
- Why unresolved: While the results suggest semantic understanding isn't being utilized, the experiments only test specific LLM architectures and don't explore whether domain-specific pretraining or architectural modifications could unlock semantic benefits.
- What evidence would resolve it: Direct comparison of LLMs with and without semantic pretraining on PDE-specific tasks, or experiments showing performance degradation when semantic context is removed from otherwise identical token representations.

### Open Question 2
- Question: What is the relationship between sentence complexity and embedding quality in capturing PDE system characteristics?
- Basis in paper: [explicit] The t-SNE analysis shows increasing structure in embeddings as more information is added, but qualitative descriptions don't form intuitive clusters matching physical intuition about equation behavior.
- Why unresolved: The paper observes clustering patterns but doesn't establish whether these patterns correlate with downstream task performance or whether more sophisticated embedding methods could better capture the physical relationships.
- What evidence would resolve it: Systematic ablation studies linking embedding structure to prediction accuracy, or controlled experiments varying sentence complexity while measuring both embedding quality and model performance.

### Open Question 3
- Question: How does transfer learning performance on individual PDE datasets relate to the diversity and complexity of the combined pretraining dataset?
- Basis in paper: [explicit] The paper notes that Shallow Water transfer learning shows high instability when training errors are very low, and that SentenceTransformer performs better with transfer learning on some datasets but not others.
- Why unresolved: The analysis is limited to a single pretraining strategy and doesn't explore how dataset composition, coefficient distribution, or boundary condition diversity affect transfer learning success across different PDEs.
- What evidence would resolve it: Controlled experiments varying pretraining dataset composition and measuring transfer learning performance across multiple target datasets, or analysis of which dataset characteristics most strongly predict transfer success.

## Limitations

- The cross-attention mechanism relies on the assumption that sentence embeddings contain meaningful PDE information, but corpus evidence is weak with only 5 related papers
- SentenceTransformer performance superiority lacks theoretical justification and doesn't explore why sentence-level embeddings outperform other approaches
- Tokenizer-only performance similar to LLM variants suggests the semantic knowledge in pretrained models may not be fully utilized
- Performance improvements could be partially attributed to increased model capacity rather than multimodal integration itself

## Confidence

**High Confidence**: The experimental methodology and evaluation metrics are clearly specified and reproducible. The baseline FactFormer implementation and the comparison across three text processing approaches follow standard practices in the field.

**Medium Confidence**: The mechanism of cross-attention fusion between text and numerical embeddings is plausible and supported by experimental results, but lacks strong theoretical grounding and corpus evidence.

**Low Confidence**: The claim that semantic knowledge in pretrained LLMs is not being utilized is based on tokenizer performance comparison alone. The paper doesn't explore whether fine-tuning the LLMs or using different embedding strategies could better leverage their semantic capabilities.

## Next Checks

1. **Fine-tuning vs. Frozen LLM Comparison**: Implement a variant where the LLM is fine-tuned during FactFormer training rather than kept frozen. Compare performance against the current approach to determine if semantic knowledge can be better leveraged through adaptation to the PDE domain.

2. **Cross-Attention Ablation**: Create variants of the multimodal FactFormer that use alternative fusion mechanisms (concatenation, gating, or simple conditioning) instead of cross-attention. This would help isolate whether the cross-attention mechanism itself provides the performance benefits or if any multimodal integration would suffice.

3. **Dataset Variation Analysis**: Generate additional PDE datasets with varying levels of system variation (similar to the Shallow-Water dataset but with controlled parameter changes). Test whether the performance improvements scale with the amount of system variation present, providing insight into when multimodal approaches are most beneficial.