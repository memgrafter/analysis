---
ver: rpa2
title: 'MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal Knowledge
  Graph'
arxiv_id: '2408.01679'
source_url: https://arxiv.org/abs/2408.01679
tags:
- knowledge
- multi-modal
- images
- entities
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MMPKUBase, a comprehensive Chinese multi-modal
  knowledge graph with over 50,000 entities and 1 million images across nine domains.
  The authors address the scarcity of high-quality Chinese multi-modal knowledge graphs
  and limited domain coverage in existing ones.
---

# MMPKUBase: A Comprehensive and High-quality Chinese Multi-modal Knowledge Graph

## Quick Facts
- arXiv ID: 2408.01679
- Source URL: https://arxiv.org/abs/2408.01679
- Reference count: 21
- Key outcome: Constructs a Chinese multi-modal knowledge graph with over 50,000 entities and 1 million high-quality images across nine domains using Prototypical Contrastive Learning and Isolation Forest filtering

## Executive Summary
This paper addresses the scarcity of high-quality Chinese multi-modal knowledge graphs by introducing MMPKUBase, a comprehensive knowledge graph covering nine diverse domains with over 50,000 entities and 1.2 million filtered images. The authors employ Prototypical Contrastive Learning (PCL) and Isolation Forest algorithms to refine image data, reducing 1.5 million initial images to 1.2 million high-quality ones. The resulting knowledge graph provides valuable resources for applications such as visual question answering and recommendation systems, with a user-friendly platform for image attribute exploration.

## Method Summary
The authors construct MMPKUBase by first selecting entities from PKUBase based on domain and taxonomy, then retrieving up to 30 images per entity from Baidu Image. They employ Prototypical Contrastive Learning with a ResNet50 backbone to extract 128-dimensional features for image clustering, followed by Isolation Forest outlier detection to filter irrelevant or corrupted images. The remaining high-quality images are stored as attributes in RDF-formatted triples, creating a comprehensive Chinese multi-modal knowledge graph.

## Key Results
- MMPKUBase contains over 50,000 entities across nine domains including birds, mammals, architecture, and military
- The filtering process reduced 1.5 million initial images to 1.2 million high-quality images using PCL and Isolation Forest
- A user-friendly SPARQL query platform was developed for image attribute exploration and retrieval

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prototypical Contrastive Learning (PCL) improves image feature quality by grouping semantically similar images into prototypes and separating dissimilar ones.
- Mechanism: PCL learns an embedding space where images are pulled toward their corresponding prototypes and pushed away from other prototypes, enhancing semantic clustering and outlier detection.
- Core assumption: Images from the same entity or domain form cohesive clusters in the learned embedding space, while irrelevant images are isolated.
- Evidence anchors:
  - [abstract] "To ensure data quality, we employ Prototypical Contrastive Learning and the Isolation Forest algorithm to refine the image data."
  - [section] "Prototypical Contrastive Learning (PCL) represents a unsupervised representation learning approach that amalgamates the principles of contrastive learning and clustering."
  - [corpus] Weak anchor: PCL is mentioned in the corpus but not in detail; assumed from general literature on representation learning.
- Break condition: If entity search results are too noisy or heterogeneous, the clustering assumption fails and irrelevant images may not be detected.

### Mechanism 2
- Claim: Isolation Forest identifies low-quality or irrelevant images as outliers in the high-dimensional PCL feature space.
- Mechanism: Isolation Forest isolates observations by randomly selecting a feature and then randomly selecting a split value between the max and min values of the selected feature. Outliers are easier to isolate, so they require fewer splits.
- Core assumption: Irrelevant or corrupted images will be structurally different from relevant images, making them easy to isolate in feature space.
- Evidence anchors:
  - [section] "To effectively identify and isolate these irrelevant or noisy images, the Isolation Forest technique, a robust outlier detection method in high-dimensional datasets, is employed."
  - [corpus] Weak anchor: Isolation Forest is not directly referenced in the corpus; inferred from standard ML practices.
- Break condition: If corrupted images share too many features with relevant images, Isolation Forest may not detect them as outliers.

### Mechanism 3
- Claim: The combination of PCL and Isolation Forest results in a robust filtering pipeline that retains high-quality, representative images while removing irrelevant or corrupted ones.
- Mechanism: PCL generates semantically meaningful features, and Isolation Forest leverages these features to detect outliers. Together, they form a two-stage filtering process that improves data quality.
- Core assumption: The quality of the image set is improved by removing outliers detected by Isolation Forest in the PCL feature space.
- Evidence anchors:
  - [section] "These images are not only representative but also suitable for downstream tasks."
  - [corpus] Weak anchor: No direct mention of the combined pipeline in the corpus; inferred from the described methodology.
- Break condition: If PCL fails to generate meaningful features, Isolation Forest will not be effective, and the filtering process will not improve data quality.

## Foundational Learning

- Concept: Unsupervised representation learning
  - Why needed here: To extract meaningful features from images without relying on labeled data, enabling semantic clustering and outlier detection.
  - Quick check question: How does PCL differ from traditional contrastive learning approaches?

- Concept: Outlier detection algorithms
  - Why needed here: To identify and remove irrelevant or corrupted images from the dataset, ensuring high data quality.
  - Quick check question: What makes Isolation Forest particularly suitable for high-dimensional data?

- Concept: Knowledge graph construction and RDF format
  - Why needed here: To structure the multimodal data in a standardized way, enabling querying and integration with other datasets.
  - Quick check question: How are images represented as attributes in the RDF format?

## Architecture Onboarding

- Component map:
  Entity Selection (PKUBase + Lexicon filtering) -> Image Retrieval (Baidu Image search) -> PCL Feature Generation (ResNet50 backbone, 128-dim vectors) -> Isolation Forest Filtering (contamination=0.2) -> Triple Completion (RDF formatting) -> User Interface (SPARQL query platform)

- Critical path:
  1. Select entities from PKUBase based on domain and taxonomy
  2. Retrieve up to 30 images per entity from Baidu Image
  3. Remove corrupted/animated images
  4. Run PCL to generate image features
  5. Apply Isolation Forest to filter out outliers
  6. Complete triples and store in RDF format
  7. Deploy user interface for querying

- Design tradeoffs:
  - Entity selection: Manual lexicon filtering ensures relevance but is time-consuming
  - Image retrieval: Baidu Image provides coverage but may include irrelevant results
  - PCL vs. supervised learning: PCL avoids labeling costs but may be less precise
  - Isolation Forest contamination: 0.2 balances recall and precision in filtering

- Failure signatures:
  - Too few images retained after filtering: PCL may not be generating meaningful clusters
  - Many corrupted images remain: Corruption detection step is insufficient
  - SPARQL queries return empty results: Triple completion or RDF formatting errors

- First 3 experiments:
  1. Test PCL feature generation on a small, manually curated image set to verify clustering
  2. Run Isolation Forest with varying contamination levels on PCL features to find optimal threshold
  3. Validate RDF triple completion by querying a small subset of entities and images

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but identifies several areas for future work including enhancing the knowledge graph, expanding to more domains, and improving the filtering methodology.

## Limitations
- The paper lacks quantitative evaluation of image quality post-filtering, with no precision/recall metrics or user studies provided
- There is no comparative analysis with alternative filtering approaches or multi-modal knowledge graph construction methods
- The manual lexicon filtering process for entity selection is not fully specified, potentially affecting reproducibility

## Confidence
- Confidence in the filtering mechanism: Medium - theoretically sound but lacks empirical validation metrics
- Confidence in domain coverage comprehensiveness: High - detailed enumeration of nine domains with 50,000+ entities explicitly stated

## Next Checks
1. Conduct a human evaluation study where annotators assess a random sample of images pre- and post-filtering to measure quality improvement.
2. Perform a comparative analysis using alternative outlier detection methods (e.g., DBSCAN, LOF) to evaluate the relative effectiveness of Isolation Forest.
3. Analyze the distribution of images across domains to verify balanced representation and identify any systematic biases in retrieval or filtering.