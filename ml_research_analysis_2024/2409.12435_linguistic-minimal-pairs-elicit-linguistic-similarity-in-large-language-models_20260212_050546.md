---
ver: rpa2
title: Linguistic Minimal Pairs Elicit Linguistic Similarity in Large Language Models
arxiv_id: '2409.12435'
source_url: https://arxiv.org/abs/2409.12435
tags:
- layers
- linguistic
- total
- sampled
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to probing linguistic representations
  in large language models (LLMs) by measuring the similarity of activation differences
  across linguistic minimal pairs. The method quantifies how LLMs represent different
  linguistic phenomena and compares these representations to theoretical linguistic
  categorizations.
---

# Linguistic Minimal Pairs Elicit Linguistic Similarity in Large Language Models

## Quick Facts
- arXiv ID: 2409.12435
- Source URL: https://arxiv.org/abs/2409.12435
- Reference count: 36
- Key outcome: Novel method measures linguistic similarity in LLMs using minimal pairs, revealing fine-grained alignment with linguistic theory and cross-lingual patterns

## Executive Summary
This paper introduces a novel approach to probing linguistic representations in large language models (LLMs) by measuring the similarity of activation differences across linguistic minimal pairs. The method quantifies how LLMs represent different linguistic phenomena and compares these representations to theoretical linguistic categorizations. The study analyzed 100+ LLMs using 150,000 linguistic minimal pairs across English, Chinese, and Russian, finding that linguistic similarity is influenced by training data exposure, with higher consistency in higher-resource languages like English.

## Method Summary
The method extracts hidden activations from LLMs on linguistic minimal pairs (sentence pairs differing in exactly one linguistic phenomenon), computes activation differences, and measures similarity between these differences using cosine similarity. The approach analyzes consistency across LLMs, compares similarity patterns with theoretical linguistic categorizations at different granularity levels, and examines cross-lingual alignment. The study uses 104 LLMs, 150,000 minimal pairs from BLiMP, SLING, and RuBLiMP datasets, and samples activations from five layers per model.

## Key Results
- Linguistic similarity strongly aligns with fine-grained theoretical linguistic categories but weakly with broader ones
- Higher-resource languages (English) show more consistent linguistic representations across LLMs
- Linguistic similarity exhibits weak correlation with semantic similarity, indicating context-dependency
- LLMs tend to group linguistic phenomena by language, though capture some cross-linguistic relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Activation difference subtraction cancels out shared semantic context, isolating linguistic phenomenon representations
- Mechanism: By taking z+ - z- where x+ and x- differ only in one linguistic phenomenon, the subtraction cancels shared elements (vocabulary, topic, semantics) leaving only differences attributable to that phenomenon
- Core assumption: The only difference between minimal pairs is the target linguistic phenomenon; all other aspects are identical
- Evidence anchors: [abstract] "information about other aspects (such as topic and semantic meaning) will be canceled out through subtraction"

### Mechanism 2
- Claim: Linguistic similarity measured via activation differences correlates with theoretical linguistic categorizations at fine-grained levels
- Mechanism: The cosine similarity between activation differences (∆z1, ∆z2) captures how similarly LLMs represent different linguistic phenomena, which aligns with linguistic theory's detailed categorizations
- Core assumption: LLMs develop internal representations that reflect linguistic structure, even without explicit training
- Evidence anchors: [abstract] "linguistic similarity strongly aligns with fine-grained theoretical linguistic categories but weakly with broader ones"

### Mechanism 3
- Claim: Cross-lingual alignment reveals LLMs capture some cross-linguistic relationships between relevant phenomena
- Mechanism: Multilingual LLMs show higher similarity between equivalent phenomena across languages than between unrelated phenomena, suggesting they recognize cross-linguistic patterns
- Core assumption: LLMs trained on multiple languages develop representations that can bridge linguistic phenomena across languages
- Evidence anchors: [abstract] "relevant phenomena in different languages enjoy higher linguistic similarities"

## Foundational Learning

- Concept: Activation space geometry and cosine similarity
  - Why needed here: The entire method relies on measuring similarity between high-dimensional activation vectors using cosine similarity
  - Quick check question: What happens to cosine similarity when two vectors point in exactly opposite directions?

- Concept: Minimal pair construction and linguistic phenomena
  - Why needed here: Understanding how minimal pairs isolate single linguistic phenomena is crucial for interpreting the results
  - Quick check question: What makes a minimal pair different from a regular sentence pair?

- Concept: Layer-wise specialization in transformer models
  - Why needed here: The paper samples activations from multiple layers, implying different layers may capture different aspects of linguistic knowledge
  - Quick check question: Why might lower layers capture different linguistic information than higher layers?

## Architecture Onboarding

- Component map: Data ingestion -> LLM inference -> Activation difference computation -> Similarity computation -> Analysis pipeline

- Critical path: Data → LLM inference → Activation difference computation → Similarity matrix → Analysis

- Design tradeoffs: Half-precision vs full precision (faster but potential precision loss), sampling 5 layers (balances coverage vs computational cost), using cosine similarity (standard but may miss other relevant relationships)

- Failure signatures: Low cross-LLM agreement (could indicate phenomenon-specific representations or dataset issues), no correlation with theoretical categories (might suggest LLM representations don't align with linguistic theory), perfect cross-lingual alignment (could indicate the method is capturing surface features rather than linguistic structure)

- First 3 experiments:
  1. Validate cancellation effect: Create controlled minimal pairs with known confounds and verify they're canceled out
  2. Layer analysis: Compare similarity patterns across different layers to identify where linguistic knowledge emerges
  3. Ablation study: Remove specific linguistic phenomena from training data and observe impact on similarity patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Method's core assumption that activation difference subtraction cleanly isolates linguistic phenomena remains unverified
- Cross-lingual analysis lacks comprehensive coverage with only three languages examined using three linguistic terms each
- Computational approach using half-precision (float16) for activation extraction may introduce noise affecting similarity measurements

## Confidence
- High Confidence: Linguistic similarity correlates with fine-grained theoretical linguistic categories
- Medium Confidence: Cross-lingual alignment patterns showing LLMs group phenomena by language while capturing some cross-linguistic relationships
- Low Confidence: Claim that training data exposure directly influences linguistic consistency

## Next Checks
1. Validate cancellation effect by creating synthetic minimal pairs with known confounds and empirically verifying that activation differences eliminate these confounds while preserving the target linguistic phenomenon representation

2. Systematically sample all layers from a subset of models and track how linguistic similarity patterns evolve from lower to higher layers, identifying where theoretical linguistic structure emerges in the activation space

3. Conduct a training data ablation study by training controlled LLMs with specific linguistic phenomena removed from their training data, then measuring changes in linguistic similarity patterns to establish causal links between training exposure and representation quality