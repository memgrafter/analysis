---
ver: rpa2
title: Counterfactual Explanations for Clustering Models
arxiv_id: '2409.12632'
source_url: https://arxiv.org/abs/2409.12632
tags:
- clustering
- data
- counterfactual
- cluster
- baseline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel model-agnostic technique for explaining
  clustering models using counterfactual statements. The method introduces soft-scoring
  techniques that capture spatial information used by clustering algorithms, building
  upon a Bayesian counterfactual generator for supervised learning.
---

# Counterfactual Explanations for Clustering Models

## Quick Facts
- arXiv ID: 2409.12632
- Source URL: https://arxiv.org/abs/2409.12632
- Authors: Aurora Spagnol; Kacper Sokol; Pietro Barbiero; Marc Langheinrich; Martin Gjoreski
- Reference count: 40
- Primary result: Model-agnostic soft-scoring method improves explained instances by 10-33% over baseline across five datasets

## Executive Summary
This paper introduces a novel model-agnostic technique for generating counterfactual explanations for clustering models. The approach adapts a Bayesian counterfactual generator with soft-scoring methods that capture spatial information used by clustering algorithms. By computing distances from candidate counterfactuals to cluster centroids or using prototypes and criticisms for model-agnostic scoring, the method provides more informative guidance for counterfactual search than binary cluster membership. The technique is evaluated on five datasets with k-means++ and HDBSCAN clustering algorithms, demonstrating significant improvements in explanation quality while maintaining comparable computational performance.

## Method Summary
The method extends BayCon, a Bayesian counterfactual generator for supervised learning, to work with clustering models. It introduces two soft-scoring approaches: model-specific scoring using centroid distances or density-based probabilities, and model-agnostic scoring using prototypes and criticisms extracted via MMD-critic. The model-agnostic approach trains a self-training classifier on representative points to provide probability-based soft scores for any clustering model. Bayesian optimization uses these soft scores to guide the search for counterfactuals that move instances between clusters while maintaining feature space similarity.

## Key Results
- Model-agnostic soft-scoring method outperforms baseline across all five datasets in terms of percentage of explained instances (Exp%)
- Improvements in Exp% range from 10% to 33% over baseline methods
- Method maintains comparable computational performance and input space quality metrics
- Model-specific methods perform better on k-means++ while model-agnostic excels on HDBSCAN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Soft-scoring captures spatial structure of clusters, enabling more effective counterfactual search.
- Mechanism: The method computes distances from candidate counterfactuals to cluster centroids and uses these distances as continuous soft scores, rather than binary cluster membership. This provides gradient-like information that guides the Bayesian optimizer toward better counterfactuals.
- Core assumption: The spatial relationships within clusters (distances to centroids, density variations) are meaningful for determining counterfactual quality.
- Evidence anchors:
  - [abstract] "Our approach relies on a novel soft-scoring method that
  - [section 4.2] "The key idea is to compute a soft score based on the distances between a counterfactual candidate and the cluster centroids"

## Foundational Learning
- [section 3.1] "We extend BayCon, a Bayesian counterfactual generator for supervised learning models, to work with clustering models"
- [section 3.2] "We introduce two approaches for soft-scoring: model-specific and model-agnostic"

## Architecture Onboarding
- [section 3] The method builds on BayCon's Bayesian optimization framework but replaces the hard classification loss with soft-scoring based on cluster distances or prototype-based probabilities
- [section 4.2] Model-specific approach uses cluster centroids or density estimates; model-agnostic uses MMD-critic to extract prototypes and criticisms

## Open Questions the Paper Calls Out
- [section 6.1] "Future work could explore extending this approach to other types of clustering algorithms or incorporating additional constraints"
- [section 6.2] "Investigating the trade-off between explanation quality and computational efficiency for larger datasets remains an open question"

## Limitations
- [section 5] The method requires access to cluster assignments and centroids, limiting applicability to black-box clustering APIs
- [section 5.1] Computational cost increases with the number of candidate counterfactuals generated during Bayesian optimization
- [section 5.2] Performance depends on the quality of prototype and criticism extraction for model-agnostic approach

## Confidence
- Moderate confidence based on evaluation across five datasets with two clustering algorithms
- Results show consistent improvements in explanation quality metrics but limited ablation studies on soft-scoring components

## Next Checks
- Verify the relationship between centroid distances and actual cluster boundaries in high-dimensional spaces
- Examine whether soft-scoring gradients consistently point toward better counterfactuals across different cluster shapes
- Assess the impact of prototype selection quality on model-agnostic soft-scoring performance