---
ver: rpa2
title: Joint Analysis of Single-Cell Data across Cohorts with Missing Modalities
arxiv_id: '2405.11280'
source_url: https://arxiv.org/abs/2405.11280
tags:
- modalities
- modality
- missing
- cell
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of integrating single-cell multi-omic
  data across cohorts when modalities are missing. The proposed SC5 framework learns
  unified cell representations under domain shift without requiring full-modality
  reference samples.
---

# Joint Analysis of Single-Cell Data across Cohorts with Missing Modalities

## Quick Facts
- arXiv ID: 2405.11280
- Source URL: https://arxiv.org/abs/2405.11280
- Reference count: 37
- Primary result: SC5 framework enables integration of single-cell multi-omic data across cohorts with missing modalities, achieving an adjusted Rand index of 0.572 for clustering and Pearson correlation of 0.444 for imputation

## Executive Summary
This paper presents SC5, a generative framework for integrating single-cell multi-omic data across cohorts when certain modalities are missing in some domains. The method learns unified cell representations under domain shift without requiring full-modality reference samples. By modeling latent topics underlying single-cell multi-modal features and learning modality-dependent and domain-dependent topic distributions, SC5 can impute missing modalities while maintaining robust performance on cell type clustering and classification tasks.

## Method Summary
SC5 employs a variational autoencoder approach to learn unified cell representations across domains with missing modalities. The framework treats cells as documents composed of features from multiple modalities (languages) and written by different domains (authors). It uses modality-specific neural networks to encode features, combines modality-specific posteriors using product-of-experts, and generates modality-dependent features using shared topic embeddings with domain-specific variations. A neighborhood contrastive loss ensures equal representation of available modalities while preserving cell-cell relationships. The model is trained to optimize the evidence lower bound while regularizing topic distributions.

## Key Results
- Achieved adjusted Rand index of 0.572 for cell type clustering under the combine setting
- Achieved Pearson correlation of 0.444 for missing modality imputation
- Outperformed baseline methods on clustering, classification, and imputation tasks
- Successfully handled scenarios where entire modalities were missing from some domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework integrates single-cell multi-omic data across cohorts with missing modalities by learning domain-specific and modality-dependent topic distributions
- Mechanism: Models each cell as a "document" with features from multiple "languages" (modalities) written by different "authors" (domains), learning shared topics while allowing domain-specific variations
- Core assumption: Latent topics are shared across modalities and domains, with proportions varying by domain
- Evidence anchors: Abstract mentions learning unified representations under domain shift; section describes modeling latent topics underlying multi-modal features
- Break condition: If latent topics aren't truly shared or domain-specific variations are too large

### Mechanism 2
- Claim: The framework imputes missing modalities by leveraging cross-modal and cross-domain relationships learned during training
- Mechanism: Uses learned topic assignments and modality-specific embeddings to reconstruct missing features based on available modalities
- Core assumption: Relationships between modalities and domains are stable enough for accurate imputation
- Evidence anchors: Abstract mentions enabling imputation of missing modalities; section describes learning modality-dependent and domain-dependent topic distributions
- Break condition: If cross-modal relationships are too weak or domain shifts are too large

### Mechanism 3
- Claim: Neighborhood contrastive loss ensures equal representation of available modalities in learned embeddings
- Mechanism: Maximizes similarity between cells and their nearest neighbors within same domain and modality while minimizing similarity with separate neighborhoods
- Core assumption: Cell-cell similarities within modalities are meaningful and should be preserved
- Evidence anchors: Section mentions ensuring equal representation of available modalities and maximizing similarity between neighboring cells
- Break condition: If modality-specific cell-cell relationships are inconsistent or contrastive loss overpowers reconstruction objective

## Foundational Learning

- Concept: Variational autoencoders and evidence lower bound (ELBO) optimization
  - Why needed here: Framework uses variational approach to learn generative model parameters and integrated features
  - Quick check question: What is the relationship between the ELBO and the true data log-likelihood in variational inference?

- Concept: Topic modeling and latent Dirichlet allocation (LDA)
  - Why needed here: Framework extends topic modeling concepts to describe cells as combinations of latent topics
  - Quick check question: How does the framework's topic modeling approach differ from traditional LDA in terms of domain and modality considerations?

- Concept: Product-of-experts for combining probability distributions
  - Why needed here: Framework uses product-of-experts approach to combine modality-specific posterior distributions
  - Quick check question: What is the mathematical form of the product-of-experts combination used in the encoder module?

## Architecture Onboarding

- Component map: Data normalization -> Encoder (NNET) -> Product-of-experts -> Topic assignment -> Decoder (reconstruction) -> Imputation (if needed) -> Contrastive loss

- Critical path: Data normalization → Encoder (NNET) → Product-of-experts → Topic assignment → Decoder (reconstruction) → Imputation (if needed) → Contrastive loss

- Design tradeoffs:
  - Flexibility vs. interpretability: Additive domain-specific term allows flexibility but makes topic embeddings less interpretable
  - Reconstruction accuracy vs. imputation capability: Balancing reconstruction loss with contrastive loss affects both performance aspects
  - Model complexity vs. training stability: More domains and modalities increase complexity and may require careful hyperparameter tuning

- Failure signatures:
  - Poor clustering/classification performance: May indicate learned representations aren't capturing relevant biological signal
  - Imputation artifacts: May indicate cross-modal relationships aren't being learned correctly
  - Mode collapse in topic distributions: May indicate KL regularization is too strong or model is underfitting

- First 3 experiments:
  1. Train on Cite-seq dataset with both modalities available in some domains and only one modality in others, evaluate clustering performance
  2. Train on Combine dataset and evaluate imputation performance for each missing modality type
  3. Compare clustering and imputation performance with and without neighborhood contrastive loss to verify effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SC5 vary with the number of latent topics K used in the model?
- Basis in paper: Paper mentions using K latent topics but does not explore how performance changes with different values of K
- Why unresolved: Paper does not include ablation study or sensitivity analysis on choice of K
- What evidence would resolve it: Results from experiments testing different values of K to find optimal number of topics

### Open Question 2
- Question: Can SC5 handle datasets with more than three modalities effectively?
- Basis in paper: Paper only tests SC5 on datasets with up to three modalities (gene expression, protein abundance, chromatin accessibility)
- Why unresolved: Scalability of SC5 to higher numbers of modalities is not investigated
- What evidence would resolve it: Experiments applying SC5 to datasets with more than three modalities

### Open Question 3
- Question: How does SC5 compare to other domain adaptation methods for single-cell data integration?
- Basis in paper: Paper compares SC5 to baseline methods but does not compare it to other domain adaptation techniques
- Why unresolved: Paper focuses on comparing to baseline methods but does not explore other domain adaptation approaches
- What evidence would resolve it: Experiments comparing SC5 to other domain adaptation methods

## Limitations
- Performance relies heavily on assumption that latent topics are truly shared across modalities and domains
- Method's sensitivity to hyperparameter choices is not thoroughly explored
- Limited validation when multiple modalities are simultaneously missing across many domains

## Confidence

- **High confidence**: Core generative modeling approach and ELBO optimization framework are sound and well-established
- **Medium confidence**: Imputation capability shows promising results but requires more extensive validation across diverse biological scenarios
- **Medium confidence**: Neighborhood contrastive loss appears effective but specific contribution needs clearer isolation through ablation studies

## Next Checks

1. **Domain shift robustness test**: Systematically evaluate SC5 performance as degree of domain shift increases between cohorts, measuring both clustering and imputation quality degradation

2. **Multi-modality missing pattern analysis**: Test imputation performance when multiple modalities are simultaneously missing across training domains, varying proportion of missing combinations

3. **Ablation study on contrastive loss**: Train SC5 with and without neighborhood contrastive loss while holding all other components constant, measuring specific contribution to clustering, classification, and imputation tasks