---
ver: rpa2
title: Using Large Language Models for OntoClean-based Ontology Refinement
arxiv_id: '2403.15864'
source_url: https://arxiv.org/abs/2403.15864
tags:
- ontology
- ontoclean
- refinement
- class
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates using LLMs (GPT-3.5 and GPT-4) to automate
  the first step of OntoClean ontology refinement, which involves assigning meta-properties
  to ontology classes. The authors propose a human-in-the-loop approach where an LLM
  labels ontology classes with OntoClean meta-properties (Identity, Unity, Rigidity,
  Dependence) and researchers validate and refine the results.
---

# Using Large Language Models for OntoClean-based Ontology Refinement

## Quick Facts
- **arXiv ID:** 2403.15864
- **Source URL:** https://arxiv.org/abs/2403.15864
- **Reference count:** 15
- **Primary result:** GPT-4 significantly outperforms GPT-3.5 on OntoClean meta-property assignment, achieving very high accuracy (4-20% inaccuracy) when provided hierarchical ontology structure

## Executive Summary
This paper investigates using large language models (LLMs) to automate the first step of OntoClean ontology refinement by assigning meta-properties (Identity, Unity, Rigidity, Dependence) to ontology classes. The authors propose a human-in-the-loop approach where an LLM labels ontology classes with OntoClean meta-properties and researchers validate and refine the results. Experiments on the Mini Pizza Ontology and Upper Ontology show that GPT-4 achieves very high accuracy across meta-properties, particularly when provided hierarchical ontology representations, while GPT-3.5 shows suboptimal performance on abstract concepts.

## Method Summary
The study employs a human-in-the-loop approach where LLMs (GPT-3.5 and GPT-4) are tasked with labeling ontology classes with OntoClean meta-properties. Two prompting strategies are tested: zero-shot and in-context learning, using both flat and hierarchical ontology representations. The hierarchical presentation preserves dependency relationships between classes, enabling the LLM to reason about class context. The study uses two benchmark ontologies (Mini Pizza Ontology and Upper Ontology) and conducts 30 trials for each permutation of ontology, model, prompting approach, and representation style, calculating accuracy scores for each meta-property.

## Key Results
- GPT-4 achieves very high accuracy (4-20% inaccuracy) across OntoClean meta-properties when using hierarchical representations
- Flat ontology representations yield unsatisfactory results with all models and prompting techniques
- GPT-4 significantly outperforms GPT-3.5, particularly on abstract ontological concepts like Identity and Unity meta-properties
- Hierarchical presentation enables better reasoning about class dependencies and relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can effectively perform the first step of OntoClean (assigning meta-properties) when provided hierarchical ontology structure.
- Mechanism: Hierarchical presentation preserves dependency relationships between classes, enabling the LLM to reason about class context and relationships when assigning meta-properties.
- Core assumption: The model's reasoning capabilities can process hierarchical structural information to infer appropriate meta-properties for each class.
- Evidence anchors:
  - [abstract] "By employing LLMs with two prompting strategies, the study demonstrates that high accuracy in the labelling process can be achieved."
  - [section] "Flat presentation is a list of entities present in the ontology. For hierarchical presentation, we first chose a random spanning tree of the ontology graph and then presented as a tab-indented text."
  - [corpus] Weak evidence - corpus contains related ontology refinement papers but none specifically test hierarchical vs flat presentation
- Break condition: If the hierarchical structure becomes too deep or complex, the LLM may lose context or fail to properly reason about distant dependencies.

### Mechanism 2
- Claim: In-context learning with meta-properties documentation improves LLM performance for abstract ontological concepts.
- Mechanism: Providing definitions of OntoClean meta-properties helps the LLM understand the philosophical distinctions needed to correctly label classes, particularly for abstract properties like Unity and Identity.
- Core assumption: The model can properly utilize provided definitions to apply abstract concepts to specific ontology classes.
- Evidence anchors:
  - [section] "we experimented with two prompts: a bare prompt, and an in-context learning prompt, where the LLM was reminded of the definitions of OntoClean meta-properties."
  - [section] "However, a notable observation was that during in-context learning, GPT-4 did not display improved performance compared to zero-shot learning in meta properties Unity (U)."
  - [corpus] Moderate evidence - related papers show prompting strategies improve LLM performance but none specifically address ontological meta-properties
- Break condition: If the provided definitions are too abstract or lack concrete examples, the model may still struggle with application.

### Mechanism 3
- Claim: GPT-4 significantly outperforms GPT-3.5 on OntoClean meta-property assignment due to better reasoning capabilities.
- Mechanism: GPT-4's more advanced reasoning and understanding of abstract concepts enables it to better distinguish between similar meta-properties and apply them correctly to ontology classes.
- Core assumption: The model's improved architecture translates to better performance on specialized ontology tasks.
- Evidence anchors:
  - [section] "Our findings indicated that using flat representations as inputs for the ontologies did not yield satisfactory results with any of the language models or prompting techniques"
  - [section] "In contrast, GPT-4 exhibited superior performance across all testing conditions. It notably achieved very high accuracy across the range of OntoClean metaproperties."
  - [corpus] Strong evidence - multiple corpus papers demonstrate GPT-4's superiority over GPT-3.5 on specialized tasks
- Break condition: If the task requires domain-specific knowledge beyond general reasoning capabilities, even GPT-4 may underperform.

## Foundational Learning

- Concept: OntoClean meta-properties (Identity, Unity, Rigidity, Dependence)
  - Why needed here: These are the core concepts the LLM must assign to ontology classes, so understanding their definitions and constraints is essential
  - Quick check question: What is the key distinction between rigid and anti-rigid classes in OntoClean?

- Concept: Hierarchical ontology structure and class relationships
  - Why needed here: The LLM needs to understand class dependencies and inheritance to properly assign meta-properties based on class context
  - Quick check question: How do OntoClean constraints on meta-properties propagate through the class hierarchy?

- Concept: Prompt engineering strategies (zero-shot vs in-context learning)
  - Why needed here: Different prompting approaches significantly impact LLM performance on this task, so understanding when to use each is critical
  - Quick check question: When would you choose in-context learning over zero-shot prompting for this task?

## Architecture Onboarding

- Component map:
  Input: Ontology classes with hierarchical structure -> LLM integration: GPT-3.5/GPT-4 with chosen prompting strategy -> Validation: Human-in-the-loop verification of LLM output -> Plugin interface: Proposed integration with ontology tools like Protege

- Critical path:
  1. Prepare hierarchical ontology representation
  2. Select appropriate LLM and prompting strategy
  3. Process classes through LLM
  4. Validate and refine LLM output
  5. Integrate results into ontology tool

- Design tradeoffs:
  - Model selection: GPT-4 offers better accuracy but higher cost vs GPT-3.5
  - Prompt strategy: In-context learning provides definitions but may not improve performance for all meta-properties
  - Representation: Hierarchical presentation enables reasoning but requires more complex input formatting

- Failure signatures:
  - Low accuracy on Identity and Unity meta-properties indicates the model is struggling with abstract concepts
  - Inconsistent application across similar classes suggests insufficient context
  - Performance degradation with deeper hierarchies indicates context window limitations

- First 3 experiments:
  1. Compare zero-shot vs in-context learning on GPT-4 with Mini Pizza Ontology using hierarchical representation
  2. Test flat vs hierarchical representation with GPT-4 on Upper Ontology
  3. Compare GPT-3.5 vs GPT-4 performance on same ontology using identical prompting strategy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the accuracy rates of GPT-4 in meta-properties Identity (I) and Rigidity (R) compare when using the hierarchical presentation of ontologies versus a different, yet unspecified, presentation method?
- Basis in paper: [explicit] The paper mentions that GPT-4 achieved very low inaccuracy rates of around 4% in meta-properties Identity (I) and Rigidity (R), but does not provide a direct comparison with other presentation methods.
- Why unresolved: The paper does not compare the performance of GPT-4 across different ontology presentation methods, focusing instead on the contrast between flat and hierarchical presentations.
- What evidence would resolve it: Comparative results of GPT-4 accuracy rates using different ontology presentation methods would clarify the impact of presentation style on performance.

### Open Question 2
- Question: What specific limitations of GPT-3.5 contribute to its suboptimal performance in handling abstract ontological concepts such as Identity (I) and Unity (U)?
- Basis in paper: [explicit] The paper indicates that GPT-3.5 showed suboptimal performance, especially in meta-properties Identity (I) and Unity (U), but does not detail the underlying reasons.
- Why unresolved: The paper identifies the issue but does not explore the technical or architectural reasons behind GPT-3.5's limitations.
- What evidence would resolve it: A technical analysis comparing the capabilities of GPT-3.5 and GPT-4 in processing abstract concepts would elucidate the specific limitations of GPT-3.5.

### Open Question 3
- Question: How might the definitions of OntoClean meta-properties be updated to improve the performance of LLMs, particularly GPT-4, in the context of Unity (U)?
- Basis in paper: [inferred] The paper suggests that the abstract nature and dated references of OntoClean definitions may pose challenges for LLMs, particularly in interpreting Unity (U).
- Why unresolved: The paper proposes a hypothesis but does not test the effect of updated definitions on LLM performance.
- What evidence would resolve it: An experimental study comparing LLM performance using both the original and updated OntoClean definitions would demonstrate the impact of definition clarity on accuracy.

## Limitations

- Evaluation was conducted on only two ontologies, which may not generalize to more complex real-world ontologies
- Accuracy measurements still represent a significant error rate (4-20% inaccuracy) that requires human validation
- The human-in-the-loop approach introduces potential subjectivity in validation that wasn't quantified

## Confidence

High confidence: GPT-4's superior performance over GPT-3.5 is well-established in the literature and consistently demonstrated across multiple prompting strategies and ontologies in this study.

Medium confidence: The effectiveness of in-context learning for OntoClean meta-property assignment shows mixed results, and the proposed plugin development for Protege remains speculative.

Low confidence: The claim that this approach will "significantly aid ontology refinement" lacks quantitative evidence about time savings or quality improvements in the human validation process.

## Next Checks

1. **Cross-domain validation:** Test the same methodology on at least 5 additional ontologies from different domains (biomedical, financial, manufacturing) to assess generalizability and identify domain-specific failure modes.

2. **Statistical validation:** Conduct significance testing (e.g., McNemar's test) between zero-shot and in-context learning conditions across all meta-properties to determine which prompting strategies provide statistically meaningful improvements.

3. **Efficiency validation:** Measure and compare the time required for manual vs. LLM-assisted ontology refinement on the same ontology, including human validation time, to quantify the practical efficiency gains of the proposed approach.