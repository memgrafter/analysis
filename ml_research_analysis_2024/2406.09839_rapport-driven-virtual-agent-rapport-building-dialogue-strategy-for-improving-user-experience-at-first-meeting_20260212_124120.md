---
ver: rpa2
title: 'Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for Improving
  User Experience at First Meeting'
arxiv_id: '2406.09839'
source_url: https://arxiv.org/abs/2406.09839
tags:
- agent
- rapport
- dialogue
- virtual
- talk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study introduced a rapport-building dialogue strategy for
  virtual agents to improve human-agent interaction during first meetings through
  small talk. The approach embedded rapport-building utterances (e.g., praise, empathy,
  storytelling) into LLM-based dialogue generation using two strategies: free-form
  and predefined sequence.'
---

# Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for Improving User Experience at First Meeting

## Quick Facts
- arXiv ID: 2406.09839
- Source URL: https://arxiv.org/abs/2406.09839
- Reference count: 0
- One-line primary result: Free-form rapport-building prompts produce more natural and satisfying interactions than predefined sequences in virtual agent dialogues

## Executive Summary
This study introduces a rapport-building dialogue strategy for virtual agents to enhance human-agent interaction during first meetings through small talk. The approach embeds rapport-building utterances (praise, empathy, storytelling) into LLM-based dialogue generation using two strategies: free-form and predefined sequence. Human evaluation with 20 participants demonstrated that the free-form strategy significantly outperformed predefined sequences in naturalness, satisfaction, usability, and rapport. The results show that adaptive, rapport-focused dialogue strategies can significantly improve user experience in human-agent interactions.

## Method Summary
The researchers implemented two rapport-building dialogue strategies using GPT-3.5-Turbo LLM: a free-form approach without turn limits and a predefined sequence approach with 20 turns. Both strategies incorporated specific rapport-building utterances (praise, empathy, storytelling, etc.) through carefully crafted prompts. The system was deployed as a virtual agent with speech recognition, text-to-speech, lip-sync, and gesture control capabilities. Human evaluations with 20 Japanese participants assessed user experience across five metrics (naturalness, satisfaction, interest, engagement, usability) and rapport scores using a 7-point Likert scale questionnaire.

## Key Results
- Free-form rapport strategy outperformed predefined sequences in naturalness, satisfaction, usability, and rapport scores (p < 0.05)
- Rapport scores correlated significantly with naturalness, satisfaction, engagement, and logical flow of conversation
- Compared to a traditional Q&A agent, the rapport-enhanced agent improved interest, engagement, and rapport metrics
- No significant correlation found between rapport scores and total conversation turns or utterance length

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Free-form rapport-building prompts produce more natural and satisfying interactions than predefined sequences.
- Mechanism: Free-form prompting allows the LLM to dynamically adapt responses to user cues and context, creating more fluid and personalized dialogue. Predefined sequences constrain the conversation path, reducing spontaneity and adaptability.
- Core assumption: User engagement and satisfaction depend on the perceived naturalness and adaptability of the dialogue.
- Evidence anchors:
  - [abstract] "free-form strategy outperformed predefined sequences in naturalness, satisfaction, usability, and rapport"
  - [section] "the Free Rapport Agent consistently outperformed the Predefined Rapport Agent across UX variables with statistical significance"
  - [corpus] Corpus lacks direct comparison studies; the claim is primarily anchored in the current paper's results.
- Break condition: If user inputs deviate significantly from expected patterns, free-form responses may become inconsistent or off-topic.

### Mechanism 2
- Claim: Embedding rapport-building utterances into dialogue generation improves user engagement and perceived connection.
- Mechanism: Specific rapport-building strategies (praise, empathy, storytelling, etc.) create positive emotional responses, making users feel valued and understood, which fosters rapport.
- Core assumption: Human-agent rapport is enhanced by relational cues that mimic human-human rapport-building behaviors.
- Evidence anchors:
  - [abstract] "rapport-building dialogue strategy for virtual agents to improve human-agent interaction through small talk"
  - [section] "Free Rapport Agent, incorporating rapport-building utterances, provided more diverse responses... made the interaction interesting and enjoyable"
  - [corpus] Limited corpus support; related studies focus on rapport in different contexts but not specifically on utterance-based strategies.
- Break condition: Overuse or misapplication of rapport utterances can feel insincere or mechanical, reducing their effectiveness.

### Mechanism 3
- Claim: User experience variables (naturalness, satisfaction, engagement, logical flow) correlate positively with rapport scores.
- Mechanism: Better UX variables create a more pleasant and coherent interaction, which users perceive as higher rapport.
- Core assumption: Rapport is a subjective experience influenced by overall interaction quality.
- Evidence anchors:
  - [abstract] "Rapport score correlated significantly with naturalness, satisfaction, engagement, and logical flow of conversation"
  - [section] "RS exhibited significant correlations with UX variables influencing the conversational experience"
  - [corpus] Corpus lacks direct studies on correlation between UX variables and rapport scores; evidence is from current paper.
- Break condition: If UX variables are high but rapport-building strategies are absent, rapport scores may not improve.

## Foundational Learning

- Concept: Rapport-building strategies in human-agent interaction
  - Why needed here: The study's core contribution is implementing specific rapport-building utterances (praise, empathy, storytelling) to enhance user experience.
  - Quick check question: What are the key rapport-building utterances used in this study?

- Concept: LLM prompting strategies (free-form vs predefined)
  - Why needed here: The study compares two prompting strategies to guide dialogue generation, which is central to the experimental design.
  - Quick check question: How do free-form and predefined prompting strategies differ in their approach to dialogue generation?

- Concept: Human evaluation metrics and correlation analysis
  - Why needed here: The study relies on human evaluations and statistical correlation analysis to assess the effectiveness of rapport-building strategies.
  - Quick check question: What UX variables were measured in the human evaluation, and how were they correlated with rapport scores?

## Architecture Onboarding

- Component map:
  ASR (Japanese) -> LLM (dialogue generation with rapport prompts) -> TTS (Japanese) -> LipSync + Gesture/Face Control

- Critical path:
  ASR → LLM (with rapport prompts) → TTS → LipSync + Gesture/Face Control

- Design tradeoffs:
  - Free-form vs predefined prompts: Flexibility vs consistency
  - Turn limits: Natural flow vs controlled interaction length
  - Rapport utterance variety: Engagement vs potential overuse

- Failure signatures:
  - ASR errors leading to misinterpretation
  - LLM generating irrelevant or repetitive responses
  - TTS/TTS synchronization issues affecting naturalness

- First 3 experiments:
  1. Test ASR accuracy with Japanese speech inputs
  2. Validate LLM responses for coherence and rapport-building effectiveness
  3. Assess synchronization between speech and non-verbal cues (LipSync, gestures)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of rapport-building dialogue strategies vary across different cultural contexts or demographic groups?
- Basis in paper: [inferred] The study was conducted with native Japanese speakers, but cultural differences in rapport-building and small talk could significantly impact effectiveness
- Why unresolved: The research only examined one cultural context (Japanese participants), leaving questions about cross-cultural applicability
- What evidence would resolve it: Conducting similar experiments with participants from diverse cultural backgrounds and comparing the effectiveness of rapport-building strategies across these groups

### Open Question 2
- Question: What is the optimal balance between structured (predefined) and spontaneous (free-form) dialogue strategies for different types of virtual agents or interaction contexts?
- Basis in paper: [explicit] The study compared free-form and predefined sequence strategies, finding free-form superior, but didn't explore hybrid approaches or context-dependent optimization
- Why unresolved: The research only examined two extreme approaches without exploring intermediate or adaptive strategies
- What evidence would resolve it: Testing various hybrid approaches that combine predefined structure with free-form adaptability, and evaluating their effectiveness across different interaction scenarios

### Open Question 3
- Question: How do non-verbal cues and emotional expressiveness in virtual agents impact the effectiveness of rapport-building strategies?
- Basis in paper: [explicit] The authors acknowledge that participants noted the impact of the agent's neutral tone and suggest exploring emotional TTS and non-verbal cues like nodding
- Why unresolved: The current study used a virtual agent with limited non-verbal communication capabilities
- What evidence would resolve it: Implementing agents with enhanced non-verbal capabilities (facial expressions, gestures, emotional voice) and measuring their impact on rapport-building effectiveness compared to the current implementation

### Open Question 4
- Question: What are the long-term effects of initial rapport-building on subsequent task performance and user satisfaction in human-agent interactions?
- Basis in paper: [inferred] The study focused on first meeting dialogues but didn't examine how initial rapport affects later interactions
- Why unresolved: The research only examined single-session interactions without tracking longitudinal effects
- What evidence would resolve it: Conducting studies that measure task performance and user satisfaction in multi-session interactions where rapport was or wasn't established in initial meetings, comparing outcomes between groups

## Limitations

- Small sample size (20 participants) may limit generalizability across different user populations
- Study focuses specifically on first meetings and Japanese language interactions, potentially limiting applicability to other contexts or languages
- Correlation analysis shows that rapport scores correlate with several UX variables but not with total turns or utterance length, suggesting incomplete understanding of interaction dynamics

## Confidence

- **High confidence**: The core finding that free-form prompting outperforms predefined sequences in user experience metrics is well-supported by statistical analysis with clear effect sizes (p < 0.05)
- **Medium confidence**: The claim that rapport-building utterances directly cause improved user experience is plausible but could be influenced by other factors such as the novelty of interacting with an AI agent
- **Low confidence**: The mechanism explaining why certain UX variables correlate with rapport scores while others do not is speculative and requires further investigation

## Next Checks

1. **Replication with larger sample**: Conduct the same experiment with 100+ participants across diverse demographic groups to verify the robustness of the free-form vs predefined strategy findings and test generalizability

2. **Cross-language validation**: Implement the rapport-building dialogue system in English and other major languages to determine if the effectiveness of specific rapport-building utterances (praise, empathy, storytelling) translates across linguistic and cultural contexts

3. **Longitudinal interaction study**: Extend the interaction beyond first meetings to examine whether rapport-building strategies maintain their effectiveness over multiple sessions and whether initial rapport translates to sustained user engagement