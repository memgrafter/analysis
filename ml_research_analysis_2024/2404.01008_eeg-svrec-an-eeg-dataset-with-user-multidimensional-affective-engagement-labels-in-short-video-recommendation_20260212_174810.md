---
ver: rpa2
title: 'EEG-SVRec: An EEG Dataset with User Multidimensional Affective Engagement
  Labels in Short Video Recommendation'
arxiv_id: '2404.01008'
source_url: https://arxiv.org/abs/2404.01008
tags:
- video
- short
- user
- signals
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EEG-SVRec introduces the first EEG dataset for short video recommendation,
  capturing user brain activity alongside multidimensional affective engagement labels
  (valence, arousal, immersion, interest, visual, and auditory). It addresses limitations
  of traditional behavioral data by providing direct cognitive signals during real-world
  video browsing.
---

# EEG-SVRec: An EEG Dataset with User Multidimensional Affective Engagement Labels in Short Video Recommendation

## Quick Facts
- **arXiv ID**: 2404.01008
- **Source URL**: https://arxiv.org/abs/2404.01008
- **Reference count**: 40
- **Primary result**: EEG-SVRec introduces the first EEG dataset for short video recommendation, capturing user brain activity alongside multidimensional affective engagement labels, with AUC improvements of up to 5% when incorporating EEG signals.

## Executive Summary
EEG-SVRec presents the first EEG dataset designed specifically for short video recommendation, capturing both brain activity signals and multidimensional affective engagement labels from users. The dataset includes EEG/ECG recordings, user behavior logs, and self-assessed engagement scores across six dimensions (valence, arousal, immersion, interest, visual, and auditory) from 30 participants during 3,657 interactions. The study demonstrates that incorporating EEG signals significantly improves recommendation performance compared to using behavioral data alone, with AUC scores increasing by up to 5% across multiple recommendation models. This work addresses limitations of traditional behavioral data by providing direct cognitive signals during real-world video browsing, enabling richer user modeling and more personalized recommendations.

## Method Summary
The EEG-SVRec dataset was collected using a controlled experimental setup where participants viewed short videos on mobile devices while EEG and ECG signals were recorded. The data collection included three types of information: user behavior logs (viewing duration, interactions), preprocessed EEG signals with differential entropy features extracted across five frequency bands, and self-assessed multidimensional affective engagement scores (MAES) across six dimensions. Recommendation models including FM, DeepFM, AFM, WideDeep, and DCN-V2 were trained using both behavioral features and EEG embeddings, with performance evaluated using AUC scores for rating prediction tasks.

## Key Results
- Incorporating EEG signals improves recommendation performance with AUC scores increasing by up to 5% across multiple models
- The dataset captures rich multidimensional affective engagement through six self-assessed dimensions (valence, arousal, immersion, interest, visual, auditory)
- EEG features provide meaningful auxiliary information beyond traditional behavioral metrics for user modeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EEG signals capture real-time cognitive activity that behavioral data alone cannot provide, leading to improved recommendation performance.
- Mechanism: EEG signals offer high temporal resolution data reflecting user engagement, emotion, and attention during short video viewing, which complements sparse and noisy behavioral data.
- Core assumption: EEG signals contain meaningful information about user affective engagement that correlates with recommendation preferences.
- Evidence anchors:
  - [abstract] "Incorporating EEG signals significantly improves recommendation performance, with AUC scores increasing by up to 5% across multiple models"
  - [section] "EEG, as a neuroelectrical signal, containing rich spatial, temporal, and frequency band information about human experience"
  - [corpus] Weak evidence - corpus contains related EEG studies but not directly comparable to short video recommendation context
- Break condition: If EEG signals do not correlate with user preferences or if the improvement in recommendation performance is negligible.

### Mechanism 2
- Claim: Multidimensional affective engagement labels (MAES) provide a more comprehensive understanding of user experience than traditional behavioral metrics.
- Mechanism: By collecting self-assessed scores across six dimensions (valence, arousal, immersion, interest, visual, and auditory), the dataset captures nuanced user preferences that go beyond simple likes or view duration.
- Core assumption: Users can accurately self-assess their affective engagement across multiple dimensions.
- Evidence anchors:
  - [abstract] "user Multidimensional Affective Engagement Labels in Short Video Recommendation"
  - [section] "We collect six Multidimensional Affective Engagement Scores (MAES), which are valence, arousal, immersion, interest, visual and auditory"
  - [corpus] No direct evidence in corpus for MAES in short video context
- Break condition: If self-assessment labels do not correlate with actual user behavior or EEG signals.

### Mechanism 3
- Claim: Combining EEG signals with behavioral data and MAES creates a richer representation of user preferences for recommendation algorithms.
- Mechanism: The integration of these three data types provides both implicit (EEG, behavior) and explicit (MAES) feedback, enabling more accurate user modeling and personalized recommendations.
- Core assumption: The combination of different data types provides complementary information that improves recommendation quality.
- Evidence anchors:
  - [abstract] "significant improvement with the inclusion of EEG signals" and "multidimensional affective engagement scores"
  - [section] "We collected three types of data: user behavior log, EEG signals, and self-assessment of six MAES"
  - [corpus] No direct evidence in corpus for combined approach
- Break condition: If adding any one data type does not improve recommendation performance beyond using the other types alone.

## Foundational Learning

- Concept: EEG signal preprocessing and feature extraction
  - Why needed here: The raw EEG data needs to be cleaned and transformed into meaningful features (like differential entropy) before it can be used in recommendation models.
  - Quick check question: What are the main steps in preprocessing EEG data for affective computing applications?

- Concept: Recommender system evaluation metrics
  - Why needed here: The paper uses AUC scores to evaluate recommendation performance, which requires understanding how these metrics work in the context of implicit feedback.
  - Quick check question: How does AUC differ from NDCG in evaluating recommendation systems with implicit feedback?

- Concept: Multi-modal data integration in machine learning
  - Why needed here: The dataset combines EEG, behavioral, and self-assessment data, requiring knowledge of how to effectively integrate different data modalities in machine learning models.
  - Quick check question: What are common approaches for combining heterogeneous data sources in recommendation systems?

## Architecture Onboarding

- Component map: Data collection -> Preprocessing -> Feature extraction -> Model training -> Evaluation
- Critical path: Data collection → Preprocessing → Feature extraction → Model training → Evaluation
- Design tradeoffs:
  - EEG equipment cost vs. data quality: High-quality EEG requires expensive equipment but provides better signals
  - Self-assessment timing: Collecting MAES immediately after viewing vs. after session completion
  - Session design: Personalized vs. randomized vs. mixed video pools to balance recommendation quality and data diversity
- Failure signatures:
  - Poor EEG signal quality due to movement artifacts or equipment issues
  - Low correlation between self-assessed MAES and actual user preferences
  - EEG features not improving recommendation performance beyond behavioral data alone
- First 3 experiments:
  1. Baseline recommendation using only behavioral data (no EEG, no MAES)
  2. Recommendation using behavioral data + MAES (no EEG)
  3. Recommendation using behavioral data + EEG features (no MAES)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do EEG-guided recommendation algorithms perform compared to traditional recommendation algorithms when using the EEG-SVRec dataset?
- Basis in paper: [explicit] The paper mentions that EEG signals can be used as auxiliary information to enhance representation and improve recommendation performance, but the experiments conducted only used a simple way of introducing EEG information by directly embedding EEG signals as features.
- Why unresolved: The paper only provides basic benchmarks using simple methods of incorporating EEG signals, leaving room for more advanced techniques to be explored.
- What evidence would resolve it: Conducting experiments using more sophisticated models, such as DGCNN, that can utilize electrode position information from the EEG signals and comparing their performance to traditional recommendation algorithms.

### Open Question 2
- Question: How can EEG signals be used to develop more inclusive recommendation systems for individuals with disabilities?
- Basis in paper: [inferred] The paper suggests that the EEG-SVRec dataset has the potential to facilitate the development of more inclusive recommendation systems tailored for individuals with disabilities by analyzing their unique cognitive and emotional experiences through EEG data.
- Why unresolved: The paper does not provide specific examples or methods for using EEG signals to develop inclusive recommendation systems for individuals with disabilities.
- What evidence would resolve it: Conducting experiments that demonstrate how EEG signals can be used to adapt recommendation algorithms to better cater to the needs and preferences of individuals with disabilities, and evaluating the effectiveness of these adapted algorithms.

### Open Question 3
- Question: How do EEG signals correlate with user multidimensional affective engagement scores (MAES) and browsing behaviors?
- Basis in paper: [explicit] The paper presents a heatmap showing the correlations between behavioral attributes and MAES, and topographical maps illustrating the correlations between EEG signals and the six MAES as well as two behaviors.
- Why unresolved: While the paper provides some insights into the correlations, further analysis is needed to fully understand the relationship between EEG signals, MAES, and browsing behaviors.
- What evidence would resolve it: Conducting in-depth analysis of the EEG-SVRec dataset to identify specific patterns and relationships between EEG signals, MAES, and browsing behaviors, and using statistical methods to validate the significance of these correlations.

## Limitations
- Small sample size of 30 participants limits generalizability across diverse user populations
- Self-assessment methodology for MAES labels introduces potential biases in affective state reporting
- Controlled lab conditions with specific EEG equipment may not reflect real-world short video consumption scenarios

## Confidence
- **High confidence**: The technical feasibility of EEG preprocessing and feature extraction methods; the AUC improvement metrics reported for the recommendation models
- **Medium confidence**: The correlation between EEG signals and user affective engagement; the practical significance of the 5% AUC improvement in real-world applications
- **Low confidence**: The long-term stability of EEG-based recommendations across different contexts; the scalability of EEG data collection for large user bases

## Next Checks
1. **Replication with diverse populations**: Test the recommendation performance on a larger, more diverse participant pool (different ages, cultural backgrounds, technical familiarity) to validate generalizability of the EEG engagement patterns.

2. **Cross-dataset validation**: Evaluate whether the EEG features extracted from the EEG-SVRec dataset transfer to other video recommendation contexts or domains (e.g., long-form videos, different content types).

3. **Real-world deployment study**: Conduct a field study where the EEG-enhanced recommendation system is deployed in naturalistic settings to assess whether the controlled-environment benefits persist in actual user environments.