---
ver: rpa2
title: The Surprising Effectiveness of Rankers Trained on Expanded Queries
arxiv_id: '2404.02587'
source_url: https://arxiv.org/abs/2404.02587
tags:
- queries
- query
- hard
- ranker
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of improving retrieval performance
  on hard queries, which are often underspecified, incomplete, or uncommon. The core
  idea is to use a specialized ranker trained on LLM-enriched hard queries to complement
  a base ranker, and then combine their outputs using a query performance prediction
  (QPP) score that estimates query hardness.
---

# The Surprising Effectiveness of Rankers Trained on Expanded Queries

## Quick Facts
- arXiv ID: 2404.02587
- Source URL: https://arxiv.org/abs/2404.02587
- Authors: Abhijit Anand; Venktesh V; Vinay Setty; Avishek Anand
- Reference count: 40
- Primary result: Specialized rankers trained on LLM-enriched hard queries improve retrieval performance by up to 25% in nDCG@10 and 48.4% in RR

## Executive Summary
This paper addresses the challenge of improving retrieval performance on hard queries, which are often underspecified, incomplete, or uncommon. The core approach involves training a specialized ranker on LLM-enriched hard queries and combining its output with a base ranker using query performance prediction (QPP) scores that estimate query hardness. Experiments on DL-Hard and TREC-DL datasets demonstrate significant improvements over baseline models, with gains of up to 25% in nDCG@10 and 48.4% in RR, even outperforming state-of-the-art models.

## Method Summary
The method involves training two rankers: a base ranker on all original queries and a specialized ranker on LLM-enriched hard queries. Hard queries are identified using heuristics like query length and uncommon terms, then enriched with context from relevant document passages using an LLM. During inference, a QPP model estimates query hardness to determine whether to use the base or specialized ranker, with final rankings produced by weighted fusion of their scores based on the QPP estimate.

## Key Results
- Up to 25% improvement in nDCG@10 over baseline
- 48.4% improvement in Mean Reciprocal Rank (RR)
- Outperforms state-of-the-art models on DL-Hard and TREC-DL datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Context-aware query enrichment using relevant documents enables specialized rankers to capture nuanced query-document features for hard queries.
- Mechanism: The LLM rewrites hard queries by conditioning on the most relevant document passage, effectively expanding the query with contextual knowledge that mirrors how the ranker will encounter document content.
- Core assumption: The most relevant document passage provides sufficient context to expand the query without introducing topic drift.
- Evidence anchors:
  - [abstract] "To help the specialized ranker easily identify the specific query-document features, our second novel contribution is to contextually expand the hard queries. Specifically, we hypothesize that if the hard queries are expanded or enriched with the active knowledge of the relevant documents, then a specialized ranker can easily extract relevant query-document features when training on the expanded queries."
  - [section] "Using the full document in the prompt for query enrichment could result in topic drift, since a document may consist of multiple aspects and different topics. To mitigate this, we employ supervised passage selection techniques (Attention, Linear) as proposed in [23]."
- Break condition: If the relevant document passage is not representative of the document's full content, or if the passage selection method fails to capture the most salient information for the query.

### Mechanism 2
- Claim: Query performance prediction (QPP) scores effectively identify hard queries at inference time, enabling appropriate routing to specialized rankers.
- Mechanism: A BERT-QPP model is trained to predict nDCG@10 scores for queries based on their retrieved documents, and these predictions serve as hardness estimates that determine whether to use the base or specialized ranker.
- Core assumption: The QPP model's nDCG@10 prediction correlates strongly with query difficulty and is a reliable indicator for ranker routing.
- Evidence anchors:
  - [abstract] "We employ query performance prediction (QPP) approaches to automatically identify hard queries [5]."
  - [section] "At inference time, we score queries using a trained BERT-QPP model and use the score to decide if a query is hard or easy. Hard queries are evaluated by SR and easy queries by BR and finally combine their ranklist."
- Break condition: If the QPP model's predictions do not correlate well with actual query difficulty, or if the threshold for distinguishing hard from easy queries is poorly calibrated.

### Mechanism 3
- Claim: Weighted fusion of base and specialized ranker scores using QPP-based weights improves ranking performance across both hard and easy queries.
- Mechanism: The final relevance score for each document is computed as a weighted sum of the base ranker and specialized ranker scores, where the weights are determined by the QPP-based hardness estimate for the query.
- Core assumption: The QPP-based hardness estimate accurately reflects the relative importance of the specialized ranker's score versus the base ranker's score for each query.
- Evidence anchors:
  - [abstract] "We combine the relevance scores from the specialized ranker and the base ranker, along with a query performance score estimated for each query."
  - [section] "Given a query (q) at inference time, we first obtain a score which is the hardness estimate for q using BERT-QPP model (QPP) defined above given the retrieved set. The hardness estimate QPP(q, R+) is used to compute final relevance score S_i by interpolating the relevance scores obtained by BR or S_base(q,d_i) and SR or S_special(q,d_i)."
- Break condition: If the QPP-based weights do not properly balance the contributions of the base and specialized rankers, or if the interpolation formula is suboptimal.

## Foundational Learning

- Concept: Query Performance Prediction (QPP)
  - Why needed here: QPP is used to automatically identify hard queries at inference time, enabling appropriate routing to specialized rankers without manual query labeling.
  - Quick check question: What is the primary task of a QPP model in the context of this paper?
- Concept: Context-aware query enrichment
  - Why needed here: Context-aware enrichment using relevant documents helps specialized rankers learn nuanced query-document features specific to hard queries, which are often underspecified or incomplete.
  - Quick check question: How does context-aware query enrichment differ from traditional query expansion techniques?
- Concept: Ranker fusion techniques
  - Why needed here: Fusion of base and specialized ranker outputs is necessary to leverage the strengths of both models and improve overall ranking performance across all query types.
  - Quick check question: What are the two main fusion approaches proposed in this paper for combining base and specialized ranker scores?

## Architecture Onboarding

- Component map: Query preprocessing -> Query enrichment -> Base ranker training -> Specialized ranker training -> QPP model training -> Inference (QPP scoring -> Ranker selection -> Score fusion)
- Critical path:
  1. Query arrives at system
  2. QPP model estimates query hardness
  3. Base ranker scores all documents
  4. If QPP indicates hard query, specialized ranker also scores all documents
  5. Fusion module combines scores using QPP-based weights
  6. Final ranked list is returned
- Design tradeoffs:
  - Using a single ranker vs. separate base and specialized rankers: Separate rankers allow capturing query-specific features but increase complexity and computational cost.
  - Enriching queries during training only vs. during inference: Training-only enrichment is more efficient but may limit the specialized ranker's ability to handle diverse query formulations at test time.
  - Simple score averaging vs. QPP-based weighted fusion: Weighted fusion can better balance the contributions of base and specialized rankers but requires an additional QPP model.
- Failure signatures:
  - Poor performance on easy queries: Indicates the specialized ranker is being used too often or the QPP model is overestimating query hardness.
  - Poor performance on hard queries: Indicates the specialized ranker is not learning the necessary query-document features or the query enrichment is not providing sufficient context.
  - QPP model predictions not correlating with actual query difficulty: Indicates the QPP model is not a reliable indicator for ranker routing.
- First 3 experiments:
  1. Evaluate base ranker performance on DL-Hard dataset to establish baseline.
  2. Evaluate specialized ranker performance on DL-Hard dataset with enriched queries to assess its effectiveness on hard queries.
  3. Evaluate QPP model's ability to distinguish hard from easy queries by comparing its predictions to actual query difficulty labels.

## Open Questions the Paper Calls Out

- Question: What are the specific mechanisms by which query performance prediction (QPP) can be further refined to improve the accuracy of identifying hard queries?
  - Basis in paper: [explicit] The paper uses BERT-QPP to identify hard queries but does not explore further refinements.
  - Why unresolved: The paper does not investigate alternative QPP methods or enhancements that could improve hardness estimation.
  - What evidence would resolve it: Experiments comparing different QPP models or enhancements (e.g., ensemble methods) on query hardness identification.

- Question: How does the context-aware query enrichment process affect the performance of specialized rankers on diverse types of hard queries (e.g., domain-specific vs. ambiguous queries)?
  - Basis in paper: [inferred] The paper focuses on context-aware query enrichment but does not analyze its impact on different query types.
  - Why unresolved: The paper does not provide a detailed analysis of how enrichment affects different query characteristics.
  - What evidence would resolve it: Comparative experiments showing the performance of specialized rankers on various query types with and without enrichment.

- Question: What are the long-term implications of using specialized rankers for hard queries on the overall ranking system's robustness and adaptability to evolving query distributions?
  - Basis in paper: [explicit] The paper demonstrates the effectiveness of specialized rankers but does not address long-term system adaptability.
  - Why unresolved: The paper does not explore how the system would handle changes in query distributions over time.
  - What evidence would resolve it: Longitudinal studies or simulations showing the system's performance over time with changing query patterns.

## Limitations

- The enrichment process depends on an unspecified LLM, introducing potential variability and dependency on the quality of the underlying model.
- The effectiveness of QPP-based routing assumes accurate hardness prediction, which may not generalize to all query distributions.
- No ablation study isolates the contribution of query expansion versus the specialized ranker itself.

## Confidence

- Medium confidence in the central claim that specialized rankers trained on expanded queries significantly improve hard-query retrieval, as the experimental gains are substantial but the approach depends on LLM-based enrichment and QPP-based fusion assumptions.

## Next Checks

1. Conduct an ablation study to isolate the impact of query expansion, specialized ranker, and QPP-based fusion on performance.
2. Evaluate the robustness of the approach to different LLM models and enrichment strategies.
3. Analyze failure cases to understand when the specialized ranker underperforms and whether this correlates with specific query characteristics.