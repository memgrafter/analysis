---
ver: rpa2
title: Faithful Temporal Question Answering over Heterogeneous Sources
arxiv_id: '2402.15400'
source_url: https://arxiv.org/abs/2402.15400
tags:
- temporal
- question
- questions
- answer
- answering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Faith, a temporal QA system that integrates
  multiple information sources (knowledge bases, text, tables, infoboxes) and provides
  faithful, explainable answers with traceable evidence. Faith resolves implicit temporal
  constraints by recursively generating intermediate questions, transforming them
  into explicit temporal values.
---

# Faithful Temporal Question Answering over Heterogeneous Sources

## Quick Facts
- arXiv ID: 2402.15400
- Source URL: https://arxiv.org/abs/2402.15400
- Reference count: 40
- P@1 of 0.491 on implicit temporal questions in Tiq benchmark

## Executive Summary
Faith is a temporal question answering system that integrates multiple heterogeneous information sources including knowledge bases, text, tables, and infoboxes. The system addresses the challenge of implicit temporal constraints by recursively generating intermediate questions that transform these constraints into explicit temporal values. Faith enforces faithfulness through temporal pruning that removes evidence inconsistent with the temporal constraints expressed in questions, and provides explainable answers with traceable evidence.

## Method Summary
Faith employs a three-stage pipeline: Temporal Question Understanding to capture temporal intent and represent it in a structured temporal signal frame (TSF), Faithful Evidence Retrieval to retrieve and prune temporally inconsistent evidence from heterogeneous sources, and Explainable Heterogeneous Answering using a graph neural network to compute answers with supporting evidence. The system introduces an implicit question resolver that recursively generates and answers intermediate questions to handle implicit temporal constraints, transforming them into explicit conditions that can be used for evidence filtering.

## Key Results
- Achieves P@1 of 0.491 on Tiq benchmark versus 0.236-0.446 for baseline systems
- Outperforms baselines on TimeQuestions with P@1 of 0.732 versus 0.521-0.583
- Demonstrates 95% temporal consistency in evidence for correct answers versus 90% for variant without temporal pruning
- Maintains robust performance across different source combinations while preserving explainability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The recursive intermediate question generation transforms implicit temporal constraints into explicit conditions, enabling the QA system to handle implicit questions as if they were explicit.
- Mechanism: When an implicit temporal constraint is detected (e.g., "when recording Bohemian Rhapsody"), the system generates intermediate questions that isolate the temporal aspect (e.g., "When Queen recorded Bohemian Rhapsody start date?"). These intermediate questions are recursively processed by the full QA pipeline, which returns explicit temporal values that can be used as constraints for the original question.
- Core assumption: The QA system can accurately answer intermediate questions about temporal values, and the generated intermediate questions are semantically equivalent to the implicit temporal constraints.
- Evidence anchors:
  - [abstract]: "For example, the implicit condition 'when recording Bohemian Rhapsody' in ð‘ž3 is transformed into 'when Queen recorded Bohemian Rhapsody?', and the recursive invocation of Faith returns the explicit condition August 1975 - September 1975."
  - [section]: "To resolve this problem, we devise a novel mechanism, the implicit question resolver, based on recursively invoking the temporal QA system itself."
  - [corpus]: "Found 25 related papers (using 8). Average neighbor FMR=0.549, average citations=0.0." (Weak corpus evidence for this specific mechanism)

### Mechanism 2
- Claim: Temporal pruning enforces faithfulness by removing evidence inconsistent with the temporal constraints expressed in the question.
- Mechanism: After retrieving evidence from heterogeneous sources, the system identifies explicit temporal expressions in each piece of evidence. Evidence that does not match the temporal constraint (expressed by the temporal signal and value in the TSF) is pruned out. This ensures that answers are only derived from temporally consistent evidence.
- Core assumption: The system can accurately identify and normalize temporal expressions in retrieved evidence, and the temporal constraints can be properly represented and matched.
- Evidence anchors:
  - [abstract]: "First, it enforces temporal constraints for faithful answering with tangible evidence."
  - [section]: "Evidence that does not match the temporal criteria is pruned out. We address two kinds of situations: (i) the question aims for a temporal value as answer and does not have any temporal constraints, and (ii) the question has a temporal constraint which needs to be matched by the evidence."
  - [corpus]: "Found 25 related papers (using 8). Average neighbor FMR=0.549, average citations=0.0." (Weak corpus evidence for this specific mechanism)

### Mechanism 3
- Claim: Heterogeneous evidence retrieval and graph neural network-based answering enable the system to leverage diverse information sources and provide explainable answers with traceable evidence.
- Mechanism: The system retrieves evidence from knowledge bases, text, tables, and infoboxes, verbalizes all evidence into textual sentences for uniform treatment, and then uses a graph neural network to compute answers and supporting evidence. This approach allows the system to handle questions that require information from multiple sources and provides users with traceable provenance for the answer derivation.
- Core assumption: The verbalization of heterogeneous evidence preserves the semantic information, and the graph neural network can effectively process the evidence graph to compute accurate answers and evidence.
- Evidence anchors:
  - [abstract]: "Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner."
  - [section]: "In the final stage, the answer is derived from this set of evidence pieces that is already known to satisfy the temporal conditions. Since this part is not the main focus of this work, we employ a state-of-the-art answering model for general-purpose QA. We use the answering stage ofExplaignn [13] that is based on graph neural networks (GNNs), and computes a subset of supporting evidence for the predicted answer."
  - [corpus]: "Found 25 related papers (using 8). Average neighbor FMR=0.549, average citations=0.0." (Weak corpus evidence for this specific mechanism)

## Foundational Learning

- Concept: Temporal question understanding and representation
  - Why needed here: The system needs to accurately capture the temporal intent of questions, including both explicit and implicit temporal constraints, to properly retrieve and filter evidence.
  - Quick check question: Can you explain the difference between explicit and implicit temporal constraints, and how the system handles each type?

- Concept: Evidence retrieval from heterogeneous sources
  - Why needed here: The system needs to effectively retrieve relevant evidence from diverse sources (knowledge bases, text, tables, infoboxes) to answer questions that may require information from multiple sources.
  - Quick check question: How does the system unify evidence from heterogeneous sources for processing, and what are the challenges in doing so?

- Concept: Graph neural networks for question answering
  - Why needed here: The system uses graph neural networks to process the evidence graph and compute answers with supporting evidence, enabling explainable and faithful answering.
  - Quick check question: What are the advantages of using graph neural networks for question answering over other approaches, and how do they contribute to explainability?

## Architecture Onboarding

- Component map: Temporal Question Understanding -> Implicit Question Resolver (if needed) -> Faithful Evidence Retrieval -> Explainable Heterogeneous Answering -> Answer with Evidence

- Critical path: Question â†’ Temporal Question Understanding â†’ Implicit Question Resolver (if needed) â†’ Faithful Evidence Retrieval â†’ Explainable Heterogeneous Answering â†’ Answer with Evidence

- Design tradeoffs:
  - Tradeoff between faithfulness and answering performance: Strict temporal pruning ensures faithfulness but may reduce answering performance by removing potentially useful evidence.
  - Tradeoff between computational cost and accuracy: Using more answer candidates for intermediate questions improves recall but increases computational cost and may introduce noise.
  - Tradeoff between source diversity and processing complexity: Integrating more heterogeneous sources improves coverage but increases processing complexity.

- Failure signatures:
  - Incorrect temporal signal or category prediction: Leads to incorrect pruning of evidence or failure to prune irrelevant evidence.
  - Failure in intermediate question generation: Results in inability to handle implicit questions or incorrect temporal constraints.
  - Inaccurate temporal expression identification: Causes incorrect pruning of evidence or retention of irrelevant evidence.
  - Graph neural network failure: Results in incorrect answers or missing supporting evidence.

- First 3 experiments:
  1. Test the temporal question understanding component on a set of explicit and implicit questions to ensure accurate TSF generation.
  2. Evaluate the implicit question resolver on a set of implicit questions to verify accurate intermediate question generation and correct temporal value extraction.
  3. Assess the faithful evidence retrieval component on a set of questions with known temporal constraints to ensure proper pruning of temporally inconsistent evidence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Faith's performance compare to large language models when answering questions that require complex temporal reasoning across multiple events?
- Basis in paper: [explicit] The paper notes that current LLMs "clearly not capable of answering temporal questions" and "underperforming Faith and baselines operating over heterogeneous sources" on both Tiq and TimeQuestions benchmarks.
- Why unresolved: The paper only tested InstructGPT and GPT-4 with simple prompts and didn't explore more sophisticated prompting strategies or chain-of-thought reasoning approaches that might improve LLM performance on temporal QA.
- What evidence would resolve it: A systematic comparison of Faith against various LLM prompting strategies (including few-shot examples, chain-of-thought, and decomposition approaches) on a carefully constructed set of complex temporal questions requiring multi-step reasoning.

### Open Question 2
- Question: What is the impact of the temporal pruning component on Faith's performance when answering questions about long-term historical events where temporal evidence might be sparse or conflicting?
- Basis in paper: [inferred] The paper shows that removing temporal pruning (Un-Faith variant) improves metrics on TimeQuestions, and the error analysis indicates that temporal pruning sometimes removes correct answers. The manual analysis shows Faith answers 93.4% of questions correctly when evidence is temporally inconsistent.
- Why unresolved: The paper doesn't provide detailed analysis of failure cases specifically related to historical questions or explore alternative temporal pruning strategies that might be more lenient while maintaining faithfulness.
- What evidence would resolve it: A detailed error analysis focusing on historical questions, comparing different temporal pruning thresholds and strategies, and measuring the trade-off between faithfulness and answer coverage.

### Open Question 3
- Question: How does Faith's implicit question resolver perform when dealing with complex temporal constraints involving multiple events or nested temporal relationships?
- Basis in paper: [explicit] The paper states that the implicit question resolver generates intermediate questions to resolve temporal constraints, but the evaluation only measures performance on simple implicit constraints like "after" or "during" relationships.
- Why unresolved: The paper doesn't provide examples or evaluation of complex implicit constraints involving multiple events, overlapping time periods, or nested temporal relationships that would require recursive resolution of multiple intermediate questions.
- What evidence would resolve it: A benchmark of implicit questions with complex temporal constraints, evaluation of the resolver's ability to correctly generate and answer multiple intermediate questions, and analysis of failure cases involving nested or overlapping temporal relationships.

## Limitations

- The evaluation of faithfulness relies heavily on automatic temporal consistency checking, which may not capture all nuances of semantic consistency.
- Faith's performance on implicit questions (P@1 of 0.491) remains substantially below its performance on explicit questions (P@1 of 0.854), indicating the intermediate question generation mechanism is not yet fully solving the implicit question challenge.
- The reported 95% faithfulness for Faith versus 90% for the variant without temporal pruning represents a relatively small absolute difference that may be sensitive to the specific temporal consistency evaluation method used.

## Confidence

**High Confidence**: The core architectural claims about Faith's three-stage pipeline and its ability to handle heterogeneous sources are well-supported by the experimental results across both Tiq and TimeQuestions benchmarks. The ablation studies showing the importance of temporal pruning and intermediate question generation are particularly convincing.

**Medium Confidence**: The claims about explainability and traceable evidence are supported by the methodology description but would benefit from more detailed user studies or qualitative analysis of the evidence chains produced. The faithfulness evaluation, while systematic, relies on automatic temporal consistency checking that may miss subtle semantic inconsistencies.

**Low Confidence**: The claims about Faith being "the first" to address both explicit and implicit temporal constraints with faithful evidence are difficult to verify given the rapidly evolving nature of temporal QA research and the limited corpus signals available.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate Faith on additional temporal QA datasets (such as TempQuestions or newly created implicit temporal questions) to verify that the 0.491 P@1 on implicit questions is not an artifact of the Tiq dataset's specific construction.

2. **Temporal consistency validation**: Manually review a random sample of 100 answered questions to verify the automatic temporal consistency checking, particularly focusing on edge cases where the temporal constraint is implied rather than explicitly stated in the evidence.

3. **Ablation on heterogeneous sources**: Conduct a more granular ablation study testing Faith's performance with individual source types (only KB, only text, only tables, only infoboxes) to better understand which source combinations are most critical for different question types and to identify potential redundancies in the current multi-source approach.