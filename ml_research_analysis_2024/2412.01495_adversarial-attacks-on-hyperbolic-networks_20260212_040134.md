---
ver: rpa2
title: Adversarial Attacks on Hyperbolic Networks
arxiv_id: '2412.01495'
source_url: https://arxiv.org/abs/2412.01495
tags:
- hyperbolic
- adversarial
- attacks
- learning
- euclidean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the need for adversarial robustness in hyperbolic\
  \ deep learning by proposing geometry-aware adversarial attacks. The authors introduce\
  \ hyperbolic variants of FGM and PGD attacks that operate in the Poincar\xE9 ball\
  \ model, using exponential maps and Riemannian geometry."
---

# Adversarial Attacks on Hyperbolic Networks

## Quick Facts
- arXiv ID: 2412.01495
- Source URL: https://arxiv.org/abs/2412.01495
- Reference count: 40
- Primary result: Geometry-aware adversarial attacks improve robustness evaluation for hyperbolic networks, but do not eliminate differences in vulnerability patterns compared to Euclidean networks

## Executive Summary
This paper introduces geometry-aware adversarial attacks for hyperbolic neural networks operating in the Poincaré ball model. The authors develop hyperbolic variants of FGM and PGD attacks that use exponential maps and Riemannian geometry to generate adversarial samples. Through experiments on CIFAR-10/100 and synthetic data, they demonstrate that Euclidean attacks perform differently on Euclidean versus hyperbolic networks, and that even geometry-aware attacks cannot eliminate these differences, suggesting that geometric choice fundamentally affects the patterns networks learn.

## Method Summary
The authors propose hyperbolic FGM and PGD attacks that operate in the Poincaré ball using exponential maps and Riemannian gradients. They train Poincaré ResNets and Euclidean ResNets on CIFAR-10/100 with specified hyperparameters, then evaluate adversarial robustness using four objective functions (cross-entropy, negative largest logit, second largest logit, smallest logit) with varying perturbation sizes. The attacks use the exponential map to generate adversarial samples along geodesics in hyperbolic space, ensuring perturbations respect the manifold's curvature.

## Key Results
- Poincaré ResNets achieve similar accuracy to Euclidean ResNets (54.1% vs 54.3% on CIFAR-100)
- Geometry-aware attacks perform better than Euclidean attacks for some objective functions but not all
- Euclidean attacks perform differently on Euclidean versus hyperbolic networks, and this discrepancy persists even with geometry-aware attacks
- The choice of geometry leads models to learn distinct patterns with different vulnerabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Geometry-aware adversarial attacks improve performance on hyperbolic networks by using exponential maps and Riemannian gradients.
- Mechanism: The proposed attacks use the exponential map to generate adversarial samples along geodesics in the Poincaré ball, ensuring perturbations respect the manifold's curvature.
- Core assumption: The manifold structure of hyperbolic space significantly affects the effectiveness of adversarial attacks compared to Euclidean space.
- Evidence anchors:
  - [abstract] "proposes hyperbolic alternatives to the commonly used FGM and PGD adversarial attacks... using exponential maps and Riemannian geometry"
  - [section 4] "Riemannian FGM with x ∈ M as ˜x = exp x(α∇xJ(θ, x, y)), where expx : TxM → M is the exponential map at x"
  - [corpus] Weak - related papers focus on general adversarial robustness but not hyperbolic-specific attacks
- Break condition: If the manifold structure is approximated as Euclidean (small perturbations), the advantage of geometry-aware attacks diminishes.

### Mechanism 2
- Claim: Poincaré ResNets and Euclidean ResNets learn distinct patterns due to their different geometries, leading to different vulnerabilities.
- Mechanism: The choice of geometry as the network's foundation causes the models to learn different feature representations, resulting in varying susceptibility to adversarial attacks.
- Core assumption: The geometric structure of the learning space directly influences the patterns learned by the network.
- Evidence anchors:
  - [abstract] "the choice of geometry leads models to learn distinct patterns with different vulnerabilities"
  - [section 6.3] "accounting for the geometry when performing the attack does not negate the discrepancy in behaviour of the two types of models. Somehow, the different geometries cause the models to learn different patterns"
  - [corpus] Weak - related papers do not discuss geometry-specific learning patterns
- Break condition: If the learned patterns are geometry-agnostic (e.g., rely on universal features), the differences in vulnerability may not hold.

### Mechanism 3
- Claim: The proposed hyperbolic attacks do not eliminate differences in adversarial robustness between Euclidean and hyperbolic networks.
- Mechanism: Even when using geometry-aware attacks on hyperbolic networks, the fundamental differences in vulnerability patterns persist, suggesting that geometry choice is a primary factor.
- Core assumption: The effectiveness of adversarial attacks is not solely determined by the attack method but also by the underlying geometry of the network.
- Evidence anchors:
  - [abstract] "the newly proposed hyperbolic attacks cannot address these differences"
  - [section 6.3] "accounting for the geometry by applying the proposed hyperbolic attacks to the hyperbolic models did not remove any of the observed differences"
  - [corpus] Weak - related papers do not explore the impact of geometry on attack effectiveness
- Break condition: If the attack method is sufficiently powerful to overcome geometric differences, the vulnerability patterns may converge.

## Foundational Learning

- Concept: Riemannian geometry and exponential maps
  - Why needed here: Understanding the manifold structure and how to navigate it is crucial for developing geometry-aware adversarial attacks.
  - Quick check question: What is the purpose of the exponential map in Riemannian geometry, and how is it used in hyperbolic space?

- Concept: Hyperbolic neural networks and their properties
  - Why needed here: Familiarity with hyperbolic networks is essential for comprehending the differences in adversarial robustness and the need for specialized attacks.
  - Quick check question: How do hyperbolic neural networks differ from their Euclidean counterparts in terms of representational capacity and learning dynamics?

- Concept: Adversarial attack methods (FGM, PGD) and their limitations in non-Euclidean spaces
  - Why needed here: Understanding the shortcomings of existing attack methods in hyperbolic spaces motivates the development of geometry-aware alternatives.
  - Quick check question: Why do conventional adversarial attacks like FGM and PGD perform differently on Euclidean and hyperbolic networks?

## Architecture Onboarding

- Component map:
  - Poincaré ResNets: Fully hyperbolic convolutional networks with layers embedded in hyperbolic space
  - Exponential maps: Used to navigate the manifold and generate adversarial samples
  - Riemannian gradients: Computed using the log map and used for attack updates
  - Projection operations: Ensure adversarial samples stay within the constraint set S

- Critical path:
  1. Preprocess input images by mapping them to the Poincaré ball using exponential maps
  2. Compute Riemannian gradients using the log map and the chosen objective function
  3. Generate adversarial samples using the exponential map and the computed gradients
  4. Project the adversarial samples back onto the constraint set S
  5. Evaluate the robustness of the model against the generated adversarial samples

- Design tradeoffs:
  - Using geometry-aware attacks vs. conventional attacks: Geometry-aware attacks are more effective but computationally more expensive
  - Choice of objective function: Different objective functions target different vulnerabilities but may have varying levels of effectiveness
  - Constraint set definition: The choice of constraint set (e.g., L∞ norm) affects the magnitude and nature of the adversarial perturbations

- Failure signatures:
  - Adversarial samples that do not significantly degrade model performance despite being generated using geometry-aware methods
  - Convergence issues when computing Riemannian gradients or performing exponential map operations
  - Projection operations that fail to keep adversarial samples within the constraint set S

- First 3 experiments:
  1. Implement and test the proposed hyperbolic FGM and PGD attacks on a synthetic hyperbolic classification task
  2. Compare the performance of hyperbolic FGM and PGD attacks against conventional FGM and PGD attacks on Poincaré ResNets
  3. Analyze the learned patterns and vulnerabilities of Poincaré ResNets and Euclidean ResNets by visualizing their feature representations and misclassification matrices

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do hyperbolic adversarial attacks consistently outperform Euclidean attacks across different network architectures and datasets?
- Basis in paper: [explicit] The authors note that hyperbolic attacks perform better for certain objective functions but not all, and that Euclidean attacks sometimes outperform hyperbolic ones depending on the gradient direction.
- Why unresolved: The paper's synthetic experiment shows mixed results, and while CIFAR experiments show some differences, the overall pattern is not conclusive across different architectures and datasets.
- What evidence would resolve it: Systematic experiments across multiple network architectures (not just ResNets), datasets with varying hierarchical structures, and comprehensive ablation studies of attack parameters.

### Open Question 2
- Question: Are the observed differences in adversarial robustness between Euclidean and hyperbolic networks primarily due to the geometric choice or other architectural differences?
- Basis in paper: [inferred] The authors conclude that geometry leads to learning different patterns, but they cannot definitively separate geometric effects from other architectural choices in their experiments.
- Why unresolved: The comparison is between fully hyperbolic networks and Euclidean networks, which may have other architectural differences beyond just the geometry.
- What evidence would resolve it: Experiments comparing networks with identical architectures but different geometric embeddings, or ablation studies isolating geometric effects.

### Open Question 3
- Question: How do hyperbolic adversarial attacks scale to larger-scale problems and more complex data distributions?
- Basis in paper: [inferred] The experiments are limited to CIFAR-10/100 datasets and a simple synthetic example, suggesting uncertainty about performance on more complex problems.
- Why unresolved: The paper only tests on relatively simple datasets and does not explore performance on larger-scale problems or more complex data distributions.
- What evidence would resolve it: Experiments on larger-scale datasets (e.g., ImageNet), complex hierarchical data, and real-world applications where hyperbolic geometry is known to be beneficial.

## Limitations

- Computational overhead: Hyperbolic operations are computationally more expensive than Euclidean counterparts, though the exact overhead is not quantified
- Limited scope: Experiments are limited to CIFAR-10/100 and synthetic data, not exploring larger-scale problems or more complex data distributions
- Statistical significance: Reported accuracy differences lack statistical significance testing across multiple training runs

## Confidence

- High confidence: The geometric foundations of the proposed attacks (exponential maps, Riemannian gradients) are mathematically sound
- Medium confidence: The empirical demonstration that Euclidean attacks perform differently on Euclidean vs hyperbolic networks
- Low confidence: The assertion that the proposed hyperbolic attacks cannot eliminate differences in adversarial robustness, as this requires extensive ablation studies

## Next Checks

1. Conduct statistical significance testing across multiple training runs to verify that accuracy differences between model types are not due to random variation
2. Perform scaling experiments with deeper architectures (e.g., ResNet-50) to assess whether the geometric effects persist at larger model scales
3. Measure and report computational overhead of hyperbolic operations compared to Euclidean counterparts to quantify the cost of geometry-aware attacks