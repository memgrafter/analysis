---
ver: rpa2
title: Can Machines Learn the True Probabilities?
arxiv_id: '2407.05526'
source_url: https://arxiv.org/abs/2407.05526
tags:
- 'true'
- machine
- probability
- then
- nature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proves that machines can learn the true objective probabilities\
  \ if and only if the probabilities are directly observable by the machines. The\
  \ paper establishes a necessary condition for machine learning: if a machine learns\
  \ the true probability P(At+1|\xDFt), then its subjective probability \u03A0(At+1|\xDF\
  t) must equal P(At+1|\xDFt)."
---

# Can Machines Learn the True Probabilities?

## Quick Facts
- arXiv ID: 2407.05526
- Source URL: https://arxiv.org/abs/2407.05526
- Authors: Jinsook Kim
- Reference count: 40
- Primary result: Machines can only learn true probabilities if they are directly observable

## Executive Summary
This paper establishes fundamental limits on machine learning by proving that machines can learn the true objective probabilities if and only if those probabilities are directly observable by the machines. The paper demonstrates that when Nature deviates from a machine's forecasts infinitely often (termed "perverse" Nature), learning the true probability becomes impossible. This result connects to computability and complexity theory, showing that true probabilities must be directly observable (like limiting relative frequencies) for machines to learn them.

## Method Summary
The paper employs rigorous mathematical proofs to establish its theoretical framework and conclusions. It defines conditions for learning in terms of the relationship between subjective probabilities Π(At+1|ßt) and true probabilities P(At+1|ßt), then proves necessary conditions for learning. The impossibility results are derived through formal analysis of what happens when Nature behaves perversely relative to machine forecasts.

## Key Results
- Machines can learn true objective probabilities if and only if those probabilities are directly observable
- A necessary condition for learning is that the machine's subjective probability must equal the true probability: Π(At+1|ßt) = P(At+1|ßt)
- When Nature is "perverse" (deviating from forecasts infinitely often), machines cannot learn true probabilities
- The results connect machine learning limitations to fundamental computability and complexity constraints

## Why This Works (Mechanism)
The paper's mechanism centers on the relationship between a machine's subjective probability estimates and the true underlying probabilities. Learning occurs when these align perfectly, but this alignment becomes impossible when Nature systematically contradicts the machine's predictions. The mechanism relies on formal probability theory and computability analysis to establish that direct observability is both necessary and sufficient for learning true probabilities.

## Foundational Learning
- **Probability theory** (why needed: to define and analyze the relationship between subjective and objective probabilities; quick check: can you explain P(At+1|ßt) notation?)
- **Computability theory** (why needed: to establish fundamental limits on what machines can learn; quick check: can you define what it means for a function to be computable?)
- **Complexity theory** (why needed: to analyze computational requirements for learning; quick check: can you explain the difference between P and NP problems?)
- **Learning theory** (why needed: to formalize what it means for a machine to "learn" a probability; quick check: can you define convergence in probability learning?)
- **Mathematical logic** (why needed: to construct rigorous proofs about learning impossibilities; quick check: can you follow a proof by contradiction?)
- **