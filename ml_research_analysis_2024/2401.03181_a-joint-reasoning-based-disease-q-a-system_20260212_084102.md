---
ver: rpa2
title: A Joint-Reasoning based Disease Q&A System
arxiv_id: '2401.03181'
source_url: https://arxiv.org/abs/2401.03181
tags:
- answer
- system
- answers
- disease
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a medical QA system that combines knowledge
  graphs (KGs) and large language models (LMs) through joint reasoning to provide
  accurate, readable answers to lay users' disease-related questions. The system uses
  a novel joint-reasoning methodology to select final answers from multiple candidates
  generated by LMs, leveraging a KG as a factual layer for scoring.
---

# A Joint-Reasoning based Disease Q&A System
## Quick Facts
- arXiv ID: 2401.03181
- Source URL: https://arxiv.org/abs/2401.03181
- Reference count: 40
- Outperforms ChatGPT on lexical similarity metrics for medical QA

## Executive Summary
This paper presents a medical question-answering system that combines knowledge graphs and large language models through joint reasoning to answer lay users' disease-related questions. The system generates multiple answer candidates using LMs, then employs a joint-reasoning methodology to select the most accurate final answer, using the KG as a factual scoring layer. Built with data from Mayo Clinic and NIH, the system is fully automated and evaluated on 75 chronic disease questions, demonstrating superior performance to baselines including ChatGPT on both lexical/semantic similarity and readability metrics.

## Method Summary
The system uses a joint-reasoning approach that generates multiple answer candidates from large language models, then selects the final answer by leveraging a knowledge graph as a factual scoring layer. The methodology is fully automated without requiring pre-created templates, using reliable medical sources like Mayo Clinic and NIH for data. The joint-reasoning component scores candidate answers against the KG to identify the most factually accurate response, with a supporting vector database enhancing answer quality.

## Key Results
- System achieved median ROUGE score of 0.36 versus 0.19 for ChatGPT
- Higher readability scores (Flesch-Kincaid) compared to baseline systems
- Ablation studies confirmed importance of joint reasoning and vector database for answer quality

## Why This Works (Mechanism)
The joint reasoning methodology effectively combines the generative capabilities of large language models with the factual accuracy of knowledge graphs. By generating multiple answer candidates and using the KG as a scoring layer, the system can identify and select the most factually accurate response while maintaining readability. The supporting vector database enables efficient retrieval and comparison of answer candidates against factual knowledge.

## Foundational Learning
- Knowledge Graph Integration: Why needed - Provides factual grounding for LM-generated answers; Quick check - Verify KG contains relevant medical entities and relationships
- Joint Reasoning Methodology: Why needed - Combines generative flexibility with factual accuracy; Quick check - Test reasoning mechanism on controlled answer sets
- Vector Database Support: Why needed - Enables efficient candidate answer comparison and retrieval; Quick check - Measure retrieval speed and accuracy on sample queries
- LM Candidate Generation: Why needed - Produces diverse answer options for joint reasoning; Quick check - Verify multiple distinct candidates are generated per query
- Factual Scoring Layer: Why needed - Evaluates candidate accuracy against KG; Quick check - Test scoring on known true/false statements
- Automated Processing: Why needed - Eliminates template dependency and manual intervention; Quick check - Verify end-to-end automation from query to answer

## Architecture Onboarding
**Component Map:** Query -> LM Candidate Generation -> Joint Reasoning -> KG Scoring -> Final Answer

**Critical Path:** User query flows through LM to generate multiple candidates, which are then evaluated by the joint reasoning module using KG as factual reference, with vector database supporting efficient retrieval.

**Design Tradeoffs:** Prioritizes factual accuracy over raw generative capability by using KG scoring, but may sacrifice some nuance that pure LM approaches capture. The automated approach eliminates template maintenance overhead but requires robust KG integration.

**Failure Signatures:** Poor performance on questions outside KG coverage, degraded quality when KG contains outdated information, potential bias toward KG-represented facts over emerging medical knowledge.

**3 First Experiments:**
1. Test joint reasoning on a small set of controlled medical questions with known correct answers
2. Compare candidate generation diversity across different LM configurations
3. Validate KG scoring accuracy by testing on manually curated fact pairs

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation scope with only 75 chronic disease questions
- Lack of clinical accuracy validation by medical experts
- Claims of hallucination avoidance not rigorously validated

## Confidence
- System outperforms ChatGPT on lexical similarity: High
- Joint reasoning improves answer quality: Medium
- System avoids hallucinations: Low
- Fully automated without templates: High

## Next Checks
1. Conduct expert medical review of system outputs to validate clinical accuracy and hallucination avoidance claims
2. Expand evaluation corpus to include acute diseases, symptoms, and treatment questions beyond chronic conditions
3. Compare system performance against specialized medical QA systems and retrieval-augmented generation frameworks