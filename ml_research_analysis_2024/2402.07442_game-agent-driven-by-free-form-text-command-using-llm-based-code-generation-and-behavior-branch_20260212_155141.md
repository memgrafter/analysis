---
ver: rpa2
title: 'Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation
  and Behavior Branch'
arxiv_id: '2402.07442'
source_url: https://arxiv.org/abs/2402.07442
tags:
- node
- game
- behavior
- commands
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a game agent control system that interprets\
  \ natural language commands using large language models (LLMs) to generate behavior\
  \ branches\u2014a novel knowledge representation extending behavior trees. The system\
  \ dynamically converts free-form text commands into executable game agent behaviors\
  \ in real time."
---

# Game Agent Driven by Free-Form Text Command: Using LLM-based Code Generation and Behavior Branch

## Quick Facts
- arXiv ID: 2402.07442
- Source URL: https://arxiv.org/abs/2402.07442
- Authors: Ray Ito; Junichiro Takahashi
- Reference count: 3
- One-line primary result: 86.11% success rate in executing natural language commands in a Pokémon-like game environment

## Executive Summary
This paper introduces a novel system for controlling game agents through free-form natural language commands by leveraging large language models (LLMs) for code generation and a proposed knowledge representation called behavior branches. The system dynamically translates natural language inputs into executable game agent behaviors in real-time, achieving an 86.11% success rate in a Pokémon-like game environment. By extending traditional behavior trees with behavior branches, the approach enables continuous and context-aware agent actions while maintaining the flexibility to integrate new commands on-the-fly.

## Method Summary
The system uses Code Llama 34B LLM to translate natural language commands into Python code that constructs behavior branches—a knowledge representation extending behavior trees. These branches dynamically update the agent's action flow in real-time. The implementation involves a Unity-based Pokémon-like game environment with predefined actions (Tackle, Thunderbolt, Iron Tail), TCP socket communication between Python and Unity, and empirical validation with 73 training and 36 test commands. The behavior branch structure supports action, condition, and control nodes with specific connection rules for integrating new commands.

## Key Results
- 86.11% success rate in executing randomly selected natural language commands
- System successfully interprets and acts on diverse command types including attack sequences and conditional behaviors
- Real-time behavior branch generation enables dynamic expansion of agent capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs successfully interpret natural language commands and generate valid Python code for behavior branch construction
- Core assumption: LLMs can reliably generate syntactically and semantically correct code representing command intent
- Evidence anchors: Abstract confirms LLM-based code generation for behavior branch creation; methodology follows Liang et al. (2022) approach
- Break condition: LLM generates invalid code that cannot be parsed or fails to represent intended command

### Mechanism 2
- Claim: Behavior branches enable real-time dynamic expansion of agent behavior
- Core assumption: Connection rules allow seamless integration of new commands without disrupting ongoing actions
- Evidence anchors: Abstract describes behavior branches as extending behavior trees for real-time expansion; section explains dynamic nature of branches
- Break condition: Connection rules fail to correctly integrate commands, causing unexpected behavior

### Mechanism 3
- Claim: High accuracy achieved through combination of well-defined environment, capable LLM, and robust behavior branch structure
- Core assumption: Predefined action set and behavior branch structure are sufficient for high command execution accuracy
- Evidence anchors: Abstract reports 86.11% success rate; results section confirms system's ability to understand and execute commands
- Break condition: Accuracy falls below acceptable thresholds due to LLM limitations or insufficient action coverage

## Foundational Learning

- Concept: Large Language Models (LLMs) and their application in code generation
  - Why needed here: System relies on LLMs to translate natural language into executable Python code for behavior branches
  - Quick check question: How can LLMs be fine-tuned or prompted to generate code for specific tasks, and what are the limitations?

- Concept: Behavior Trees and their extension to Behavior Branches
  - Why needed here: Understanding behavior trees is crucial for grasping how behavior branches extend them for real-time command integration
  - Quick check question: How do behavior trees differ from finite state machines, and what are the advantages in game AI?

- Concept: TCP sockets and inter-process communication
  - Why needed here: System uses TCP sockets to establish communication between Python-based LLM processing and Unity game environment
  - Quick check question: Can you describe setting up a TCP socket connection between two applications and potential challenges?

## Architecture Onboarding

- Component map:
  User Interface -> LLM Service -> Behavior Branch Generator -> Game Environment -> Communication Layer -> Unity Environment

- Critical path:
  1. User inputs natural language command
  2. Command sent to LLM service
  3. LLM generates Python code for behavior branch
  4. Behavior branch constructed and integrated into agent's current behavior
  5. Game agent executes updated behavior branch
  6. Results observed and feedback provided

- Design tradeoffs:
  - Latency vs. Responsiveness: Longer LLM processing increases latency, affecting real-time responsiveness
  - LLM Model Size vs. Accuracy: Larger models may provide more accurate code generation but increase processing time
  - Predefined Actions vs. Flexibility: Limited action set simplifies system but may restrict executable commands

- Failure signatures:
  - High latency leading to unresponsive gameplay
  - Incorrect or nonsensical agent behavior from flawed branch construction
  - System errors when LLM generates invalid Python code
  - Low accuracy indicating LLM understanding or integration issues

- First 3 experiments:
  1. Test LLM's ability to generate valid Python code for predefined natural language commands
  2. Validate behavior branch construction by manually inspecting generated branches for correctness
  3. Measure system latency from command input to agent action execution and identify bottlenecks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can latency be reduced to meet the Doherty Threshold of under 0.4 seconds?
- Basis in paper: [explicit] Current 2.0-second latency substantially exceeds desired 0.4-second threshold
- Why unresolved: Paper suggests speeding up LLM inference but provides no specific methods
- What evidence would resolve it: Working prototype with latency below 0.4 seconds and optimization details

### Open Question 2
- Question: What is the optimal method for creating effective code prompts for LLM-based behavior branch generation?
- Basis in paper: [explicit] Current prompt design may not be most effective; calls for clarifying best practices
- Why unresolved: No empirical comparisons of different prompt designs provided
- What evidence would resolve it: Comparative studies showing performance of various prompt designs

### Open Question 3
- Question: How can the system handle commands requiring perception of previous actions?
- Basis in paper: [explicit] Failure case where system couldn't execute "The same action" due to lack of perception
- Why unresolved: No solutions proposed for integrating memory or perception mechanisms
- What evidence would resolve it: System implementation that can track and reference previous actions

## Limitations

- Current 2.0-second latency substantially exceeds the 0.4-second Doherty Threshold for optimal user experience
- Evaluation conducted in simplified Pokémon-like environment with only three attack types, raising scalability questions
- Behavior branch connection rules lack detailed specification for handling complex edge cases and sequential commands

## Confidence

**High Confidence**: Core LLM code generation mechanism is technically sound with 86.11% empirical success rate
**Medium Confidence**: Behavior branch architecture is theoretically valid but implementation details remain underspecified
**Low Confidence**: System's ability to handle diverse, complex commands beyond tested set is uncertain due to limited evaluation scope

## Next Checks

1. **Latency Decomposition Analysis**: Measure timing for each pipeline component (LLM processing, code generation, branch construction, TCP communication, Unity execution) to identify specific bottlenecks

2. **Behavior Branch Edge Case Testing**: Systematically test connection rules with complex command sequences, focusing on "then" control nodes and priority-based replacement

3. **Scalability Evaluation**: Extend evaluation to more complex game environment with 10-15 distinct actions to measure accuracy and latency scaling