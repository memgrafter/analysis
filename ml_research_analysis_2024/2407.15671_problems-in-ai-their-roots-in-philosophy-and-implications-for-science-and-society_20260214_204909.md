---
ver: rpa2
title: Problems in AI, their roots in philosophy, and implications for science and
  society
arxiv_id: '2407.15671'
source_url: https://arxiv.org/abs/2407.15671
tags:
- popper
- knowledge
- deutsch
- these
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that current AI technologies operate based on
  mistaken philosophies of knowledge, particularly inductivism and Bayesianism, which
  have significant implications for their use in science and society. The authors
  draw on the ideas of Karl Popper and David Deutsch to show that these philosophies
  fail to capture how humans generate new explanations and knowledge.
---

# Problems in AI, their roots in philosophy, and implications for science and society

## Quick Facts
- arXiv ID: 2407.15671
- Source URL: https://arxiv.org/abs/2407.15671
- Authors: Max Velthoven; Eric Marcus
- Reference count: 0
- This paper argues that current AI technologies operate based on mistaken philosophies of knowledge, particularly inductivism and Bayesianism, which have significant implications for their use in science and society.

## Executive Summary
This paper examines how current AI technologies are built on flawed philosophical foundations, specifically inductivism and Bayesianism, which fail to capture how humans generate new explanations and knowledge. Drawing on the ideas of Karl Popper and David Deutsch, the authors argue that AI systems, while useful as tools, cannot by themselves formulate new scientific theories or explanations. The paper emphasizes the critical need for human oversight and responsibility in AI applications, especially in sensitive areas like public governance and taxation, to prevent issues such as discrimination and lack of accountability. Additionally, the authors provide a realistic outlook on Artificial General Intelligence (AGI), asserting that current AI developments are moving away from achieving AGI, which would require a fundamental breakthrough in understanding how humans create explanations.

## Method Summary
The paper employs a philosophical analysis approach, drawing primarily on the epistemological frameworks of Karl Popper and David Deutsch to critique current AI methodologies. The authors examine the philosophical underpinnings of AI systems, particularly focusing on how inductivism and Bayesianism shape AI development and capabilities. Through theoretical argumentation rather than empirical studies, the paper explores the limitations of AI in scientific reasoning and knowledge creation, contrasting these with human cognitive processes. The analysis extends to practical implications for AI use in governance and societal applications, emphasizing the philosophical basis for requiring human oversight in critical decision-making contexts.

## Key Results
- Current AI technologies are built on flawed philosophical foundations (inductivism and Bayesianism) that fail to capture human knowledge generation
- AI systems cannot formulate new scientific theories or explanations independently, requiring human oversight in critical applications
- Current AI development trends are moving away from achieving Artificial General Intelligence (AGI)

## Why This Works (Mechanism)
The paper's argument works by exposing the fundamental mismatch between how current AI systems operate (based on pattern recognition and statistical inference) and how human knowledge is actually created (through creative conjecture and criticism). By drawing on Popper's falsificationism and Deutsch's explanations-based epistemology, the authors demonstrate that AI's reliance on inductivism and Bayesian updating cannot capture the creative, explanatory aspects of human intelligence. This philosophical foundation explains why AI excels at pattern recognition but struggles with genuine scientific reasoning and theory formation. The mechanism also clarifies why human oversight remains essential - AI lacks the capacity for creative explanation that is fundamental to scientific progress and responsible decision-making in complex societal contexts.

## Foundational Learning

1. **Inductivism**
   - Why needed: Understanding this philosophical approach to knowledge formation is crucial as it forms the basis of how current AI systems learn from data
   - Quick check: Can you explain why the problem of induction (Hume's argument) poses challenges for AI learning systems?

2. **Bayesianism**
   - Why needed: Essential for understanding how AI systems update beliefs based on evidence and make probabilistic inferences
   - Quick check: How does Bayesian updating differ from the way humans form new explanations according to Popper and Deutsch?

3. **Falsificationism**
   - Why needed: Key to understanding Popper's alternative to inductivism and why scientific theories require creative conjecture
   - Quick check: Can you distinguish between confirmation and falsification in scientific methodology?

4. **Explanatory Knowledge**
   - Why needed: Central to Deutsch's argument about what distinguishes human intelligence from AI pattern recognition
   - Quick check: What makes an explanation different from a mere prediction or correlation?

## Architecture Onboarding

**Component Map:**
Human Knowledge Creation -> AI System Capabilities -> Application Domain Requirements -> Oversight Mechanisms

**Critical Path:**
The critical path involves understanding the philosophical foundations (Popper/Deutsch) -> identifying AI limitations -> recognizing the need for human oversight -> implementing appropriate governance frameworks.

**Design Tradeoffs:**
- Automation vs. human control in decision-making
- Efficiency vs. accountability in AI applications
- Pattern recognition capabilities vs. explanatory power

**Failure Signatures:**
- Over-reliance on AI predictions without human verification
- Application of AI in domains requiring creative explanation
- Lack of accountability mechanisms in AI-driven governance

**First Experiments:**
1. Compare AI-generated scientific explanations with human-generated ones in a controlled setting
2. Test AI performance in creative problem-solving tasks requiring novel explanations
3. Evaluate the effectiveness of human oversight in preventing AI-related governance failures

## Open Questions the Paper Calls Out
None

## Limitations
- The paper relies heavily on philosophical arguments from Popper and Deutsch, which may not be universally accepted in AI research communities
- The critique of inductivism and Bayesianism as foundational AI philosophies is philosophically contested and lacks empirical validation
- The assessment of current AI capabilities and limitations is based on theoretical arguments rather than systematic empirical studies

## Confidence
- High: Current AI systems require human oversight in critical applications (supported by documented AI failures)
- Medium: Philosophical critique of inductivism and Bayesianism in AI (ongoing epistemological debates)
- Low: Current AI development is moving away from AGI (speculative claim about future research directions)

## Next Checks
1. Conduct systematic empirical studies comparing AI-generated scientific explanations with human-generated ones to assess the validity of the claim that AI cannot formulate new theories
2. Survey AI researchers and practitioners to gauge acceptance of the philosophical critiques presented and identify alternative perspectives
3. Analyze recent AI research publications to empirically assess whether current AI development trends align with or contradict the paper's assessment of AGI progress