---
ver: rpa2
title: Teams of LLM Agents can Exploit Zero-Day Vulnerabilities
arxiv_id: '2406.01637'
source_url: https://arxiv.org/abs/2406.01637
tags:
- agents
- agent
- vulnerabilities
- work
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work shows that teams of LLM agents can autonomously exploit
  real-world zero-day vulnerabilities, resolving an open question in prior work. The
  core method idea is a multi-agent framework called HPTSA, which uses hierarchical
  planning and task-specific expert agents (e.g., XSS, SQLi, CSRF) to explore websites
  and determine which vulnerabilities to target.
---

# Teams of LLM Agents can Exploit Zero-Day Vulnerabilities

## Quick Facts
- arXiv ID: 2406.01637
- Source URL: https://arxiv.org/abs/2406.01637
- Reference count: 10
- Primary result: HPTSA achieves 42% pass rate at 5 attempts on 14 real-world zero-day vulnerabilities

## Executive Summary
This work demonstrates that teams of LLM agents can autonomously exploit real-world zero-day vulnerabilities, resolving a key open question in prior research. The authors introduce HPTSA, a hierarchical multi-agent framework that decomposes complex exploitation tasks into manageable subgoals. HPTSA achieves a 42% pass rate on 14 zero-day vulnerabilities, outperforming prior agent frameworks by up to 4.3× and open-source vulnerability scanners by 100%.

## Method Summary
HPTSA uses hierarchical planning where a planning agent explores websites and delegates to task-specific expert agents (XSS, SQLi, CSRF, etc.) with specialized tools and documents. The system includes HTML simplification to reduce token costs and improve performance. The hierarchical approach resolves long-term planning failures that plague single-agent systems by decomposing tasks and preventing context overload.

## Key Results
- HPTSA achieves 42% pass rate at 5 attempts on 14 real-world zero-day vulnerabilities
- Outperforms prior agent frameworks by up to 4.3× (CLA: 0%, Magika: 10%)
- Task-specific agents outperform generic agents by 2.1× at 1 attempt and 50% at 5 attempts
- Open-source vulnerability scanners achieve 0% success rate on the same benchmark

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical planning with subagent dispatch resolves long-term planning failures in single-agent systems
- Mechanism: A high-level planning agent explores the website, identifies vulnerability types and target pages, then delegates to task-specific expert agents. This decomposes the complex task into manageable subgoals and prevents context overload
- Core assumption: LLMs struggle with long context when simultaneously exploring, planning, and executing attacks. Breaking these into specialized agents reduces cognitive load
- Evidence anchors:
  - [abstract] "Prior agents struggle with exploring many different vulnerabilities and long-range planning when used alone. To resolve this, we introduce HPTSA, a system of agents with a planning agent that can launch subagents."
  - [section 3.1] "Our first component is the hierarchical planner, which explores the environment... After exploring the environment, it determines the set of instructions to send to the team manager."
  - [corpus] Found 25 related papers; average neighbor FMR=0.369 suggests moderate field overlap but no direct evidence of this hierarchical approach
- Break condition: If the planning agent cannot accurately identify vulnerability types or if task-specific agents fail to communicate results back effectively

### Mechanism 2
- Claim: Task-specific expert agents outperform generic agents on targeted vulnerability types
- Mechanism: Each agent is fine-tuned or prompted with documents specific to a vulnerability class (XSS, SQLi, CSRF, etc.), allowing deeper exploitation knowledge than a generic agent
- Core assumption: Specialized knowledge and tooling for each vulnerability class enables more effective attacks than broad, shallow knowledge
- Evidence anchors:
  - [section 3.2] "We designed 6 total expert agents: XSS, SQLi, CSRF, SSTI, ZAP, and a 'generic' web hacking agent. Our AI agents have: 1) access to tools, 2) access to documents, and 3) specific prompts."
  - [section 5.3] "As shown, removing the task-specific agents and removing the documents results in dramatically reduced performance. Removing task-specific agents results in a 2.1× lower pass at 1 and a 50% lower pass at 5."
  - [corpus] No direct evidence of task-specific agent performance comparison in corpus
- Break condition: If the vulnerability type doesn't match any expert agent or if the expert agents' documents are outdated

### Mechanism 3
- Claim: HTML simplification reduces token costs and improves agent performance
- Mechanism: Before passing HTML to agents, unnecessary tags (images, SVGs, styles) are removed, reducing context length and focusing the agent on relevant content
- Core assumption: Large portions of HTML are irrelevant to vulnerability exploitation and only increase context cost without adding value
- Evidence anchors:
  - [section 3.3] "To reduce the token count (directly reducing costs), we observed that the client-side HTML was the vast majority of the tokens. We implemented an HTML simplifying strategy to reduce this cost. Before passing the HTML of the webpage to the agent, we remove unnecessary HTML tags..."
  - [section 7] Cost analysis shows GPT-4 costs $4.39 per run with 18% success rate
  - [corpus] No evidence of HTML simplification techniques in corpus
- Break condition: If important vulnerability indicators are removed during simplification or if the simplification logic fails to exclude relevant content

## Foundational Learning

- Concept: Zero-day vulnerability exploitation
  - Why needed here: The entire system is designed to exploit vulnerabilities unknown to defenders, which is the most challenging and impactful scenario
  - Quick check question: What distinguishes a zero-day vulnerability from a one-day vulnerability in this work?

- Concept: ReAct-style agent architecture
  - Why needed here: The paper contrasts HPTSA's hierarchical approach with traditional ReAct agents that iterate through action-observation cycles
  - Quick check question: How does HPTSA's approach differ from ReAct-style iteration in terms of long-term planning?

- Concept: Context length limitations in LLMs
  - Why needed here: The paper explicitly cites context length as a key reason why single agents fail at complex exploitation tasks
  - Quick check question: What specific challenge does context length create for single-agent cybersecurity exploitation?

## Architecture Onboarding

- Component map: Hierarchical Planner → Team Manager → Task-Specific Agent(s) → Exploitation → Feedback to Team Manager → Planner update
- Critical path: Hierarchical Planner explores website → identifies vulnerability types → Team Manager dispatches appropriate expert agents → agents execute exploitation → results fed back to update planning
- Design tradeoffs:
  - Hierarchical vs. flat architecture: Better planning vs. added coordination complexity
  - Specialized vs. generic agents: Higher performance vs. more components to maintain
  - HTML simplification: Reduced cost vs. risk of removing important information
  - Multiple attempts: Higher success rate vs. increased cost
- Failure signatures:
  - Planner fails to identify correct vulnerability type → No appropriate agent dispatched
  - Agent repeatedly fails without new information → Backtracking issue not resolved
  - High refusal rates from models → Model-level issues or insufficient prompting
  - 0% success rate → Benchmark construction issues or fundamental approach flaws
- First 3 experiments:
  1. Test hierarchical planner alone on a simple website to verify it can identify vulnerability types correctly
  2. Test a single task-specific agent (e.g., XSS) on a known XSS vulnerability to verify expert knowledge
  3. Run the full HPTSA pipeline on a simple vulnerability with known solution to verify end-to-end coordination

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can AI agents be improved to detect and exploit vulnerabilities that require access to specific, undocumented endpoints or hidden routes?
- Basis in paper: [inferred] The paper mentions that HPTSA failed to exploit CVE-2024-25635 and CVE-2024-33247, which required access to specific endpoints not easily discoverable.
- Why unresolved: The current approach relies on exploring visible parts of a website and lacks mechanisms for discovering hidden or undocumented endpoints, which are common in real-world vulnerabilities.
- What evidence would resolve it: Developing and testing agents with enhanced exploration techniques, such as brute-force endpoint discovery or integration with network scanning tools, and measuring their success rate on similar vulnerabilities.

### Open Question 2
- Question: How can the cost of using AI agents for cybersecurity tasks be reduced while maintaining or improving performance?
- Basis in paper: [explicit] The paper discusses the cost of running HPTSA with GPT-4 and anticipates that costs will decrease over time, but does not provide a detailed strategy for cost reduction.
- Why unresolved: The high cost of proprietary models like GPT-4 limits the scalability and accessibility of AI agents in cybersecurity, and the paper does not explore alternative cost-reduction strategies.
- What evidence would resolve it: Experimenting with open-source models, optimizing token usage, or developing hybrid systems that combine cheaper models with human oversight, and comparing the performance and cost of these approaches.

### Open Question 3
- Question: How do AI agents impact the balance between cybersecurity offense and defense, and which side benefits more from their use?
- Basis in paper: [explicit] The paper concludes that the impact of AI agents on cybersecurity offense and defense is unclear and calls for future work to address this question.
- Why unresolved: The paper does not provide empirical data or analysis on how AI agents affect the offensive and defensive capabilities in cybersecurity, nor does it explore the broader societal implications.
- What evidence would resolve it: Conducting studies that measure the effectiveness of AI agents in both offensive and defensive scenarios, analyzing their impact on the overall security landscape, and evaluating the potential risks and benefits for different stakeholders.

## Limitations

- Benchmark Representativeness: The 42% success rate was achieved on 14 curated zero-day vulnerabilities, but the methodology section lacks detail on how these were selected, suggesting potential selection bias toward easier targets.
- Cost-Effectiveness: The cost analysis shows $4.39 per run for GPT-4, with 18% success rate. At 5 attempts (required for 42% pass rate), this represents $22 per successful vulnerability, which may be prohibitive for practical deployment.
- GPT-4 Dependency: The results rely entirely on GPT-4, with no ablation studies comparing against other frontier models or open-source alternatives, raising questions about reproducibility.

## Confidence

- High Confidence: The claim that HPTSA outperforms open-source vulnerability scanners (0% vs 42%) is well-supported by the experimental results, as is the finding that task-specific agents outperform generic agents by 2.1× at 1 attempt.
- Medium Confidence: The 4.3× improvement over prior agent frameworks is based on comparisons to CLA (0% pass rate) and Magika (10% pass rate), but the paper lacks detailed methodology on how these baselines were evaluated under identical conditions.
- Low Confidence: The mechanism claims about HTML simplification improving performance lack direct evidence - the paper only reports cost reduction without showing performance impact, and the HTML preprocessing logic could potentially remove vulnerability indicators.

## Next Checks

1. Replicate with open-source models: Test HPTSA with GPT-3.5, LLaMA-2, or Claude to determine whether the hierarchical approach itself drives improvements independent of frontier model capability.

2. Cross-validation on independent benchmark: Apply HPTSA to an external vulnerability dataset (e.g., Metasploit modules or CVE samples) to verify the 42% success rate generalizes beyond the curated test set.

3. Ablation study on HTML simplification: Run controlled experiments with and without HTML preprocessing on identical vulnerabilities to measure the actual performance impact versus cost savings.