---
ver: rpa2
title: How much is a noisy image worth? Data Scaling Laws for Ambient Diffusion
arxiv_id: '2411.02780'
source_url: https://arxiv.org/abs/2411.02780
tags:
- data
- clean
- noisy
- algorithm
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how the quality of training data impacts the
  performance of diffusion models. The authors show that while models trained solely
  on noisy data perform poorly compared to those trained on clean data, a small fraction
  of clean images (e.g., 10%) combined with a large set of noisy images can match
  the performance of models trained only on clean data.
---

# How much is a noisy image worth? Data Scaling Laws for Ambient Diffusion

## Quick Facts
- arXiv ID: 2411.02780
- Source URL: https://arxiv.org/abs/2411.02780
- Reference count: 40
- Primary result: Small fraction of clean images can compensate for large amounts of noisy data in diffusion model training

## Executive Summary
This paper investigates how training data quality affects diffusion model performance, revealing that noisy images can be effectively utilized when combined with a small fraction of clean data. The authors demonstrate that models trained on 90% noisy and 10% clean data can match the performance of models trained on 100% clean data across multiple datasets including CIFAR-10, CelebA-HQ, and ImageNet. They provide theoretical justification showing that noisy samples are exponentially less useful for fine-grained estimation but still valuable for dimensionality reduction, establishing sample complexity bounds for Gaussian Mixture Models with heterogeneous variances.

## Method Summary
The authors propose a simple yet effective approach for training diffusion models on heterogeneous data quality. Their method involves training a single diffusion model on a mixture of clean and noisy images, where the noise level varies across samples. The model learns to denoise images while adapting to different noise levels during training. This approach leverages the natural capability of diffusion models to handle varying noise levels through their progressive denoising process. The training procedure uses a weighted loss that accounts for the different noise levels present in the data, allowing the model to effectively utilize both clean and noisy samples.

## Key Results
- Models trained on 90% noisy and 10% clean data match performance of models trained on 100% clean data
- Theoretical analysis shows noisy samples are exponentially less useful for fine-grained estimation
- State-of-the-art performance achieved on standard benchmarks with heterogeneous data quality
- Sample complexity bounds established for learning Gaussian Mixture Models with heterogeneous variances

## Why This Works (Mechanism)
The effectiveness of combining clean and noisy data stems from the complementary nature of these samples for diffusion model training. Clean images provide precise signal for learning fine details and high-frequency information, while noisy images contribute to learning robust low-frequency structure and help the model generalize better. The progressive denoising process in diffusion models naturally accommodates varying noise levels, allowing the model to learn a mapping from corrupted to clean data. The theoretical analysis reveals that while noisy samples are exponentially less informative for precise estimation tasks, they still capture essential structural information that aids in dimensionality reduction and overall model robustness.

## Foundational Learning
- **Diffusion Models**: Why needed - Core architecture being studied; Quick check - Understand the denoising process and noise schedule
- **Sample Complexity Theory**: Why needed - Provides theoretical justification for empirical results; Quick check - Verify understanding of Gaussian Mixture Model bounds
- **Data Heterogeneity**: Why needed - Central to the paper's contribution; Quick check - Understand implications of mixed data quality
- **Scaling Laws**: Why needed - Framework for analyzing performance trends; Quick check - Verify ability to interpret scaling behavior
- **Denoising Objective**: Why needed - Fundamental to how diffusion models learn; Quick check - Understand the relationship between noise level and learning signal

## Architecture Onboarding

Component Map: Noisy/Clean Data -> Diffusion Model -> Denoised Output

Critical Path: Data Preprocessing -> Noise Level Assignment -> Diffusion Training -> Sampling

Design Tradeoffs:
- Clean vs noisy data ratio: Balancing performance with data efficiency
- Noise level distribution: Affects model's ability to generalize across corruption levels
- Model capacity: Larger models can better handle heterogeneous data quality
- Training duration: Noisy data may require different convergence characteristics

Failure Signatures:
- Mode collapse when clean data ratio is too low
- Overfitting to noise patterns when noisy data dominates
- Suboptimal sample quality when noise levels are poorly calibrated
- Training instability with extreme noise level variations

First Experiments:
1. Train baseline diffusion model on 100% clean data for comparison
2. Train model on pure noisy data to establish lower bound performance
3. Test intermediate ratios (e.g., 50% clean/50% noisy) to observe scaling behavior

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis relies on simplifying assumptions about Gaussian Mixture Models
- Experimental validation covers limited range of noise types and corruption ratios
- Performance under different corruption mechanisms remains unexplored
- Theoretical justification may not fully capture diffusion model training dynamics

## Confidence
- Small fraction of clean data compensates for large amounts of noisy data (High confidence)
- Noisy samples are exponentially less useful for fine-grained estimation (Medium confidence)
- State-of-the-art performance with proposed approach (High confidence)

## Next Checks
1. Test scaling behavior with alternative noise types beyond additive noise model
2. Extend theoretical analysis to account for diffusion model specific denoising objectives
3. Evaluate approach on more diverse datasets and tasks with higher dimensional content