---
ver: rpa2
title: Leveraging Memory Retrieval to Enhance LLM-based Generative Recommendation
arxiv_id: '2412.17593'
source_url: https://arxiv.org/abs/2412.17593
tags:
- recommendation
- automr
- generative
- long-term
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes AutoMR, a framework to address the limited context
  window problem in LLM-based generative recommendation by incorporating long-term
  user interests through memory retrieval. AutoMR stores long-term user interactions
  in memory and uses a learned retriever to extract relevant information to augment
  the LLM's short-term context.
---

# Leveraging Memory Retrieval to Enhance LLM-based Generative Recommendation

## Quick Facts
- arXiv ID: 2412.17593
- Source URL: https://arxiv.org/abs/2412.17593
- Reference count: 19
- Improves LLM-based generative recommendation by incorporating long-term user interests through memory retrieval

## Executive Summary
This paper introduces AutoMR, a framework that addresses the limited context window problem in LLM-based generative recommendation by incorporating long-term user interests through memory retrieval. The framework stores encoded long-term interactions in memory and uses a learned retriever to extract relevant information to augment the LLM's short-term context. Experiments on Amazon Book and Movie datasets demonstrate that AutoMR outperforms strong baselines including BIGRec, ReLLa, and TRSR, with improvements in Recall@1 and NDCG@5 metrics. The retriever is trained automatically by measuring the reduction in perplexity when memory elements are included.

## Method Summary
AutoMR stores long-term user interactions in memory by encoding them at layer ùêø of a generative LLM and reusing these hidden representations for retrieval. A retriever MLP scores memory elements based on their relevance to short-term context by measuring perplexity reduction when each element is included. The framework fine-tunes the LLM generator on a training set with annotated memory elements, then at inference combines the top-retrieved memory element with short-term context to generate next-item predictions. The approach is evaluated on Amazon Book and Movie datasets using Recall@1, Recall@5, and NDCG@5 metrics.

## Key Results
- AutoMR achieves Recall@1 of 0.0291 on Amazon Book dataset, outperforming BIGRec (0.0281), ReLLa (0.0278), TRSR (0.0270), and SASRec (0.0262)
- AutoMR achieves NDCG@5 of 0.0338 on Amazon Book dataset, outperforming BIGRec (0.0323), ReLLa (0.0319), TRSR (0.0305), and SASRec (0.0299)
- Case studies demonstrate AutoMR can effectively retrieve distant long-term interactions, confirming its ability to model long-term interests

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AutoMR improves recommendation performance by learning to retrieve long-term user interests relevant to the next-item prediction task.
- Mechanism: The framework stores encoded long-term interactions in memory and trains a retriever to extract useful historical information by optimizing a reduction in perplexity (PPL) when memory elements are combined with short-term context.
- Core assumption: A decrease in PPL when incorporating a memory element indicates its relevance to predicting the next item.
- Evidence anchors:
  - [abstract] "The retriever is trained automatically by measuring the reduction in perplexity when memory elements are included."
  - [section 3.2] "we assign a relevance score label for each element in the corresponding memory... based on the change in perplexity when the element is included versus when it is excluded."
  - [corpus] Weak evidence: no direct citations on PPL-based relevance scoring; assumed novel within context.
- Break condition: If PPL reduction does not correlate with actual recommendation quality, the retriever may learn to select irrelevant or noisy information.

### Mechanism 2
- Claim: By storing encoded interactions at layer ùêø of the LLM, AutoMR reduces computational overhead and avoids repeated encoding during retrieval.
- Mechanism: Each long-term interaction is encoded once by the generative LLM and stored as a hidden representation; the retriever uses these pre-encoded representations instead of re-encoding at inference time.
- Core assumption: Encoding once and reusing hidden states preserves information while improving efficiency.
- Evidence anchors:
  - [section 3.1] "we directly store its hidden representations obtained in the ùêø-th layer of the generative LLM recommender."
  - [abstract] No explicit mention of computational savings; inferred from design.
  - [corpus] Weak evidence: no direct citations on layer-ùêø encoding reuse; assumed novel.
- Break condition: If the ùêø-th layer representations lose task-relevant information, the memory contents become ineffective for retrieval.

### Mechanism 3
- Claim: AutoMR overcomes the context window limitation by augmenting the short-term user context with retrieved long-term interactions during generation.
- Mechanism: The final LLM generation step combines the encoded short-term context and the top-retrieved long-term memory element before producing the next-item prediction.
- Core assumption: Adding relevant long-term context to short-term input improves prediction accuracy beyond using short-term context alone.
- Evidence anchors:
  - [abstract] "stores long-term user interactions in memory and uses a learned retriever to extract relevant information to augment the LLM's short-term context."
  - [section 3.1] "we would combine the retrieved result with the local information to produce the final recommendation."
  - [corpus] Weak evidence: no direct citations on context window augmentation; assumed novel.
- Break condition: If retrieved information introduces noise or distraction, it may degrade performance compared to short-term context alone.

## Foundational Learning

- Concept: Perplexity as a relevance metric
  - Why needed here: Used to annotate memory elements with relevance scores for training the retriever.
  - Quick check question: What does a decrease in perplexity when including a memory element signify about its usefulness?
- Concept: Layer-wise encoding in LLMs
  - Why needed here: Understanding why representations from layer ùêø are stored and reused for retrieval.
  - Quick check question: Why might layer ùêø hidden states be a good balance between semantic richness and computational efficiency?
- Concept: Self-attention and transformer masking
  - Why needed here: Relevant for understanding how LLM layers process and encode user interaction histories.
  - Quick check question: How does masking in the transformer influence the representation of sequential user-item interactions?

## Architecture Onboarding

- Component map:
  - Memory store: Pre-encoded user interaction vectors from LLM layer ùêø
  - Retriever: MLP that scores memory elements based on their relevance to short-term context
  - LLM generator: Fine-tuned generative model for next-item prediction, augmented with retrieved context
- Critical path:
  1. Encode and store long-term interactions during training
  2. At inference, encode short-term context
  3. Retriever selects top memory element
  4. Combine context and memory element
  5. Generate next item prediction
- Design tradeoffs:
  - Memory storage vs. re-encoding: Storing pre-encoded vectors saves time but may lose adaptability to fine-tuning
  - Retrieval granularity: Using only the top-1 memory element simplifies computation but may miss complementary signals from other elements
  - Layer selection (ùêø): Earlier layers may retain more detailed interaction features; later layers may be more task-specific
- Failure signatures:
  - Retriever selects irrelevant memory elements ‚Üí PPL reduction does not improve actual recall
  - Memory encoding loses task-relevant features ‚Üí No performance gain over short-term context alone
  - Context augmentation introduces noise ‚Üí Recall and NDCG metrics drop compared to baseline
- First 3 experiments:
  1. Ablation: Compare performance with no memory retrieval vs. AutoMR to confirm long-term context improves results
  2. Random retrieval: Replace learned retriever with random memory element selection to validate learning effectiveness
  3. Layer sensitivity: Test storing representations from different LLM layers (e.g., ùêø=6, ùêø=12) to find optimal encoding depth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of AutoMR scale with increasing memory size and sequence length? Is there an optimal trade-off between retrieval effectiveness and computational cost?
- Basis in paper: [inferred] The paper discusses the importance of long-term history but only uses a fixed maximum sequence length of 100 and a fixed number of recent interactions (10) for short-term features. The experiments do not explore varying memory sizes or sequence lengths.
- Why unresolved: The paper does not investigate the impact of different memory sizes or sequence lengths on AutoMR's performance. It's unclear how well AutoMR would perform with much longer sequences or larger memory banks, and whether there are diminishing returns or computational bottlenecks.
- What evidence would resolve it: Experiments varying the maximum sequence length (e.g., 50, 200, 500) and the number of interactions stored in memory (e.g., 20, 50, 100) on both datasets, measuring performance and computational cost (inference time, memory usage).

### Open Question 2
- Question: How robust is AutoMR to noise and sparsity in user interaction histories? Does it maintain performance when users have very few interactions or highly irregular interaction patterns?
- Basis in paper: [inferred] The datasets are filtered to remove items with fewer than 5 interactions and sequences shorter than 20 behaviors, suggesting some pre-processing for data quality. However, the paper doesn't analyze how AutoMR performs on inherently sparse or noisy data.
- Why unresolved: Real-world recommendation systems often deal with sparse user histories and noisy data. It's unclear if AutoMR's retrieval mechanism can effectively handle these cases or if it degrades significantly when user histories are limited or contain irrelevant interactions.
- What evidence would resolve it: Experiments on datasets with varying levels of sparsity (e.g., by subsampling interactions per user) and injecting noise (e.g., random interactions) to measure performance degradation. Analysis of performance across users with different numbers of interactions.

### Open Question 3
- Question: Can the retriever in AutoMR be generalized across different domains or user segments without requiring extensive retraining? How transferable are the learned retrieval patterns?
- Basis in paper: [explicit] The paper focuses on two specific datasets (Book and Movie) and does not discuss cross-domain generalization or transfer learning for the retriever module.
- Why unresolved: The retriever is trained specifically on annotated data from the target domain. It's unclear whether the learned patterns for identifying relevant long-term interests are domain-specific or if they can be transferred to other recommendation domains (e.g., music, electronics) with minimal adaptation.
- What evidence would resolve it: Experiments transferring the trained retriever from one domain (e.g., Book) to another (e.g., Movie) with minimal fine-tuning, comparing performance to domain-specific training. Analysis of which types of retrieval patterns are domain-specific versus generalizable.

### Open Question 4
- Question: How does AutoMR handle the cold-start problem for new users with no interaction history? Can the memory-retrieval framework be adapted to incorporate content-based or demographic information for initial recommendations?
- Basis in paper: [inferred] The paper focuses on users with established interaction histories (sequences longer than 20 behaviors) and does not address new users with no historical data.
- Why unresolved: The memory-retrieval framework relies on past interactions stored in memory, which new users don't have. It's unclear how AutoMR could provide meaningful recommendations for cold-start users or whether it needs to be combined with other approaches (e.g., content-based filtering, demographic-based recommendations).
- What evidence would resolve it: Experiments on a dataset with new users (e.g., by simulating cold-start scenarios) comparing AutoMR's performance to other cold-start methods. Analysis of how incorporating content or demographic features into the memory framework affects cold-start performance.

## Limitations

- The PPL reduction as a relevance metric lacks strong external validation and may not correlate with true recommendation quality
- The layer-ùêø encoding strategy is assumed optimal without ablation studies showing impact of different layer choices
- Case studies for retrieval effectiveness are limited in scale and lack quantitative metrics for memory retrieval quality

## Confidence

- **High confidence**: Experimental results showing AutoMR outperforms baselines (BIGRec, ReLLa, TRSR, SASRec) on Recall@1 and NDCG@5 metrics
- **Medium confidence**: Theoretical framework for using PPL reduction as relevance metric and memory storage at layer ùêø
- **Low confidence**: Claim that AutoMR effectively models long-term interests based on case studies

## Next Checks

1. **Ablation study on layer selection**: Test AutoMR with memory stored from different LLM layers (e.g., layer 6, 12, 24) to empirically determine if layer ùêø is optimal for preserving task-relevant information while maintaining computational efficiency.

2. **Retrieval quality metrics**: Evaluate the retriever's performance using precision@k or recall@k on the memory retrieval task itself, separate from end-to-end recommendation metrics, to validate that PPL reduction correlates with actual relevance.

3. **Random retriever baseline comparison**: Implement a version of AutoMR where memory elements are selected randomly instead of by learned relevance scores to confirm that the learned retriever provides meaningful improvement over naive selection strategies.