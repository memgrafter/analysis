---
ver: rpa2
title: "$\u03C0$-yalli: un nouveau corpus pour le nahuatl"
arxiv_id: '2412.15821'
source_url: https://arxiv.org/abs/2412.15821
tags:
- pour
- dans
- nahuatl
- nous
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The \u03C0-YALLI project addresses the scarcity of computational\
  \ resources for Nahuatl, a polysynthetic language spoken by around 2 million people.\
  \ The project developed a new corpus of approximately 1.9 million tokens across\
  \ six categories (historical, Wikipedia, poetry, legal, academic, and scientific\
  \ texts) to enable research and development of language models and NLP tools for\
  \ Nahuatl."
---

# $π$-yalli: un nouveau corpus pour le nahuatl

## Quick Facts
- arXiv ID: 2412.15821
- Source URL: https://arxiv.org/abs/2412.15821
- Reference count: 19
- Corpus of ~1.9M tokens across six categories for Nahuatl NLP research

## Executive Summary
The π-YALLI project addresses the scarcity of computational resources for Nahuatl, a polysynthetic language spoken by around 2 million people. The project developed a new corpus of approximately 1.9 million tokens across six categories (historical, Wikipedia, poetry, legal, academic, and scientific texts) to enable research and development of language models and NLP tools for Nahuatl. The corpus includes multiple dialects and orthographic variants. Initial evaluation through semantic similarity tasks involving 27 Nahuatl speakers showed moderate inter-annotator agreement (Kendall's W coefficient averaging 0.389), with significant variation across terms.

## Method Summary
The project constructed a Nahuatl corpus of approximately 1.9 million tokens across six text categories, incorporating multiple dialects and orthographic variants. The corpus was made available through a CQPweb interface for querying. Initial evaluation involved a semantic similarity task where 27 Nahuatl speakers ranked 5 candidate words for each of 23 reference terms based on semantic closeness. The project plans to develop static language models (Word2Vec, FastText) and dynamic models (BERT-type) for various NLP applications including grapheme unification, word segmentation, POS analysis, and text summarization.

## Key Results
- Corpus comprises approximately 1.9 million tokens across six categories with multiple dialects and orthographic variants
- Initial semantic similarity evaluation with 27 Nahuatl speakers showed moderate inter-annotator agreement (Kendall's W averaging 0.389)
- The corpus will enable development of both static (Word2Vec, FastText) and dynamic (BERT-type) language models for Nahuatl NLP tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The corpus enables meaningful semantic similarity evaluation for Nahuatl.
- Mechanism: A task was designed where 27 Nahuatl speakers ranked 5 candidate words for each of 23 reference terms based on semantic closeness. This produced inter-annotator agreement scores (Kendall's W) averaging 0.389, indicating the corpus supports semantic evaluation despite being a low-resource language.
- Core assumption: Native speakers can reliably judge semantic similarity in their language.
- Evidence anchors:
  - [abstract]: "Initial evaluation through semantic similarity tasks involving 27 Nahuatl speakers showed moderate inter-annotator agreement (Kendall's W coefficient averaging 0.389)"
  - [section]: "We have established a semantic similarity protocol to conduct an initial quality evaluation of the π-YALLI corpus. Given 23 reference terms, each with a list of 5 candidate terms, we asked 27 Nahuatl speakers to semantically rank the candidate terms, from closest to farthest from the reference."
- Break condition: If native speakers lack shared semantic intuitions due to dialectal variation or cultural differences in word association, the agreement scores would drop significantly.

### Mechanism 2
- Claim: The corpus enables training of NLP tools for Nahuatl.
- Mechanism: The corpus contains approximately 1.9 million tokens across six categories (historical, Wikipedia, poetry, legal, academic, scientific) with multiple dialects and orthographic variants, providing sufficient linguistic diversity for training static models (Word2Vec, FastText) and dynamic models (BERT-type) for tasks like grapheme unification, word segmentation, POS analysis, and text summarization.
- Core assumption: A corpus of this size and diversity is sufficient for training effective language models for Nahuatl.
- Evidence anchors:
  - [abstract]: "The corpus includes multiple dialects and orthographic variants. Initial evaluation through semantic similarity tasks... The corpus will be made publicly available and used to develop static and dynamic language models (Word2Vec, FastText, BERT-type) and NLP tools including grapheme unification, word segmentation, POS analysis, and text summarization."
  - [section]: "The π-YALLI corpus thus comprises approximately 1.912M tokens or 14.8M characters (14.8 MB of raw text encoded in utf8) with the ISO 639-3 code nah"
- Break condition: If the corpus is too small relative to the morphological complexity of Nahuatl, models may not learn robust representations, especially for agglutinative structures.

### Mechanism 3
- Claim: The corpus supports research on the impact of corpus size on language model learning.
- Mechanism: By providing a baseline corpus and the capability to expand it, researchers can systematically study how increasing corpus size affects the performance of both static and dynamic language models on Nahuatl, measuring intrinsic (semantic representation quality) and extrinsic (downstream task performance) metrics.
- Core assumption: Corpus size has a measurable impact on language model performance that can be isolated and studied.
- Evidence anchors:
  - [abstract]: "Although the π-YALLI corpus is small compared to corpora of other languages and is still under development, we believe it is an interesting resource for studying the Nahuatl language"
  - [section]: "Although the π-YALLI corpus is small compared to corpora of other languages and is still under development, we believe it is an interesting resource for studying the Nahuatl language"
- Break condition: If Nahuatl's polysynthetic nature requires disproportionately large corpora compared to other languages, small corpus experiments may not generalize.

## Foundational Learning

- Concept: Kendall's W coefficient for inter-annotator agreement
  - Why needed here: To quantify how consistently native speakers agree on semantic similarity rankings, providing a measure of corpus quality for semantic tasks
  - Quick check question: If three annotators rank three items as (1,2,3), (2,1,3), and (2,1,3), what is Kendall's W coefficient? (Answer: 0.778)

- Concept: Word embeddings and static vs. dynamic language models
  - Why needed here: To understand how the corpus will be used to train different types of language models (Word2Vec/FastText for static embeddings vs. BERT for contextual embeddings) and their respective strengths for polysynthetic languages
  - Quick check question: What key difference between FastText and Word2Vec makes FastText more suitable for morphologically rich languages like Nahuatl? (Answer: FastText incorporates subword information)

- Concept: Corpus linguistics and token statistics
  - Why needed here: To evaluate whether the corpus size (1.9M tokens) is adequate for the intended NLP applications and to understand how token counts relate to model performance
  - Quick check question: If a corpus has 1.9 million tokens across 6 categories, what is the approximate average number of tokens per category? (Answer: ~317,000 tokens per category)

## Architecture Onboarding

- Component map: Corpus collection → Preprocessing (metadata, cleaning) → Storage (CQPweb interface) → Model training (Word2Vec, FastText, BERT) → Evaluation (semantic similarity, downstream tasks) → Tool development (grapheme unification, word segmentation, POS tagging, summarization)
- Critical path: Corpus construction → Semantic similarity evaluation → Static model training → Dynamic model training → Tool development → Community deployment
- Design tradeoffs: Small corpus size vs. model performance; dialectal variation vs. model generalization; orthographic variants vs. normalization complexity; static vs. dynamic model approaches for polysynthetic morphology
- Failure signatures: Low Kendall's W scores indicating poor semantic consistency; model evaluation metrics showing poor performance on agglutinative structures; downstream tools failing on dialectal variants; corpus query interface returning insufficient results
- First 3 experiments:
  1. Train Word2Vec and FastText models on the corpus, then evaluate semantic similarity performance on the annotated test set using Kendall's tau correlation with human rankings
  2. Implement grapheme unification tool and evaluate on a subset of texts with known orthographic variants, measuring reduction in unique grapheme patterns
  3. Train a POS tagger using the corpus and evaluate on a held-out set of manually annotated sentences, measuring accuracy per morphological category

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal corpus size needed for effective Nahuatl language model training?
- Basis in paper: [explicit] The paper states "Bien que le corpus π-YALLI ait une taille réduite vis-à-vis de corpus d'autres langues" and mentions they will study "l'impact de la taille du corpus dans l'apprentissage –profond ou pas– de Modèles de Langue nahuatl."
- Why unresolved: The current corpus is only 1.9 million tokens, which the authors acknowledge is small compared to other languages, and they plan to study the impact of corpus size but haven't completed this analysis yet.
- What evidence would resolve it: Systematic experiments varying corpus size and measuring downstream task performance to identify the minimum effective size for various Nahuatl NLP applications.

### Open Question 2
- Question: Which language model architecture (Word2Vec, FastText, or BERT-type) performs best for Nahuatl NLP tasks?
- Basis in paper: [explicit] The paper states they will "évaluer ces modèles pour le nahuatl afin de mesurer leur capacité à produire des représentations précises et cohérentes" and mentions they are "encore en cours" with calculating results for Word2Vec, GloVe, and FastText.
- Why unresolved: The evaluation of different model architectures is still in progress, and no comparative results have been reported yet.
- What evidence would resolve it: Completed evaluation metrics (intrinsic and extrinsic) comparing all three architectures across the same Nahuatl tasks with statistical significance testing.

### Open Question 3
- Question: How can we improve inter-annotator agreement for Nahuatl semantic similarity tasks?
- Basis in paper: [explicit] The paper reports "modéré inter-annotateur accord (Kendall's W coefficient averaging 0.389)" and discusses challenges including "différence culturelle entre ce que nous comprenons comme une association sémantique logique" and "interférence sémantique dans des contextes de bilinguisme."
- Why unresolved: The authors acknowledge low agreement and cultural/linguistic factors affecting it, but haven't proposed or tested solutions to improve this.
- What evidence would resolve it: Comparative studies testing different annotation protocols, annotator selection criteria, or training methods to increase agreement scores on the same semantic similarity task.

## Limitations
- Corpus size of 1.9 million tokens is relatively small compared to resources for other languages, potentially limiting model performance
- Moderate inter-annotator agreement (Kendall's W averaging 0.389) suggests challenges in semantic evaluation for Nahuatl
- The impact of corpus size on model learning has not yet been systematically studied for this polysynthetic language

## Confidence
- **High Confidence**: The corpus construction methodology and its planned use for developing NLP tools (grapheme unification, word segmentation, POS analysis, text summarization) is well-specified and technically sound.
- **Medium Confidence**: The semantic similarity evaluation methodology is appropriate, but the moderate agreement scores (0.389) indicate that semantic judgments in Nahuatl may be more variable than in languages with larger evaluation datasets.
- **Low Confidence**: The projected performance of language models trained on this corpus for downstream tasks, given the relatively small size and the challenges of polysynthetic morphology, cannot be confidently predicted without empirical validation.

## Next Checks
1. **Corpus Adequacy Analysis**: Conduct a detailed analysis of token distribution across the six categories and compare coverage against Nahuatl's morphological inventory to determine if 1.9 million tokens provides sufficient statistical power for learning agglutinative patterns.

2. **Semantic Evaluation Expansion**: Replicate the semantic similarity task with additional Nahuatl speakers and a broader set of reference terms to determine whether the moderate Kendall's W scores (0.389) represent systematic uncertainty or can be improved through protocol refinement.

3. **Model Performance Benchmarking**: Train and evaluate Word2Vec and FastText models on a subset of the corpus, then systematically measure performance degradation as corpus size decreases to identify the minimum viable corpus size for reasonable Nahuatl language modeling.