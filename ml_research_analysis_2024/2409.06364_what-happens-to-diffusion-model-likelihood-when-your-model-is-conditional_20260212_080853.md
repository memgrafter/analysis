---
ver: rpa2
title: What happens to diffusion model likelihood when your model is conditional?
arxiv_id: '2409.06364'
source_url: https://arxiv.org/abs/2409.06364
tags:
- likelihood
- diffusion
- conditional
- grad-tts
- likelihoods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the properties of exact likelihood computation
  in diffusion models (DMs) when applied to conditional tasks like Text-to-Speech
  (TTS) and Text-to-Image (TTI) synthesis. The authors find that despite DMs being
  trained to maximize likelihood, the conditional likelihood does not always reflect
  the expected properties of input compatibility.
---

# What happens to diffusion model likelihood when your model is conditional?
## Quick Facts
- arXiv ID: 2409.06364
- Source URL: https://arxiv.org/abs/2409.06364
- Reference count: 29
- This paper investigates conditional likelihood properties in diffusion models for TTS and TTI, finding mismatches between likelihood values and expected input-output compatibility

## Executive Summary
This paper explores the behavior of exact likelihood computation in conditional diffusion models through empirical studies on Text-to-Speech (TTS) and Text-to-Image (TTI) tasks. The authors discover that despite diffusion models being trained to maximize likelihood, the conditional likelihoods do not always reflect intuitive expectations about input compatibility and output quality. In TTS applications, likelihoods show sensitivity to speaker characteristics and audio quality but fail to capture linguistic intelligibility, while in TTI tasks, likelihoods correlate with image quality and prompt compatibility but struggle with complex compositional relationships.

The findings reveal a fundamental gap in understanding how conditional likelihoods function in practice, challenging the assumption that higher likelihood values necessarily indicate better semantic alignment or perceptual quality. The study demonstrates that diffusion models can generate outputs with high likelihood scores while failing at basic intelligibility or compositional reasoning tasks, highlighting the need for more nuanced evaluation metrics and deeper theoretical understanding of conditional likelihood behavior in generative models.

## Method Summary
The authors conducted empirical investigations using two conditional diffusion model architectures: Grad-TTS for Text-to-Speech synthesis and SDXL for Text-to-Image generation. They computed exact likelihoods for various test conditions, systematically varying input characteristics such as speaker identity, audio quality, linguistic complexity, image compositionality, and prompt compatibility. The study involved both quantitative likelihood measurements and qualitative assessments of output quality across different dimensions, allowing for comparison between likelihood values and perceptual properties.

## Key Results
- TTS likelihoods are sensitive to speaker characteristics and audio quality but not to linguistic intelligibility
- TTI likelihoods improve with image quality and prompt compatibility but fail on compositionally complex prompts
- Diffusion models can achieve high likelihood scores while producing outputs that fail basic quality or compatibility tests

## Why This Works (Mechanism)
The conditional likelihood computation in diffusion models relies on the training objective of maximizing the probability of generating correct outputs given specific inputs. However, the mechanism by which likelihoods capture semantic relationships between inputs and outputs appears to be incomplete or misaligned with human perceptual judgments. The training process optimizes for statistical regularities in the training data rather than ensuring that likelihood values directly correspond to meaningful quality or compatibility measures.

## Foundational Learning
- **Diffusion process fundamentals**: Understanding the forward noising and reverse denoising processes is essential for grasping how likelihoods are computed at each timestep. Quick check: Verify you understand how the score function guides the generation process.
- **Conditional modeling**: The framework for conditioning diffusion models on external inputs (text, audio, etc.) determines how likelihoods capture input-output relationships. Quick check: Explain how conditioning information is incorporated into the denoising process.
- **Score matching**: The training objective for diffusion models involves matching gradients of log-density, which differs from direct likelihood maximization. Quick check: Compare score matching to maximum likelihood estimation.
- **Log-likelihood computation**: Exact likelihood calculation in diffusion models requires sophisticated techniques like denoising score matching, making the relationship between training and evaluation non-trivial. Quick check: Outline the steps needed to compute exact likelihood from a trained diffusion model.
- **Perceptual quality vs statistical likelihood**: The gap between human perceptual judgments and statistical likelihood measures represents a fundamental challenge in evaluating generative models. Quick check: Identify scenarios where high likelihood might not indicate high perceptual quality.

## Architecture Onboarding
Component map: Text/Prompt -> Conditioning Layer -> Diffusion UNet -> Noised Latent -> Dequantization -> Output Image/Speech
Critical path: Input conditioning → Score function estimation → Denoising iterations → Output generation
Design tradeoffs: The choice between approximate and exact likelihood computation involves computational cost versus evaluation precision
Failure signatures: High likelihood values paired with perceptual quality failures indicate mismatch between statistical optimization and semantic alignment
First experiments:
1. Compare likelihoods across varying levels of input conditioning complexity
2. Measure correlation between likelihood values and human perceptual ratings
3. Test likelihood sensitivity to adversarial perturbations in conditioning inputs

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis limited to specific model architectures (Grad-TTS and SDXL) without broader generalizability testing
- Experimental scope focused on single-modality outputs without cross-modal consistency checks
- Study does not investigate impact of training data distribution shifts on likelihood reliability

## Confidence
High confidence in observed likelihood-quality mismatches for basic TTS and TTI applications
Medium confidence in generalizability across different diffusion model architectures
Low confidence for edge cases involving extreme linguistic complexity or highly abstract compositional prompts

## Next Checks
1. Conduct ablation studies across multiple diffusion model architectures and training regimes to assess whether likelihood-compatibility mismatches persist universally
2. Implement human evaluation studies correlating likelihood scores with perceptual quality metrics across multiple linguistic and compositional complexity levels
3. Design controlled experiments testing conditional likelihoods under systematic domain shifts to determine whether likelihood values remain meaningful under distribution mismatch conditions