---
ver: rpa2
title: Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource
  Languages
arxiv_id: '2401.13165'
source_url: https://arxiv.org/abs/2401.13165
tags:
- languages
- https
- bengali
- such
- gender
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper examines gender-related errors in machine translation
  (MT) for low-resource languages, focusing on Bengali. It argues that MT systems
  often assume binary gender when translating between Bengali and English, leading
  to representational harms such as stereotyping and under-representation.
---

# Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages

## Quick Facts
- arXiv ID: 2401.13165
- Source URL: https://arxiv.org/abs/2401.13165
- Reference count: 0
- Primary result: Machine translation systems often assume binary gender when translating between Bengali and English, leading to representational harms including stereotyping and under-representation

## Executive Summary
This paper examines gender-related errors in machine translation (MT) systems when working with low-resource languages, focusing on Bengali as a case study. The authors demonstrate that MT systems frequently make assumptions about gender that are not present in source texts, resulting in representational harms. Through analysis of 100 translation examples (50 Bengali→English and 50 English→Bengali), they identify instances where systems assume binary gender when no such information is provided, leading to stereotyping and under-representation of non-binary identities. The paper argues that these errors are particularly problematic for low-resource languages and proposes solutions including mindful data collection, engaging local communities, and supporting interdisciplinary research to address these issues and promote linguistic equity.

## Method Summary
The paper presents a qualitative analysis of gender-related translation errors by examining Bengali text translated to/from English using GPT-3 and other MT systems. The methodology involves analyzing 50 Bengali sentences with occupations and 50 English sentences with occupations to identify instances where MT systems assume binary gender when no such information is provided in source texts. While the paper discusses the problem and suggests solutions, it does not provide a specific method or training procedure for reproduction, making it challenging to replicate the exact setup. The analysis focuses on identifying representational harms such as stereotyping and under-representation that arise from these gender-related translation errors.

## Key Results
- MT systems frequently assume binary gender when translating between Bengali and English, even when source texts do not specify gender
- Analysis of 100 translation examples revealed consistent patterns of representational harms including stereotyping and under-representation
- These gender-related errors are particularly problematic for low-resource languages and can contribute to the flattening of non-binary identities into binary defaults

## Why This Works (Mechanism)
The paper demonstrates that machine translation systems, when trained on predominantly binary-gendered data, tend to default to binary gender assumptions when encountering ambiguous or ungendered source text. This occurs because the systems learn statistical patterns from training data where gender information is often explicitly provided or strongly correlated with certain words and contexts. When translating between languages with different gender systems (such as Bengali and English), these learned patterns can lead to inappropriate gender assumptions that perpetuate representational harms.

## Foundational Learning
- Gender Systems in Language (why needed: Understanding how different languages encode gender is crucial for identifying translation errors)
  * Quick check: Compare gender encoding in Bengali (natural gender) vs. English (grammatical gender)

- Representational Harms in AI (why needed: Recognizing how AI systems can perpetuate harmful stereotypes through seemingly neutral translations)
  * Quick check: Identify specific examples of stereotyping in translation outputs

- Low-Resource Language Challenges (why needed: Understanding the unique difficulties in developing MT systems for languages with limited training data)
  * Quick check: Assess availability of parallel corpora for Bengali-English translation

## Architecture Onboarding
Component map: Input text -> MT system (e.g., GPT-3) -> Translation output -> Gender assumption analysis

Critical path: The translation process from source to target language, where gender information may be lost, assumed, or incorrectly added

Design tradeoffs: Balancing translation accuracy with gender sensitivity, considering the limitations of training data and model architecture

Failure signatures: Systematic gender assumptions in translations where no gender information exists in source text, particularly affecting non-binary and gender-diverse representations

First experiments:
1. Test translation of explicitly ungendered sentences across multiple low-resource languages
2. Compare gender assumptions across different MT systems (rule-based, statistical, neural)
3. Analyze translation patterns for occupations and roles with varying gender associations

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What specific technical modifications to machine translation systems would most effectively reduce gender-related errors when translating between languages with different gender systems?
- Basis in paper: The paper discusses gender errors in MT but does not provide specific technical solutions beyond general recommendations
- Why unresolved: While the paper identifies the problem and suggests solutions like better data collection and community engagement, it does not delve into specific algorithmic or architectural changes that could address the gender bias issues
- What evidence would resolve it: Empirical studies comparing different technical approaches (e.g., gender-aware embeddings, context-aware translation models) in reducing gender-related errors across multiple language pairs

### Open Question 2
- Question: How do gender-related translation errors impact the linguistic preservation efforts of endangered languages compared to widely spoken low-resource languages like Bengali?
- Basis in paper: The paper mentions that Indigenous languages are continually facing erasure and extinction, and suggests that different strategies are needed for different types of low-resource languages
- Why unresolved: The paper discusses the general impact of gender errors on low-resource languages but does not specifically address how these errors affect endangered languages versus more widely spoken ones
- What evidence would resolve it: Comparative studies on the effects of gender-related translation errors on endangered languages versus more widely spoken low-resource languages, including quantitative measures of linguistic preservation

### Open Question 3
- Question: What are the long-term societal impacts of persistent gender-related errors in machine translation on non-binary and gender-diverse communities?
- Basis in paper: The paper discusses representational harms caused by gender errors, including the flattening of non-binary identities into binary defaults
- Why unresolved: While the paper identifies the potential for harm, it does not explore the long-term consequences of these errors on gender-diverse communities or provide empirical evidence of such impacts
- What evidence would resolve it: Longitudinal studies on the experiences of non-binary and gender-diverse individuals using machine translation services, including qualitative interviews and quantitative measures of linguistic representation over time

## Limitations
- The paper lacks quantitative metrics for evaluating the severity and frequency of gender-related errors
- The findings are based on analysis of Bengali-English translations and may not generalize to other low-resource language pairs
- The solutions proposed are conceptual and lack specific implementation guidelines or evaluation criteria

## Confidence
- High confidence in the identification of gender-related translation errors as a significant issue
- Medium confidence in the generalizability of findings to other low-resource languages
- Medium confidence in the proposed solutions, pending implementation studies

## Next Checks
1. Replicate the analysis with a larger sample size (200+ examples) across multiple low-resource languages to assess generalizability
2. Implement and evaluate specific interventions for mindful data collection and community engagement
3. Compare translation accuracy and gender-related error rates across different MT systems (including rule-based and statistical approaches)