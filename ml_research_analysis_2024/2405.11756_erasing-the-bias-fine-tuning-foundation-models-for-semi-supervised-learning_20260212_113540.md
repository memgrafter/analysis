---
ver: rpa2
title: 'Erasing the Bias: Fine-Tuning Foundation Models for Semi-Supervised Learning'
arxiv_id: '2405.11756'
source_url: https://arxiv.org/abs/2405.11756
tags:
- learning
- uni00000013
- performance
- uni00000048
- uni00000046
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FineSSL, a method for improving semi-supervised
  learning (SSL) by fine-tuning pre-trained foundation models. It addresses the issues
  of aggregated biases and cognitive deviation in foundation models, which hinder
  the generation and selection of reliable pseudo-labels.
---

# Erasing the Bias: Fine-Tuning Foundation Models for Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2405.11756
- Source URL: https://arxiv.org/abs/2405.11756
- Authors: Kai Gan; Tong Wei
- Reference count: 36
- The paper proposes FineSSL, achieving state-of-the-art performance on multiple SSL benchmarks while reducing training cost by over six times compared to training from scratch.

## Executive Summary
This paper addresses the challenge of fine-tuning pre-trained foundation models for semi-supervised learning by tackling two key problems: aggregated biases and cognitive deviation. The authors propose FineSSL, which combines balanced margin softmax, decoupled label smoothing, and sample reweighting to improve pseudo-label generation and selection. Through extensive experiments on vision benchmarks, FineSSL demonstrates superior performance compared to existing SSL methods while significantly reducing computational costs through parameter-efficient fine-tuning.

## Method Summary
FineSSL is a semi-supervised learning framework that fine-tunes pre-trained foundation models by addressing inherent biases and cognitive deviation. The method uses visual prompt tuning (VPT) to update only a small set of parameters in the frozen CLIP model, while incorporating three key innovations: balanced margin softmax to reduce class imbalance in pseudo-labels, decoupled label smoothing to regularize confidence without damaging representations, and sample reweighting to better utilize all unlabeled data. These components work together to generate more reliable pseudo-labels and improve overall SSL performance.

## Key Results
- Achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and FOOD-101 SSL benchmarks
- Reduces training cost by over six times compared to training from scratch
- Outperforms existing methods like FlexMatch and FixMatch across all labeled data regimes (N1, N4, N25, N100)

## Why This Works (Mechanism)

### Mechanism 1
The balanced margin softmax dynamically adjusts class margins based on learning pace, where classes with slower learning paces (fewer confident pseudo-labels) receive larger margins. This forces the model to pay more attention to underrepresented classes during training. The core assumption is that pseudo-label count above a threshold reliably indicates class difficulty. If the threshold is poorly chosen or learning pace doesn't correlate with actual class difficulty, margin adjustments could worsen performance.

### Mechanism 2
Decoupled label smoothing addresses cognitive deviation by training an auxiliary classifier with label smoothing while being detached from the main branch. This creates discriminative weights between correct and incorrect pseudo-labels without harming representation learning in the main branch. The assumption is that label smoothing applied to the auxiliary classifier can effectively regularize confidence. If the auxiliary classifier becomes too powerful or detachment prevents useful gradient signals, regularization could be insufficient.

### Mechanism 3
Sample reweighting uses auxiliary classifier confidence scores to weight unlabeled samples by their maximum probability output. This enables low-confidence samples to contribute to training with appropriate weights rather than being discarded entirely. The assumption is that the auxiliary classifier can generate discriminative probabilities reflecting pseudo-label quality. If confidence scores are poorly calibrated or the weighting parameter is poorly chosen, reweighting could amplify noise.

## Foundational Learning

- Concept: Semi-supervised learning fundamentals (combining labeled and unlabeled data)
  - Why needed here: The paper builds upon SSL frameworks like FixMatch and FlexMatch, so understanding how pseudo-labeling and consistency regularization work is essential
  - Quick check question: What are the two main components of modern SSL loss functions, and how do they differ in their treatment of labeled vs unlabeled data?

- Concept: Foundation model fine-tuning strategies (FFT, LP, PEFT)
  - Why needed here: The paper compares VPT against full fine-tuning and linear probing, showing why parameter-efficient methods work better for SSL tasks
  - Quick check question: How does VPT differ from full fine-tuning in terms of which parameters are updated during training?

- Concept: Label smoothing and its variants
  - Why needed here: The decoupled label smoothing is a key innovation, so understanding standard label smoothing and its limitations is crucial
  - Quick check question: What is the primary purpose of label smoothing in training, and why might applying it directly to representation learning be problematic?

## Architecture Onboarding

- Component map: Pre-trained CLIP vision encoder (frozen) -> VPT modules (learnable prompts at each layer) -> Main branch classifier with balanced margin softmax -> Auxiliary classifier (detached linear layer) -> Sample weighting module using auxiliary classifier outputs -> Standard SSL components (weak/strong augmentations, consistency regularization)

- Critical path: 1. Forward pass through main branch with balanced margin softmax 2. Forward pass through auxiliary classifier with label smoothing 3. Compute sample weights from auxiliary classifier 4. Weighted consistency regularization for main branch 5. Update parameters (only VPT modules and classifier)

- Design tradeoffs: Using VPT vs full fine-tuning offers better efficiency but potentially less flexibility; detached auxiliary classifier prevents representation damage but may reduce signal flow; dynamic margins are more adaptive but require additional computation

- Failure signatures: Poor performance on minority classes likely indicates margin calculation issues; overconfidence in incorrect predictions suggests label smoothing parameters need adjustment; training instability may indicate improper weight scaling or learning rate issues

- First 3 experiments: 1. Compare balanced margin softmax vs standard cross-entropy on a simple SSL task to verify bias reduction 2. Test auxiliary classifier with and without detachment to confirm representation preservation 3. Evaluate sample reweighting with different γ values to find optimal weighting strategy

## Open Questions the Paper Calls Out

### Open Question 1
How does FINE SSL perform on pre-trained models other than CLIP, such as SimCLR or MOCO?
The paper mentions that future work will investigate the impact of alternative pre-training methods, including SimCLR and MOCO, on performance. This remains unresolved as the paper primarily focuses on the pre-trained CLIP model and does not provide experimental results for other pre-training methods. Conducting experiments using FINE SSL with pre-trained models like SimCLR or MOCO and comparing their performance with the CLIP-based results would resolve this question.

### Open Question 2
What is the impact of incorporating the text encoder in CLIP on the performance of FINE SSL?
The paper acknowledges that the current approach only utilizes the image encoder in CLIP and suggests that exploring the inclusion of the text encoder could potentially augment the model's performance. This remains unresolved as the paper does not include experiments or results that demonstrate the impact of using the text encoder in FINE SSL. Implementing FINE SSL with both the image and text encoders of CLIP and evaluating the performance compared to the image encoder-only approach would resolve this question.

### Open Question 3
How does FINE SSL handle pre-trained models with significantly different feature distributions compared to the downstream SSL task?
The paper discusses the importance of addressing aggregated biases and cognitive deviation in foundation models, which can arise due to differences in pre-training and downstream task data distributions. This remains unresolved as the paper does not provide specific experimental results or analysis on the performance of FINE SSL when dealing with pre-trained models that have substantially different feature distributions from the SSL task. Conducting experiments using FINE SSL with pre-trained models that have significantly different feature distributions from the SSL task and analyzing the performance and any potential challenges encountered would resolve this question.

## Limitations
- Evaluation is restricted to vision tasks using CLIP as the foundation model, leaving open questions about performance on language or multimodal models
- Hyperparameter sensitivity, particularly around γ (reweighting strength) and α (margin scale), is not thoroughly explored
- The claim of "erasing" bias is somewhat overstated - the method appears to mitigate rather than eliminate aggregated biases

## Confidence

**High Confidence**: The effectiveness of decoupled label smoothing in preserving representation quality while regularizing confidence

**Medium Confidence**: The balanced margin softmax's ability to reduce class imbalance in pseudo-labels across diverse datasets

**Medium Confidence**: The six-fold training cost reduction claim, as this depends heavily on implementation details and hardware

## Next Checks

1. **Ablation Study**: Remove the balanced margin softmax component and measure the increase in pseudo-label imbalance to directly validate Mechanism 1's contribution

2. **Cross-Domain Evaluation**: Apply FineSSL to a non-CIFAR/FOOD dataset (e.g., medical imaging) to test generalizability beyond standard benchmarks

3. **Foundation Model Transfer**: Test whether improvements generalize to other pre-trained models like ViT or ResNet-50 trained from scratch to isolate CLIP-specific effects