---
ver: rpa2
title: 'CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation'
arxiv_id: '2408.14572'
source_url: https://arxiv.org/abs/2408.14572
tags:
- curlora
- matrix
- ne-tuning
- lora
- catastrophic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CURLoRA addresses catastrophic forgetting in LLM fine-tuning by
  applying CUR matrix decomposition to LoRA. It modifies CUR by using inverted probabilities
  for column/row selection and initializing the U matrix as zeros, which acts as implicit
  regularization.
---

# CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation

## Quick Facts
- arXiv ID: 2408.14572
- Source URL: https://arxiv.org/abs/2408.14572
- Authors: Muhammad Fawi
- Reference count: 23
- Primary result: CURLoRA mitigates catastrophic forgetting in LLM fine-tuning through CUR decomposition with inverted probabilities

## Executive Summary
CURLoRA addresses catastrophic forgetting in large language model fine-tuning by applying CUR matrix decomposition to LoRA. The key innovation involves using inverted probabilities for column/row selection and initializing the U matrix as zeros, which acts as implicit regularization. This approach constrains parameter space, limits adaptation magnitude, and preserves original model knowledge. Experiments on GPT-2 and Mistral 7B demonstrate CURLoRA outperforms standard LoRA in mitigating forgetting across tasks while maintaining base model perplexity, with significantly fewer trainable parameters.

## Method Summary
CURLoRA builds on LoRA by replacing the low-rank decomposition with CUR decomposition where C and R matrices are selected using inverted probabilities from the original weight matrix's leverage scores. The U matrix is initialized to zero and fine-tuned while C, R, and original weights remain frozen. This creates a constrained adaptation space with only r² trainable parameters instead of k(m+n) in LoRA. The inverted probability sampling acts as implicit regularization by focusing adaptation on less influential components, while zero initialization provides stability by starting from minimal adaptation.

## Key Results
- CURLoRA maintained MRPC accuracy at 0.66 after continual fine-tuning vs LoRA's drop to 0.32
- WikiText-2 perplexity remained unchanged with CURLoRA vs significant increase with LoRA
- Parameter efficiency improved dramatically: 24,576 vs 9,437,184 trainable parameters for LoRA-16

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inverted probability sampling of columns/rows acts as implicit regularization by constraining adaptation magnitude
- Mechanism: By sampling columns/rows with lower original leverage scores, CURLoRA forces adaptation through less influential components, limiting parameter changes and preserving original knowledge
- Core assumption: Columns/rows with lower leverage scores are less critical to core functionality and can be modified freely without catastrophic forgetting
- Evidence anchors:
  - [abstract]: "utilizing inverted probabilities for column and row selection which acts as an implicit regularization"
  - [section]: "By constraining the updates to the subspace defined by C and R, CURLoRA limits drastic changes, thereby preserving the model's original knowledge"
  - [corpus]: Weak - No direct corpus evidence of inverted probability sampling as regularization; this appears to be a novel contribution
- Break condition: If critical functionality depends on exact columns/rows with low leverage scores, constraining adaptation could degrade performance

### Mechanism 2
- Claim: Zero initialization of U matrix combined with fixed C and R matrices provides stability during continual fine-tuning
- Mechanism: Initializing U as zeros means minimal initial adaptation, and fixed C/R constrain updates to a well-defined subspace, preventing runaway parameter updates
- Core assumption: Starting from minimal adaptation and constraining updates to fixed subspace prevents deviation from original configuration
- Evidence anchors:
  - [abstract]: "initializing the U matrix as a zero matrix, and only fine-tuning it"
  - [section]: "This unique combination ensures that the fine-tuning process not only starts from the base configuration but also remains constrained throughout training"
  - [corpus]: Weak - While CUR decomposition is established, the specific combination with zero-initialized U for continual learning appears novel
- Break condition: If fixed C/R matrices don't capture sufficient information for new task, constrained adaptation may be insufficient

### Mechanism 3
- Claim: Reduced degrees of freedom (r² vs k(m+n) in LoRA) inherently limits catastrophic forgetting
- Mechanism: Fewer trainable parameters constrain adaptation space and preserve original knowledge
- Core assumption: Fewer degrees of freedom means less capacity to deviate from original model configuration
- Evidence anchors:
  - [section]: "If W ∈ Rm×n and we use a rank-k adaptation, then: Full fine-tuning has mn degrees of freedom, LoRA has k(m+n) degrees of freedom, CURLoRA has only k² degrees of freedom"
  - [section]: "This significant reduction in degrees of freedom inherently limits how far the model can stray from its original configuration"
  - [corpus]: Moderate - Parameter efficiency is established in LoRA literature, but specific r² constraint in CURLoRA appears novel
- Break condition: If reduced degrees of freedom are insufficient for new task, model may underfit

## Foundational Learning

- Concept: Matrix decomposition (CUR decomposition)
  - Why needed here: Essential to understand how CURLoRA differs from LoRA and constrains adaptation
  - Quick check question: What are the three matrices in CUR decomposition and how do they differ from SVD?

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper's core contribution is addressing catastrophic forgetting
  - Quick check question: Why does standard fine-tuning typically lead to catastrophic forgetting?

- Concept: Low-Rank Adaptation (LoRA)
  - Why needed here: CURLoRA builds on LoRA, so understanding its mechanics and limitations is necessary
  - Quick check question: How does LoRA reduce the number of trainable parameters compared to full fine-tuning?

## Architecture Onboarding

- Component map: Base model -> CURLoRA layer (C, U, R matrices) -> Original weight matrix W (frozen) -> Task-specific output layer

- Critical path:
  1. Precompute C and R matrices using inverted probability sampling
  2. Initialize U matrix to zeros
  3. During forward pass: compute adapted weights as W + CU*R
  4. During training: update only U matrix while keeping C, R, and W fixed

- Design tradeoffs:
  - Stability vs. flexibility: Prioritizes stability by constraining adaptation, potentially at cost of some new task performance
  - Parameter efficiency: r² parameters vs. k(m+n) in LoRA, trading some expressiveness for greater efficiency
  - Fixed vs. dynamic decomposition: C and R are fixed after initial computation, which may not be optimal for all tasks

- Failure signatures:
  - Underfitting: If CURLoRA performs significantly worse than LoRA on new tasks, constraint may be too tight
  - No improvement in forgetting: If accuracy on previous tasks still drops significantly, regularization may be insufficient
  - Performance worse than base model: If CURLoRA degrades performance on all tasks, adaptation may be counterproductive

- First 3 experiments:
  1. Reproduce baseline LoRA results on MRPC task to establish performance reference
  2. Apply CURLoRA to same task and compare accuracy and parameter efficiency
  3. Test catastrophic forgetting by fine-tuning on SST-2 after MRPC and measuring MRPC performance retention

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CURLoRA's performance scale with increasingly larger models (e.g., GPT-4, LLaMA-65B) compared to LoRA?
- Basis in paper: [inferred] The paper mentions "Scalability: While CURLoRA shows promising results, its scalability to larger models needs further investigation" as a future work direction
- Why unresolved: Current experiments are limited to smaller models (GPT-2 Large, Mistral 7B), and larger-scale evaluation is explicitly stated as needed
- What evidence would resolve it: Systematic experiments comparing CURLoRA vs LoRA across a range of model sizes (e.g., 1B, 8B, 70B parameters) using standardized benchmarks

### Open Question 2
- Question: What is the optimal method for selecting the rank parameter in CURLoRA to balance parameter efficiency and task performance?
- Basis in paper: [inferred] The paper tests ranks [8, 16, 24] but states "Optimal Rank and Alpha Selection: Investigating methods for automatically selecting the optimal rank and alpha for CURLoRA could further improve performance" as future work
- Why unresolved: The paper uses fixed rank values and doesn't explore adaptive or data-driven methods for rank selection, despite showing it significantly impacts parameter count
- What evidence would resolve it: Development and validation of a principled method (e.g., cross-validation, information criteria, or data-dependent heuristics) for rank selection that consistently outperforms fixed-rank approaches

### Open Question 3
- Question: Does CURLoRA maintain its catastrophic forgetting mitigation when applied to non-sequential task learning scenarios (e.g., multi-task learning, few-shot adaptation)?
- Basis in paper: [explicit] The paper focuses on continual learning with sequential task addition, but notes "Further studies are needed to assess CURLoRA's performance on larger models and more diverse tasks like instruction tuning and datasets"
- Why unresolved: All experiments follow a strict sequential task order, and the paper explicitly mentions instruction tuning as an unexplored area where CURLoRA might behave differently
- What evidence would resolve it: Comparative experiments of CURLoRA vs LoRA in multi-task learning settings where tasks are learned simultaneously or in few-shot scenarios with interleaved examples from different tasks

## Limitations

- Scalability to larger models (e.g., GPT-4, LLaMA-65B) needs further investigation as current experiments are limited to smaller models
- Lack of ablation studies to isolate contributions of inverted probability sampling vs zero-initialized U
- Limited task diversity in evaluation - all experiments follow strict sequential task order without exploring multi-task or few-shot scenarios

## Confidence

- Medium confidence in core claim that CURLoRA mitigates catastrophic forgetting through CUR decomposition
- Low confidence in specific mechanism by which inverted probability sampling provides regularization
- Medium confidence in experimental evaluation due to limited task diversity and absence of comparison with other continual learning methods

## Next Checks

1. **Ablation study**: Implement CURLoRA variants with standard CUR probabilities (not inverted) and non-zero U initialization to quantify contribution of each component to forgetting mitigation

2. **Sensitivity analysis**: Systematically vary the rank r in CUR decomposition and measure impact on both forgetting mitigation and task performance across multiple continual learning scenarios

3. **Comparative evaluation**: Benchmark CURLoRA against established continual learning methods (e.g., EWC, MAS) on diverse task sequences to establish relative effectiveness in forgetting mitigation while maintaining base model performance