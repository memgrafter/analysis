---
ver: rpa2
title: Solving robust MDPs as a sequence of static RL problems
arxiv_id: '2410.06212'
source_url: https://arxiv.org/abs/2410.06212
tags:
- robust
- iwocs
- policy
- value
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of finding robust policies in
  uncertain MDPs, specifically the static model of transition function uncertainty
  where the environment's dynamics remain fixed during episodes. The authors propose
  a novel approach, IWOCS (Incremental Worst-Case Search), which incrementally builds
  a discrete uncertainty set by identifying worst-case transition models and solving
  a sequence of non-robust MDPs.
---

# Solving robust MDPs as a sequence of static RL problems

## Quick Facts
- arXiv ID: 2410.06212
- Source URL: https://arxiv.org/abs/2410.06212
- Authors: Adil Zouitine; Matthieu Geist; Emmanuel Rachelson
- Reference count: 40
- Key outcome: IWOCS achieves 2.04x improvement on average across MuJoCo environments compared to M2TD3

## Executive Summary
This paper addresses robust Markov Decision Processes (MDPs) under transition function uncertainty by proposing a novel approach called IWOCS (Incremental Worst-Case Search). Rather than viewing robust MDPs as two-player games (dynamic model), the authors exploit the equivalence between static and dynamic models for stationary policies under sa-rectangular uncertainty sets. IWOCS incrementally builds a discrete uncertainty set by identifying worst-case transition models and solving a sequence of non-robust MDPs, enabling scalable deep RL implementation.

The authors instantiate IWOCS using SAC for policy optimization and CMA-ES for worst-case search, demonstrating competitive performance with state-of-the-art robust RL algorithms on MuJoCo environments. Experiments show IWOCS achieves significant improvements in worst-case performance across 2D and 3D uncertainty sets, opening new perspectives on robust MDP resolution through sequential non-robust problem solving.

## Method Summary
IWOCS is a meta-algorithm that solves robust MDPs by incrementally building a discrete uncertainty set of transition models. Starting with a default model, it iteratively identifies the worst-case transition function using a search method (CMA-ES or grid search), adds it to the uncertainty set, and solves the resulting non-robust MDP using SAC. The algorithm exploits the equivalence between static and dynamic models for stationary policies under sa-rectangular uncertainty sets and the no-duality gap property. For deep RL implementation, IWOCS uses neural networks to approximate Q-functions for each transition model and predictive coding-based indicator functions to determine valid policies per state.

## Key Results
- IWOCS achieves 2.04-fold improvement on average across MuJoCo environments compared to M2TD3
- Competitive performance against state-of-the-art robust RL methods (M3DDPG, RARL, DR) on 2D and 3D uncertainty sets
- Demonstrates scalability to continuous control tasks while maintaining robust performance guarantees
- Shows effectiveness of the incremental approach in building uncertainty sets that capture worst-case scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Static and dynamic models are equivalent for stationary policies under sa-rectangular uncertainty sets
- Mechanism: The equivalence follows from the lemma stating that for stationary policies, the value function in the dynamic model equals that in the static model, because the adversary's best response to a stationary policy is static
- Core assumption: The uncertainty set is sa-rectangular (Cartesian product of independent marginal sets of distributions for each state-action pair)
- Evidence anchors:
  - [abstract]: "Departing from the common perspective which views robust MDPs as two-player games, we investigate whether it is possible to solve them through a series of non-robust problems. The two-player game formulation is called the dynamic model of transition function uncertainty, as an adversarial environment is allowed to change the transition dynamics at each time step. The solution to this game can be shown to be equivalent, for stationary policies and rectangular uncertainty sets, to that of the static model..."
  - [section]: "Departing from the common perspective which views robust MDPs as two-player games, we investigate whether it is possible to solve them through a series of non-robust problems. The two-player game formulation is called the dynamic model of transition function uncertainty, as an adversarial environment is allowed to change the transition dynamics at each time step. The solution to this game can be shown to be equivalent, for stationary policies and rectangular uncertainty sets, to that of the static model..."
- Break condition: If the uncertainty set is not sa-rectangular, the equivalence fails and the dynamic model may require non-stationary policies

### Mechanism 2
- Claim: IWOCS exploits the no-duality gap property to incrementally identify worst-case transition models
- Mechanism: The algorithm builds a discrete uncertainty set by solving for the worst-case transition model at each iteration and solving a sequence of non-robust MDPs. The monotonic decrease in the robust value function is guaranteed by the property that each new candidate robust policy is at least as good as the previous one
- Core assumption: The no-duality gap property holds (maxπ minT VπT = minT maxπ VπT) for sa-rectangular uncertainty sets
- Evidence anchors:
  - [abstract]: "The authors propose a novel approach, IWOCS (Incremental Worst-Case Search), which incrementally builds a discrete uncertainty set by identifying worst-case transition models and solving a sequence of non-robust MDPs. This method exploits the equivalence between static and dynamic models for stationary policies and the no-duality gap property."
  - [section]: "No-duality gap. Wiesemann et al. [2013, Equation 4 and Proposition 9] introduce an important saddle point condition stating that maxπ minT VπT = minT maxπ VπT. 2"
- Break condition: If the no-duality gap property does not hold (e.g., non-rectangular uncertainty sets), the monotonic decrease and convergence guarantees may fail

### Mechanism 3
- Claim: Decoupling policy optimization from worst-case search enables scalable deep RL implementation
- Mechanism: IWOCS separates the policy optimization (using SAC for regularized MDPs) from the worst-case search (using CMA-ES or grid search). This allows using efficient deep RL methods for the policy optimization step while handling the potentially complex worst-case search separately
- Core assumption: The policy optimization method (SAC) can handle the regularized MDPs encountered during IWOCS iterations, and the worst-case search method can effectively explore the uncertainty set
- Evidence anchors:
  - [abstract]: "We derive a deep RL version of IWOCS and demonstrate it is competitive with state-of-the-art algorithms on classical benchmarks."
  - [section]: "Computational complexity. Recall that the complexity of robust value iteration (RVI), in discrete state and action MDPs, and for sa-rectangular uncertainty sets, is Opcn2SnA log(1/ϵ) / log(1-γ)), where nS is the number of states, nA the number of actions, ϵ is the tolerance for the robust value function and c is the cost of computing a single minT solution [Iyengar, 2005]. Comparing IWOCS and RVI is a delicate matter because IWOCS is not based on a contraction mapping and has no convergence guarantees to the robust value function. Yet, it is legitimate to wonder whether one can analyse the time complexity of IWOCS versus RVI. One iteration of IWOCS in discrete state and action spaces, as presented in Section 4, has the complexity of VI for the policy search part, plus the complexity of finding a worst case transition function in an sa-rectangular uncertainty set, which is OpcnSnA. Hence, the overall complexity for M iterations of IWOCS is OpM(n2SnA log(1/ϵ) / log(1-γ) + cnSnA)). Compared to RVI, this bound will be smaller when c is large, which is the case when one deals with complex uncertainty sets and without further hypotheses."
- Break condition: If the policy optimization method fails to find good policies for the regularized MDPs, or if the worst-case search method cannot effectively explore the uncertainty set, the algorithm performance will degrade

## Foundational Learning

- Concept: Markov Decision Processes (MDPs) and their solution methods
  - Why needed here: The paper builds on MDP theory and extends it to robust MDPs. Understanding MDPs, value iteration, policy iteration, and the Bellman equations is crucial for grasping the paper's contributions
  - Quick check question: What is the Bellman optimality equation for a standard MDP, and how does it differ from the robust Bellman equation?

- Concept: Robust MDPs and the dynamic/static model distinction
  - Why needed here: The paper's core contribution is solving robust MDPs using the static model, exploiting its equivalence with the dynamic model. Understanding these models and their differences is essential
  - Quick check question: What is the key difference between the dynamic and static models of transition function uncertainty, and under what conditions are they equivalent?

- Concept: Saddle point conditions and no-duality gap property
  - Why needed here: The paper relies on the no-duality gap property to justify its approach of incrementally building a discrete uncertainty set. Understanding saddle point conditions and their implications is important
  - Quick check question: What is the no-duality gap property, and why is it crucial for the IWOCS algorithm?

## Architecture Onboarding

- Component map: Policy Optimization (SAC) -> Worst-Case Search (CMA-ES/Grid Search) -> Uncertainty Set Management -> Value Function Approximation (Neural Networks) -> Indicator Functions (Predictive Coding)

- Critical path:
  1. Initialize with a default transition model and train a policy using SAC
  2. For each iteration:
     a. Identify the worst-case transition model using CMA-ES or grid search
     b. Add this model to the uncertainty set
     c. Train a new policy using SAC on the expanded uncertainty set
     d. Check for convergence (if the worst-case model is already in the set)

- Design tradeoffs:
  - Policy optimization precision vs. overall robustness: More precise policy optimization may lead to better policies but at the cost of computational resources
  - Size of the uncertainty set vs. computational complexity: Larger uncertainty sets provide better robustness guarantees but increase computational complexity
  - Choice of worst-case search method: CMA-ES is more scalable but may be less precise than grid search

- Failure signatures:
  - Stagnation: The algorithm fails to find new worst-case models, indicating it may have converged to a suboptimal solution
  - Divergence: The algorithm keeps finding worse and worse models, suggesting issues with the policy optimization or worst-case search
  - High variance in performance: Indicates instability in the policy optimization or worst-case search components

- First 3 experiments:
  1. Implement IWOCS on a simple grid-world with a small uncertainty set to verify the basic algorithm works and produces robust policies
  2. Test IWOCS on a continuous control task (e.g., MuJoCo environments) with a 2D uncertainty set to evaluate scalability and performance
  3. Compare IWOCS with other robust RL methods (e.g., M2TD3, RARL) on benchmark environments to assess competitive performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of IWOCS scale with increasing dimensionality of the uncertainty set beyond 3D?
- Basis in paper: [explicit] The paper mentions that CMA-ES used for worst-case search "will not scale to larger uncertainty set dimensions" and compares it with a grid search baseline
- Why unresolved: The experiments only tested 2D and 3D uncertainty sets. No theoretical analysis or empirical results are provided for higher-dimensional cases
- What evidence would resolve it: Experimental results showing IWOCS performance on uncertainty sets with 4+ dimensions, or a theoretical analysis of the computational complexity as a function of uncertainty set dimensionality

### Open Question 2
- Question: What is the theoretical convergence guarantee for IWOCS when using approximate value functions instead of exact solutions?
- Basis in paper: [inferred] The paper notes that IWOCS "is not based on a contraction mapping and has no convergence guarantees to the robust value function" and discusses using SAC (an approximate method) in the deep RL instantiation
- Why unresolved: While the paper discusses convergence for the idealized case with exact value functions, it doesn't analyze how approximation errors in value functions affect convergence properties
- What evidence would resolve it: A theoretical analysis showing how the quality of approximate value functions impacts the convergence rate or final solution quality of IWOCS

### Open Question 3
- Question: How sensitive is IWOCS to the choice of initial policy and the threshold parameter ρ?
- Basis in paper: [explicit] The paper mentions that "all choices induce a number of parameters to tune (here ρ)" and shows results with different initial policies in the appendix
- Why unresolved: While the paper demonstrates that IWOCS works with different initial policies and discusses the need to tune ρ, it doesn't systematically analyze how these choices affect performance or provide guidance on parameter selection
- What evidence would resolve it: A sensitivity analysis showing IWOCS performance across a range of initial policies and ρ values, or an adaptive method for setting these parameters

## Limitations

- The algorithm relies on sa-rectangular uncertainty sets and stationary policies, which may not capture all practical scenarios
- Lacks convergence guarantees since it's not based on a contraction mapping
- Performance depends heavily on the effectiveness of the worst-case search method in high-dimensional uncertainty sets
- Computational complexity can become prohibitive as the uncertainty set grows
- Indicator function mechanism using predictive coding may introduce approximation errors

## Confidence

**High Confidence:** The equivalence between static and dynamic models for stationary policies under sa-rectangular uncertainty sets - supported by established theory and cited literature.

**Medium Confidence:** The no-duality gap property enabling IWOCS - theoretically sound but practical performance depends on implementation details.

**Medium Confidence:** The decoupling approach enabling scalable deep RL implementation - demonstrated empirically but may face scalability challenges in very high-dimensional uncertainty sets.

## Next Checks

1. **Theoretical validation:** Verify the no-duality gap property for the specific uncertainty sets used in experiments, as this is crucial for the algorithm's correctness.

2. **Worst-case search robustness:** Compare CMA-ES performance against exhaustive grid search on small uncertainty sets to quantify potential approximation errors in identifying worst-case models.

3. **Indicator function accuracy:** Measure the classification accuracy of the predictive coding-based indicator functions and assess their impact on overall performance by comparing against ground truth state-policy validity.