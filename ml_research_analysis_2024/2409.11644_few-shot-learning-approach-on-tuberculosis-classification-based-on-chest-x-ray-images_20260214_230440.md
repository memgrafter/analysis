---
ver: rpa2
title: Few-Shot Learning Approach on Tuberculosis Classification Based on Chest X-Ray
  Images
arxiv_id: '2409.11644'
source_url: https://arxiv.org/abs/2409.11644
tags:
- data
- learning
- training
- classification
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses class imbalance in tuberculosis (TB) classification
  using chest X-ray images by employing a few-shot learning (FSL) approach with Prototypical
  Networks. The proposed method leverages transfer learning with pre-trained CNN backbones
  (ResNet-18, ResNet-50, VGG16) for feature extraction, followed by FSL-based classification.
---

# Few-Shot Learning Approach on Tuberculosis Classification Based on Chest X-Ray Images

## Quick Facts
- arXiv ID: 2409.11644
- Source URL: https://arxiv.org/abs/2409.11644
- Reference count: 18
- ResNet-18 achieves 98.93% accuracy on TBX11K dataset

## Executive Summary
This study addresses class imbalance in tuberculosis classification using chest X-ray images by employing a few-shot learning approach with Prototypical Networks. The proposed method leverages transfer learning with pre-trained CNN backbones (ResNet-18, ResNet-50, VGG16) for feature extraction, followed by FSL-based classification. Experimental results on the TBX11K dataset demonstrate superior performance with ResNet-18 achieving 98.93% accuracy and ResNet-50 achieving 98.60% accuracy, significantly outperforming VGG16 (33.33%). The FSL approach effectively mitigates data imbalance issues, particularly for rare active-latent TB cases, by enabling robust classification with limited samples per class.

## Method Summary
The approach uses Prototypical Networks for few-shot learning, combining transfer learning with pre-trained CNN backbones for feature extraction. Chest X-ray images are preprocessed (resized to 224×224, normalized) and augmented before feature extraction using VGG16, ResNet-18, or ResNet-50. The extracted features are then used to compute class prototypes, which classify query images based on Euclidean distance. The model is evaluated across different shot numbers (1, 5, 10, 20) with an 80/20 train/validation split.

## Key Results
- ResNet-18 achieves 98.93% accuracy on the TBX11K dataset
- ResNet-50 achieves 98.60% accuracy, significantly outperforming VGG16 (33.33%)
- The FSL approach effectively mitigates class imbalance, particularly for rare active-latent TB cases
- Meta-training with ResNet-18 achieves 96.80% accuracy with just 1 shot, reaching 98.93% with 20 shots

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prototypical Networks effectively mitigate class imbalance by learning class prototypes from limited samples, improving classification accuracy for rare classes like active-latent TB.
- Mechanism: The algorithm calculates a prototype (mean vector) for each class from support samples and classifies query images by Euclidean distance to these prototypes, enabling robust classification with few examples per class.
- Core assumption: Class prototypes capture sufficient discriminative information to represent each class despite limited samples.
- Evidence anchors:
  - [abstract]: "The FSL approach effectively mitigates data imbalance issues, particularly for rare active-latent TB cases, by enabling robust classification with limited samples per class."
  - [section III-F]: "Prototypical Networks compute an M-dimensional representation ck RM (or prototype) of each class via an embedding function fϕ..."
  - [corpus]: Weak evidence - no direct comparison of prototypical networks vs. other methods for class imbalance.
- Break condition: If the prototype representation fails to capture class-specific features, or if the embedding space does not preserve class separability.

### Mechanism 2
- Claim: Pre-trained CNN backbones (ResNet-18, ResNet-50) provide effective feature extraction for few-shot learning, with ResNet-50 showing superior performance due to its deeper architecture.
- Mechanism: The pre-trained CNNs extract high-level features from chest X-ray images, which are then used by the Prototypical Network to compute class prototypes. Deeper architectures like ResNet-50 capture more abstract features, improving classification accuracy.
- Core assumption: Pre-trained CNNs on ImageNet generalize well to chest X-ray images for feature extraction.
- Evidence anchors:
  - [abstract]: "Experimental results on the TBX11K dataset demonstrate superior performance with ResNet-18 achieving 98.93% accuracy and ResNet-50 achieving 98.60% accuracy..."
  - [section III-E]: "Feature extraction is performed using three pre-trained CNN models: VGG16, ResNet-18, and ResNet-50."
  - [corpus]: Weak evidence - no direct comparison of different CNN backbones in few-shot learning for TB detection.
- Break condition: If the pre-trained features do not generalize to the medical domain, or if the architecture is too shallow to capture necessary features.

### Mechanism 3
- Claim: Meta-training enhances the model's ability to generalize from minimal data, leading to improved classification accuracy for underrepresented TB classes.
- Mechanism: Meta-training adapts the model to quickly learn from few examples by optimizing the embedding function, allowing the Prototypical Network to generalize better with limited support samples.
- Core assumption: Meta-training effectively optimizes the embedding space for few-shot learning tasks.
- Evidence anchors:
  - [section III-C]: "In model with training... the dataset train is being trained in the first place, then the test train is tested after the training process is done."
  - [section IV-B]: "With meta-training, ResNet-18 achieves 96.80% accuracy with just 1 shot, reaching 98.93% with 20 shots."
  - [corpus]: No direct evidence - the corpus does not mention meta-training in the context of few-shot learning for TB detection.
- Break condition: If meta-training fails to improve generalization, or if the optimization process converges to poor local minima.

## Foundational Learning

- Concept: Few-shot learning
  - Why needed here: The TBX11K dataset has class imbalance, with rare active-latent TB cases having limited samples. Few-shot learning enables robust classification with minimal examples per class.
  - Quick check question: How does few-shot learning differ from traditional supervised learning in handling class imbalance?

- Concept: Prototypical Networks
  - Why needed here: Prototypical Networks provide a simple yet effective method for few-shot learning by computing class prototypes and classifying based on distance metrics.
  - Quick check question: What is the role of the embedding function in Prototypical Networks?

- Concept: Transfer learning
  - Why needed here: Pre-trained CNNs (ResNet-18, ResNet-50) are used for feature extraction, leveraging knowledge from ImageNet to improve performance on chest X-ray images.
  - Quick check question: Why is transfer learning beneficial in medical image classification tasks with limited data?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Feature extraction (CNN backbone) -> Prototypical Network (prototype computation and classification) -> Model evaluation

- Critical path:
  1. Preprocess chest X-ray images
  2. Extract features using pre-trained CNN backbone
  3. Compute class prototypes using Prototypical Network
  4. Classify query images based on distance to prototypes
  5. Evaluate model performance

- Design tradeoffs:
  - Backbone selection: VGG16 vs. ResNet-18 vs. ResNet-50 (tradeoff between depth and computational efficiency)
  - Meta-training: With vs. without meta-training (tradeoff between generalization and computational cost)
  - Data augmentation: Extent of augmentation (tradeoff between robustness and overfitting)

- Failure signatures:
  - Low accuracy across all classes: Backbone feature extraction is not effective
  - High accuracy for majority class, low for minority: Class imbalance is not adequately addressed
  - Overfitting: Data augmentation is insufficient or model is too complex

- First 3 experiments:
  1. Compare VGG16, ResNet-18, and ResNet-50 backbones without meta-training to assess feature extraction effectiveness
  2. Implement Prototypical Network with ResNet-18 backbone and evaluate performance with and without meta-training
  3. Test different shot numbers (1-shot, 5-shot, 10-shot, 20-shot) to determine optimal number of support samples per class

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Prototypical Networks perform on other medical imaging datasets with different types of class imbalance beyond tuberculosis classification?
- Basis in paper: [inferred] The paper demonstrates successful mitigation of class imbalance in TBX11K dataset using Prototypical Networks, but doesn't explore applicability to other medical imaging domains
- Why unresolved: The study focuses exclusively on TB classification without testing the approach on other medical imaging tasks with class imbalance
- What evidence would resolve it: Comparative experiments applying the same Prototypical Network approach to datasets like COVID-19 detection, pneumonia classification, or other medical imaging tasks with class imbalance

### Open Question 2
- Question: What is the optimal trade-off between the number of backbone layers frozen versus fine-tuned during Prototypical Network training for medical image classification?
- Basis in paper: [inferred] The paper freezes all convolutional layers in VGG16, ResNet-18, and ResNet-50, but doesn't explore whether fine-tuning some layers could improve performance
- Why unresolved: The methodology assumes freezing all layers is optimal without testing alternative configurations
- What evidence would resolve it: Systematic experiments comparing performance across different freezing/fine-tuning strategies for the backbone networks

### Open Question 3
- Question: How does the performance of Prototypical Networks compare to other few-shot learning algorithms like Matching Networks or Relation Networks on the same TBX11K dataset?
- Basis in paper: [explicit] The paper focuses exclusively on Prototypical Networks without comparing to other few-shot learning approaches
- Why unresolved: Only one few-shot learning algorithm was tested, leaving open questions about whether it's the optimal choice
- What evidence would resolve it: Direct performance comparison between Prototypical Networks, Matching Networks, Relation Networks, and other few-shot learning algorithms on the same TBX11K dataset with identical experimental conditions

## Limitations
- Narrow evaluation scope with only three backbone architectures tested and no comparison to alternative few-shot learning methods
- Exceptional accuracy (98.93%) may indicate potential overfitting or optimistic evaluation without cross-validation or independent test set validation
- Limited methodology details on meta-training implementation and data augmentation strategies

## Confidence

**High Confidence**: The core mechanism of Prototypical Networks for few-shot learning is well-established in the literature, and the general approach of using pre-trained CNNs for feature extraction is standard practice.

**Medium Confidence**: The reported accuracy improvements over VGG16 are credible given the known limitations of VGG architectures, but the specific numerical results require independent verification due to the lack of detailed methodology.

**Low Confidence**: The claim that meta-training specifically contributes to the performance gains is weakly supported, as the paper provides limited detail on the meta-training implementation and no direct comparison with and without meta-training.

## Next Checks

1. **Cross-Validation Replication**: Implement k-fold cross-validation (k=5 or k=10) on the TBX11K dataset to verify the reported accuracy figures are not inflated by a particularly favorable train/test split.

2. **Alternative Method Comparison**: Replicate the experiment using alternative few-shot learning approaches (MAML, relation networks) and standard class-imbalanced techniques (SMOTE, weighted loss) to establish whether Prototypical Networks offer unique advantages for this specific task.

3. **Meta-Training Ablation**: Conduct a controlled experiment comparing the full Prototypical Network with the same architecture but without meta-training to quantify the actual contribution of meta-training to the reported performance improvements.