---
ver: rpa2
title: Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting
arxiv_id: '2407.00502'
source_url: https://arxiv.org/abs/2407.00502
tags:
- time
- frequency
- series
- forecasting
- fourier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses non-stationary time series forecasting by
  proposing a novel framework, DERITS, that utilizes the entire frequency spectrum
  for transformation rather than just the zero frequency component as in existing
  methods. DERITS consists of a Frequency Derivative Transformation (FDT) that converts
  time series into more stationary frequency representations using Fourier derivatives,
  followed by an Order-adaptive Fourier Convolution Network (OFCN) that performs frequency
  filtering and dependency learning.
---

# Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting

## Quick Facts
- arXiv ID: 2407.00502
- Source URL: https://arxiv.org/abs/2407.00502
- Reference count: 15
- Primary result: DERITS achieves over 20% improvement in MAE and RMSE compared to best transformer-based models

## Executive Summary
This paper addresses non-stationary time series forecasting by proposing DERITS, a framework that utilizes the entire frequency spectrum rather than just the zero frequency component as in existing methods. The framework consists of Frequency Derivative Transformation (FDT) that converts time series into more stationary frequency representations using Fourier derivatives, followed by an Order-adaptive Fourier Convolution Network (OFCN) that performs frequency filtering and dependency learning. Extensive experiments on seven real-world datasets demonstrate consistent superiority over state-of-the-art methods in both forecasting accuracy and distribution shift alleviation.

## Method Summary
DERITS transforms time series to the frequency domain using the entire spectrum, applies frequency derivative operations to improve stationarity, then uses adaptive frequency filtering and convolution operations before converting back to the time domain. The framework employs a parallel-stacked architecture with multiple frequency orders, each capturing different aspects of the signal, which are then fused through learnable weights. This approach aims to capture more distribution information than traditional normalization methods while reducing the burden of modeling distribution shifts.

## Key Results
- DERITS achieves over 20% improvement in MAE and RMSE compared to best transformer-based models
- Consistent superiority across seven diverse real-world datasets (Exchange, ILI, Weather, Traffic, Electricity, ETTh1, ETTm1)
- Effective distribution shift alleviation demonstrated through improved forecasting performance on non-stationary data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transforming time series to the frequency domain using the entire spectrum captures more distribution information than traditional normalization
- Mechanism: Traditional normalization methods only adjust the mean and variance (zero frequency component), missing higher frequency information that contains important signal patterns and distribution characteristics
- Core assumption: Time series distribution information is encoded across the entire frequency spectrum, not just in the mean and variance
- Evidence anchors:
  - [abstract]: "these operations can theoretically be seen as the transformation towards zero frequency component of the spectrum which cannot reveal full distribution information"
  - [section 1]: "After our careful theoretical analysis, we have found that these operations can actually be regarded as the normalization towards the zero frequency component of the spectrum in the frequency domain"
  - [corpus]: Weak - related papers focus on normalization methods but don't explicitly discuss the frequency spectrum perspective
- Break condition: If time series distribution information is primarily contained in the mean and variance, or if frequency domain transformation introduces more noise than signal

### Mechanism 2
- Claim: Frequency derivative transformation makes time series representations more stationary by modeling gradients rather than raw signals
- Mechanism: Taking derivatives in the frequency domain (equivalent to time domain derivatives via Fourier Derivative Operator) removes trends and non-stationary components, making the signal more stationary
- Core assumption: Derivatives in the frequency domain effectively remove non-stationary components while preserving useful signal patterns
- Evidence anchors:
  - [section 4.1]: "FDT let models aim for modeling gradients of signals rather than raw input signals, which could mitigate their burden of forecasting with distribution shifts"
  - [section 4.1]: "Proposition 1... the k-order Fourier Derivative Operator on X(f) is equivalent to k-order derivation on X(t) with respect to t"
  - [corpus]: Weak - related papers don't discuss frequency derivative transformation as a stationarity technique
- Break condition: If the derivative operation removes too much signal information or if the frequency domain derivative doesn't accurately represent time domain derivatives

### Mechanism 3
- Claim: Multi-order frequency derivative learning with parallel architecture captures both low and high frequency patterns effectively
- Mechanism: Different orders of frequency derivation capture different aspects of the signal - lower orders capture trends and broad patterns, higher orders capture local variations and fine details
- Core assumption: Different frequency orders contain complementary information that improves forecasting when combined
- Evidence anchors:
  - [section 4.2]: "different order corresponds to different frequency comments... we design an adaptive mask mk to concentrate on only S/2(K-k) frequency components"
  - [section 5.4]: "with the increase of order, the original time series would be derived too much... This might cause the information loss"
  - [corpus]: Weak - related papers don't discuss multi-order frequency derivative learning architecture
- Break condition: If different orders provide redundant information or if the fusion mechanism doesn't effectively combine the complementary information

## Foundational Learning

- Concept: Fourier Transform and its properties
  - Why needed here: The entire framework relies on converting signals between time and frequency domains using Fourier Transform
  - Quick check question: Can you explain why the Fourier Transform of a derivative in time domain equals multiplication by j2πf in frequency domain?

- Concept: Stationarity in time series analysis
  - Why needed here: The core motivation is to make non-stationary time series more stationary for better forecasting
  - Quick check question: What are the key statistical properties that define stationarity in time series?

- Concept: Convolution theorem and frequency domain operations
  - Why needed here: The Order-adaptive Fourier Convolution Network performs convolutions in the frequency domain
  - Quick check question: How does convolution in the frequency domain relate to multiplication in the time domain?

## Architecture Onboarding

- Component map: Input → Frequency Derivative Transformation (FDT) → Order-adaptive Frequency Filter → Fourier Convolution → Inverse FDT → Multi-order Fusion → Output
- Critical path: The transformation to frequency domain, frequency filtering, convolution learning, and inverse transformation back to time domain
- Design tradeoffs: More frequency orders capture more information but increase complexity; aggressive filtering removes noise but may remove useful signal
- Failure signatures: Poor performance when frequency domain representation doesn't capture essential time domain characteristics; vanishing gradients in high-order derivatives
- First 3 experiments:
  1. Compare single-order FDT (k=1) vs no transformation baseline on Exchange dataset
  2. Test different numbers of frequency orders (K=1,2,3) on Weather dataset
  3. Compare adaptive frequency filtering vs uniform filtering on Traffic dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed FDT scale to extremely long time series with millions of timesteps?
- Basis in paper: [explicit] The paper mentions that time series data are usually collected at high frequency over long duration, leading to distribution shifts. However, the scalability analysis of FDT for extremely long time series is not discussed.
- Why unresolved: The paper does not provide any empirical evidence or theoretical analysis on the computational complexity or memory requirements of FDT when applied to extremely long time series.
- What evidence would resolve it: Experimental results comparing the performance and computational efficiency of FDT on time series of varying lengths, including extremely long ones, would provide insights into its scalability.

### Open Question 2
- Question: How does the choice of the order k in FDT affect the performance of DERITS on different types of time series data?
- Basis in paper: [explicit] The paper mentions that different orders of derivation represent different signal representations and that higher orders can lead to information loss. However, the optimal choice of k for different types of time series data is not discussed.
- Why unresolved: The paper does not provide any empirical evidence or theoretical analysis on how the choice of k affects the performance of DERITS on different types of time series data, such as those with varying levels of non-stationarity or periodicity.
- What evidence would resolve it: Experimental results comparing the performance of DERITS with different values of k on various types of time series data would provide insights into the optimal choice of k for different scenarios.

### Open Question 3
- Question: How does the proposed FDT compare to other frequency-based time series forecasting methods, such as those using wavelet transforms or empirical mode decomposition?
- Basis in paper: [explicit] The paper mentions that frequency analysis has been widely used in time series modeling and forecasting, but does not provide a direct comparison between FDT and other frequency-based methods.
- Why unresolved: The paper does not provide any empirical evidence or theoretical analysis on how FDT compares to other frequency-based time series forecasting methods in terms of accuracy, computational efficiency, or robustness to noise.
- What evidence would resolve it: Experimental results comparing the performance of FDT with other frequency-based time series forecasting methods on various benchmark datasets would provide insights into its relative strengths and weaknesses.

## Limitations

- The theoretical foundation of frequency derivative transformation requires further validation across diverse non-stationary patterns
- The effectiveness of adaptive frequency filtering depends on learned mask weights without sufficient analysis across different types of non-stationarity
- Computational complexity of processing multiple frequency orders in parallel may limit scalability to very large datasets or high-dimensional multivariate series

## Confidence

- **High confidence**: The framework's superior performance metrics (MAE and RMSE improvements over 20% compared to transformer-based models) are well-supported by experimental results across seven diverse datasets
- **Medium confidence**: The theoretical claim that frequency domain transformations capture more distributional information than traditional normalization methods is logically sound but lacks comprehensive empirical validation
- **Medium confidence**: The mechanism that frequency derivatives improve stationarity and reduce distribution shift burden is supported by the mathematical framework but requires more extensive ablation studies

## Next Checks

1. **Ablation study on frequency orders**: Conduct experiments varying K (number of frequency orders) from 1 to 5 on all seven datasets to determine optimal order count and identify diminishing returns

2. **Distribution shift robustness testing**: Apply the framework to synthetic time series with controlled distribution shifts (e.g., sudden mean changes, variance changes, trend reversals) to quantify distribution shift alleviation capabilities

3. **Computational efficiency analysis**: Measure and compare GPU memory usage and inference latency between DERITS and baseline methods across different batch sizes and sequence lengths to assess practical scalability