---
ver: rpa2
title: 'A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash
  Synergy Potential'
arxiv_id: '2406.03963'
source_url: https://arxiv.org/abs/2406.03963
tags:
- llms
- framework
- knowledge
- generator
- reader
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a general "A + B" generator-reader framework
  for optimizing LLMs to unleash synergy potential. The authors explore the efficacy
  of base and chat versions of LLMs, finding their different functionalities suitable
  for generator A and reader B, respectively.
---

# A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential

## Quick Facts
- arXiv ID: 2406.03963
- Source URL: https://arxiv.org/abs/2406.03963
- Reference count: 10
- Authors: Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Pengyuan Zhou
- One-line primary result: Base models as generators + chat models as readers consistently outperform single models, especially in complex scenarios

## Executive Summary
This paper introduces a general "A + B" generator-reader framework that combines different versions of LLMs to leverage their complementary strengths. The authors systematically investigate base versus chat models, finding that base models excel at factual memorization for generation tasks while chat models produce more helpful and aligned responses for reading tasks. The framework demonstrates consistent performance improvements over single models across knowledge-intensive tasks, and the authors extend it to scenarios involving source documents through continuous learning. The approach provides a practical solution for integrating external knowledge into LLMs while maintaining safety and helpfulness.

## Method Summary
The method involves systematically pairing different LLM versions as generators (A) and readers (B), with base models typically serving as generators due to superior factual accuracy and chat models as readers for their alignment with human preferences. The framework is evaluated across multiple datasets (NQ, TriviaQA, WebQuestions, HotpotQA) using Exact Match and BLEU metrics. The authors also introduce a continuous pretraining approach to integrate external knowledge by embedding documents into LLM parameters using the NarrativeQA dataset. Experiments explore the impact of model sizes, with findings suggesting larger generators provide more benefit than larger readers.

## Key Results
- Base models outperform chat models as generators on memorization tasks, with base models achieving higher BLEU scores
- Chat models consistently outperform base models as readers, producing more helpful and safer responses judged by GPT-4
- The A+B framework achieves consistent performance gains across all tested datasets compared to single models
- Larger generators provide more substantial performance improvements than larger readers in the framework

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Base models outperform chat models as generators due to better factual memorization.
- **Mechanism**: Base models retain raw knowledge from pretraining without the interference of alignment fine-tuning, enabling more accurate retrieval of memorized facts during generation.
- **Core assumption**: Alignment fine-tuning (SFT/RLHF) reduces the model's ability to output factually consistent content, even though it improves helpfulness and safety.
- **Evidence anchors**:
  - [abstract]: "base performs better than chat in memorization tasks, which is the key ability of generator"
  - [section]: "base model is capable of generating more accurate content than the chat model... SFT could negatively impact performance on factual QA and reasoning benchmarks"
  - [corpus]: Weak; no direct corpus evidence supporting this mechanism, only inference from internal comparison.
- **Break condition**: If alignment fine-tuning preserves factual accuracy (e.g., with careful training data curation), this mechanism would weaken or fail.

### Mechanism 2
- **Claim**: Chat models are superior as readers because they generate responses aligned with human preferences (helpful, clear, safe).
- **Mechanism**: Chat models are fine-tuned with human preference data (SFT/RLHF), which improves their ability to produce contextually appropriate, safe, and helpful responses when interpreting generated content.
- **Core assumption**: Human preference alignment in chat models improves response quality without compromising the ability to interpret factual content generated by base models.
- **Evidence anchors**:
  - [abstract]: "chat can generate more helpful and safer response than base and is more suitable as reader"
  - [section]: "chat models, fine-tuned with alignment data, consistently excel in delivering responses that are helpful, clear, and safe"
  - [corpus]: No direct corpus evidence; evidence is internal experimental comparison.
- **Break condition**: If chat models over-align and become overly cautious or fail to interpret factual content correctly, this mechanism would break.

### Mechanism 3
- **Claim**: Larger generator models provide more benefit than larger reader models in the A+B framework.
- **Mechanism**: The reader relies on the quality of context generated by the generator; a larger generator can produce more comprehensive and accurate context, which the smaller reader can then interpret effectively.
- **Core assumption**: The bottleneck in the A+B pipeline is the quality and coverage of generated context, not the reader's interpretation capacity.
- **Evidence anchors**:
  - [abstract]: "enlarging the generator results in more substantial benefits compared to increasing the size of the reader"
  - [section]: "enlarging the generator results in more substantial benefits compared to increasing the size of the reader"
  - [corpus]: Weak; only general statement without specific corpus citation.
- **Break condition**: If reader interpretation becomes the bottleneck (e.g., complex reasoning tasks), increasing reader size could become more beneficial.

## Foundational Learning

- **Concept**: Retrieval-Augmented Generation (RAG) and its limitations.
  - Why needed here: The paper builds on RAG by replacing retrieval with generation, so understanding RAG's strengths and weaknesses is foundational.
  - Quick check question: What is the primary bottleneck of traditional RAG systems according to the paper?

- **Concept**: The distinction between base and chat versions of LLMs.
  - Why needed here: The framework relies on using base models for generation and chat models for reading, so understanding their differences is critical.
  - Quick check question: Why does the paper claim base models are better at memorization than chat models?

- **Concept**: Continuous learning for integrating external knowledge.
  - Why needed here: The paper extends the framework to scenarios with source documents via continuous pretraining, so understanding this technique is essential.
  - Quick check question: How does the paper propose to integrate external knowledge into LLMs without supervised fine-tuning?

## Architecture Onboarding

- **Component map**: Generator A (base LLM) -> Reader B (chat LLM) -> Final answer
- **Critical path**: Query → Generator A produces context → Reader B interprets context + query → Final answer
- **Design tradeoffs**:
  - Base vs chat for generator: Base models have better factual accuracy but may produce less helpful outputs; chat models are safer but less accurate.
  - Generator size vs reader size: Larger generators improve context quality more than larger readers improve interpretation.
  - Single model vs A+B framework: A+B consistently outperforms single models, especially in complex tasks.
- **Failure signatures**:
  - Generator produces irrelevant or inaccurate context → Reader cannot recover correct answer.
  - Reader misinterprets factual content → Final answer is incorrect despite good context.
  - Over-alignment in chat reader → Reader refuses to answer or gives overly cautious responses.
- **First 3 experiments**:
  1. Compare base vs chat models as generators on a memorization task (e.g., quote completion).
  2. Compare base vs chat models as readers on a helpfulness/safety evaluation (e.g., using GPT-4 as judge).
  3. Implement A+B framework with different combinations and compare to single model baselines on NQ/TriviaQA datasets.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the "A + B" framework perform when scaled to larger models (e.g., 70B parameters or more) as the generator, and what is the optimal size ratio between the generator and reader?
- Basis in paper: Inferred from the section "Influence of Sizes and Types" where the authors mention that larger generators yield greater benefits but do not extensively test with 70B models as generators.
- Why unresolved: The paper only briefly mentions 70B models in the context of readers, not as generators, and does not explore the performance impact of scaling generators beyond 13B parameters.
- What evidence would resolve it: Conducting experiments with 70B+ parameter models as generators paired with smaller readers, and comparing performance gains to smaller generator-reader combinations.

### Open Question 2
- Question: How does the "A + B" framework perform in domains outside of knowledge-intensive tasks, such as creative writing or code generation, where factual accuracy is less critical?
- Basis in paper: Explicit from the conclusion stating the framework's potential to improve LLM applications "across various domains" but only tested on factual question answering.
- What evidence would resolve it: Evaluating the framework on benchmarks for creative writing (e.g., story continuation) and code generation (e.g., HumanEval), comparing performance to single models and traditional RAG approaches.

### Open Question 3
- Question: What is the impact of the "A + B" framework on inference efficiency and computational cost, particularly when using large generators?
- Basis in paper: Inferred from the section "Influence of Sizes and Types" where the authors note that larger generators improve performance but do not discuss the trade-offs in terms of inference speed or computational resources.
- What evidence would resolve it: Benchmarking the framework's latency, memory usage, and token generation speed compared to single models and RAG, and analyzing the cost-benefit ratio of using larger generators.

### Open Question 4
- Question: How does the "A + B" framework handle ambiguous or underspecified queries where the correct answer is not clear-cut?
- Basis in paper: Explicit from the experiments focusing on factual question answering where answers are well-defined, but no evaluation on ambiguous queries.
- What evidence would resolve it: Testing the framework on datasets with ambiguous questions (e.g., Winogrande for commonsense reasoning) and analyzing how well the generator-reader setup disambiguates and responds compared to single models.

### Open Question 5
- Question: Can the "A + B" framework be extended to handle multi-modal inputs (e.g., text and images) by using different model types for generation and reading?
- Basis in paper: Inferred from the discussion on combining different model types for text generation and reading, suggesting potential for extension to other modalities.
- What evidence would resolve it: Implementing the framework with multi-modal models (e.g., GPT-4V for generation and text-only models for reading) and evaluating performance on multi-modal QA datasets like VQA or GQA.

## Limitations
- The paper's claims about base models' superior factual memorization are primarily based on internal comparisons rather than external corpus evidence.
- The continuous learning extension lacks detailed implementation specifications, particularly regarding the pretraining hyperparameters and LoRA configuration.
- Safety and helpfulness improvements are evaluated through GPT-4 judging rather than human evaluation, which may not fully capture nuanced alignment effects.

## Confidence
- **High confidence**: The A+B framework consistently outperforming single models across multiple datasets (NQ, TriviaQA, WebQ, HotpotQA) - supported by systematic experiments with clear performance metrics.
- **Medium confidence**: The mechanism that base models memorize facts better than chat models - supported by internal comparisons but lacking direct corpus evidence or ablation studies on alignment effects.
- **Medium confidence**: The superiority of chat models as readers for producing helpful and safe responses - supported by GPT-4 evaluation but would benefit from human judgment validation.

## Next Checks
1. **Ablation study on alignment fine-tuning**: Systematically compare base and chat models while isolating the effects of SFT vs RLHF on factual accuracy and response quality to validate the claimed mechanism.

2. **Human evaluation of safety and helpfulness**: Supplement the GPT-4 judging with human evaluation to verify the claimed superiority of chat readers in producing aligned responses, particularly for edge cases.

3. **Detailed hyperparameter validation**: Replicate the continuous learning extension with specified (or experimentally determined) LoRA rank, alpha values, and pretraining epochs to verify the knowledge integration claims and assess reproducibility.