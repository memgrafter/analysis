---
ver: rpa2
title: A Systems Thinking Approach to Algorithmic Fairness
arxiv_id: '2412.16641'
source_url: https://arxiv.org/abs/2412.16641
tags:
- fairness
- decision
- discrimination
- group
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a systems thinking approach to model algorithmic
  fairness by combining machine learning, causal inference, and system dynamics. It
  encodes prior knowledge about bias into causal graphs, linking AI systems to political
  and legal frameworks.
---

# A Systems Thinking Approach to Algorithmic Fairness

## Quick Facts
- arXiv ID: 2412.16641
- Source URL: https://arxiv.org/abs/2412.16641
- Authors: Chris Lam
- Reference count: 40
- Introduces a systems thinking approach combining ML, causal inference, and system dynamics to model algorithmic fairness

## Executive Summary
This paper presents a novel framework for understanding algorithmic fairness by integrating systems thinking, causal inference, and machine learning. The approach encodes prior knowledge about bias into causal graphs that connect AI systems to broader political and legal frameworks. By modeling different ideological perspectives on fairness and incorporating feedback loops, the framework captures how fairness policies can either perpetuate or reduce disparities over time. A case study on racial disparities demonstrates that "fairness through unawareness" may be more effective than affirmative action in reducing long-term inequities.

## Method Summary
The paper introduces a systems thinking approach that combines machine learning, causal inference, and system dynamics to model algorithmic fairness. The method encodes prior knowledge about bias into causal graphs, linking AI systems to political and legal frameworks. It captures different ideological perspectives on fairness, showing how they map to distinct fairness criteria and antidiscrimination laws. The approach integrates reinforcing and balancing feedback loops to model how fairness policies can perpetuate or reduce disparities over time.

## Key Results
- Fairness through unawareness may better reduce long-term inequities than affirmative action
- The framework provides a unified causal hierarchy and systems map to bridge social science and technical fairness concepts
- Different ideological perspectives on fairness map to distinct fairness criteria and antidiscrimination laws

## Why This Works (Mechanism)
The framework works by treating algorithmic fairness as a complex adaptive system where multiple interacting components create emergent outcomes. By using causal graphs to encode prior knowledge about bias and its relationship to legal and political frameworks, the approach captures the multi-level nature of fairness interventions. The integration of system dynamics with causal inference allows the model to simulate how feedback loops between AI systems, societal outcomes, and policy responses create long-term effects that simple static analyses miss.

## Foundational Learning
1. Causal Graphs
   - Why needed: To represent complex relationships between AI systems, bias, and social outcomes
   - Quick check: Can the graph capture both direct and indirect effects of fairness interventions?

2. System Dynamics
   - Why needed: To model how fairness policies create feedback loops that amplify or dampen disparities over time
   - Quick check: Does the model capture both reinforcing and balancing feedback loops?

3. Ideological Perspectives Mapping
   - Why needed: To connect technical fairness concepts with real-world political and legal frameworks
   - Quick check: Can the framework map different fairness ideologies to specific legal requirements?

4. Multi-level Modeling
   - Why needed: To bridge individual-level AI decisions with systemic social outcomes
   - Quick check: Does the model capture interactions between technical, organizational, and societal levels?

5. Temporal Dynamics
   - Why needed: To understand how fairness interventions create different outcomes over time
   - Quick check: Can the model predict both short-term and long-term effects of different fairness approaches?

## Architecture Onboarding

Component Map:
Prior Knowledge -> Causal Graphs -> System Dynamics Model -> Fairness Policy Simulation -> Outcome Analysis

Critical Path:
1. Encode prior knowledge about bias into causal structure
2. Integrate causal relationships with system dynamics
3. Simulate policy interventions over time
4. Analyze emergent outcomes and feedback effects

Design Tradeoffs:
- Granularity vs. tractability in causal graph construction
- Empirical validation vs. theoretical completeness
- Model complexity vs. interpretability for policymakers

Failure Signatures:
- Over-simplified causal relationships leading to inaccurate predictions
- Missing key feedback loops that drive system behavior
- Misalignment between technical fairness metrics and legal requirements

First Experiments:
1. Validate causal relationships against empirical data on fairness intervention outcomes
2. Test model predictions against historical data from implemented fairness policies
3. Compare model outputs with expert assessments of fairness intervention impacts

## Open Questions the Paper Calls Out
None

## Limitations
- Limited empirical validation of causal graphs and system dynamics models
- Reliance on illustrative rather than empirical data for case studies
- Assumptions about causal graph adequacy for encoding complex social phenomena

## Confidence
Empirical validation: Low
Theoretical framework: Medium
Policy recommendations: Low

## Next Checks
1. Conduct empirical studies to validate the causal relationships encoded in the graphs against real-world fairness intervention outcomes
2. Test the system dynamics models with historical data from actual fairness policy implementations
3. Compare model predictions against observed long-term impacts of different fairness approaches across multiple domains