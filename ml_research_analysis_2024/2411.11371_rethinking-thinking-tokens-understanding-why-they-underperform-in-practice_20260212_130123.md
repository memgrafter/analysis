---
ver: rpa2
title: 'Rethinking Thinking Tokens: Understanding Why They Underperform in Practice'
arxiv_id: '2411.11371'
source_url: https://arxiv.org/abs/2411.11371
tags:
- reasoning
- tokens
- thinking
- tasks
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Thinking Tokens (TT) are an unsupervised approach for reasoning
  in language models, using a single embedding to simulate intermediate reasoning
  steps. This study compares TTs against Chain-of-Thought (CoT) prompting across arithmetic
  (digit multiplication, GSM8K) and symbolic reasoning tasks (OpenBookQA).
---

# Rethinking Thinking Tokens: Understanding Why They Underperform in Practice

## Quick Facts
- **arXiv ID**: 2411.11371
- **Source URL**: https://arxiv.org/abs/2411.11371
- **Reference count**: 5
- **Primary result**: Thinking Tokens (TT) using single embeddings underperform Chain-of-Thought prompting across arithmetic and symbolic reasoning tasks due to gradient noise and limited embedding movement

## Executive Summary
Thinking Tokens are an unsupervised approach for reasoning in language models that use a single embedding to simulate intermediate reasoning steps. This study compares TTs against Chain-of-Thought (CoT) prompting across arithmetic (digit multiplication, GSM8K) and symbolic reasoning tasks (OpenBookQA). Results show that TTs marginally improve or even hurt performance compared to CoT. Empirical analysis reveals that the single-token embedding in TTs leads to noisy gradients and inconsistent learning signals, limiting the model's ability to learn effective reasoning steps. Using multiple distinct embeddings instead of one significantly improves gradient quality and embedding movement, validating the hypothesis.

## Method Summary
The study compares Thinking Tokens (TT) against Chain-of-Thought (CoT) prompting using GPT-2 and Llama 3.2 models across three task domains: synthetic digit multiplication (2d, 3d, 4d), GSM8K mathematical reasoning, and OpenBookQA symbolic reasoning. Models are trained for 100 epochs (digit multiplication) or 5 epochs (natural language tasks) on 2 L40 GPUs with batch sizes of 128 and 512 respectively. The key innovation tests TT with one versus two distinct embeddings to evaluate gradient quality and learning effectiveness.

## Key Results
- TT marginally improves or hurts performance compared to CoT (e.g., 2.3% improvement on 4d multiplication, 0.7% on GSM8K)
- Single TT embedding shows minimal movement from initialization during training with smallest cumulative gradients
- Two distinct TT embeddings receive clear large cumulative gradients and show significant deviation from initialization, improving performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single embedding reuse causes gradient noise that degrades learning signals
- Mechanism: When the same embedding vector is used for multiple reasoning steps, backpropagation creates conflicting updates because each context requires different information
- Core assumption: Each reasoning step should ideally have independent learning signals to avoid interference
- Evidence anchors:
  - [abstract] "We hypothesize that this underperformance stems from the reliance on a single embedding for TTs, which results in inconsistent learning signals and introduces noisy gradients"
  - [section 3] "The gradient ∇L(eT T) with respect to the loss function L becomes inconsistent across training examples, as eT T serves multiple, contextually distinct roles across the token sequence"

### Mechanism 2
- Claim: Distinct embeddings provide clearer gradient signals by separating reasoning contexts
- Mechanism: Using multiple unique embeddings allows the model to isolate learning signals for each reasoning step, reducing interference and gradient ambiguity
- Core assumption: Separate embeddings create orthogonal learning spaces that prevent cross-context contamination
- Evidence anchors:
  - [section 3.1] "This reuse of embeddings across different contexts introduces ambiguity into the learning signals, making it harder for the model to cleanly separate the contribution of each reasoning step"
  - [section 4.2] Figure 4 shows two TT embeddings receive "clear large cumulative gradients" compared to one embedding

### Mechanism 3
- Claim: Embedding movement correlates with learning effectiveness
- Mechanism: When embeddings travel significant distances from initialization during training, it indicates the model is adapting representations to capture reasoning patterns
- Core assumption: Static embeddings near initialization indicate the model isn't learning useful representations
- Evidence anchors:
  - [section 4.2] Figure 2 shows "One TT embedding hardly moves from the initialized value" indicating limited expressivity
  - [section 4.2] Figure 5 shows two embeddings "show clear deviation from initialization" with measurable L2 distance

## Foundational Learning

- **Concept**: Gradient descent and backpropagation mechanics
  - Why needed here: Understanding how single vs multiple embeddings affect gradient computation and update rules is central to the hypothesis
  - Quick check question: What happens to gradient updates when the same parameter is used in multiple parts of the computation graph?

- **Concept**: Embedding space geometry and vector representation
  - Why needed here: The analysis relies on understanding how embeddings move in vector space and what different movement patterns indicate about learning
  - Quick check question: How does L2 distance between initial and final embedding values relate to learning progress?

- **Concept**: Chain-of-thought vs unsupervised reasoning architectures
  - Why needed here: The comparison between explicit step-by-step reasoning and implicit latent reasoning requires understanding both approaches' mechanisms
  - Quick check question: What's the fundamental difference in how CoT and TT handle intermediate reasoning steps at the architectural level?

## Architecture Onboarding

### Component Map
GPT-2/Llama 3.2 model -> Input sequence -> TT or CoT processing -> Output prediction

### Critical Path
Input tokenization → Embedding layer → TT/CoT processing → Attention layers → Output layer → Loss computation → Backpropagation

### Design Tradeoffs
- TT offers unsupervised reasoning without manual step specification vs CoT's explicit step-by-step approach
- Single embedding provides parameter efficiency but causes gradient interference vs multiple embeddings providing better learning signals but increased parameters

### Failure Signatures
- TT underperforms CoT by 1-3% on accuracy metrics
- Single TT embeddings show minimal movement from initialization during training
- Cumulative gradients for single embeddings are significantly smaller than multiple embeddings

### First 3 Experiments
1. Compare TT vs CoT performance on synthetic digit multiplication tasks
2. Measure embedding movement and cumulative gradients for single vs multiple TT embeddings
3. Test TT performance with varying numbers of distinct embeddings (1, 2, 3) to find optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Thinking Tokens compare when using multiple distinct embeddings versus a single embedding across different reasoning tasks?
- Basis in paper: [explicit] The paper explicitly compares performance using one versus two distinct TT embeddings and shows significant improvements with multiple embeddings.
- Why unresolved: The study only tested two embeddings; the optimal number of distinct embeddings for different reasoning tasks remains unexplored.
- What evidence would resolve it: Systematic experiments varying the number of distinct embeddings (3, 4, 5, etc.) across multiple reasoning tasks to determine performance saturation points.

### Open Question 2
- Question: Can Thinking Tokens be combined with other unsupervised reasoning approaches to achieve performance comparable to Chain-of-Thought prompting?
- Basis in paper: [inferred] The paper shows that TT underperforms compared to CoT and suggests that future approaches should consider richer vector representations.
- Why unresolved: The paper only tests TT in isolation and combined with CoT, but does not explore other potential combinations with different unsupervised reasoning mechanisms.
- What evidence would resolve it: Experiments combining TT with other unsupervised methods like Pause Tokens, Tree-of-Thought, or other reasoning augmentation techniques.

### Open Question 3
- Question: What is the theoretical relationship between embedding dimensionality and the effectiveness of Thinking Tokens in capturing reasoning steps?
- Basis in paper: [explicit] The paper hypothesizes that single embedding leads to noisy gradients and inconsistent learning signals.
- Why unresolved: While the paper identifies the single-embedding problem, it doesn't establish a theoretical framework for optimal embedding dimensionality or structure.
- What evidence would resolve it: Mathematical analysis connecting embedding dimensionality, gradient stability, and reasoning task complexity, validated through controlled experiments.

## Limitations
- Modest performance differences (1-3%) between TT and CoT lack statistical significance testing
- Results may not generalize beyond arithmetic and symbolic reasoning to more complex tasks
- Implementation details like prompt formatting and tokenization strategies are underspecified

## Confidence
- **High Confidence**: The core finding that single TT embeddings show limited movement during training and receive smaller cumulative gradients is well-supported by empirical analysis
- **Medium Confidence**: The hypothesis that single embedding reuse causes gradient noise is plausible but relies on indirect evidence
- **Low Confidence**: The claim that TT "significantly underperforms" CoT is overstated given modest performance differences and lack of statistical testing

## Next Checks
1. **Statistical Significance Analysis**: Re-run experiments with multiple random seeds and compute confidence intervals for performance differences to determine if modest TT vs CoT differences are statistically significant
2. **Gradient Noise Quantification**: Implement direct measurements of gradient variance and interference for single vs multiple embeddings to empirically validate the noise hypothesis
3. **Cross-Domain Generalization**: Test TT and CoT on broader reasoning tasks including commonsense reasoning, multi-step planning, and code generation to evaluate whether single-embedding limitations persist across different reasoning modalities