---
ver: rpa2
title: Semantic Change Characterization with LLMs using Rhetorics
arxiv_id: '2407.16624'
source_url: https://arxiv.org/abs/2407.16624
tags:
- word
- sense
- change
- sentence
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes using large language models (LLMs) with rhetorical
  devices to characterize semantic change in three dimensions: dimension (broadening/narrowing),
  relation (metaphorization/metonymization), and orientation (amelioration/pejoration).
  The method leverages Chain-of-Thought reasoning with rhetorical techniques like
  zeugma, metaphor/metonymy identification, and antanagoge to infer sense differences
  and polarity changes.'
---

# Semantic Change Characterization with LLMs using Rhetorics

## Quick Facts
- arXiv ID: 2407.16624
- Source URL: https://arxiv.org/abs/2407.16624
- Reference count: 37
- Key outcome: Rhetoric-based approach using LLaMA-3-70B achieves 78% accuracy for dimension, 59% for relation, and 39% for orientation in semantic change characterization

## Executive Summary
This paper introduces a novel approach for characterizing semantic change using large language models (LLMs) with rhetorical devices. The method leverages Chain-of-Thought reasoning combined with rhetorical techniques like zeugma, metaphor/metonymy identification, and antanagoge to analyze semantic changes across three dimensions: dimension (broadening/narrowing), relation (metaphorization/metonymization), and orientation (amelioration/pejoration). The approach demonstrates improved accuracy over standard few-shot and Chain-of-Thought baselines, showing that LLMs can effectively mimic human-like semantic associations using stored cultural knowledge and rhetorical reasoning.

## Method Summary
The approach combines LLMs' Chain-of-Thought reasoning with rhetorical devices to characterize semantic change. For each dimension, specific rhetorical techniques are employed: zeugma for sense differentiation in dimension analysis, metaphor/metonymy identification for relation analysis, and antanagoge for orientation analysis. The method uses three newly created datasets containing 260, 331, and 262 sentence pairs respectively for evaluation. Few-shot Chain-of-Thought prompting guides the LLM through a step-by-step reasoning process using these rhetorical devices, enriching the context and allowing consideration of broader knowledge during decision-making.

## Key Results
- LLaMA-3-70B achieves highest accuracy: 78% for dimension, 59% for relation, and 39% for orientation
- Rhetoric-based approach outperforms standard few-shot and Chain-of-Thought baselines
- Experimental results validate the effectiveness of combining rhetorical devices with Chain-of-Thought prompting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can mimic human-like semantic associations by leveraging stored cultural knowledge and rhetorical reasoning.
- Mechanism: The approach combines Chain-of-Thought reasoning with rhetorical devices (zeugma, metaphor/metonymy identification, antanagoge) to create "cognitive-appealing" arguments that help the LLM differentiate between word senses and characterize semantic change.
- Core assumption: LLMs encode extensive cultural knowledge, including relationships, associations, and events, which can be leveraged for semantic change characterization.
- Evidence anchors: [abstract] "The approach demonstrates LLMs can effectively mimic human-like semantic associations using stored cultural knowledge and rhetorical reasoning."

### Mechanism 2
- Claim: Rhetorical devices facilitate sense differentiation and orientation analysis by creating explicit comparisons between word usages.
- Mechanism: Zeugma is used to test if two sentences can share the same word sense by attempting to construct a grammatically correct sentence that preserves the sense. Antanagoge is used to compare the positive/negative orientation of word senses by contrasting them.
- Core assumption: Rhetorical devices can effectively guide LLMs to perform sense disambiguation and orientation analysis similar to human evaluators.
- Evidence anchors: [abstract] "The method leverages Chain-of-Thought reasoning with rhetorical techniques like zeugma, metaphor/metonymy identification, and antanagoge to infer sense differences and polarity changes."

### Mechanism 3
- Claim: Few-shot Chain-of-Thought prompting with rhetorical devices improves LLM accuracy over standard few-shot and Chain-of-Thought baselines.
- Mechanism: The prompts are designed to guide the LLM through a step-by-step reasoning process using rhetorical devices, which enriches the context and allows the model to consider a broader range of knowledge during decision-making.
- Core assumption: Instructing an LLM to generate a rationale before providing an answer improves performance on tasks that require logical reasoning.
- Evidence anchors: [abstract] "Experimental results show that the rhetoric-based approach improves LLM accuracy over standard few-shot and Chain-of-Thought baselines."

## Foundational Learning

- Concept: Rhetorical devices and their cognitive functions
  - Why needed here: Rhetorical devices are used to guide the LLM's reasoning process and facilitate sense differentiation and orientation analysis.
  - Quick check question: Can you explain how zeugma, metaphor/metonymy identification, and antanagoge are used in this approach?

- Concept: Chain-of-Thought prompting
  - Why needed here: Chain-of-Thought prompting is used to guide the LLM through a step-by-step reasoning process, which improves performance on tasks that require logical reasoning.
  - Quick check question: What is the difference between standard few-shot prompting and Chain-of-Thought prompting?

- Concept: Lexical semantic change and its typologies
  - Why needed here: The approach is designed to characterize three types of semantic change: dimension (broadening/narrowing), relation (metaphorization/metonymization), and orientation (amelioration/pejoration).
  - Quick check question: Can you explain the difference between broadening and narrowing, metaphorization and metonymization, and amelioration and pejoration?

## Architecture Onboarding

- Component map: LLM -> Rhetorical devices (Zeugma, Metaphor/Metonymy ID, Antanagoge) -> Chain-of-Thought prompting -> Semantic change characterization

- Critical path:
  1. Provide the LLM with two sentences that share a specific word
  2. Instruct the LLM to analyze how the word is used in each sentence and determine if its usage in the second sentence represents the same sense, a metaphor/metonymy, or a different orientation
  3. Use rhetorical devices and Chain-of-Thought prompting to guide the LLM's reasoning process
  4. Generate the final answer based on the LLM's reasoning

- Design tradeoffs:
  - Accuracy vs. efficiency: Using more complex rhetorical devices and Chain-of-Thought prompting may improve accuracy but also increase computational cost
  - Generalizability vs. specificity: The approach is designed to characterize three types of semantic change, but it may not be applicable to other types of semantic change

- Failure signatures:
  - Incorrect sense differentiation: If the LLM fails to correctly identify whether two sentences use the same word sense or different senses
  - Incorrect figurative usage classification: If the LLM fails to correctly classify whether a word usage is a metaphor, metonymy, or unrelated
  - Incorrect orientation classification: If the LLM fails to correctly classify whether a word sense is positive, negative, or neutral

- First 3 experiments:
  1. Evaluate the approach on a small subset of the dimension dataset to assess the effectiveness of zeugma in sense differentiation
  2. Evaluate the approach on a small subset of the relation dataset to assess the effectiveness of metaphor/metonymy identification
  3. Evaluate the approach on a small subset of the orientation dataset to assess the effectiveness of antanagoge in orientation analysis

## Open Questions the Paper Calls Out

- Open Question 1: How do LLMs perform on semantic change characterization tasks in languages other than English, and what factors influence this performance?
- Open Question 2: Can LLMs generate genuinely novel rhetorical devices for semantic change characterization, or are they merely reproducing patterns from their training data?
- Open Question 3: How does the performance of rhetorical reasoning techniques compare to alternative prompting strategies for semantic change characterization?
- Open Question 4: What is the relationship between LLM reasoning coherence and accuracy in semantic change characterization tasks?

## Limitations

- Dataset Reliability Concerns: The paper creates three new datasets but does not provide detailed information about their construction methodology or inter-annotator agreement.
- Generalization Limitations: The approach relies heavily on cultural knowledge stored in LLMs and specific rhetorical devices, limiting broader applicability.
- Implementation Details: Several critical implementation details are missing, including exact few-shot examples and specific model configurations.

## Confidence

- High Confidence: The core mechanism of combining Chain-of-Thought prompting with rhetorical devices shows consistent improvement over baselines.
- Medium Confidence: The experimental results showing improved accuracy with the rhetoric-based approach are credible but require further validation.
- Low Confidence: Claims about LLMs effectively mimicking human-like semantic associations through stored cultural knowledge are largely theoretical.

## Next Checks

1. Conduct inter-annotator agreement studies on the three new datasets to establish reliability metrics.
2. Systematically remove each rhetorical device from the prompts to quantify their individual contributions.
3. Apply the approach to at least two additional languages with different typological features to assess generalizability.