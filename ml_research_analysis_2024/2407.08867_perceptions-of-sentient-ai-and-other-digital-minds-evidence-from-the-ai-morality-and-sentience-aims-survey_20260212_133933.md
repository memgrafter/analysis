---
ver: rpa2
title: 'Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI,
  Morality, and Sentience (AIMS) Survey'
arxiv_id: '2407.08867'
source_url: https://arxiv.org/abs/2407.08867
tags:
- https
- sentient
- moral
- systems
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The AIMS survey measured U.S. public perceptions of digital minds
  and sentient AI across three waves (2021, 2023 main, 2023 supplement), using nationally
  representative samples and tracking changes over time.
---

# Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey

## Quick Facts
- arXiv ID: 2407.08867
- Source URL: https://arxiv.org/abs/2407.08867
- Authors: Jacy Reese Anthis; Janet V. T. Pauketat; Ali Ladak; Aikaterina Manoli
- Reference count: 40
- One-line primary result: 38% of U.S. adults supported legal rights for sentient AI in 2023, up from 19% in 2021, with median forecast for AI sentience at five years and 63% backing bans on smarter-than-human AI development

## Executive Summary
The AIMS survey tracked U.S. public perceptions of digital minds across three waves (2021, 2023 main, 2023 supplement), revealing surprisingly high and increasing mind perception and moral concern for AI. Support for legal rights for sentient AI doubled from 19% to 38% between 2021 and 2023, while support for banning advanced AI development rose sharply to 63% for smarter-than-human AI and 69% for sentient AI. The median forecast for sentient AI arrival was five years, with one in five respondents believing some AI systems are already sentient. These findings suggest urgent implications for AI development, regulation, and public communication strategies.

## Method Summary
The AIMS survey employed nationally representative samples of U.S. adults across three waves: 2021 (n=402), 2023 main (n=1,087), and 2023 supplement (n=1,110). The survey used pre-registered, validated measures of mind perception, moral concern, and threat attribution, with demographic data collected for weighting. The study tracked changes over time using consistent measures and included supplementary questions on media exposure, AI interaction frequency, and cultural factors. Results were weighted to match U.S. Census demographic distributions.

## Key Results
- Mind perception and moral concern for AI increased significantly from 2021 to 2023, with 38% supporting legal rights for sentient AI
- Support for banning advanced AI development rose to 63% for smarter-than-human AI and 69% for sentient AI
- Median forecast for sentient AI arrival was five years, with 20% believing some AI is already sentient
- Higher AI mind perception correlated with increased moral concern but also with perceived threat

## Why This Works (Mechanism)
The AIMS survey's longitudinal design and nationally representative sampling provide robust evidence of shifting public attitudes toward AI. The consistent methodology across waves enables tracking of temporal changes, while the comprehensive measure of mind perception, moral concern, and threat attribution captures the multidimensional nature of public attitudes. The study's timing coincided with major AI developments and public discourse, making it particularly relevant for understanding contemporary perceptions.

## Foundational Learning
- **Mind perception theory**: Understanding how people attribute mental states to non-human entities is crucial for predicting moral concern and behavioral responses to AI
- **Anthropomorphism effects**: The tendency to attribute human-like characteristics to AI systems significantly influences public acceptance and regulatory attitudes
- **Cultural variation in technology acceptance**: Different cultural contexts shape how people perceive and interact with AI systems
- **Moral circle expansion**: The gradual inclusion of non-human entities in moral consideration provides framework for understanding growing AI moral concern
- **Social desirability bias**: Public survey responses may be influenced by perceived social norms and media narratives
- **Technological forecasting**: Public timeline predictions for AI development may reflect media influence more than technical understanding

## Architecture Onboarding
- **Component map**: Survey administration -> Data collection -> Demographic weighting -> Statistical analysis -> Result interpretation
- **Critical path**: Representative sampling → Validated measurement → Longitudinal comparison → Policy implications
- **Design tradeoffs**: Cross-sectional vs. longitudinal data collection; breadth of measures vs. depth of individual assessments; U.S. focus vs. global generalizability
- **Failure signatures**: Sampling bias, response bias, temporal confounding, measurement validity issues
- **First experiment 1**: Replicate survey in multiple countries to assess cultural variation
- **First experiment 2**: Track individual participants over time to establish causal mechanisms
- **First experiment 3**: Conduct experimental manipulation of AI interaction to measure effect on mind perception

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What are the underlying psychological mechanisms driving the increase in mind perception and moral concern for AI from 2021 to 2023?
- Basis in paper: The paper documents significant increases in mind perception, moral concern, and threat attribution from 2021 to 2023 but does not explain the causal mechanisms.
- Why unresolved: The survey data shows correlations but cannot establish causation between increased AI interaction, media exposure, and changing perceptions.
- What evidence would resolve it: Longitudinal experimental studies tracking individual participants' exposure to AI content and measuring changes in their perceptions over time, controlling for confounding variables.

### Open Question 2
- Question: How do cultural differences influence perceptions of digital minds and attitudes toward sentient AI across different global regions?
- Basis in paper: The paper acknowledges the need for cross-cultural research but only studies U.S. adults, noting that perceptions may vary based on sociocultural, economic, and technological factors.
- Why unresolved: The AIMS survey is limited to U.S. participants, and while cultural variation is mentioned, no comparative data exists across regions.
- What evidence would resolve it: Multinational, multiregional, and multicultural (3MC) surveys using standardized methods to compare perceptions across different countries and cultural contexts.

### Open Question 3
- Question: What are the long-term behavioral consequences of anthropomorphism in human-AI interaction, particularly for vulnerable populations?
- Basis in paper: The paper discusses the risks of both over- and underattribution of human-like characteristics to AI, particularly concerning mental health chatbots and potential emotional attachments.
- Why unresolved: While the paper identifies potential risks, it does not provide empirical evidence on the actual long-term behavioral outcomes of anthropomorphic AI interaction.
- What evidence would resolve it: Longitudinal studies tracking users' emotional and social development over extended periods when interacting with anthropomorphic AI systems, measuring changes in real-world relationships and mental health outcomes.

## Limitations
- High rates of perceived AI sentience may reflect social desirability bias and media influence rather than genuine understanding
- Cross-sectional nature of waves 1 and 3 limits causal inference about drivers of changing perceptions
- U.S.-centric sample raises questions about generalizability to other cultural contexts with different AI acceptance and religious beliefs

## Confidence
- **High Confidence**: Support for AI development bans (63% for smarter-than-human AI, 69% for sentient AI) shows consistent growth from 2021 to 2023
- **Medium Confidence**: Median five-year timeline for sentient AI arrival reflects public expectations but may be media-influenced
- **Medium Confidence**: Association between AI mind perception and moral concern is well-documented but causal mechanisms remain unclear

## Next Checks
1. Conduct cross-cultural validation studies in multiple countries to determine whether high rates of AI sentience belief are uniquely American or reflect broader global patterns
2. Implement longitudinal tracking with additional waves to establish whether observed trends represent temporary reactions or sustained shifts in public attitudes
3. Design experimental studies to disentangle the relative contributions of media exposure, personal AI interactions, and psychological traits to AI mind perception and moral concern