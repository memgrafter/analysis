---
ver: rpa2
title: 'FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop
  Question Answering'
arxiv_id: '2407.02964'
source_url: https://arxiv.org/abs/2407.02964
tags:
- answer
- question
- reasoning
- manchu
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FSM, a zero-shot prompting paradigm for multi-hop
  question answering using large language models. FSM addresses challenges like hallucination,
  error propagation, and limited context length by decomposing complex questions into
  iterative sub-tasks, enabling step-by-step reasoning with self-correction.
---

# FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering

## Quick Facts
- arXiv ID: 2407.02964
- Source URL: https://arxiv.org/abs/2407.02964
- Reference count: 6
- Primary result: Introduces FSM (Finite State Machine) paradigm for zero-shot multi-hop question answering using LLMs, achieving higher F1 scores than baselines on Musique, HotpotQA, and 2Wiki datasets

## Executive Summary
This paper introduces FSM (Finite State Machine), a zero-shot prompting paradigm for multi-hop question answering using large language models. FSM addresses challenges like hallucination, error propagation, and limited context length by decomposing complex questions into iterative sub-tasks, enabling step-by-step reasoning with self-correction. Experiments on benchmarks like Musique, HotpotQA, and 2Wiki show FSM achieves higher F1 scores than baselines, especially on challenging datasets. FSM also improves format consistency, reducing the need for post-processing. The method is adaptable to other tasks like natural language to SQL.

## Method Summary
FSM operates by decomposing complex multi-hop questions into iterative sub-tasks using a state machine framework. The approach breaks down reasoning into discrete states where each state represents a specific reasoning step or sub-task. The system employs self-correction mechanisms at each state transition to mitigate error propagation. By structuring the reasoning process as a finite state machine, FSM can handle the complexity of multi-hop questions while maintaining interpretability and reducing hallucination through its step-by-step approach.

## Key Results
- FSM achieves higher F1 scores than baseline approaches on Musique, HotpotQA, and 2WikiMultiHopQA benchmarks
- The method shows particular effectiveness on challenging datasets where traditional approaches struggle
- FSM improves format consistency of outputs, significantly reducing the need for post-processing steps
- The approach demonstrates adaptability to other tasks such as natural language to SQL conversion

## Why This Works (Mechanism)
FSM works by structuring the reasoning process as a finite state machine, which provides a systematic framework for decomposing complex multi-hop questions into manageable sub-tasks. Each state represents a specific reasoning step, allowing the model to focus on one aspect of the problem at a time. The self-correction mechanism at state transitions helps prevent error accumulation that typically occurs in sequential reasoning tasks. The iterative decomposition approach ensures that each sub-task receives appropriate attention and resources, while the state-based structure provides clear checkpoints for validation and correction.

## Foundational Learning
- **Multi-hop question answering**: Understanding questions requiring multiple reasoning steps and evidence pieces - needed to identify the complexity FSM addresses
- **Error propagation in LLMs**: Recognizing how mistakes compound in sequential reasoning tasks - needed to appreciate FSM's self-correction mechanisms
- **State machine theory**: Basic understanding of finite state machines as computational models - needed to grasp FSM's architectural foundation
- **Zero-shot prompting**: Knowledge of prompting techniques that don't require task-specific training - needed to understand FSM's operational paradigm
- **Hallucination in LLMs**: Awareness of how models generate plausible but incorrect information - needed to contextualize FSM's format consistency improvements

## Architecture Onboarding

**Component map**: Question Decomposition -> State Machine Engine -> Self-Correction Module -> Output Generation

**Critical path**: Input Question → Decomposition (State 1) → Intermediate Reasoning (State 2-N) → Self-Correction (Between States) → Final Answer (State N+1)

**Design tradeoffs**: 
- FSM prioritizes interpretability and error control over raw speed
- The state machine approach adds structural overhead but reduces hallucination
- Iterative decomposition increases computational steps but improves accuracy
- Self-correction mechanisms add latency but prevent error propagation

**Failure signatures**:
- Improperly formatted outputs in multi-turn dialogue scenarios
- State transitions that don't align with natural reasoning flow
- Accumulation of small errors in highly complex reasoning chains
- Performance degradation when question structure doesn't map well to discrete states

**3 first experiments**:
1. Test FSM on a simple two-hop question to verify basic state transition functionality
2. Run an ablation study removing self-correction to measure its impact on error propagation
3. Evaluate FSM's performance on a single-hop question to establish baseline effectiveness

## Open Questions the Paper Calls Out
- How FSM handles improperly formatted outputs in multi-turn dialogue scenarios
- Whether the state machine approach can be optimized for faster processing without sacrificing accuracy
- The scalability of FSM to questions requiring more than 3-4 reasoning hops

## Limitations
- Limited evaluation to specific benchmark datasets (Musique, HotpotQA, 2Wiki) without extensive cross-dataset validation
- Adaptability claims to other tasks like natural language to SQL lack experimental demonstration
- Acknowledged difficulty handling improperly formatted outputs in multi-turn dialogue scenarios
- No extensive ablation studies to isolate the contribution of individual components

## Confidence
- **Medium-High**: Core methodology and demonstrated improvements over baselines on tested datasets
- **Medium-Lower**: Generalizability claims across diverse datasets and question types
- **Medium**: Adaptability claims to other tasks without supporting experimental evidence
- **Medium**: Interpretability benefits without user studies or comprehensive error analysis

## Next Checks
1. Conduct ablation studies to quantify the individual contributions of the FSM components (state transitions, self-correction mechanisms, iterative decomposition) to overall performance
2. Test FSM on additional multi-hop QA datasets and related reasoning tasks (e.g., complex mathematical reasoning, multi-document summarization) to evaluate generalizability
3. Implement and evaluate the natural language to SQL adaptation claim with quantitative performance metrics on established semantic parsing benchmarks