---
ver: rpa2
title: 'Cradle: Empowering Foundation Agents Towards General Computer Control'
arxiv_id: '2403.03186'
source_url: https://arxiv.org/abs/2403.03186
tags:
- action
- task
- should
- current
- last
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "CRADLE is a novel modular LMM-powered framework that enables foundation\
  \ agents to interact with diverse software environments through a unified interface\
  \ of screenshots as input and keyboard/mouse actions as output. By integrating six\
  \ key modules\u2014Information Gathering, Self-Reflection, Task Inference, Skill\
  \ Curation, Action Planning, and Memory\u2014CRADLE can autonomously complete complex\
  \ tasks across commercial video games (e.g., Red Dead Redemption 2, Stardew Valley,\
  \ Dealer\u2019s Life 2, Cities: Skylines) and software applications (Chrome, Outlook,\
  \ CapCut, Meitu, Feishu)."
---

# Cradle: Empowering Foundation Agents Towards General Computer Control

## Quick Facts
- arXiv ID: 2403.03186
- Source URL: https://arxiv.org/abs/2403.03186
- Reference count: 40
- One-line primary result: CRADLE achieves high success rates in general computer control across commercial games and software applications using a unified screenshot-to-action framework

## Executive Summary
CRADLE introduces a novel modular framework that enables foundation agents to interact with diverse software environments through a unified interface using screenshots as input and keyboard/mouse actions as output. By integrating six key modules—Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory—CRADLE can autonomously complete complex tasks across commercial video games and software applications. The framework demonstrates strong generalization capabilities, achieving high success rates in environments ranging from Red Dead Redemption 2 to Chrome and Outlook, advancing the path toward generalist AI agents.

## Method Summary
CRADLE is a modular LMM-powered framework that enables foundation agents to interact with diverse software environments through a unified interface of screenshots as input and keyboard/mouse actions as output. The framework integrates six key modules—Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory—to process multimodal observations and generate executable control actions. Information Gathering extracts visual and textual data from screenshots, while Action Planning converts high-level reasoning into low-level OS-level keyboard and mouse commands. Memory modules (episodic and procedural) store experiences and skills for reuse and adaptation across tasks. The framework uses GPT-4o as the backbone model and demonstrates autonomous completion of complex tasks across commercial video games and software applications.

## Key Results
- Completes 40-minute missions in Red Dead Redemption 2 with high success rates
- Creates cities of over 1,000 people in Cities: Skylines
- Achieves up to 87% weekly profit in Dealer's Life 2

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CRADLE's modular LMM-powered framework can generalize across diverse software environments by using screenshots as input and keyboard/mouse actions as output, avoiding reliance on built-in APIs.
- Mechanism: The framework integrates six key modules—Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory—to process multimodal observations and generate executable control actions. Information Gathering extracts visual and textual data from screenshots, while Action Planning converts high-level reasoning into low-level OS-level keyboard and mouse commands. Memory modules (episodic and procedural) store experiences and skills for reuse and adaptation across tasks.
- Core assumption: Multimodal LMMs can accurately interpret diverse UI layouts, icons, and dynamic content from screenshots and map them to corresponding keyboard and mouse actions

## Foundational Learning

### Multimodal Large Language Models (LMMs)
- Why needed: To process both visual and textual information from software interfaces for decision-making
- Quick check: Verify LMM can accurately identify UI elements and text from screenshots across different applications

### Computer Vision Integration
- Why needed: To extract structured information from unstructured visual inputs like screenshots and video frames
- Quick check: Test object detection accuracy on diverse UI layouts and dynamic game scenes

### Action Planning Pipeline
- Why needed: To convert high-level reasoning into executable low-level keyboard and mouse commands
- Quick check: Validate generated actions produce expected outcomes when executed on target applications

## Architecture Onboarding

### Component Map
- Information Gathering -> Self-Reflection -> Task Inference -> Skill Curation -> Action Planning -> Memory

### Critical Path
- Screenshot capture → Information Gathering → Task Inference → Action Planning → Execute actions → Memory update

### Design Tradeoffs
- Flexibility vs. efficiency: Modular design enables generalization but increases computational overhead
- Visual prompting vs. tool augmentation: Additional visual cues help LMM understanding but add complexity

### Failure Signatures
- OCR failures leading to incorrect information extraction
- Spatial reasoning limitations causing imprecise mouse movements
- Skill mismatch between planned actions and available procedures

### 3 First Experiments
1. Test basic screenshot interpretation across 5 different software applications
2. Validate action planning module generates correct keyboard/mouse sequences for simple tasks
3. Measure memory module effectiveness in task completion rate improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CRADLE handle situations where GPT-4o's OCR capabilities fail to recognize critical UI elements or text?
- Basis in paper: [explicit] The paper mentions relying on GPT-4o's OCR capabilities but also notes limitations in recognizing domain-specific concepts and icons.
- Why unresolved: The paper doesn't provide specific strategies for handling OCR failures beyond mentioning the use of additional tools like Grounding DINO and template matching.
- What evidence would resolve it: Examples of how CRADLE adapts when OCR fails, alternative methods for information gathering, or quantitative data on OCR accuracy and fallback mechanisms.

### Open Question 2
- Question: What is the computational overhead of CRADLE's multiple module system compared to simpler, single-request approaches?
- Basis in paper: [inferred] The paper discusses six distinct modules (Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory) but doesn't provide performance comparisons with simpler approaches.
- Why unresolved: The paper focuses on the framework's capabilities rather than efficiency metrics, leaving questions about practical deployment costs.
- What evidence would resolve it: Runtime comparisons between CRADLE and single-request approaches, cost analysis of multiple LMM interactions, or benchmarks of processing time per action.

### Open Question 3
- Question: How does CRADLE scale to handle multiple simultaneous tasks or multitasking scenarios?
- Basis in paper: [inferred] The paper discusses long-horizon tasks but doesn't address how the framework handles task switching or concurrent operations.
- Why unresolved: The sequential nature of the modules suggests potential limitations in multitasking, but this isn't explicitly explored in the paper.
- What evidence would resolve it: Experiments testing task switching performance, metrics on context switching efficiency, or demonstrations of handling multiple concurrent software applications.

## Limitations

- Limited evaluation to 6 games and 5 software applications, all in English language environments
- Success rates may not reflect efficiency or reliability of the system
- Acknowledged technical limitations in spatial reasoning and pixel-level precision

## Confidence

- **Medium**: Claims about CRADLE's modular architecture and integration of six key modules
- **Medium**: Success rate comparisons with baseline methods on specified benchmarks
- **Low**: Generalization claims to "any software" as benchmark without systematic testing across diverse applications

## Next Checks

1. Test CRADLE on at least 10 additional software applications with diverse UI paradigms (CAD software, data analysis tools, enterprise applications) to validate generalization claims beyond the initial 11 environments.

2. Implement automated error recovery and continue execution protocols to measure true autonomous capability without human intervention, particularly for the long-horizon tasks (40-minute missions, 1000+ population cities).

3. Conduct ablation studies removing individual modules (Memory, Self-Reflection, Skill Curation) to quantify their specific contributions to overall performance and identify potential redundancy or bottlenecks in the system architecture.