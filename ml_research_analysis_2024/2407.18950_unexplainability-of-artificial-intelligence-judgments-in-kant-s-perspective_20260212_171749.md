---
ver: rpa2
title: Unexplainability of Artificial Intelligence Judgments in Kant's Perspective
arxiv_id: '2407.18950'
source_url: https://arxiv.org/abs/2407.18950
tags:
- judgment
- judgments
- human
- kant
- however
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examines the unexplainability of AI judgments by analyzing\
  \ them through Kant\u2019s framework of judgment forms. It identifies that AI judgments\
  \ exhibit uncertainty because different forms of judgment (quantity, quality, relation,\
  \ modality) become entangled and are not clearly distinguishable."
---

# Unexplainability of Artificial Intelligence Judgments in Kant's Perspective

## Quick Facts
- arXiv ID: 2407.18950
- Source URL: https://arxiv.org/abs/2407.18950
- Authors: Jongwoo Seo
- Reference count: 6
- Primary result: AI judgments are inherently unexplainable because different Kantian judgment forms become entangled and the SoftMax function forces all judgments into probabilistic possibility forms.

## Executive Summary
This study examines why AI judgments cannot be fully explained by analyzing them through Kant's framework of judgment forms. The research identifies that AI outputs exhibit uncertainty because quantity, quality, relation, and modality forms become entangled rather than being clearly distinguishable. The SoftMax function in AI systems forces all judgments into possibility forms, regardless of their true modal nature. Since natural language lacks complete definitions, full functional implementation of concepts remains theoretically impossible, leading to inherent unexplainability even in advanced AI systems.

## Method Summary
The study draws on Kant's theory of judgment from the Critique of Pure Reason to analyze AI system outputs. It examines how AI numerical outputs map (or fail to map) to Kant's four logical forms of judgment: quantity, quality, relation, and modality. The research focuses particularly on the role of the SoftMax function in reframing AI judgments as possibility judgments and considers the limitations imposed by the incompleteness of natural language definitions. The analysis is primarily philosophical and conceptual rather than empirical.

## Key Results
- AI judgments exhibit uncertainty because different Kantian judgment forms become entangled in the same output
- The SoftMax function collapses all judgments into possibility judgments, erasing modality distinctions
- Natural language words lack complete definitions, making full functional implementation of concepts theoretically impossible

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AI judgments lack full explainability because different Kantian judgment forms become entangled in the same output
- Mechanism: When an AI system produces a numerical output (e.g., 1 for "dog present"), that output cannot be uniquely mapped to a single logical form like "universal" or "singular," nor to a specific quality form like "affirmative" or "negative." This forces multiple judgment types into one undifferentiated signal.
- Core assumption: Each form of judgment requires distinct logical structure that cannot be captured by a single numeric output.
- Evidence anchors:
  - [abstract] "AI's uncertainty, a condition in which different forms of judgment become entangled"
  - [section] "we cannot classify its form in quantity in Table 1" and "it is unclear which pure concepts of the understanding listed in Table 3 should mediate the interpretation"
- Break condition: If future AI architectures explicitly separate and encode each judgment form as distinct components, this entanglement could be resolved.

### Mechanism 2
- Claim: The SoftMax function collapses all judgments into possibility judgments, erasing modality distinctions.
- Mechanism: SoftMax normalizes outputs to probabilities summing to 1, forcing interpretation as "might be" rather than preserving necessity, actuality, or contingency forms. Even definite judgments are reframed probabilistically.
- Core assumption: Different modalities (problematic, assertoric, apodictic) are semantically and functionally distinct.
- Evidence anchors:
  - [abstract] "the SoftMax function forcibly reframes AI judgments as possibility judgments"
  - [section] "SoftMax acts as an epistemological filter, compelling the interpretation of AI judgments in terms of possibility" and "even firm judgments can be reframed within a probability distribution"
- Break condition: If alternative output layers or loss functions preserve modality distinctions without probabilistic collapse, this mechanism would break.

### Mechanism 3
- Claim: Natural language words lack complete definitions, so full functional implementation of concepts is theoretically impossible.
- Mechanism: Since definitions are inherently incomplete (Kant's incompleteness), words cannot be fully specified; thus any system learning from natural language cannot achieve complete functional realization of concepts.
- Core assumption: A complete functional implementation requires a complete definition.
- Evidence anchors:
  - [abstract] "since complete definitions in natural language are impossible, words are, by their very nature, ultimately unexplainable"
  - [section] "a definition is always incomplete and can only express a concept to the extent that it is distinguishable"
- Break condition: If a formal symbolic system or grounded representation can achieve operational completeness without natural language definitions, this mechanism would break.

## Foundational Learning

- Concept: Kantian judgment forms (quantity, quality, relation, modality)
  - Why needed here: The paper's core argument rests on mapping AI outputs to these forms; without understanding them, the entanglement claim cannot be evaluated.
  - Quick check question: Which judgment form answers "How many?" versus "How sure?"
- Concept: SoftMax function in neural networks
  - Why needed here: The mechanism that forces AI outputs into probabilistic possibility judgments; essential to understanding modality collapse.
  - Quick check question: What property must all SoftMax outputs satisfy, and why does that imply possibility?
- Concept: Functionalism in AI
  - Why needed here: The paper's framework assumes AI can be judged by functional similarity rather than ontological identity; understanding this distinction is key to interpreting the claims.
  - Quick check question: How does functionalism differ from asking whether AI has "true understanding"?

## Architecture Onboarding

- Component map:
  - Input layer → Neural network (matrix multiplications) → Output layer (often SoftMax) → Post-processing (interpretation as judgment)
  - Separate module needed to map outputs to Kantian forms (currently missing)
- Critical path:
  - Forward pass → Output generation → SoftMax normalization → Interpretation as judgment
  - Weakness: No stage explicitly preserves or distinguishes judgment forms
- Design tradeoffs:
  - Using SoftMax simplifies multi-class prediction but collapses modality distinctions
  - Using raw logits preserves more information but lacks probabilistic interpretability
- Failure signatures:
  - Inability to map outputs to specific Kantian forms
  - All judgments interpreted as possibility regardless of true modality
  - Inconsistent interpretation of the same numeric output across contexts
- First 3 experiments:
  1. Replace SoftMax with a multi-head output where one head predicts modality and another predicts probability; check if modality can be preserved.
  2. Train a classifier to categorize model outputs into Kantian judgment forms based on input-output pairs; measure accuracy of classification.
  3. Implement a symbolic layer that maps neural outputs to explicit logical forms; test if this layer can disambiguate entangled judgments.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can AI judgments be mapped to Kant's specific categories of quantity, quality, and relation given their numerical outputs?
- Basis in paper: [explicit] The paper identifies that AI judgments produce numerical outputs (e.g., 0 or 1 for classification) that don't clearly map to Kant's categories of quantity (Universal, Particular, Singular), quality (Affirmative, Negative, Infinite), or relation (Categorical, Hypothetical, Disjunctive).
- Why unresolved: The paper demonstrates that AI outputs are ambiguous when interpreted through Kant's framework, as numerical representations lack the categorical distinctions present in human language and judgment.
- What evidence would resolve it: Developing formal mappings between AI output representations (probabilities, classifications) and Kant's logical categories, or creating AI systems that explicitly produce judgments in Kantian forms.

### Open Question 2
- Question: Does the SoftMax function fundamentally limit AI judgments to possibility modality, preventing other modal forms like actuality or necessity?
- Basis in paper: [explicit] The paper argues that SoftMax function normalizes outputs to sum to 1, forcing AI judgments into probabilistic forms that resemble possibility judgments, even when the underlying judgment might be assertoric (actual) or apodictic (necessary).
- Why unresolved: The paper demonstrates that SoftMax creates an epistemological filter that reframes all judgments as possibilities, but doesn't prove whether alternative architectures could preserve modal distinctions.
- What evidence would resolve it: Developing AI architectures that can produce judgments in multiple modalities without probability normalization, or demonstrating that modal distinctions are indeed lost in current implementations.

### Open Question 3
- Question: Can complete functional implementation of concepts be achieved in AI systems given the inherent incompleteness of natural language definitions?
- Basis in paper: [explicit] The paper states that according to Kant, definitions in natural language are always incomplete and can only express concepts to the extent they are distinguishable, making complete functional implementation theoretically unattainable.
- Why unresolved: The paper demonstrates the theoretical limitation through Kant's epistemology but doesn't explore whether practical implementations can overcome this limitation through alternative approaches.
- What evidence would resolve it: Demonstrating AI systems that can functionally implement concepts with complete precision, or proving through formal methods that such completeness is impossible regardless of technological advancement.

## Limitations

- The mapping between Kant's judgment forms and AI outputs is conceptual rather than operationalized, making claims difficult to verify empirically
- The assertion that natural language definitions are "impossible" to complete lacks formal proof or computational demonstration
- The study does not address whether alternative AI architectures or training approaches could circumvent the identified limitations

## Confidence

- High confidence: The SoftMax function does indeed produce probability distributions and can be shown to reframe outputs as possibility judgments (Mechanism 2)
- Medium confidence: The conceptual argument that judgment forms become entangled in AI outputs is philosophically coherent but lacks empirical demonstration (Mechanism 1)
- Low confidence: The claim that complete definitions in natural language are theoretically impossible requires further philosophical and computational justification (Mechanism 3)

## Next Checks

1. **Empirical validation of judgment form entanglement**: Create a dataset where human annotators categorize AI outputs according to Kant's four judgment forms, then measure inter-annotator agreement and consistency. Low agreement would support the entanglement claim.

2. **Alternative output layer comparison**: Implement and train models with both SoftMax and alternative output layers (raw logits, sigmoid for multi-label, or explicit modality prediction heads) on the same task. Compare interpretability, performance, and ability to preserve modality distinctions.

3. **Formal incompleteness proof**: Attempt to formalize the incompleteness of natural language definitions using formal semantics or type theory. Either construct a proof of inherent incompleteness or identify cases where complete definitions are possible, challenging the theoretical impossibility claim.