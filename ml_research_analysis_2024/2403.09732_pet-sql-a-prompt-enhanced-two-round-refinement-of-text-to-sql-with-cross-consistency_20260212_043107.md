---
ver: rpa2
title: 'PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency'
arxiv_id: '2403.09732'
source_url: https://arxiv.org/abs/2403.09732
tags:
- schema
- llms
- prompt
- table
- linking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a two-round Text-to-SQL framework called PET-SQL,
  which addresses challenges in handling verbose database information and complex
  user intentions. The method introduces a reference-enhanced prompt representation
  that includes schema information and randomly sampled cell values, followed by a
  preliminary SQL generation and schema linking approach.
---

# PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency

## Quick Facts
- arXiv ID: 2403.09732
- Source URL: https://arxiv.org/abs/2403.09732
- Reference count: 40
- Key outcome: Achieves 87.6% execution accuracy on Spider benchmark, outperforming state-of-the-art by 1.3%

## Executive Summary
This paper introduces PET-SQL, a two-round Text-to-SQL framework that addresses challenges in handling verbose database information and complex user intentions. The method employs a reference-enhanced prompt representation that includes schema information, randomly sampled cell values, and foreign key declarations. A novel PreSQL-based schema linking approach generates preliminary SQL to identify relevant schema elements before final query generation. The framework incorporates cross-consistency across multiple LLMs as post-refinement, replacing traditional self-consistency methods. The approach achieves state-of-the-art results on the Spider benchmark with 87.6% execution accuracy.

## Method Summary
PET-SQL is a two-round Text-to-SQL framework that first generates a reference-enhanced prompt representation including schema information and randomly sampled cell values. It then produces a preliminary SQL (PreSQL) to identify relevant schema elements through parsing, which simplifies the prompt for final SQL generation. The framework employs cross-consistency across multiple LLMs as post-refinement, where different models generate SQL queries at low temperatures and results are voted on to produce the final output. This approach reduces prompt length by 32% while improving execution accuracy by 2% compared to baseline methods.

## Key Results
- Achieves 87.6% execution accuracy on Spider benchmark, outperforming state-of-the-art by 1.3%
- PreSQL-based schema linking reduces prompt length by 32% while maintaining accuracy
- Cross-consistency mechanism improves accuracy by 2% compared to self-consistency
- Combines reference-enhanced representation with schema simplification for optimal performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reference-enhanced prompt representation improves SQL generation by providing schema information, randomly sampled cell values, and foreign key declarations.
- Mechanism: The prompt includes optimization rules for SQL execution efficiency, cell value references to standardize query formats, and foreign key declarations to help LLMs understand table relationships.
- Core assumption: LLMs can better understand database structures and user intentions when provided with comprehensive prompt information including cell values and foreign key relationships.
- Evidence anchors:
  - [abstract] "We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries."
  - [section] "We enrich the prompt based on OpenAI Demonstration (ODp), and we name our proposed as Reference-Enhanced representation (REp)."

### Mechanism 2
- Claim: PreSQL-based schema linking improves accuracy by generating a preliminary SQL and parsing table/column entities from it.
- Mechanism: Instead of directly linking schema, the LLM first generates a preliminary SQL (PreSQL), then the mentioned table/column entities are parsed as the linking results.
- Core assumption: LLMs are better at generating SQL code than directly performing schema linking tasks, and the PreSQL can provide more accurate schema information.
- Evidence anchors:
  - [abstract] "After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information."
  - [section] "Therefore, rather than instructing the LLMs to link schema, we instruct LLMs to generate a preliminary SQL (PreSQL), and then the table and column entities mentioned in the PreSQL are parsed as the linking results."

### Mechanism 3
- Claim: Cross-consistency across different LLMs improves performance by reducing hallucinations and increasing diversity.
- Mechanism: Multiple LLMs generate SQL queries at low temperatures, and the results are voted on to produce the final SQL.
- Core assumption: Different LLMs have different strengths and weaknesses, and combining their outputs can lead to more accurate results than using a single LLM.
- Evidence anchors:
  - [abstract] "Finally, as the post-refinement module, we propose using cross-consistency across different LLMs rather than self-consistency within a particular LLM."
  - [section] "We instead innovatively propose a 'cross-consistency', which calls multiple different LLMs at a low temperature, guaranteeing diversity (due to different LLMs) and further converging to a high-quality result (due to low temperature)."

## Foundational Learning

- Concept: Text-to-SQL task
  - Why needed here: Understanding the Text-to-SQL task is crucial for comprehending the challenges and solutions proposed in this paper.
  - Quick check question: What is the main objective of the Text-to-SQL task?

- Concept: In-context learning
  - Why needed here: In-context learning is a key technique used in this paper to improve LLM performance on Text-to-SQL tasks.
  - Quick check question: How does in-context learning help LLMs perform better on Text-to-SQL tasks?

- Concept: Schema linking
  - Why needed here: Schema linking is a critical component of Text-to-SQL systems, and the paper proposes an innovative approach to improve it.
  - Quick check question: What is the purpose of schema linking in Text-to-SQL systems?

## Architecture Onboarding

- Component map: SQL-Tailored Prompting -> PreSQL Generation -> Schema Linking -> Simplified Prompt Generation -> Final SQL Generation -> Cross-consistency
- Critical path: The critical path in the PET-SQL framework is the sequence of operations that must be completed to generate the final SQL query: Prompt generation → PreSQL generation → Schema linking → Simplified prompt generation → Final SQL generation → Cross-consistency voting.
- Design tradeoffs: The main design tradeoffs in PET-SQL are between prompt complexity and LLM performance, between using a single powerful LLM versus multiple LLMs, and between different voting strategies in cross-consistency.
- Failure signatures: Common failure modes include incorrect schema linking, generation of invalid SQL, and poor performance of the cross-consistency voting mechanism. These can be identified through execution accuracy metrics and analysis of the generated SQL queries.
- First 3 experiments:
  1. Compare the performance of different prompt representations (REp vs. ODp vs. CRp) on a small dataset.
  2. Evaluate the effectiveness of PreSQL-based schema linking by comparing it to direct schema linking methods.
  3. Test the cross-consistency mechanism with different combinations of LLMs and voting strategies to find the optimal configuration.

## Open Questions the Paper Calls Out

None

## Limitations

- Cross-consistency mechanism relies on executing multiple SQL queries, which could be computationally expensive and may not scale well for production deployment.
- Effectiveness depends on having access to multiple capable LLMs, which may not be available to all users.
- Voting mechanism's performance in difficulty-aware mode depends on accurate difficulty assessment, which is not fully detailed in the paper.

## Confidence

**High Confidence**: The core claims about PET-SQL's architecture and its improvements over baseline methods (REp vs ODp, PreSQL-based schema linking, cross-consistency vs self-consistency) are well-supported by the experimental results and ablation studies presented in the paper.

**Medium Confidence**: The claims about the 1.3% absolute improvement over state-of-the-art and the 87.6% execution accuracy on Spider are based on reported results, but without access to the exact implementation details and hyperparameters, exact replication may yield slightly different results.

**Low Confidence**: The scalability claims and real-world deployment feasibility are not thoroughly evaluated, particularly regarding the computational cost of executing multiple SQL queries per question.

## Next Checks

1. **Schema Linking Robustness Test**: Evaluate PET-SQL's PreSQL-based schema linking on a held-out subset of Spider with particularly complex schemas (many tables/columns) to verify the claimed 32% prompt length reduction doesn't compromise accuracy on challenging cases.

2. **Cross-Consistency Voting Analysis**: Conduct a detailed analysis of the cross-consistency voting mechanism by tracking which LLM's predictions are selected in the final voting across different question difficulty levels to validate the claimed 2% accuracy improvement.

3. **Resource Utilization Benchmark**: Measure the computational overhead of PET-SQL's two-round framework, particularly the cost of executing multiple SQL queries for cross-consistency, to assess practical deployment feasibility compared to single-model approaches.