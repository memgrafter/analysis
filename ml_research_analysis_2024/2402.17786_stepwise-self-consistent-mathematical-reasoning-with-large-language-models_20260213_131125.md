---
ver: rpa2
title: Stepwise Self-Consistent Mathematical Reasoning with Large Language Models
arxiv_id: '2402.17786'
source_url: https://arxiv.org/abs/2402.17786
tags:
- intermediate
- reasoning
- ssc-cot
- question
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces SSC-CoT, an algorithm for complex mathematical
  reasoning with LLMs. It uses multiple reasoning chains to identify overlapping intermediate
  steps, verifies their correctness, and leverages a knowledge graph for domain-specific
  hints.
---

# Stepwise Self-Consistent Mathematical Reasoning with Large Language Models

## Quick Facts
- arXiv ID: 2402.17786
- Source URL: https://arxiv.org/abs/2402.17786
- Authors: Zilong Zhao; Yao Rong; Dongyang Guo; Emek Gözlüklü; Emir Gülboy; Enkelejda Kasneci
- Reference count: 35
- Key outcome: SSC-CoT triples performance on TriMaster100 and surpasses second-best method by 7.2% on MATH level 5

## Executive Summary
This work introduces SSC-CoT, a novel algorithm for complex mathematical reasoning with LLMs that leverages multiple reasoning chains to identify overlapping intermediate steps, verifies their correctness, and uses a knowledge graph for domain-specific hints. The approach is evaluated on a new dataset, TriMaster100, specifically designed to test intermediate reasoning steps for complex trigonometry problems. Results show significant improvements over prior methods, with SSC-CoT achieving three times better performance on TriMaster100 and 7.2% higher accuracy on MATH level 5 compared to the second-best method.

## Method Summary
SSC-CoT is a stepwise self-consistent mathematical reasoning algorithm that generates multiple reasoning chains per question, identifies overlapping intermediate steps using cosine similarity, verifies their correctness through LLM-based verification, and retrieves domain-specific hints from a knowledge graph to guide subsequent reasoning rounds. The method operates iteratively, using verified intermediate steps to query the knowledge graph for relevant trigonometric identities and theorems, which are then incorporated into subsequent reasoning chains to help the model discover critical intermediate steps it might otherwise miss.

## Key Results
- TriMaster100: SSC-CoT achieves 3× better performance than prior methods with sum of scores reaching 750 points maximum
- MATH Level 5: SSC-CoT surpasses second-best method by 7.2% in accuracy across 1,324 challenging mathematical questions
- The knowledge graph integration provides domain-specific hints that guide models toward critical intermediate steps in trigonometric reasoning

## Why This Works (Mechanism)

### Mechanism 1
SSC-CoT improves reasoning by selecting intermediate steps based on their overlap across multiple reasoning chains. The algorithm generates multiple reasoning chains and identifies intermediate steps that appear in more than one chain, prioritizing these as they are more likely to be correct and critical for problem-solving. Core assumption: Correct intermediate steps will tend to appear across multiple reasoning chains because different reasoning paths converge on key mathematical truths.

### Mechanism 2
SSC-CoT uses a knowledge graph to retrieve domain-specific hints that guide the model toward critical intermediate steps. The algorithm extracts relevant trigonometric functions and angles from the question, queries the KG for related identities and theorems, and uses this information as hints to prompt the model in subsequent reasoning rounds. Core assumption: The KG contains relevant domain knowledge that can help the model overcome obstacles and discover critical intermediate steps it might miss on its own.

### Mechanism 3
SSC-CoT employs a verification process to ensure the correctness of selected intermediate steps before proceeding. After identifying overlapping intermediate steps, the algorithm sends them to a verifier (implemented as an LLM) to check their correctness. Only verified steps are used to query the KG and prompt the model in subsequent rounds. Core assumption: The LLM-based verifier can accurately assess the correctness of intermediate steps, ensuring that only valid steps are used to guide further reasoning.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: SSC-CoT builds upon the CoT approach by generating multiple reasoning chains and selecting intermediate steps based on their overlap
  - Quick check question: Can you explain the basic idea behind Chain-of-Thought prompting and how it differs from direct answer generation?

- Concept: Knowledge Graphs (KGs)
  - Why needed here: SSC-CoT uses a KG to retrieve domain-specific hints for guiding the model toward critical intermediate steps
  - Quick check question: What is a knowledge graph, and how can it be used to represent and retrieve information in a structured way?

- Concept: Cosine similarity
  - Why needed here: SSC-CoT uses cosine similarity to assess the similarity between pairs of intermediate results and identify overlapping steps
  - Quick check question: How is cosine similarity calculated, and what does it measure in the context of text or vector representations?

## Architecture Onboarding

- Component map: Input → E (Extractor) → S (Searcher) → G (Generator) → V (Verifier) → S → G → ... (iterative process)
- Critical path: E → S → G → V → S → G → ... (iterative process)
- Design tradeoffs: Using multiple reasoning chains increases chances of finding critical intermediate steps but increases computational cost; LLM-based verification may not be as robust as dedicated verification systems; KG needs to be comprehensive yet efficiently queryable
- Failure signatures: If model generates diverse, non-overlapping chains, overlap-based selection may fail; incomplete KG may not provide useful hints; LLM verifier may incorrectly assess intermediate steps
- First 3 experiments: 1) Implement E component to extract trigonometric functions and angles from questions; 2) Create small KG with trigonometric identities and implement S component; 3) Implement G component to generate single reasoning chain using LLM with KG hints

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of SSC-CoT vary with the number of reasoning chains generated per round? The paper states that "For SSC-CoT, we generate 5 reasoning chains per round, with a limit of 4 rounds, resulting in a maximum of 20 reasoning chains per question." This remains unresolved as the paper does not explore the impact of varying the number of reasoning chains on performance.

### Open Question 2
Can the knowledge graph be further improved by incorporating more diverse mathematical concepts and relationships? The paper mentions that "As users apply our method to solve trigonometry problems, certain conclusions drawn from these problems can serve as lemmas for subsequent questions. Our KG is designed to be expandable." This remains unresolved as the paper does not explore potential benefits of expanding the knowledge graph with more diverse mathematical concepts.

### Open Question 3
How does the performance of SSC-CoT compare to other advanced in-context learning algorithms on other mathematical domains beyond trigonometry? While the paper benchmarks SSC-CoT against other algorithms on TriMaster100 and MATH datasets, it does not provide comprehensive comparison across a wide range of mathematical domains.

## Limitations

- Evaluation is primarily conducted on two datasets (TriMaster100 and MATH Level 5), which may not capture full diversity of mathematical reasoning challenges
- Reliance on LLM-based verification for intermediate steps introduces potential brittleness, as LLMs can struggle with complex mathematical reasoning
- Knowledge graph's coverage and quality are critical to performance but not extensively validated
- Computational cost of generating multiple reasoning chains and performing pairwise comparisons is substantial but not fully characterized

## Confidence

- **High confidence:** The core algorithm design (SSC-CoT) and its three main components (overlap detection, KG retrieval, verification) are clearly specified and implemented
- **Medium confidence:** Performance improvements on TriMaster100 (3× better) and MATH Level 5 (+7.2% accuracy) are reported, but limited comparison to state-of-the-art methods beyond three baselines
- **Low confidence:** Claims about knowledge graph's contribution to performance and robustness of LLM-based verification system, as these components are not independently validated

## Next Checks

1. **Knowledge Graph Coverage Validation:** Systematically evaluate the KG's coverage across all trigonometric identities and theorems used in TriMaster100. Identify missing or incomplete entries and measure their impact on performance by comparing results with and without KG hints for each question.

2. **Verification Robustness Test:** Design a controlled experiment where intermediate steps are intentionally perturbed (some correct, some incorrect) and measure the LLM verifier's accuracy in detecting errors. Compare against a simple rule-based verifier for arithmetic operations to quantify the reliability gap.

3. **Generalization Cross-Domain Study:** Apply SSC-CoT to a non-trigonometric mathematical dataset (e.g., algebra or geometry problems) to test whether the overlap-based reasoning and KG retrieval mechanisms generalize beyond the primary domain. Measure performance degradation and identify which components break first.