---
ver: rpa2
title: Contextual Evaluation of Large Language Models for Classifying Tropical and
  Infectious Diseases
arxiv_id: '2409.09201'
source_url: https://arxiv.org/abs/2409.09201
tags:
- performance
- dataset
- diseases
- symptoms
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study expands a tropical and infectious diseases (TRINDs)
  dataset to 11,719 queries incorporating demographic, semantic, and language variations.
  It evaluates generalist (Gemini Ultra) and specialist (MedLM) LLMs, finding that
  the generalist model outperforms the specialist (61.5% vs 47.9% accuracy on clinical
  personas).
---

# Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases

## Quick Facts
- arXiv ID: 2409.09201
- Source URL: https://arxiv.org/abs/2409.09201
- Reference count: 29
- Key outcome: Generalist LLM (Gemini Ultra) outperforms specialist LLM (MedLM) in tropical disease classification, with contextual factors improving accuracy from 46.8% to 61.5%

## Executive Summary
This study evaluates large language models for classifying tropical and infectious diseases, expanding a dataset to 11,719 queries with demographic, semantic, and language variations. The research compares generalist (Gemini Ultra) and specialist (MedLM) models, finding that contextual information significantly improves classification accuracy. Location, symptoms, and risk factors prove most valuable for disambiguation, while demographic variations show minimal impact. The study develops TRINDs-LM, a research tool demonstrating how context influences LLM outputs, and highlights the need for contextual information in improving tropical disease classification performance.

## Method Summary
The study expanded an original tropical and infectious diseases dataset to 11,719 queries through systematic augmentation incorporating demographic variations, semantic styles, and French language translations. Two LLMs were evaluated: Gemini Ultra (generalist) and MedLM Medium (specialist), using in-context learning with 2-shot examples. Performance was measured through automated rater LLM scoring across multiple experimental conditions including original datasets, contextual variations, counterfactual scenarios, and multiple-choice formats. Human expert baselines (n=7) provided comparison points, with statistical analysis using t-tests to evaluate significance across 5 outcomes per experiment.

## Key Results
- Generalist LLM (Gemini Ultra) outperformed specialist LLM (MedLM) with 61.5% vs 47.9% accuracy on clinical personas
- Contextual factors improved performance from 46.8% (symptoms alone) to significantly higher levels when including location and risk factors
- Human expert baselines scored lower than LLMs on short-answer questions but matched on multiple-choice formats
- Location changes in counterfactual testing reduced accuracy across all contexts, while race and gender variations showed minimal impact

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual information such as location, symptoms, and risk factors significantly improves LLM classification accuracy for tropical and infectious diseases.
- Mechanism: Including additional contextual factors helps the LLM disambiguate between diseases with overlapping symptoms by providing distinguishing features.
- Core assumption: The contextual factors provided are accurate, relevant, and available for the diseases being classified.
- Evidence anchors:
  - [abstract] "Contextual factors like symptoms, location, and risk factors significantly improve performance compared to symptoms alone (46.8%)"
  - [section] "We found that symptoms, location and risk factors enable the best model performance, followed by the full persona of symptoms, location, risk factors and personal attributes (Figure 1c)"
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.442, average citations=0.0."
- Break Condition: If contextual information is inaccurate, irrelevant, or unavailable for the disease in question, the performance benefit may be negated or reversed.

### Mechanism 2
- Claim: In-context learning with a small set of high-quality data improves model performance and robustness across different demographics, locations, and question styles.
- Mechanism: Providing the model with relevant examples in the prompt helps it learn the task and generalize to new inputs.
- Core assumption: The examples provided are representative of the task and cover a diverse range of cases.
- Evidence anchors:
  - [abstract] "We demonstrate through systematic experimentation, the benefit of contextual information such as demographics, location, gender, risk factors for optimal LLM response."
  - [section] "We found that in-context learning by providing the model with many-shot examples of the full original set for each disease, significantly increased Gemini performance for demographic and semantic augmentations"
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.442, average citations=0.0."
- Break Condition: If the examples provided are not representative or are too few, the model may not learn effectively or may overfit to the examples.

### Mechanism 3
- Claim: Generalist LLMs outperform specialist LLMs for classifying tropical and infectious diseases.
- Mechanism: Larger, more general models have more parameters and have been trained on a wider variety of data, allowing them to better handle out-of-distribution cases like tropical diseases.
- Core assumption: The generalist model is sufficiently large and has been trained on diverse enough data to handle tropical disease classification.
- Evidence anchors:
  - [abstract] "It evaluates generalist (Gemini Ultra) and specialist (MedLM) LLMs, finding that the generalist model outperforms the specialist (61.5% vs 47.9% accuracy on clinical personas)"
  - [section] "Overall the generalist gemini model outperformed MedLM, which might be due to factors such as differences in model sizes, or overfitting of the MedLM tuned model to specific datasets"
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.442, average citations=0.0."
- Break Condition: If the specialist model is sufficiently large and has been trained on enough tropical disease data, it may outperform the generalist model.

## Foundational Learning

- Concept: Prompt Engineering
  - Why needed here: The study relies heavily on prompt engineering to generate diverse queries and to provide in-context examples to the LLM.
  - Quick check question: What are some common techniques for prompt engineering with LLMs?

- Concept: Data Augmentation
  - Why needed here: The study uses data augmentation techniques to expand the original dataset and create diverse queries for evaluation.
  - Quick check question: What are some common techniques for data augmentation with text data?

- Concept: Statistical Analysis
  - Why needed here: The study uses statistical analysis (t-tests) to compare the performance of different models and datasets.
  - Quick check question: What is a t-test and when would you use it to compare two datasets?

## Architecture Onboarding

- Component map:
  Dataset Generation and Expansion -> Model Evaluation -> Auto-rater LLM Evaluations -> Human Expert Baseline -> TRINDs-LM Tool

- Critical path:
  Generate dataset -> Evaluate LLMs -> Score outputs -> Compare to human baseline

- Design tradeoffs:
  - Using a generalist vs specialist LLM
  - Including vs excluding contextual information
  - Manual vs automated scoring

- Failure signatures:
  - Low LLM performance across all datasets
  - Inconsistent LLM performance across different datasets
  - Human expert performance significantly higher than LLM performance

- First 3 experiments:
  1. Evaluate the baseline performance of the generalist and specialist LLMs on the original dataset.
  2. Evaluate the impact of contextual information on LLM performance by testing different combinations of contextual factors.
  3. Evaluate the impact of in-context learning on LLM performance by providing the model with examples from the original dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different contextual factors (demographics, location, symptoms, risk factors) interact to influence LLM performance in tropical disease classification, and what is the optimal combination of these factors?
- Basis in paper: Explicit
- Why unresolved: The paper shows that certain combinations of contextual factors (symptoms + location + risk factors) perform better than others, but doesn't fully explore the interaction effects between these factors or identify an optimal combination that maximizes accuracy across all disease types.
- What evidence would resolve it: A systematic experimental design testing all possible combinations of contextual factors across the full dataset, followed by statistical analysis of interaction effects, would identify the optimal contextual information set for LLM performance.

### Open Question 2
- Question: How does LLM performance vary across different tropical and infectious diseases, and what disease characteristics (prevalence, symptom specificity, geographic distribution) most strongly predict classification accuracy?
- Basis in paper: Explicit
- Why unresolved: While the paper shows performance varies by disease (e.g., better on Trachoma/HIV vs. Tuberculosis), it doesn't analyze which disease characteristics drive these differences or develop predictive models for LLM performance based on disease attributes.
- What evidence would resolve it: A regression analysis correlating disease characteristics (prevalence, symptom specificity, geographic spread, etc.) with LLM accuracy scores, potentially revealing patterns that could guide dataset development and model improvement.

### Open Question 3
- Question: What is the minimum viable dataset size for effective in-context learning in tropical disease classification, and how does dataset quality versus quantity affect LLM performance?
- Basis in paper: Inferred
- Why unresolved: The paper demonstrates that in-context learning with the original dataset improves performance, but doesn't systematically vary dataset size or quality to determine minimum requirements or optimal training set characteristics.
- What evidence would resolve it: Experiments testing LLM performance with progressively smaller subsets of the dataset, varying in quality and diversity, would establish minimum requirements and identify whether quality or quantity is more critical for tropical disease classification tasks.

## Limitations
- Small human expert baseline (n=7) limits generalizability of human performance comparisons
- Automated rater LLM evaluation introduces additional layer of potential bias not independently validated
- US-based medical professionals for dataset creation may limit performance in regions where these diseases are endemic
- LLM advantage disappears in multiple-choice questions where human performance matches accuracy

## Confidence
- High Confidence: The finding that contextual information improves LLM performance (61.5% vs 47.9% accuracy) is well-supported with systematic experimentation and statistical analysis.
- Medium Confidence: The superiority of generalist over specialist LLMs may be influenced by model size differences and training data composition that aren't fully explored.
- Low Confidence: The human expert baseline comparison has significant limitations due to the small sample size (n=7) and uneven comparison conditions.

## Next Checks
1. Have human experts independently score a subset of LLM outputs to verify the accuracy and reliability of the automated rater LLM evaluation system.

2. Recruit a larger and more diverse group of medical professionals (nâ‰¥20) across different specialties and regions to establish a more robust human performance baseline, particularly for short-answer questions.

3. Evaluate the models on actual clinical case data from tropical disease-endemic regions to assess performance in realistic settings where contextual information may be incomplete or uncertain.