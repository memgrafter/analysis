---
ver: rpa2
title: 'Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation'
arxiv_id: '2401.13884'
source_url: https://arxiv.org/abs/2401.13884
tags:
- q-learning
- have
- convergence
- proof
- stepsize
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies constant-stepsize Q-learning from a distributional
  convergence perspective. By connecting the algorithm to a time-homogeneous Markov
  chain, the authors establish distributional convergence in Wasserstein distance
  with exponential convergence rate.
---

# Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation

## Quick Facts
- arXiv ID: 2401.13884
- Source URL: https://arxiv.org/abs/2401.13884
- Authors: Yixuan Zhang; Qiaomin Xie
- Reference count: 40
- Primary result: Establishes distributional convergence in Wasserstein distance, proves CLT, provides explicit bias expansion, and applies Richardson-Romberg extrapolation to reduce bias

## Executive Summary
This paper provides a comprehensive analysis of constant-stepsize Q-learning from a distributional convergence perspective. The authors establish exponential convergence in Wasserstein distance by connecting Q-learning to a time-homogeneous Markov chain, prove a Central Limit Theorem for averaged iterates, and derive an explicit asymptotic bias expansion showing bias is proportional to stepsize. Most significantly, they apply Richardson-Romberg extrapolation to construct a new estimate that provably reduces the bias to O(α²), with numerical results validating the theoretical improvements.

## Method Summary
The authors analyze constant-stepsize Q-learning by modeling the iterates as a time-homogeneous Markov chain. They employ coupling arguments to prove distributional convergence in Wasserstein distance with exponential rate, establish a Central Limit Theorem for averaged iterates, and derive an explicit bias expansion. The key innovation is applying Richardson-Romberg extrapolation to the averaged Q-learning iterates, constructing a new estimate 2q(α)∞ - q(2α)∞ that reduces the bias from O(α) to O(α²). The theoretical analysis is supported by numerical experiments on benchmark problems.

## Key Results
- Establishes exponential convergence in Wasserstein 2-distance for constant-stepsize Q-learning
- Proves a Central Limit Theorem for averaged Q-learning iterates
- Derives explicit asymptotic bias expansion: E[q∞] = q* + αB + O(α²)
- Applies Richardson-Romberg extrapolation to reduce bias from O(α) to O(α²)
- Numerical results validate theoretical bias reduction claims

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Markov chain theory enables proving distributional convergence in Wasserstein distance with exponential rate.
- Mechanism: By viewing constant stepsize Q-learning as a time-homogeneous Markov chain, the authors can apply coupling arguments to show that the iterates converge to a unique stationary distribution geometrically fast.
- Core assumption: The stepsize α satisfies αtα ≤ c₀/(1-β)² log(|S||A|) and the underlying Markov chain mixes geometrically.
- Evidence anchors:
  - [abstract] "By connecting the constant stepsize Q-learning to a time-homogeneous Markov chain, we show the distributional convergence of the iterates in Wasserstein distance and establish its exponential convergence rate."
  - [section] "We thus have for all k ≥ tα: ¯W₂²(L(xk, q[1]k), L(xk+1, q[1]k+1)) ≤ ρ ¯W₂²(¯μ, L(xk, qk)) k→∞ − →0."
  - [corpus] Weak corpus evidence - only 2 related papers with non-zero citations, but none directly discussing Wasserstein convergence rates.
- Break condition: If the Markov chain doesn't mix geometrically fast or the stepsize condition is violated, the exponential convergence rate claim fails.

### Mechanism 2
- Claim: The explicit bias expansion enables Richardson-Romberg extrapolation to provably reduce bias.
- Mechanism: The authors derive an exact asymptotic expansion of the bias as αB + O(α²), where B is independent of α. This allows constructing a new estimate 2q(α)∞ - q(2α)∞ with bias reduced to O(α²).
- Core assumption: The optimal policy is unique (Assumption 2) and the bias coefficient B is independent of α.
- Evidence anchors:
  - [abstract] "Moreover, we provide an explicit expansion of the asymptotic bias of the averaged iterate in stepsize. Specifically, the bias is proportional to the stepsize up to higher-order terms and we provide an explicit expression for the linear coefficient."
  - [section] "E[q∞] = q* + αB + O(α² + α²t²α²), where B = B(r, γ, P) is explicitly given in the appendix."
  - [corpus] Weak corpus evidence - only 2 related papers with non-zero citations, but none directly discussing Richardson-Romberg extrapolation for Q-learning bias reduction.
- Break condition: If the optimal policy is not unique or B depends on α, the extrapolation technique fails to provably reduce bias.

### Mechanism 3
- Claim: Tail averaging combined with bias characterization provides a complete error decomposition.
- Mechanism: The Polyak-Ruppert tail averaging reduces variance to O(1/k) while the explicit bias characterization allows quantifying the remaining bias term, leading to a complete MSE decomposition.
- Core assumption: The Markov chain mixes geometrically and the bias expansion holds.
- Evidence anchors:
  - [abstract] "We also establish a Central Limit Theory for Q-learning iterates, demonstrating the asymptotic normality of the averaged iterates."
  - [section] "Corollary 2. Under the setting of Theorem 3, the tail-averaged iterates(11) satisfy the following: ∀k > k₀ ≥ tα/2: E[¯qk₀,k] − q* =αB + O(α² + α²t²α²) + O(1/α(k − k₀) exp(−α(1 − β)k₀/4))."
  - [corpus] Weak corpus evidence - only 2 related papers with non-zero citations, but none directly discussing tail averaging for Q-learning error decomposition.
- Break condition: If the mixing time is too large or the bias expansion is incorrect, the error decomposition breaks down.

## Foundational Learning

- Concept: Markov chain mixing times and their relationship to stepsize conditions
  - Why needed here: The convergence rate and bias characterization depend critically on the mixing time tα and the condition αtα ≤ c₀/(1-β)² log(|S||A|)
  - Quick check question: If tα = O(1/α²), what is the maximum allowable stepsize for the theory to hold?

- Concept: Wasserstein distance and its properties for convergence analysis
  - Why needed here: The distributional convergence is established in Wasserstein 2-distance, requiring understanding of its definition and properties
  - Quick check question: How does convergence in W2 distance differ from convergence in distribution?

- Concept: Richardson-Romberg extrapolation technique
  - Why needed here: The bias reduction technique relies on extrapolating between estimates with different stepsizes
  - Quick check question: What is the key requirement for RR extrapolation to work, and how is it satisfied in this paper?

## Architecture Onboarding

- Component map: Markov chain modeling -> Coupling argument -> Convergence proof -> Local linearization -> Bias expansion -> Tail averaging -> Richardson-Romberg extrapolation
- Critical path: Markov chain → Coupling → Convergence → Bias expansion → Extrapolation
- Design tradeoffs:
  - Larger stepsize gives faster convergence but larger bias
  - Tail averaging reduces variance but doesn't eliminate bias
  - RR extrapolation requires running two Q-learning instances in parallel
- Failure signatures:
  - Slow mixing (large tα) → Convergence rate degrades
  - Non-unique optimal policy → Bias expansion breaks down
  - Poor stepsize choice → Neither fast convergence nor good bias
- First 3 experiments:
  1. Implement Q-learning with varying stepsizes and verify exponential convergence rate empirically
  2. Add tail averaging and measure variance reduction across different stepsizes
  3. Implement RR extrapolation and compare bias reduction against single-step Q-learning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the convergence rate of constant stepsize Q-learning in Wasserstein distance depend on the specific structure of the MDP (e.g., state space size, action space size) beyond the mixing time and discount factor?
- Basis in paper: [inferred] The paper shows convergence in W2 distance with exponential rate, but the exact dependence on MDP parameters beyond the mixing time and discount factor is not explicitly characterized.
- Why unresolved: The paper establishes the existence of a convergence rate but doesn't provide a tight characterization of how the rate depends on MDP-specific parameters like state and action space sizes.
- What evidence would resolve it: A more detailed analysis of the coupling argument and the local linearization error term could provide a tighter bound on the convergence rate in terms of the MDP's specific parameters.

### Open Question 2
- Question: How does the bias expansion result generalize to non-tabular settings, such as Q-learning with function approximation?
- Basis in paper: [explicit] The paper mentions that the bias expansion result (Theorem 3) can be extended to linear function approximation based on empirical results, but a rigorous theoretical justification is not provided.
- Why unresolved: The local linearization approach used in the proof of Theorem 3 relies on the nonsmoothness of the Q-learning operator, which may not directly translate to settings with function approximation.
- What evidence would resolve it: A theoretical analysis of the bias expansion for Q-learning with function approximation, potentially using techniques from the analysis of stochastic approximation with function approximation.

### Open Question 3
- Question: Can the Richardson-Romberg extrapolation technique be further improved to reduce the bias in Q-learning beyond the O(α^2) order achieved in the paper?
- Basis in paper: [explicit] The paper shows that RR extrapolation reduces the bias from O(α) to O(α²) by using two Q-learning iterates with stepsizes α and 2α.
- Why unresolved: The paper only considers using two Q-learning iterates with a specific ratio of stepsizes. It's unclear whether using more iterates with different stepsizes or a different extrapolation scheme could further reduce the bias.
- What evidence would resolve it: A theoretical analysis of the bias reduction achievable with different extrapolation schemes and a comparison of their performance in practice.

## Limitations

- Theoretical framework relies heavily on geometric mixing of the underlying Markov chain
- Stepsize condition αtα ≤ c₀/(1-β)² log(|S||A|) may be restrictive in practice
- Bias expansion assumes unique optimal policy, which may not hold in all RL scenarios
- Empirical validation limited to relatively small examples

## Confidence

**High Confidence Claims:**
- The Markov chain connection to Q-learning is mathematically sound
- The coupling argument for exponential convergence rate is valid
- The tail averaging technique effectively reduces variance

**Medium Confidence Claims:**
- The explicit bias expansion formula B = B(r, γ, P) is correct
- The Richardson-Romberg extrapolation reduces bias as claimed
- The stepsize conditions are tight and necessary

**Low Confidence Claims:**
- Performance guarantees extend to all practical MDPs
- The bias reduction from RR extrapolation is significant in practice
- The framework scales well to high-dimensional problems

## Next Checks

1. **Stepsize Sensitivity Analysis**: Systematically vary the stepsize α across multiple orders of magnitude and measure both convergence rate and final bias to verify the theoretical bounds empirically. This should include both small problems (where theory is proven) and larger problems (where assumptions may break).

2. **Policy Uniqueness Impact**: Construct MDPs with non-unique optimal policies and measure how the bias expansion and RR extrapolation performance degrade. Compare against the theoretical predictions to identify where the unique policy assumption is critical.

3. **Mixing Time Verification**: For various MDP structures, empirically estimate the mixing time tα and verify whether the condition αtα ≤ c₀/(1-β)² log(|S||A|) is satisfied in practice. This will help understand when the theoretical framework is applicable.