---
ver: rpa2
title: 'VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language
  Models'
arxiv_id: '2412.01095'
source_url: https://arxiv.org/abs/2412.01095
tags: []
core_contribution: This paper introduces VERA, a framework that enables frozen vision-language
  models (VLMs) to perform video anomaly detection (VAD) without parameter modification
  or instruction tuning. VERA learns guiding questions that break down the abstract
  concept of "anomaly" into concrete, identifiable patterns, and uses them to elicit
  reasoning from VLMs.
---

# VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models

## Quick Facts
- arXiv ID: 2412.01095
- Source URL: https://arxiv.org/abs/2412.01095
- Authors: Muchao Ye; Weiyang Liu; Pan He
- Reference count: 40
- Achieves 86.55% AUC on UCF-Crime and 88.26% AUC on XD-Violence without parameter modification

## Executive Summary
This paper introduces VERA, a framework that enables frozen vision-language models (VLMs) to perform video anomaly detection (VAD) without parameter modification or instruction tuning. VERA learns guiding questions that break down the abstract concept of "anomaly" into concrete, identifiable patterns, and uses them to elicit reasoning from VLMs. The method uses a verbalized learning framework to optimize these questions through data-driven interactions between learner and optimizer VLMs, requiring only coarsely labeled training data. During inference, VERA generates segment-level anomaly scores using the learned questions and refines them into frame-level scores via scene and temporal context fusion. VERA achieves state-of-the-art explainable VAD performance on UCF-Crime (86.55% AUC) and XD-Violence (88.26% AUC), while providing interpretable explanations for detected anomalies.

## Method Summary
VERA introduces a verbalized learning framework that enables frozen vision-language models to perform video anomaly detection without parameter modification. The method learns guiding questions that decompose the abstract concept of "anomaly" into concrete, identifiable patterns. During training, a learner VLM interacts with an optimizer VLM through a data-driven process to refine these questions. At inference, VERA generates segment-level anomaly scores using the learned questions and refines them into frame-level scores through scene and temporal context fusion. The approach requires only coarsely labeled training data and provides interpretable explanations for detected anomalies through the generated questions and reasoning chains.

## Key Results
- Achieves state-of-the-art performance on UCF-Crime with 86.55% AUC
- Achieves state-of-the-art performance on XD-Violence with 88.26% AUC
- Provides interpretable explanations for detected anomalies through learned questions and reasoning chains

## Why This Works (Mechanism)
VERA works by transforming the abstract concept of "anomaly" into a series of concrete, answerable questions that frozen VLMs can reason about effectively. Instead of requiring parameter updates or instruction tuning, the method learns to ask the right questions through a verbalized learning framework. This approach leverages the existing reasoning capabilities of VLMs while adapting them to the specific domain of video anomaly detection. The learned questions guide the VLM's attention to specific patterns and events that constitute anomalies, enabling accurate detection without modifying the model's parameters. The framework's ability to provide interpretable explanations stems from the transparency of the question-answering process, where each detection is accompanied by the specific questions and reasoning that led to it.

## Foundational Learning

**Vision-Language Models (VLMs)**: Models that can process both visual and textual inputs to generate reasoning outputs. Needed because they provide strong reasoning capabilities that can be leveraged for anomaly detection without parameter modification. Quick check: Can the VLM understand and reason about video content when prompted with questions?

**Verbalized Learning**: A framework where models learn through question-answer interactions rather than direct parameter updates. Needed to adapt frozen VLMs to anomaly detection tasks without instruction tuning. Quick check: Does the question optimization process improve detection accuracy over time?

**Coarsely Labeled Data**: Training data with only segment-level labels rather than frame-level annotations. Needed to reduce annotation burden while maintaining detection performance. Quick check: Can the method achieve good performance with only binary segment labels?

## Architecture Onboarding

**Component Map**: Video Input -> Frame Extraction -> Segment Formation -> Question Generation -> VLM Reasoning -> Segment Score Fusion -> Frame-Level Score Refinement -> Anomaly Detection Output

**Critical Path**: The core inference pipeline involves generating learned questions for each video segment, feeding these through the frozen VLM to obtain reasoning outputs, and then fusing these outputs with scene and temporal context to produce final anomaly scores. The question generation and VLM reasoning stages are the most computationally intensive parts of the pipeline.

**Design Tradeoffs**: VERA prioritizes explainability and parameter efficiency over computational speed. The method trades increased inference time (due to multiple question generations and VLM calls) for the benefits of using frozen models and providing interpretable explanations. The choice to use coarsely labeled data reduces annotation costs but may limit performance on more subtle anomalies.

**Failure Signatures**: The method may struggle with anomalies that don't fit the learned question patterns or require very fine-grained temporal reasoning. Performance could degrade on datasets with significant domain shift from the training data. The explainability feature might produce less meaningful explanations when the VLM's reasoning is uncertain or when anomalies are genuinely novel.

**3 First Experiments**:
1. Test VERA on a held-out validation set to verify that learned questions generalize beyond the training data
2. Compare segment-level detection performance with and without the scene and temporal context fusion to quantify the contribution of each component
3. Generate explanations for a sample of true and false positive detections to qualitatively assess the interpretability of the output

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited comparison with recently published VLM-based methods that may use instruction tuning or parameter updates
- Computational efficiency during inference, particularly the overhead of generating and processing multiple questions, is not quantified
- Performance on datasets with more subtle anomalies or those requiring fine-grained temporal reasoning remains untested

## Confidence

**Performance Claims (High)**: The reported AUC scores on UCF-Crime and XD-Violence are well above previous methods, and the methodology for generating segment-level scores appears sound. The ablation studies support the contribution of key components.

**Explainability Claims (Medium)**: While the paper demonstrates that VERA generates interpretable questions and reasoning chains, the quality and utility of these explanations for real-world applications is not thoroughly validated. User studies or expert evaluations of the explanations would strengthen this claim.

**Generalization Claims (Low)**: The paper demonstrates success on two datasets but doesn't address how well the learned questions generalize to new anomaly types or domains. The assumption that coarsely labeled training data is sufficient may not hold for more complex anomaly detection scenarios.

## Next Checks
1. Conduct a controlled experiment comparing VERA against VLM-based methods that use instruction tuning or parameter updates on the same datasets to isolate the benefit of the verbalized learning approach.

2. Measure and report inference time and memory usage for VERA, including the overhead of question generation and processing, to establish computational efficiency relative to baseline methods.

3. Test VERA on a dataset with more subtle anomalies (e.g., ShanghaiTech or StreetScene) to evaluate performance on anomalies that require fine-grained temporal reasoning rather than clear-cut events.