---
ver: rpa2
title: 'Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis'
arxiv_id: '2410.10278'
source_url: https://arxiv.org/abs/2410.10278
tags:
- chinese
- data
- mandarin
- dataset
- flores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a FLORES+ dataset as a benchmark for Wu Chinese
  machine translation models. The authors translate and validate 997 sentences from
  English to the Chongming dialect of Wu Chinese.
---

# Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis

## Quick Facts
- arXiv ID: 2410.10278
- Source URL: https://arxiv.org/abs/2410.10278
- Reference count: 2
- This paper presents a FLORES+ dataset as a benchmark for Wu Chinese machine translation models.

## Executive Summary
This paper introduces a FLORES+ dataset for evaluating machine translation models in Wu Chinese, focusing on the Chongming dialect. The authors translate 997 English sentences into Wu Chinese and validate the dataset's compatibility with existing Wu resources through language identification experiments using FastText models. The study demonstrates that preprocessing steps including normalization and segmentation can enhance the fidelity of Wu Chinese text processing, achieving over 90% accuracy in most classification tasks across Mandarin, Wu, and Yue. While the results validate the internal consistency of the FLORES+ Wu dataset, limitations are noted regarding orthographic variations and Mandarin influence on Wu Chinese.

## Method Summary
The methodology involves creating a Wu Chinese translation benchmark by translating English sentences into the Chongming dialect, then validating this dataset through language identification experiments. The process includes preprocessing Wikimedia data for Mandarin, Wu, and Yue using OpenCC for Traditional-to-Simplified Chinese conversion, and segmenting text using jieba with auxiliary dictionaries for Wu and cantoseg for Yue. FastText text classification models are trained and evaluated on these processed datasets, using 9:1 splits for internal consistency testing and cross-validation between FLORES+ and Wikimedia datasets to assess compatibility.

## Key Results
- Achieved over 90% accuracy in most binary language identification tasks (Mandarin-Wu, Mandarin-Yue, Wu-Yue) using FastText models
- Demonstrated dataset compatibility through cross-validation between FLORES+ Wu and Wikimedia data
- Developed preliminary tools for Wu Chinese normalization and segmentation to improve processing fidelity
- Validated internal consistency of the 997-sentence FLORES+ Wu dataset through held-out testing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language identification models can validate Wu Chinese translation quality by measuring orthographic compatibility with existing Wu resources
- Mechanism: FastText classification models trained on parallel corpora achieve high accuracy when the test and training languages share similar orthographic features and lexical overlap
- Core assumption: Orthographic similarity between Wu, Mandarin, and Yue enables cross-lingual classification without requiring deep linguistic parsing
- Evidence anchors:
  - [abstract]: "demonstrate the dataset's compatibility with existing Wu data through language identification experiments"
  - [section]: "We train a language identification model on the FLORES+ Wu dataset to show its compatibility with other Wu Chinese text resources"
  - [corpus]: Weak - corpus analysis shows limited citation support, suggesting this methodology may be under-explored in peer literature
- Break condition: Model performance drops significantly when Wu data contains substantial Mandarin-influenced features or when segmentation tools fail to capture Wu-specific syntax

### Mechanism 2
- Claim: Normalization and segmentation preprocessing improves language model performance on Wu Chinese text
- Mechanism: By converting traditional to simplified Chinese and standardizing variant spellings, the model can better learn language-specific patterns rather than orthography variations
- Core assumption: Wu Chinese orthographic variation creates noise that segmentation and normalization can reduce
- Evidence anchors:
  - [abstract]: "We also devised measures to normalize and segment Wu Wikipedia data in order to enhance their fidelity"
  - [section]: "Because Mandarin and Yue Wikimedia were written in Traditional Chinese and Wu Wikimedia partially, we utilized OpenCC which supports character-level and phrase-level conversion"
  - [corpus]: Weak - no explicit corpus citations for normalization effectiveness, though related papers discuss similar preprocessing
- Break condition: Normalization rules are too aggressive and remove dialect-specific features, or segmentation tools lack sufficient Wu-specific training data

### Mechanism 3
- Claim: Small parallel datasets can achieve reasonable language identification accuracy when combined with strong preprocessing
- Mechanism: Even with limited data (997 sentences), FastText can learn discriminative features when input is properly segmented and normalized
- Core assumption: Quality of preprocessing and data alignment matters more than raw data volume for language identification tasks
- Evidence anchors:
  - [abstract]: "We translate and validate 997 sentences from English to the Chongming dialect of Wu Chinese"
  - [section]: "In part 1, we conducted a 9:1 split on FLORES+ datasets to test their internal consistency"
  - [corpus]: Weak - corpus shows no citations for this specific claim about small dataset effectiveness
- Break condition: Model overfits to specific orthographic patterns in the small dataset and fails to generalize to broader Wu varieties

## Foundational Learning

- Concept: Orthographic variation in Chinese dialects
  - Why needed here: Understanding why Wu Chinese requires special normalization and segmentation approaches
  - Quick check question: What is the difference between Wendu and Baidu readings in Wu Chinese?

- Concept: FastText text classification methodology
  - Why needed here: The paper relies on FastText for language identification experiments
  - Quick check question: How does FastText represent words for classification tasks?

- Concept: Language identification as translation quality validation
  - Why needed here: The paper uses language ID accuracy as a proxy for translation dataset quality
  - Quick check question: What assumptions underlie using language identification accuracy to validate translation quality?

## Architecture Onboarding

- Component map: English source data -> Human translation to Chongming dialect -> Normalization layer (OpenCC + custom rules) -> Segmentation layer (jieba + auxiliary Wu dictionary) -> FastText classification model for validation
- Critical path: Translation -> Normalization -> Segmentation -> Classification -> Evaluation
- Design tradeoffs: Using Chongming dialect provides consistency but may reduce generalizability to other Wu varieties; manual translation ensures quality but limits scalability
- Failure signatures: High classification error rates indicate segmentation problems or orthographic inconsistencies; low accuracy on Mandarin-Wu pairs suggests insufficient Wu-specific features
- First 3 experiments:
  1. Train FastText on FLORES+ Wu dataset and test on held-out portion to verify internal consistency
  2. Train on Wikimedia data and test on FLORES+ to check cross-dataset compatibility
  3. Train on FLORES+ and test on Wikimedia to evaluate generalization capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would a larger Wu Chinese dataset impact the accuracy of language identification models, particularly for distinguishing Wu from Mandarin and Yue?
- Basis in paper: [explicit] The paper discusses limitations in the Wu Chinese dataset size and its impact on model accuracy, noting that "due to insufficient training data, the models exhibit tendency to misclassify Wu and Yue data as Mandarin."
- Why unresolved: The study only used a small Wu dataset (997 sentences), which may not be representative enough for robust language identification.
- What evidence would resolve it: Training and evaluating language identification models on larger, more diverse Wu datasets would provide insight into whether dataset size correlates with improved accuracy.

### Open Question 2
- Question: What are the specific challenges in creating a standardized orthography for Wu Chinese that can accommodate dialectal variations across Northern and Southern Wu?
- Basis in paper: [explicit] The paper highlights orthographic challenges, stating "the overlap between the Chongming dialect and Southern Wu dialects might be less prominent" and that "the current manually configured word list for Wu in the auxiliary dictionary of jieba is relatively small."
- Why unresolved: The paper uses Chongming dialect as a representative Northern Wu variety but acknowledges that this may not generalize well to Southern Wu dialects.
- What evidence would resolve it: Developing and testing a standardized orthography that explicitly addresses both Northern and Southern Wu variations, and evaluating its performance across different Wu dialect datasets.

### Open Question 3
- Question: How does the influence of Mandarin on Wu Chinese text affect the development of language models, and what strategies could mitigate this issue?
- Basis in paper: [explicit] The paper notes that "the tendency of Wu Chinese to be influenced by Mandarin poses problems, exemplified by our classifier mislabeling Wu data containing 'äº†' as Mandarin, because this grammar particle is common in Mandarin but infrequent in older Wu data."
- Why unresolved: The study identifies this issue but does not explore potential solutions or the extent to which Mandarin influence affects model performance.
- What evidence would resolve it: Implementing and testing strategies such as domain adaptation, data augmentation, or adversarial training to reduce Mandarin influence on Wu Chinese language models, and measuring the impact on model performance.

## Limitations
- Limited Wu-specific linguistic resources: The paper relies heavily on general Chinese tools rather than Wu-specific linguistic resources
- Dialectal generalization concerns: Using only the Chongming dialect (with 997 sentences) raises questions about representativeness across Wu Chinese varieties
- Orthographic variation challenges: Wu Chinese exhibits significant orthographic variation that may affect language identification accuracy

## Confidence
- High confidence: Claims about the FLORES+ dataset creation process and basic language identification methodology
- Medium confidence: Claims about the effectiveness of normalization and segmentation for Wu Chinese processing
- Low confidence: Claims about the representativeness of Chongming dialect for all Wu Chinese varieties

## Next Checks
1. Conduct human evaluation on a sample of the FLORES+ Wu dataset to assess whether the Chongming dialect orthography aligns with broader Wu Chinese writing conventions
2. Evaluate the language identification models on Wu Chinese text from multiple dialect regions beyond Chongming to determine if the benchmark generalizes across Wu varieties
3. Compare the performance of general Chinese NLP tools against Wu-specific alternatives on the same Wu Chinese text corpus to quantify the impact of using non-specialized tools