---
ver: rpa2
title: Functional relevance based on the continuous Shapley value
arxiv_id: '2411.18575'
source_url: https://arxiv.org/abs/2411.18575
tags:
- value
- data
- shapley
- functional
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for interpreting functional data models
  by extending the Shapley value to continuous games. The method computes a relevance
  function that ranks the importance of each point in the functional input space.
---

# Functional relevance based on the continuous Shapley value

## Quick Facts
- arXiv ID: 2411.18575
- Source URL: https://arxiv.org/abs/2411.18575
- Authors: Pedro Delicado; Cristian Pachón-García
- Reference count: 7
- This paper proposes a method for interpreting functional data models by extending the Shapley value to continuous games, computing a relevance function that ranks the importance of each point in the functional input space.

## Executive Summary
This paper addresses the challenge of interpreting functional data models by proposing a novel approach based on the continuous Shapley value. The method computes a relevance function that measures the importance of each point in the functional input space by averaging marginal contributions over all possible partitions. It achieves feature importance ranking without retraining models by using ghost variables constructed via conditional expectations. The approach is model-agnostic and can be applied to any functional data model, with experiments demonstrating its ability to identify important features on both simulated and real data.

## Method Summary
The method extends the Shapley value framework to continuous functional games by treating each infinitesimal subinterval as a "player" in a cooperative game. The payoff function measures predictive accuracy gain when including that subinterval's information. For any subset S of the input domain, the method constructs modified functional inputs where values outside S are replaced with their conditional expectations given values inside S. This allows measuring the predictive contribution of S without computationally expensive model retraining. The approach is implemented in a Python package called ShapleyFDA, which provides both exact and approximate Shapley value computations using random permutations.

## Key Results
- The continuous Shapley value framework provides a fair allocation of predictive relevance across functional features
- Feature importance ranking is achieved without retraining models through ghost variables constructed via conditional expectations
- The method extends naturally to feature selection through distance correlation and minimum redundancy-maximum relevance (mRMR) criteria

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Shapley value framework provides a fair allocation of predictive relevance across continuous functional features by averaging marginal contributions over all possible partitions of the input domain.
- Mechanism: The continuous game theory extension treats each infinitesimal subinterval as a "player" in a cooperative game. The payoff function measures predictive accuracy gain when including that subinterval's information. By applying the asymptotic Shapley value over increasingly fine partitions, the method yields a continuous relevance function that satisfies efficiency, symmetry, and linearity axioms.
- Core assumption: The underlying process generating the functional data can be approximated as Gaussian, enabling conditional expectations to be computed analytically.
- Evidence anchors:
  - [abstract] "proposes an interpretability method based on the Shapley value for continuous games"
  - [section 3.3] "Shapley value must be defined for continuous games" and describes asymptotic approach
  - [corpus] Weak evidence - related papers focus on finite Shapley values or graph-based applications, not continuous functional extensions
- Break condition: If the functional data cannot be reasonably approximated by Gaussian processes, the conditional expectation estimation fails and the Shapley value computation becomes invalid.

### Mechanism 2
- Claim: Feature importance ranking is achieved without retraining models by using ghost variables constructed via conditional expectations.
- Mechanism: For any subset S of the input domain, the method constructs modified functional inputs where values outside S are replaced with their conditional expectations given values inside S. This allows measuring the predictive contribution of S without computationally expensive model retraining for each subset.
- Core assumption: The trained model is sufficiently stable that evaluating it on modified inputs provides meaningful importance measures without retraining.
- Evidence anchors:
  - [section 4.1] "we propose the creation of a new data set in which the data from t ∈ S are retained while the remaining data are inferred from S, the new data set is created using the conditional expectation"
  - [section 2.2] References Delicado and Peña (2023) using ghost variables for finite predictors
  - [corpus] Moderate evidence - the shapr package implements conditional Shapley values but focuses on tabular data
- Break condition: If the model is highly non-linear or unstable, the conditional expectation approximation may not preserve the true importance structure.

### Mechanism 3
- Claim: The method extends naturally to feature selection through distance correlation and minimum redundancy-maximum relevance (mRMR) criteria.
- Mechanism: Two alternative games are defined - one based on distance correlation between functional inputs and outputs, and another using mRMR relevance/redundancy measures. These provide complementary selection criteria that can identify both strongly associated features and those that reduce redundancy.
- Core assumption: Distance correlation captures non-linear dependencies relevant for functional data, and mRMR balances relevance with redundancy effectively.
- Evidence anchors:
  - [section 4.2] "we propose to use two distinct games: the first one is inspired by the minimum Redundancy Maximum Relevance method (mRMR)"
  - [appendix A] Provides mRMR framework adapted to functional data
  - [corpus] Weak evidence - corpus lacks specific applications of mRMR to functional data or distance correlation for selection
- Break condition: If the feature space exhibits complex dependencies not captured by pairwise correlations or distance measures, these selection methods may fail to identify truly relevant features.

## Foundational Learning

- Concept: Functional Data Analysis (FDA) basics
  - Why needed here: The entire framework operates on functional inputs where observations are curves/functions rather than vectors
  - Quick check question: What is the fundamental difference between multivariate analysis and functional data analysis in terms of data representation?

- Concept: Game Theory and Shapley value for finite games
  - Why needed here: The method extends Shapley value from finite to continuous games to allocate relevance
  - Quick check question: What are the three key axioms (efficiency, symmetry, dummy) that uniquely characterize the Shapley value?

- Concept: Conditional expectation and Gaussian process assumptions
  - Why needed here: Ghost variables are constructed using conditional expectations, which require Gaussian assumptions for analytical computation
  - Quick check question: How does the conditional expectation of a Gaussian process given partial observations relate to the original process?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training (external) -> Partition generation -> Conditional expectation computation -> Payoff function calculation -> Shapley value approximation -> Relevance visualization
- Critical path: The bottleneck is conditional expectation computation, which must be performed for each test sample and each permutation of the partition
- Design tradeoffs: Exact Shapley values require all permutations (computationally prohibitive); random sampling provides approximation with tunable accuracy vs. runtime
- Failure signatures: Low R² values for trained models, high variance in conditional expectations, or Shapley value functions that are nearly flat indicate problems
- First 3 experiments:
  1. Verify conditional expectation computation on synthetic Gaussian functional data with known structure
  2. Test Shapley value computation on simple linear functional regression with few partitions
  3. Validate relevance ranking on simulated data where ground truth importance is known

## Open Questions the Paper Calls Out
- The paper does not explicitly call out any open questions in the provided content.

## Limitations
- High computational cost due to the need to compute conditional expectations across all permutations, limiting scalability to large functional datasets
- The Gaussian process assumption may not hold for non-smooth or discontinuous functional data, potentially invalidating the conditional expectation approach
- The method's performance on high-dimensional functional inputs (where T >> m) requires further investigation

## Confidence
- Theoretical framework: High confidence based on established game theory foundations
- Proof of concept: High confidence demonstrated on synthetic data with known structure
- Real-world applicability: Medium confidence due to limited evaluation scope on real datasets
- Computational efficiency: Low confidence without benchmark comparisons against alternative methods

## Next Checks
1. Benchmark computational runtime against alternative functional feature importance methods (functional ANOVA, functional PLS) on identical datasets with varying dimensions (m = 50, 200, 1000; T = 50, 200, 1000).
2. Test method robustness on non-Gaussian functional data (piecewise constant functions, periodic functions with non-normal noise) and quantify performance degradation.
3. Evaluate on real-world functional datasets (e.g., medical imaging time series, climate data) with expert-validated feature importance to assess practical utility beyond synthetic benchmarks.