---
ver: rpa2
title: Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate
  Synthetic CT Scans from MRIs
arxiv_id: '2407.10888'
source_url: https://arxiv.org/abs/2407.10888
tags:
- images
- synthetic
- scans
- image
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores using deep learning, specifically CycleGAN,
  to generate synthetic CT scans from MRI scans in a clinical setting. The goal is
  to reduce the need for dual imaging, which is costly, time-consuming, and stressful
  for patients.
---

# Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs

## Quick Facts
- arXiv ID: 2407.10888
- Source URL: https://arxiv.org/abs/2407.10888
- Reference count: 40
- Key outcome: CycleGAN models using in-phase and out-of-phase T1-weighted MRI images perform best at generating synthetic CTs that are sometimes indistinguishable from real CTs by medical professionals

## Executive Summary
This work explores using deep learning, specifically CycleGAN, to generate synthetic CT scans from MRI scans in a clinical setting. The goal is to reduce the need for dual imaging, which is costly, time-consuming, and stressful for patients. The study trains CycleGAN models on unpaired MRI and CT data, using various configurations and input modalities. Evaluation includes quantitative metrics like FID and KL divergence, as well as qualitative assessment by medical professionals. Results show that models using in-phase and out-of-phase T1-weighted MRI images perform best, with some models generating images difficult for physicians to distinguish from real CT scans. The study demonstrates the potential of this approach for data augmentation and synthetic image generation in medical imaging.

## Method Summary
The study employs CycleGAN architectures to translate MRI scans to synthetic CT scans without requiring paired data. Models are trained on unpaired MRI (T1-Dual in-phase and out-of-phase, T2) and CT data from the CHAOS and AUTOMI datasets. Various configurations are explored, including single-input and multimodal (2-3 input channels) models. Generators use 9 residual blocks between downsampling and upsampling blocks, with PatchGAN discriminators. Training is unsupervised on unpaired data. Performance is evaluated using quantitative metrics (FID, KL divergence, histogram comparison, spectral analysis) and qualitative assessment by medical professionals through blind testing.

## Key Results
- Multimodal CycleGAN models using in-phase and out-of-phase T1-weighted MRI images achieved the best performance metrics
- Some synthetic CT images generated by the best models were difficult for physicians to distinguish from real CT scans
- Distribution-based metrics (FID, KL divergence) effectively assessed image quality in the absence of ground truth

## Why This Works (Mechanism)

### Mechanism 1
CycleGAN's cycle consistency loss enforces bidirectional anatomical fidelity between MRI and CT domains. The architecture trains two generators: MRI→CT and CT→MRI. Cycle consistency penalizes the difference between input MRI and reconstructed MRI after CT→MRI→CT passes. This preserves anatomical structure while allowing domain-specific texture changes. Core assumption: The anatomical structures are shared between modalities and can be recovered via cyclic transformation. Break condition: If paired data existed, supervised methods could be used instead, making cycle consistency unnecessary.

### Mechanism 2
Multimodal inputs (in-phase + out-of-phase T1) provide complementary tissue contrast that improves synthetic CT realism. Two MRI channels capture different fat/water tissue properties. The model learns to fuse these channels in a latent space, improving differentiation of soft tissues that appear similar in single-channel input. Core assumption: Complementary MRI sequences encode distinct but related information about tissue composition. Break condition: If tissue contrast differences between in-phase and out-of-phase are minimal, adding the second channel provides no benefit.

### Mechanism 3
Distribution-based metrics (FID, KL divergence) provide reasonable proxy for image quality when ground truth is unavailable. These metrics compare statistical distributions of pixel intensities or features between synthetic and real CT images, providing quantitative assessment without requiring pixel-level correspondence. Core assumption: Matching distributions implies matching image quality for medical imaging tasks. Break condition: If synthetic images have correct statistics but incorrect anatomical structures, metrics would be misleading.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: GANs provide the framework for learning the mapping from MRI to CT without paired data.
  - Quick check question: What are the two main components of a GAN and their respective roles?

- Concept: Cycle Consistency
  - Why needed here: Enables training without paired data by enforcing that transformations are reversible.
  - Quick check question: How does cycle consistency help when you don't have corresponding MRI-CT pairs?

- Concept: Fréchet Inception Distance (FID)
  - Why needed here: Provides quantitative measure of synthetic image quality by comparing distributions in feature space.
  - Quick check question: What does a lower FID score indicate about the relationship between real and synthetic image distributions?

## Architecture Onboarding

- Component map: MRI input → Generator → Synthetic CT → Discriminator → Adversarial loss; Synthetic CT → Inverse Generator → Reconstructed MRI → Cycle consistency loss
- Critical path: MRI input → Generator → Synthetic CT → Discriminator → Adversarial loss
- Design tradeoffs:
  - 2D slices vs 3D volumes: 2D is simpler but loses volumetric context
  - Single vs multimodal input: Multimodal improves tissue differentiation but requires more data
  - Contrast vs non-contrast CT: Contrast-enhanced is easier to generate but less clinically useful
- Failure signatures:
  - Poor cycle consistency: Synthetic images don't preserve anatomical structure
  - Mode collapse: Generator produces limited variety of outputs
  - High FID: Statistical mismatch between real and synthetic distributions
- First 3 experiments:
  1. Train single-input CycleGAN with in-phase T1 MRI → CT and evaluate FID
  2. Train multimodal (in-phase + out-of-phase) CycleGAN and compare FID to single-input
  3. Evaluate physician discrimination ability between real and synthetic CTs from best model

## Open Questions the Paper Calls Out

### Open Question 1
How do CycleGAN models trained on unpaired MRI and CT data perform in generating synthetic CT scans that are indistinguishable from real CT scans for medical professionals in a clinical setting? While the study showed that some models could generate images difficult for physicians to distinguish from real CT scans, the extent of this indistinguishability in a real clinical setting remains unclear. The qualitative assessment was conducted in a non-clinical environment, and the study did not explore the practical implications of using these synthetic CT scans in actual medical decision-making processes.

### Open Question 2
What are the optimal input modalities and configurations for CycleGAN models to generate the most anatomically accurate synthetic CT scans from MRI data? While the study identified some promising configurations, such as using in-phase and out-of-phase T1-weighted images, the optimal combination of input modalities and model architecture for generating the most accurate synthetic CT scans remains to be determined.

### Open Question 3
How can the performance of CycleGAN models in generating synthetic CT scans be further improved, particularly in terms of addressing challenges related to anatomical variability and image quality? While the study proposed some potential solutions, such as using spectral analysis to identify and address noise-related issues, further research is needed to develop more effective strategies for improving the performance of CycleGAN models in generating high-quality synthetic CT scans.

## Limitations
- Results are limited to abdominal imaging data, raising questions about generalizability to other anatomical regions
- Reliance on unpaired data necessitates validation of anatomical accuracy beyond statistical metrics
- The study's clinical utility assessment was limited to qualitative evaluation by a small number of medical professionals

## Confidence

**High Confidence**: CycleGAN framework effectiveness for unpaired MRI-to-CT translation; multimodal input superiority (in-phase + out-of-phase T1) for tissue differentiation

**Medium Confidence**: Clinical utility for radiotherapy planning (based on limited physician assessment); quantitative metrics correlation with visual quality

**Low Confidence**: Generalizability to other anatomical regions; long-term clinical adoption potential without paired data requirements

## Next Checks

1. Conduct blinded reader study with multiple radiation oncologists assessing synthetic CT utility for actual dose calculation in treatment planning
2. Test model performance on external datasets from different institutions to evaluate generalization across acquisition protocols
3. Perform dosimetric validation comparing dose calculations from synthetic vs real CT scans using the same treatment plans