---
ver: rpa2
title: 'GAS-Norm: Score-Driven Adaptive Normalization for Non-Stationary Time Series
  Forecasting in Deep Learning'
arxiv_id: '2410.03935'
source_url: https://arxiv.org/abs/2410.03935
tags:
- time
- normalization
- series
- forecasting
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deep neural networks (DNNs)
  underperforming in time series forecasting due to non-stationarity in input data.
  The authors propose GAS-Norm, a novel adaptive normalization method that combines
  Generalized Autoregressive Score (GAS) models with DNNs.
---

# GAS-Norm: Score-Driven Adaptive Normalization for Non-Stationary Time Series Forecasting in Deep Learning

## Quick Facts
- arXiv ID: 2410.03935
- Source URL: https://arxiv.org/abs/2410.03935
- Authors: Edoardo Urettini; Daniele Atzeni; Reshawn J. Ramjattan; Antonio Carta
- Reference count: 40
- Primary result: GAS-Norm improves deep forecasting models' performance in 21 out of 25 settings compared to other normalization methods

## Executive Summary
This paper addresses the challenge of deep neural networks underperforming in time series forecasting due to non-stationarity in input data. The authors propose GAS-Norm, a novel adaptive normalization method that combines Generalized Autoregressive Score (GAS) models with DNNs. GAS models filter time-varying parameters online, providing updated statistics for normalization. The method introduces a hyperparameter γ to control normalization strength and update speed, making it model-agnostic and applicable to any DNN forecasting model.

## Method Summary
GAS-Norm is a novel adaptive normalization method that combines Generalized Autoregressive Score (GAS) models with deep neural networks for time series forecasting. GAS models are statistical models that filter time-varying parameters online, updating them based on the score of the conditional distribution of observations. In GAS-Norm, GAS models are used to provide updated statistics for normalization, which are then used to normalize the input data for DNNs. The method introduces a hyperparameter γ to control the strength of the normalization and the speed of the update. GAS-Norm is model-agnostic and can be applied to any DNN forecasting model, improving their performance on non-stationary time series data.

## Key Results
- GAS-Norm improves deep forecasting models' performance in 21 out of 25 settings compared to other normalization methods
- On AR data, GAS-Norm achieved a MASE of 1.9345 with an input sequence length of 200, outperforming other normalization methods
- The method demonstrated robustness to different data characteristics, including heteroscedastic data with outliers and data with strong seasonality

## Why This Works (Mechanism)
GAS-Norm works by leveraging the online parameter estimation capabilities of GAS models to provide adaptive normalization statistics for DNNs. The GAS model filters time-varying parameters based on the score of the conditional distribution of observations, which captures the changing statistical properties of the data. By using these updated statistics for normalization, GAS-Norm allows DNNs to better adapt to non-stationarity in the input data. The hyperparameter γ controls the strength of the normalization and the speed of the update, allowing for fine-tuning of the method's performance.

## Foundational Learning
- **Generalized Autoregressive Score (GAS) models**: Statistical models that filter time-varying parameters online based on the score of the conditional distribution of observations. Needed to capture changing statistical properties of non-stationary data.
- **Deep neural networks (DNNs)**: Machine learning models composed of multiple layers that can learn complex patterns in data. Needed for time series forecasting tasks.
- **Non-stationarity in time series data**: The property of time series data where statistical properties (e.g., mean, variance) change over time. Quick check: Analyze time series data for trends, seasonality, and structural breaks.
- **Normalization in deep learning**: The process of scaling input data to have zero mean and unit variance. Needed to improve convergence and performance of DNNs.

## Architecture Onboarding
- **Component map**: Input data -> GAS model -> Normalization statistics -> DNN -> Forecast
- **Critical path**: The GAS model provides updated normalization statistics to the DNN, which uses them to make more accurate forecasts on non-stationary time series data.
- **Design tradeoffs**: GAS-Norm trades off computational complexity (due to the online parameter estimation of the GAS model) for improved performance on non-stationary data.
- **Failure signatures**: GAS-Norm may underperform on stationary time series data or when the GAS model fails to accurately capture the changing statistical properties of the data.
- **First experiments**:
  1. Apply GAS-Norm to a simple DNN forecasting model on a synthetic non-stationary time series dataset.
  2. Compare the performance of GAS-Norm with other normalization methods on a real-world non-stationary time series dataset.
  3. Analyze the impact of the hyperparameter γ on the performance of GAS-Norm across different types of non-stationarity.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation focuses primarily on MASE as the performance metric, with limited exploration of alternative error measures
- The hyperparameter γ is introduced as a key control mechanism, but the paper does not provide comprehensive sensitivity analysis or guidance on optimal γ selection across different data regimes
- The empirical validation covers 25 settings across multiple datasets, but the sample size remains relatively modest for establishing generalizability

## Confidence
- **High confidence**: The core methodology combining GAS models with adaptive normalization is technically sound and the general improvement pattern across experiments is well-established.
- **Medium confidence**: The claims about model-agnostic applicability and robustness to various data characteristics need further validation across more diverse forecasting architectures and real-world datasets.
- **Medium confidence**: The quantitative results showing lower MASE are convincing within the tested scenarios, but broader generalization requires additional verification.

## Next Checks
1. Conduct comprehensive sensitivity analysis for the γ hyperparameter across diverse data regimes to establish optimal tuning strategies
2. Expand empirical evaluation to include additional normalization baselines and state-of-the-art forecasting architectures beyond the current scope
3. Test GAS-Norm's performance on larger-scale, real-world time series datasets with varying degrees of non-stationarity to validate robustness claims