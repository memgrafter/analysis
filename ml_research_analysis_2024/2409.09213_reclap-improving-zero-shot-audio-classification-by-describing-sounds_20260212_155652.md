---
ver: rpa2
title: 'ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds'
arxiv_id: '2409.09213'
source_url: https://arxiv.org/abs/2409.09213
tags:
- audio
- reclap
- clap
- zsac
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of zero-shot audio classification
  (ZSAC), where the goal is to classify audio samples into categories not seen during
  training. The authors propose ReCLAP, an improved audio-language model that incorporates
  caption augmentation during training.
---

# ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds

## Quick Facts
- **arXiv ID**: 2409.09213
- **Source URL**: https://arxiv.org/abs/2409.09213
- **Reference count**: 30
- **Primary result**: Achieves 1%-18% improvement on ZSAC benchmarks with prompt augmentation

## Executive Summary
This paper addresses the challenge of zero-shot audio classification (ZSAC), where the goal is to classify audio samples into categories not seen during training. The authors propose ReCLAP, an improved audio-language model that incorporates caption augmentation during training. Specifically, they use a large language model (LLM) to generate diverse rewrites of audio captions, describing sounds using their unique acoustic characteristics. This approach helps the model better understand the relationship between audio and language. Additionally, they introduce prompt augmentation, which generates custom prompts for each category label by describing its acoustic properties in diverse scenes. ReCLAP outperforms baselines on both multi-modal audio-text retrieval and ZSAC tasks. With prompt augmentation, ReCLAP achieves 1%-18% improvement on ZSAC benchmarks and outperforms all baselines by 1%-55%. The results demonstrate the effectiveness of incorporating descriptive features of sounds in both training and inference stages for ZSAC.

## Method Summary
The ReCLAP method involves training an audio-language model with caption augmentation using LLM-generated rewrites of audio captions. During training, each audio sample is paired with multiple rewritten captions describing its acoustic features in varied ways. For zero-shot classification, the method employs prompt augmentation where custom prompts are generated for each category label by describing its acoustic properties in diverse real-world scenes. The model uses contrastive learning between audio and text embeddings, with similarity computed between audio embeddings and text embeddings of category prompts to determine classification.

## Key Results
- ReCLAP outperforms baselines on multi-modal audio-text retrieval and ZSAC tasks
- With prompt augmentation, achieves 1%-18% improvement on ZSAC benchmarks
- Outperforms all baselines by 1%-55% on ZSAC tasks
- Optimal performance achieved with N=2 custom prompts per category

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Caption augmentation via LLM rewriting improves audio-language model understanding by exposing it to diverse linguistic expressions of the same sound event.
- Mechanism: The model is trained on contrastive pairs where each audio sample is paired with multiple rewritten captions describing its acoustic features in varied ways, encouraging the model to focus on underlying sound properties rather than specific phrasing.
- Core assumption: Rewriting preserves the core meaning while varying sentence structure and vocabulary, allowing the model to generalize across different linguistic forms.
- Evidence anchors:
  - [abstract] "These rewritten captions describe each sound event in the original caption using their unique discriminative characteristics."
  - [section] "The instruction used to prompt the LLM is provided in our GitHub. We employ LLaMa-3.1-8B with in-context examples written by humans."
  - [corpus] Weak evidence; related works focus on different prompt strategies but do not explicitly discuss caption augmentation during training.
- Break condition: If rewritten captions introduce noise or alter core meanings, the contrastive training signal becomes unreliable.

### Mechanism 2
- Claim: Prompt augmentation improves zero-shot classification by providing category-specific acoustic descriptions in diverse contexts.
- Mechanism: For each label, the LLM generates multiple prompts that first describe the sound's acoustic properties and then embed that description in different real-world scenes, enriching the model's context for classification.
- Core assumption: Including scene context helps the model disambiguate between similar sound categories by associating them with distinct scenarios.
- Evidence anchors:
  - [abstract] "We generate custom prompts for each category. These custom prompts first describe the sound event in the label and then employ them in diverse scenes."
  - [section] "These custom prompts first describe the sound event in the label and then employ them in diverse scenes."
  - [corpus] Limited; no direct mention of prompt augmentation with scene diversity in the corpus.
- Break condition: If the generated prompts become too verbose or diverge from the intended category meaning, classification accuracy may degrade.

### Mechanism 3
- Claim: Using N=2 custom prompts per category optimizes the balance between coverage and noise.
- Mechanism: Sampling two diverse prompts per category provides enough variability to cover different acoustic contexts without introducing excessive noise from too many unrelated descriptions.
- Core assumption: More than two prompts introduce diminishing returns and potential noise that outweighs the benefit of additional context.
- Evidence anchors:
  - [section] "As we see, the optimal performance is achieved at N=2, and model performance decreases with an increase in N."
  - [corpus] No corpus evidence for this specific hyperparameter choice; inference is from ablation results.
- Break condition: If dataset complexity or category ambiguity increases, a higher N might be beneficial.

## Foundational Learning

- Concept: Contrastive learning between audio and text embeddings
  - Why needed here: The entire ReCLAP model is built on a contrastive objective that aligns audio and text representations, enabling zero-shot classification.
  - Quick check question: What similarity metric is used between audio and text embeddings in ReCLAP's training objective?

- Concept: Zero-shot classification via nearest neighbor search in embedding space
  - Why needed here: After training, classification is performed by comparing audio embeddings to text embeddings of category prompts, requiring understanding of similarity search.
  - Quick check question: How does the model decide which category an audio sample belongs to during inference?

- Concept: Prompt engineering and template-based classification
  - Why needed here: Traditional ZSAC uses fixed prompt templates; understanding this baseline is necessary to appreciate the improvement from custom prompts.
  - Quick check question: What is the main limitation of using fixed prompt templates like "The sound of a {category}"?

## Architecture Onboarding

- Component map:
  - Audio encoder (HTSAT base) -> Text encoder (T5 large) -> Contrastive loss layer -> LLM-based caption rewriter -> LLM-based prompt generator -> Similarity computation module

- Critical path:
  1. Train ReCLAP with augmented captions
  2. Generate custom prompts per category
  3. Compute similarity scores between audio and prompt embeddings
  4. Assign category with highest similarity

- Design tradeoffs:
  - Caption augmentation vs. synthetic audio augmentation (text-based is more interpretable and scalable)
  - Number of custom prompts (N=2 balances coverage and noise)
  - LLM choice (LLaMa-3.1-8B used for quality and efficiency)

- Failure signatures:
  - Degraded performance when rewritten captions lose semantic meaning
  - Overfitting to specific prompt phrasings if augmentation is too limited
  - Noisy prompts if LLM generates irrelevant contexts

- First 3 experiments:
  1. Train ReCLAP on AudioCaps with k=4 caption augmentations and evaluate on text-to-audio retrieval
  2. Generate N=2 custom prompts per category and evaluate ZSAC accuracy on ESC-50
  3. Compare performance with N=1 and N=3 to confirm optimal N=2

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness of caption augmentation relies heavily on LLM rewrite quality, which is not detailed in the paper
- Optimal number of custom prompts (N=2) determined empirically but may not generalize across datasets
- Specific LLM instructions and in-context examples used for caption rewriting are not provided

## Confidence

- **High Confidence**: The core architectural approach of using contrastive learning between audio and text embeddings is well-established. The improvement from 1%-18% on ZSAC benchmarks is supported by ablation studies showing N=2 as optimal.

- **Medium Confidence**: The claim that scene diversity in custom prompts helps disambiguate similar categories assumes that the LLM generates contextually relevant prompts. Without access to the actual prompt templates or evaluation of prompt quality, this mechanism is plausible but not fully verified.

- **Low Confidence**: The specific choice of LLaMa-3.1-8B for caption rewriting and the exact in-context examples used are not detailed, making it difficult to assess whether the same results would be achieved with different LLM configurations.

## Next Checks

1. **Rewrite Quality Analysis**: Analyze a random sample of original and rewritten captions to assess semantic preservation and diversity. Compute embedding similarity between original and rewritten captions to quantify how much variation is introduced.

2. **Prompt Quality Evaluation**: Generate custom prompts for a subset of categories and have human annotators rate their relevance, diversity, and acoustic descriptiveness. Compare with baseline fixed templates.

3. **Ablation on N**: Beyond N=2, test N=1, N=3, and N=5 on multiple datasets to confirm the optimal point and identify any dataset-specific variations in the optimal number of prompts.