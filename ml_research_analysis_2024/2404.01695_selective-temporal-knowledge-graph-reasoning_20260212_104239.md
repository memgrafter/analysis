---
ver: rpa2
title: Selective Temporal Knowledge Graph Reasoning
arxiv_id: '2404.01695'
source_url: https://arxiv.org/abs/2404.01695
tags:
- reasoning
- predictions
- historical
- cehis
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of selective temporal knowledge
  graph (TKG) reasoning, which allows TKG reasoning models to abstain from making
  uncertain predictions. The authors propose a confidence estimator called CEHis that
  combines a certainty scorer (measuring the model's certainty of the current prediction)
  and a historical accuracy scorer (measuring the accuracy of historical predictions
  on related queries).
---

# Selective Temporal Knowledge Graph Reasoning

## Quick Facts
- arXiv ID: 2404.01695
- Source URL: https://arxiv.org/abs/2404.01695
- Reference count: 0
- Key outcome: CEHis improves selective TKG reasoning by modeling both current prediction certainty and historical accuracy using a Hawkes process, outperforming other confidence estimators on ICEWS14 and ICEWS18 datasets.

## Executive Summary
This paper addresses selective temporal knowledge graph (TKG) reasoning, enabling models to abstain from uncertain predictions to control risk. The authors propose CEHis, a confidence estimator that combines a certainty scorer (measuring current prediction confidence) with a historical accuracy scorer (measuring past prediction accuracy on related queries). The historical accuracy scorer uses a Hawkes process to model time-varying impacts of historical predictions. Experiments on ICEWS14 and ICEWS18 demonstrate CEHis outperforms other confidence estimators in AUC and coverage under various risk levels, enabling more reliable TKG reasoning.

## Method Summary
CEHis is a confidence estimator for selective TKG reasoning that combines two scores: a certainty scorer (SR) measuring the model's confidence in the current prediction, and a historical accuracy scorer measuring past prediction accuracy on related queries. The historical accuracy scorer employs a Hawkes process to weight recent historical accuracies more heavily than older ones. A ranking-based aggregation strategy combines these two scores to produce a final confidence score, allowing fair combination regardless of absolute score magnitudes. The method is integrated with baseline TKG reasoning models and evaluated using coverage, risk, effective reliability, and AUC metrics.

## Key Results
- CEHis outperforms other confidence estimators on ICEWS14 and ICEWS18 datasets
- The Hawkes process effectively models time-varying impacts of historical prediction accuracy
- Ranking-based aggregation enables fair combination of certainty and historical accuracy scores
- CEHis achieves better AUC and coverage under different risk levels compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CEHis improves selective prediction by modeling both the certainty of the current prediction and the historical accuracy of related queries.
- Mechanism: CEHis uses a certainty scorer (SR) to measure the model's confidence in the current prediction and a historical accuracy scorer to quantify how accurate past predictions were on related queries. The two scores are then combined using a ranking-based strategy to produce a final confidence score.
- Core assumption: The accuracy of past predictions on queries related to the current one is a strong indicator of whether the current prediction is likely to be correct.
- Evidence anchors:
  - [abstract] "CEHis takes two kinds of information into consideration, namely, the certainty of the current prediction and the accuracy of historical predictions."
  - [section] "there usually exist some historical predictions that may also help the model decide whether or not to abstain."
  - [corpus] Weak evidence: related papers focus on rule-based and LLM-based TKG forecasting, not selective prediction.
- Break condition: If the historical predictions are irrelevant or the time-varying impact is incorrectly modeled, the historical accuracy score may mislead the confidence estimator.

### Mechanism 2
- Claim: The Hawkes process models the time-varying impact of historical prediction accuracy on current confidence.
- Mechanism: The Hawkes process assigns greater weight to recent historical prediction accuracies and exponentially decays the impact of older ones, using a decay rate δ. This captures both long-term base accuracy and short-term recent accuracy.
- Core assumption: Recent historical predictions have a stronger influence on the confidence of the current prediction than older ones.
- Evidence anchors:
  - [section] "we employ the Hawkes process (Hawkes, 2018) to estimate this impact of long-term and short-term."
  - [section] "the accuracy of recent historical predictions is more important than older ones."
  - [corpus] No direct evidence in corpus papers; this is specific to the paper's method.
- Break condition: If the decay rate δ is poorly chosen or the assumption about recency is invalid for the dataset, the Hawkes process weighting may distort the confidence estimation.

### Mechanism 3
- Claim: The ranking-based aggregation strategy avoids scale mismatch between certainty and historical accuracy scores.
- Mechanism: Instead of directly adding the two scores (which may be on different scales), CEHis ranks all queries by each score separately, then combines the ranks using a weight β. This allows fair combination regardless of absolute score magnitudes.
- Core assumption: The relative ordering of queries by certainty and historical accuracy is more meaningful than their absolute values for combining into a single confidence score.
- Evidence anchors:
  - [section] "they cannot be directly combined using absolute values. To this end, CEHis utilizes a ranking-based aggregation strategy."
  - [section] "CEHis utilizes a ranking-based aggregation strategy, which first ranks queries according to the above two different scores, and then calculates the final confidence score of two based on the results of the two rankings."
  - [corpus] No direct evidence in corpus papers; this is a unique design choice in the paper.
- Break condition: If the distribution of certainty scores or historical accuracy scores is highly skewed, ranking-based aggregation may lose important absolute score information.

## Foundational Learning

- Concept: Temporal Knowledge Graphs (TKGs) store evolving facts with timestamps as (subject, relation, object, timestamp).
  - Why needed here: Understanding TKGs is essential to grasp the problem setting of predicting future facts and the need for selective prediction.
  - Quick check question: What are the four components of a fact in a TKG?

- Concept: Selective prediction allows models to abstain from making uncertain predictions to control risk.
  - Why needed here: This is the core setting the paper addresses; understanding it is key to understanding CEHis's purpose.
  - Quick check question: What is the trade-off that selective prediction seeks to balance?

- Concept: The Hawkes process models self-exciting event sequences with time-varying impact.
  - Why needed here: CEHis uses the Hawkes process to model how historical prediction accuracies impact current confidence over time.
  - Quick check question: How does the Hawkes process weight recent events compared to older ones?

## Architecture Onboarding

- Component map: Basic TKG reasoning model → Certainty scorer (SR) → Historical accuracy scorer (Hawkes process on related queries) → Ranking-based aggregation (β-weighted sum of ranks) → Final confidence score.
- Critical path: Input query → Basic model prediction probabilities → Certainty scorer (max probability) → Related queries extraction → Historical accuracy scorer (Hawkes process) → Ranking-based aggregation → Final confidence score.
- Design tradeoffs: Certainty scorer vs. historical accuracy scorer importance (controlled by β); Hawkes process decay rate δ; length hyperparameter l for truncation.
- Failure signatures: Overconfident predictions (low abstention despite wrong answers); overly conservative predictions (high abstention despite correct answers); time-decay parameters poorly tuned.
- First 3 experiments:
  1. Verify certainty scorer (SR) alone on validation set: measure coverage/risk tradeoff.
  2. Verify historical accuracy scorer alone: compare with certainty scorer performance.
  3. Full CEHis with varying β and δ: tune hyperparameters on validation set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific impact does modeling the accuracy of historical predictions on related queries have on the overall performance of selective TKG reasoning?
- Basis in paper: [explicit] The paper mentions that CEHis outperforms other confidence estimators by modeling the accuracy of historical predictions on related queries.
- Why unresolved: The paper does not provide detailed quantitative analysis on how much each type of related query (subject, relation, both) contributes to the final confidence score.
- What evidence would resolve it: A detailed ablation study showing the individual and combined effects of each related query type on the performance metrics (AUC, coverage, effective reliability).

### Open Question 2
- Question: How does the decay rate δ in the Hawkes process affect the performance of CEHis?
- Basis in paper: [explicit] The paper mentions that δ is a hyperparameter used to calculate the decaying impact of historical accuracy.
- Why unresolved: The paper does not provide a sensitivity analysis of the decay rate on the performance of CEHis.
- What evidence would resolve it: A study showing the performance of CEHis with different values of δ and how it affects the AUC, coverage, and effective reliability.

### Open Question 3
- Question: How does the aggregation weight β in the ranking-based aggregation strategy affect the performance of CEHis?
- Basis in paper: [explicit] The paper mentions that β is an aggregation weight used to combine the certainty score and historical accuracy score.
- Why unresolved: The paper does not provide a sensitivity analysis of the aggregation weight on the performance of CEHis.
- What evidence would resolve it: A study showing the performance of CEHis with different values of β and how it affects the AUC, coverage, and effective reliability.

## Limitations

- The method's performance is tied to the quality of the underlying TKG reasoning model
- The decay rate δ in the Hawkes process is assumed optimal without thorough sensitivity analysis
- The approach may struggle with cold-start scenarios where limited historical predictions exist

## Confidence

- Mechanism 1: Medium - The correlation between historical and current prediction accuracy is plausible but not universally validated
- Mechanism 2: Medium - The Hawkes process is theoretically sound but its effectiveness for this specific application needs more empirical validation
- Mechanism 3: Medium - Ranking-based aggregation is a reasonable approach but may lose important absolute score information

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of certainty scoring vs. historical accuracy scoring
2. Test CEHis with varying decay rates δ across different TKG datasets to assess sensitivity
3. Evaluate performance on datasets with different temporal patterns (e.g., bursty vs. steady prediction frequencies) to test the robustness of the Hawkes process assumption