---
ver: rpa2
title: 'Towards a clinically accessible radiology foundation model: open-access and
  lightweight, with automated evaluation'
arxiv_id: '2403.08002'
source_url: https://arxiv.org/abs/2403.08002
tags:
- llav
- a-rad
- image
- report
- radiology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents LLaVA-Rad, a lightweight and open-source multimodal
  foundation model designed to address the challenges of deploying state-of-the-art
  medical AI in clinical settings. The key innovation is a modular training approach
  that leverages pre-trained image and text models, with a focus on a lightweight
  adapter to align modalities.
---

# Towards a clinically accessible radiology foundation model: open-access and lightweight, with automated evaluation

## Quick Facts
- **arXiv ID:** 2403.08002
- **Source URL:** https://arxiv.org/abs/2403.08002
- **Authors:** Juan Manuel Zambrano Chaves, Shih-Cheng Huang, Yanbo Xu, Hanwen Xu, Naoto Usuyama, Sheng Zhang, Fei Wang, Yujia Xie, Mahmoud Khademi, Ziyi Yang, Hany Awadalla, Julia Gong, Houdong Hu, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Yu Gu, Cliff Wong, Mu Wei, Tristan Naumann, Muhao Chen, Matthew P. Lungren, Akshay Chaudhari, Serena Yeung-Levy, Curtis P. Langlotz, Sheng Wang, Hoifung Poon
- **Reference count:** 40
- **Primary result:** LLaVA-Rad achieves state-of-the-art performance on radiology benchmarks with a lightweight 2.7B parameter model

## Executive Summary
LLaVA-Rad is a multimodal foundation model designed for clinical radiology applications, addressing the challenge of deploying AI in resource-constrained healthcare settings. The model leverages pre-trained image and text encoders with a lightweight adapter to align modalities, enabling efficient training and inference. Trained on 697,000 chest X-ray images paired with radiology reports, it outperforms larger models like GPT-4V and Med-PaLM M on standard tasks such as report generation and cross-modal retrieval. The model's modular design allows fast inference on a single V100 GPU, making it accessible for real-world clinical deployment.

## Method Summary
LLaVA-Rad employs a modular training approach using pre-trained vision (BiomedCLIP-CXR) and text (Vicuna-7B-v1.5) models, with a focus on training a lightweight MLP adapter to align image features with the language model's word embedding space. The model was trained on a large dataset of 697,000 chest X-ray images paired with radiology reports, augmented with GPT-4 for data processing and synthesis. For evaluation, the authors introduced CheXprompt, a GPT-4-based metric for factual accuracy that demonstrated high correlation with expert radiologist assessments. The model achieved state-of-the-art performance on benchmarks like MIMIC-CXR, with F1-RadGraph score of 29.4 and ROUGE-L of 38.1.

## Key Results
- Achieved F1-RadGraph score of 29.4 and ROUGE-L of 38.1 on MIMIC-CXR benchmark
- Outperformed larger models like GPT-4V and Med-PaLM M (84B) in report generation and cross-modal retrieval
- Demonstrated efficient inference on a single V100 GPU with fast fine-tuning capabilities
- Introduced CheXprompt, a GPT-4-based evaluation metric showing high correlation with expert assessments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Using a modular approach with domain-specific pre-trained models and a lightweight adapter improves data efficiency and model performance in clinical radiology tasks.
- **Mechanism:** The model leverages pre-trained vision and text encoders (BiomedCLIP-CXR and Vicuna-7B-v1.5) and focuses on training a lightweight MLP to align image features with the language model's word embedding space. This modular approach allows the model to benefit from large-scale pre-training while focusing computational resources on the alignment task.
- **Core assumption:** Pre-trained models on general domains can be effectively adapted to specialized biomedical tasks with minimal fine-tuning.
- **Evidence anchors:**
  - [abstract]: "We adopt a modular approach by incorporating state-of-the-art pre-trained models for image and text modalities, and focusing on training a lightweight adapter to ground each modality to the text embedding space."
  - [section]: "Our intuition for designing LLaVA-Rad is that a lightweight, specialized SMM can be efficiently developed by decomposing training into unimodal pretraining on individual modalities followed by lightweight cross-modal learning focusing on a small adapter to ground a non-text modality to the text embedding space."

### Mechanism 2
- **Claim:** GPT-4 can be effectively used to synthesize radiology reports from structured labels and translate reports, enhancing the training dataset.
- **Mechanism:** GPT-4 is used to generate synthetic reports based on annotated image labels for datasets that lack free-text reports. It also translates reports from other languages into English, ensuring linguistic consistency across the training data.
- **Core assumption:** GPT-4 can generate clinically accurate and relevant reports that are consistent with the ground-truth labels.
- **Evidence anchors:**
  - [abstract]: "For training, we assemble a large dataset comprising 697 thousand radiology image-report pairs from 7 diverse sources. Some data sources only contain structured labels of key findings, in which case we use GPT-4 to synthesize the report based on the ground-truth labels."
  - [section]: "Since CXR images are often published with a limited number of associated findings or image labels instead of a complete report, we used GPT-4 to synthesize a report based on annotated image labels."

### Mechanism 3
- **Claim:** CheXprompt, a GPT-4-based evaluation metric, provides a more accurate assessment of factual correctness in generated radiology reports compared to traditional metrics.
- **Mechanism:** GPT-4 is used to evaluate the factual correctness of generated reports by identifying specific error types, such as false positive findings, omission of findings, and incorrect locations/positions of findings. The evaluation is designed to be consistent with expert radiologist assessments.
- **Core assumption:** GPT-4 can accurately identify and categorize errors in radiology reports, providing a reliable assessment of factual correctness.
- **Evidence anchors:**
  - [abstract]: "For evaluation, we propose CheXprompt, a GPT-4-based metric for factuality evaluation, and demonstrate its parity with expert evaluation."
  - [section]: "We thus explore the utility of an LLM-based evaluation system, which has shown success in other domains [32, 48, 15]. Specifically, we employ GPT-4 as an evaluator to count how often the generated report contains errors in each of the following six categories, as per a previous study [53]."

## Foundational Learning

- **Concept:** Multimodal learning and alignment of image and text representations.
  - **Why needed here:** The model needs to understand the relationship between chest X-ray images and their corresponding radiology reports to generate accurate and relevant reports.
  - **Quick check question:** How does the model align image features with the word embedding space of the language model?

- **Concept:** Data augmentation and synthetic data generation using large language models.
  - **Why needed here:** The model requires a large and diverse dataset to learn the complex relationship between chest X-ray images and their corresponding reports. GPT-4 is used to generate synthetic reports from structured labels and translate reports from other languages.
  - **Quick check question:** How does GPT-4 generate synthetic reports that are clinically accurate and relevant?

- **Concept:** Evaluation of factual correctness in generated reports using language models.
  - **Why needed here:** Traditional metrics may not accurately assess the factual correctness of generated radiology reports. GPT-4 is used to identify specific error types and provide a more reliable assessment of factual correctness.
  - **Quick check question:** How does GPT-4 identify and categorize errors in radiology reports?

## Architecture Onboarding

- **Component map:** BiomedCLIP-CXR (Image encoder) -> MLP adapter -> Vicuna-7B-v1.5 (Text encoder) -> Generated report
- **Critical path:** Image encoder → MLP adapter → Text encoder → Generated report
- **Design tradeoffs:**
  - Using a modular approach with pre-trained models allows for efficient training but may limit the model's ability to learn complex relationships between images and reports.
  - Using GPT-4 for data augmentation and evaluation can enhance the training dataset and provide a more accurate assessment of factual correctness but may introduce biases or errors.
- **Failure signatures:**
  - Poor alignment between image and text representations may result in inaccurate or irrelevant generated reports.
  - Errors in GPT-4-generated reports may lead to incorrect associations between images and reports.
  - Inconsistencies between GPT-4's evaluation and expert radiologist assessments may indicate limitations in the CheXprompt metric.
- **First 3 experiments:**
  1. Evaluate the alignment between image and text representations using cross-modal retrieval tasks.
  2. Assess the accuracy of GPT-4-generated reports by comparing them to ground-truth reports.
  3. Validate the CheXprompt metric by comparing its evaluations to those of expert radiologists.

## Open Questions the Paper Calls Out
None

## Limitations
- Clinical applicability remains uncertain due to lack of real-world validation across diverse patient populations and imaging protocols
- Reliance on GPT-4 for data synthesis and evaluation introduces potential biases and limitations
- Lightweight design may limit capacity to capture complex multimodal relationships in rare or complex clinical scenarios

## Confidence

- **High Confidence:** The modular training approach with pre-trained models and lightweight adapters is technically sound and well-supported by experimental results
- **Medium Confidence:** The effectiveness of GPT-4 for data synthesis and evaluation is promising but requires further validation
- **Low Confidence:** The model's real-world clinical utility and generalizability across diverse healthcare settings remain unproven

## Next Checks
1. **Clinical Validation Study:** Conduct a prospective study evaluating LLaVA-Rad's performance in actual clinical settings, comparing its outputs against radiologist interpretations across diverse patient populations and imaging protocols.

2. **Cross-Center Performance Evaluation:** Test the model's performance on chest X-ray datasets from multiple institutions with different imaging equipment, protocols, and patient demographics.

3. **Longitudinal Reliability Assessment:** Implement a monitoring framework to evaluate the model's performance consistency over time as new clinical data becomes available.