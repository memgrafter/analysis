---
ver: rpa2
title: Optimal feature rescaling in machine learning based on neural networks
arxiv_id: '2402.10964'
source_url: https://arxiv.org/abs/2402.10964
tags:
- training
- test
- problem
- ffnn
- grinding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel Optimal Feature Rescaling (OFR) method
  to improve Feed Forward Neural Network (FFNN) performance by reshaping the input
  space through optimal scaling factors determined via a Genetic Algorithm (GA). The
  OFR approach enhances gradient-based training efficiency and helps avoid local minima
  by enabling a multi-start global search, as the scale factors exploration corresponds
  to different weight initializations.
---

# Optimal feature rescaling in machine learning based on neural networks

## Quick Facts
- arXiv ID: 2402.10964
- Source URL: https://arxiv.org/abs/2402.10964
- Reference count: 20
- Primary result: OFR improves FFNN R² by 51.44% over standardization on centerless grinding task

## Executive Summary
This paper introduces Optimal Feature Rescaling (OFR), a method that uses a Genetic Algorithm to find optimal scaling factors for input features in Feed Forward Neural Networks. By reshaping the input space, OFR improves gradient-based training efficiency and helps avoid local minima through a multi-start global search. Tested on a centerless grinding roundness prediction task, OFR outperformed standard feature standardization with a 51.44% improvement in R² coefficient of determination.

## Method Summary
The OFR method combines Genetic Algorithm optimization with FFNN training to find optimal scaling factors for input features. A GA searches over scaling factors in log-scale [-3,3] to minimize validation RMSE, while FFNNs are trained with ADAM optimizer and MAE loss. The approach is tested on a centerless grinding dataset with 12 process parameters and 4069 samples, using 70/15/15 train/validation/test splits. Three FFNN architectures are evaluated with 10-fold cross-validation.

## Key Results
- OFR achieved 51.44% improvement in R² coefficient of determination over baseline standardization
- The method reduced overfitting when combined with Early Stopping
- Training time increased due to GA optimization overhead
- OFR enabled better-conditioned gradients and multi-start optimization through different first-layer weight initializations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal Feature Rescaling improves FFNN performance by reshaping the input space to improve gradient-based algorithm conditioning.
- Mechanism: Rescaling input features with optimal scaling factors changes the effective weights of the first layer, making the loss surface smoother and gradients more stable during training.
- Core assumption: The loss surface becomes more convex-like in the rescaled space, allowing gradient descent to converge faster and avoid poor local minima.
- Evidence anchors:
  - [abstract] "The OFR reshapes the input space improving the conditioning of the gradient-based algorithm used for the training."
  - [section] "the scale factors exploration entailed by GA trials and selection corresponds to different initialization of the first layer weights at each training attempt"

### Mechanism 2
- Claim: OFR enables a restrained multi-start global search by exploring different weight initializations through scale factor exploration.
- Mechanism: Each GA trial applies a different set of scaling factors, which is equivalent to a different initialization of the first-layer weights; the GA selects the initialization that yields the lowest validation error.
- Core assumption: The multiple local minima accessible via different first-layer initializations correspond to meaningful variations in model performance, and GA can identify better ones than random initialization.
- Evidence anchors:
  - [abstract] "the scale factors exploration entailed by GA trials and selection corresponds to different initialization of the first layer weights at each training attempt, thus realizing a multi-start global search algorithm"
  - [section] "different scale factors make training converge to different minima"

### Mechanism 3
- Claim: OFR reduces overfitting when combined with Early Stopping by finding a better basin of attraction for the optimizer.
- Mechanism: Better-conditioned gradients and improved initialization lead to solutions that generalize more robustly, so Early Stopping halts training before the model starts fitting noise.
- Core assumption: The local minimum found by OFR + gradient descent is inherently smoother or flatter, making it less prone to overfitting even with longer training.
- Evidence anchors:
  - [section] "analyzing the discrepancy between the performances on the train set and the ones obtained with cross-validation, it can be deduced that the model is affected by the overfitting problem"
  - [section] "the improvement achieved by using the OFR technique can be seen from Table III. However, the performances of the FFNN are still rather poor despite the implementation of ES"

## Foundational Learning

- Concept: Genetic Algorithm (GA) as a global optimizer
  - Why needed here: The objective function (validation error as a function of scaling factors) is non-convex and lacks analytical form, so local methods are insufficient.
  - Quick check question: What is the role of the fitness function in a GA, and how does it differ from a loss function in gradient descent?

- Concept: Input feature scaling and its effect on neural network training
  - Why needed here: Scaling alters the effective first-layer weights and the conditioning of the Hessian, directly influencing convergence speed and local minima quality.
  - Quick check question: How does feature standardization affect the range of sigmoid activations compared to unscaled inputs?

- Concept: Early Stopping as regularization
  - Why needed here: OFR improves convergence to better minima, but without regularization the model can still overfit; Early Stopping halts training when validation error rises.
  - Quick check question: What is the difference between training error and validation error, and why does their divergence indicate overfitting?

## Architecture Onboarding

- Component map: Dataset preprocessing -> GA optimization -> FFNN training -> Validation evaluation -> GA selection
- Critical path:
  1. Preprocess data (standardize → rescale with GA-selected factors)
  2. For each GA individual: train FFNN → evaluate validation RMSE
  3. GA selection, crossover, mutation → new scaling candidates
  4. Repeat until GA convergence or max iterations
  5. Final model: trained with best scaling factors, optionally with ES

- Design tradeoffs:
  - GA population size vs. search coverage: larger populations explore more but cost more per iteration
  - GA iterations vs. training epochs: more GA steps improve scaling but increase wall-clock time
  - FFNN complexity vs. overfitting: deeper nets may fit better but need stronger regularization
  - Standardization before OFR vs. raw inputs: standardization can help GA focus on multiplicative adjustments

- Failure signatures:
  - No improvement over baseline: scaling factors too constrained or GA search too limited
  - Overfitting persists: model capacity too high or regularization too weak
  - Training time explodes: too many GA evaluations or excessive FFNN epochs

- First 3 experiments:
  1. Run GA with only standardization (scaling factors = 1) to confirm baseline performance
  2. Run GA with random scaling factors to verify that scaling exploration changes training outcomes
  3. Run GA with early stopping enabled to test overfitting reduction claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Optimal Feature Rescaling (OFR) method scale with higher-dimensional input spaces (M >> 12) in terms of computational time and performance?
- Basis in paper: [inferred] The paper tests OFR on a 12-parameter centerless grinding problem, but does not explore scalability to high-dimensional problems.
- Why unresolved: Computational time for GA scales poorly with dimensionality (exponential growth in search space), and the method's effectiveness in capturing optimal rescaling factors for large M is unclear.
- What evidence would resolve it: Experiments on synthetic or real-world datasets with M > 50 parameters, comparing OFR's performance and runtime to standard scaling methods.

### Open Question 2
- Question: Can the OFR approach be generalized to recurrent or convolutional neural network architectures, or is its benefit limited to Feed Forward Neural Networks (FFNNs)?
- Basis in paper: [explicit] The paper explicitly states that future work will explore extending the OFR strategy to all network weights, suggesting current limitations to FFNNs.
- Why unresolved: The paper focuses solely on FFNNs and does not test OFR on architectures with weight-sharing (e.g., CNNs) or temporal dependencies (e.g., RNNs).
- What evidence would resolve it: Application of OFR to CNNs or RNNs on tasks like image classification or time series forecasting, measuring performance gains over standard initialization and scaling.

### Open Question 3
- Question: Is there a theoretical justification for why the GA-selected rescaling factors improve generalization, beyond the empirical observation of better validation performance?
- Basis in paper: [inferred] The paper suggests OFR improves conditioning and acts as a multi-start global search, but does not provide rigorous mathematical proof.
- Why unresolved: The link between input rescaling, weight initialization, and global minima in non-convex loss landscapes is only hypothesized, not formally proven.
- What evidence would resolve it: A theoretical analysis (e.g., spectral properties of the Hessian, Lipschitz continuity bounds) connecting OFR-induced weight scaling to smoother loss landscapes and reduced sensitivity to initialization.

### Open Question 4
- Question: How sensitive is the OFR method to the choice of GA hyperparameters (population size, mutation rate, crossover strategy), and can these be optimized automatically?
- Basis in paper: [explicit] The paper uses fixed GA hyperparameters (population size 20, mutation rate 0.2, etc.) without exploring their impact on performance.
- Why unresolved: GA is a stochastic method, and suboptimal hyperparameters could lead to premature convergence or excessive computation without performance gains.
- What evidence would resolve it: A hyperparameter sensitivity analysis or automated tuning (e.g., Bayesian optimization) to identify the most robust GA settings for OFR across diverse datasets.

## Limitations
- Limited to a single industrial dataset (centerless grinding) for empirical validation
- GA optimization significantly increases training time compared to standard methods
- No theoretical proof of why GA-selected rescaling factors improve generalization
- Sensitivity to GA hyperparameters not explored

## Confidence
- Mechanism 1: Medium - Conditioning improvement is theoretically sound but needs broader empirical validation
- Mechanism 2: Medium - Multi-start optimization through scaling is plausible but GA's effectiveness needs more testing
- Mechanism 3: Low - Overfitting reduction claim needs more rigorous statistical validation

## Next Checks
1. Replicate the centerless grinding experiment with different random seeds to assess result stability
2. Test OFR on benchmark regression datasets (Boston Housing, Energy Efficiency) to evaluate generalization
3. Compare GA-based OFR with grid search and random search baselines to isolate the benefit of evolutionary optimization