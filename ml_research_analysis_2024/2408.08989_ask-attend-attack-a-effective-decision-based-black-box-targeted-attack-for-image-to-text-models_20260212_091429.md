---
ver: rpa2
title: 'Ask, Attend, Attack: A Effective Decision-Based Black-Box Targeted Attack
  for Image-to-Text Models'
arxiv_id: '2408.08989'
source_url: https://arxiv.org/abs/2408.08989
tags:
- target
- text
- attack
- attacks
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes Ask, Attend, Attack (AAA), a decision-based
  black-box targeted attack method for image-to-text models. The key idea is to use
  a three-stage framework: Ask stage generates target text semantically aligned with
  the image; Attend stage identifies critical image regions using attention heatmaps;
  Attack stage employs an evolutionary algorithm to optimize perturbations in these
  regions.'
---

# Ask, Attend, Attack: A Effective Decision-Based Black-Box Targeted Attack for Image-to-Text Models

## Quick Facts
- arXiv ID: 2408.08989
- Source URL: https://arxiv.org/abs/2408.08989
- Reference count: 38
- Primary result: AAA achieves significantly higher semantic similarity scores with minimal perturbation compared to existing gray-box methods

## Executive Summary
This paper proposes Ask, Attend, Attack (AAA), a novel decision-based black-box targeted attack method for image-to-text models. The key innovation is a three-stage framework that generates semantically aligned target texts, identifies critical image regions through attention heatmaps, and employs evolutionary optimization to achieve targeted attacks without semantic loss. Experiments on VIT-GPT2 and Show-Attend-Tell models demonstrate AAA outperforms existing gray-box methods, achieving higher semantic similarity metrics while maintaining minimal perturbation requirements.

## Method Summary
AAA introduces a three-stage decision-based black-box targeted attack framework for image-to-text models. The Ask stage generates target text semantically aligned with the image by compiling a semantic dictionary from words within the image's feature space. The Attend stage identifies critical image regions using attention heatmaps computed through a surrogate model and Grad-CAM visualization, effectively reducing the search space. The Attack stage employs differential evolution to optimize perturbations in these regions, directly minimizing distance between target text and model output in CLIP's embedding space. This approach addresses the semantic loss issue common in gray-box methods while maintaining attack success.

## Key Results
- AAA outperforms existing gray-box methods on VIT-GPT2 and Show-Attend-Tell models
- Achieves significantly higher semantic similarity scores (CLIP, METEOR, BLEU) with minimal perturbation (ϵ ≤ 25)
- Effectively addresses semantic loss while maintaining attack success rates
- Successfully demonstrates targeted attacks without semantic drift across various image-to-text models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AAA reduces the effective search space by identifying critical image regions through attention heatmaps
- Mechanism: The Attend stage uses Grad-CAM attention heatmaps to localize regions most important for generating target text, restricting differential evolution search to these regions
- Core assumption: Attention heatmaps accurately identify regions critical to model's text generation for target text
- Evidence anchors: [abstract], [section], weak corpus evidence
- Break condition: If attention heatmap misidentifies regions due to surrogate model mismatch, attack may fail or require more queries

### Mechanism 2
- Claim: AAA prevents semantic loss by using target semantic dictionary aligned with image's feature space
- Mechanism: Ask stage creates semantic dictionary by searching feature space around clean image for words semantically related to attacker's target semantics
- Core assumption: Words closer to clean image in feature space are more likely to be used by model in generating text
- Evidence anchors: [abstract], [section], weak corpus evidence
- Break condition: If semantic dictionary is too limited or target semantics too ambiguous, attack may not achieve desired target text

### Mechanism 3
- Claim: AAA achieves targeted attacks without semantic loss by directly optimizing against target text's deep features
- Mechanism: Attack stage uses differential evolution to optimize perturbations, minimizing distance between target text and model's output text in CLIP embedding space
- Core assumption: CLIP text encoder provides meaningful similarity metric for text that model can optimize against
- Evidence anchors: [abstract], [section], weak corpus evidence
- Break condition: If CLIP embedding space doesn't align well with model's text generation space, optimization may not converge to target text

## Foundational Learning

- Concept: Evolutionary algorithms for large-scale optimization
  - Why needed here: Search space for adversarial perturbations is huge (all pixels), making gradient-based methods infeasible in black-box settings
  - Quick check question: How does differential evolution differ from genetic algorithms, and why is it suitable for continuous optimization like image pixels?

- Concept: Attention mechanisms and Grad-CAM
  - Why needed here: Understanding how attention heatmaps can identify important regions in image for given text output
  - Quick check question: What is difference between Grad-CAM and class activation maps (CAM), and how does Grad-CAM work with surrogate model?

- Concept: Text similarity metrics and embedding spaces
  - Why needed here: Method relies on measuring semantic similarity between texts using CLIP embeddings
  - Quick check question: How does cosine similarity between CLIP embeddings relate to semantic similarity, and why is it used instead of string-based metrics like BLEU?

## Architecture Onboarding

- Component map: Ask stage -> Attend stage -> Attack stage (sequential, each stage depends on previous)
- Critical path: Ask → Attend → Attack
- Design tradeoffs:
  - Search space reduction vs. attack coverage: Too aggressive reduction may miss important regions
  - Semantic dictionary size vs. search efficiency: Larger dictionaries provide more options but increase search complexity
  - CLIP embedding similarity vs. model's internal text representation: May not perfectly align
- Failure signatures:
  - Attack fails to converge: Check if attention heatmap is accurate and search space is appropriately reduced
  - Semantic loss occurs: Verify target semantic dictionary is correctly generated and target text is properly constructed
  - High perturbation size needed: Attention heatmap may not be identifying most critical regions
- First 3 experiments:
  1. Verify Ask stage generates reasonable semantic dictionary for simple image and target semantics
  2. Test Attend stage with known image and target text to ensure attention heatmap highlights correct regions
  3. Run Attack stage with reduced search space to confirm it can find valid adversarial example

## Open Questions the Paper Calls Out
- How does AAA perform against other types of vision-language models beyond VIT-GPT2 and Show-Attend-Tell?
- Can AAA framework be adapted for real-time adversarial attacks where computation time is critical?
- How does choice of surrogate model impact effectiveness of Attend stage across different image domains?
- What are implications of AAA's targeted attacks on user trust and safety in real-world applications?

## Limitations
- No ablation studies provided to quantify performance degradation when skipping attention stage or using different attention mechanisms
- Limited empirical validation of semantic dictionary construction and its sensitivity to dictionary size and composition
- No verification that CLIP embedding space aligns well with target image-to-text model's internal text representation

## Confidence
- **High confidence**: Overall framework design and sequential nature of Ask→Attend→Attack is logically sound and well-articulated
- **Medium confidence**: Experimental results showing AAA outperforms existing gray-box methods are compelling but comparison setup may not fully capture real-world black-box scenarios
- **Low confidence**: Claims about preventing semantic loss and achieving targeted attacks without semantic drift lack rigorous validation

## Next Checks
1. **Ablation study on attention heatmap**: Run full AAA attack with and without Attend stage on subset of Flick30k images, measuring attack success rate and query efficiency
2. **CLIP embedding space validation**: Compute both CLIP embedding similarity and actual output similarity from target image-to-text model for set of target texts and their adversarial examples
3. **Semantic drift analysis**: Systematically vary target semantics complexity and measure semantic similarity between target and generated texts using multiple metrics and human evaluation