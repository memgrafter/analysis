---
ver: rpa2
title: Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive
  Tasks
arxiv_id: '2407.09893'
source_url: https://arxiv.org/abs/2407.09893
tags:
- knowledge
- trajectory
- learning
- intent
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SMART, a novel multi-agent framework for
  knowledge-intensive tasks that leverages external knowledge to enhance the interpretability
  and factual consistency of LLM-generated responses. The framework comprises four
  specialized agents (Intent Reconstructor, Knowledge Retriever, Fact Locator, and
  Response Generator) that perform distinct sub-trajectory actions, addressing challenges
  like complex query intent, distractors in retrieved knowledge, and insufficient
  knowledge utilization.
---

# Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks

## Quick Facts
- **arXiv ID**: 2407.09893
- **Source URL**: https://arxiv.org/abs/2407.09893
- **Reference count**: 40
- **Primary result**: SMART achieves significant improvements in knowledge-intensive tasks using only 40% of long trajectory data while maintaining strong performance when agents are missing

## Executive Summary
This paper introduces SMART, a novel multi-agent framework designed to address knowledge-intensive tasks by leveraging external knowledge sources to enhance interpretability and factual consistency of LLM-generated responses. The framework consists of four specialized agents (Intent Reconstructor, Knowledge Retriever, Fact Locator, and Response Generator) that perform distinct sub-trajectory actions to handle complex query intents, distractors in retrieved knowledge, and insufficient knowledge utilization. To optimize agent collaboration while maintaining fine-grained execution, the authors propose Long-Short Trajectory Learning, a two-stage training approach that first develops individual agent capabilities and then establishes inter-agent interactions through trajectory tokens. Extensive experiments on five knowledge-intensive tasks demonstrate SMART's superior performance compared to widely adopted knowledge internalization and enhancement methods, achieving significant improvements across accuracy, fluency, and factuality metrics while substantially reducing development costs.

## Method Summary
The SMART framework employs a two-stage Long-Short Trajectory Learning approach for training multi-agent systems on knowledge-intensive tasks. The method first uses Short Trajectory Learning to develop individual agent capabilities in isolation, preventing error accumulation common in traditional pipelined approaches. Then Long Trajectory Learning establishes inter-agent communication patterns through special trajectory tokens that mark agent boundaries and provide skeleton structure for the workflow. The framework consists of four specialized agents: Intent Reconstructor (processes user instructions and identifies key queries), Knowledge Retriever (accesses top-k knowledge documents using off-the-shelf retrieval), Fact Locator (evaluates retrieved knowledge and identifies factual spans), and Response Generator (produces final responses with proper citations). The approach achieves strong performance using only 40% of long trajectory data, substantially reducing development costs while maintaining flexibility when agents are missing during inference.

## Key Results
- SMART achieves significant improvements across accuracy, fluency, and factuality metrics on five knowledge-intensive tasks
- The framework maintains strong performance using only 40% of long trajectory data, substantially reducing development costs
- SMART demonstrates flexibility by maintaining performance when agents are missing during inference, unlike traditional pipelined approaches

## Why This Works (Mechanism)

### Mechanism 1: Two-stage training prevents error accumulation
The framework separates fine-grained agent training from inter-agent coordination through Short Trajectory Learning (isolating individual capabilities) followed by Long Trajectory Learning (establishing communication patterns). This prevents earlier agent mistakes from propagating through the pipeline, as agent-specific tasks don't require strict sequential dependencies.

### Mechanism 2: Trajectory tokens enable effective coordination
Special tokens (e.g., <Reconstructor>, <Locator>, <Generator>) mark agent boundaries and provide skeleton structure for the multi-agent framework. During training, agents learn to predict both outputs and trajectory tokens, establishing logical associations that guide fine-grained intra-trajectory and inter-trajectory interactions.

### Mechanism 3: Flexible inference through trajectory token-based training
Short Trajectory Learning enables flexible plug-in combinations of agents while maintaining performance, as each agent learns independent capabilities with trajectory tokens providing sufficient context. This allows the framework to function effectively even when agents are missing during inference.

## Foundational Learning

- **Multi-agent coordination patterns**: Understanding how specialized agents can collaborate without error propagation is crucial for the framework's effectiveness. *Quick check*: Can you explain why traditional pipelined multi-agent systems suffer from error accumulation?

- **Trajectory-based training methodology**: The framework relies on trajectory tokens to segment and organize agent learning, differing from traditional sequence-to-sequence approaches. *Quick check*: How do trajectory tokens differ from traditional sequence-to-sequence training approaches?

- **Knowledge-intensive task decomposition**: Breaking complex tasks into intent reconstruction, knowledge retrieval, fact location, and response generation enables specialized agent development. *Quick check*: What are the four distinct agent types in the SMART framework and their primary functions?

## Architecture Onboarding

- **Component map**: Instruction → Intent Reconstructor → Knowledge Retriever → Fact Locator → Response Generator → Final Response

- **Critical path**: User instruction flows through Intent Reconstructor for query identification, then to Knowledge Retriever for document access, Fact Locator for factual span identification, and finally Response Generator for response generation with citations.

- **Design tradeoffs**: The framework balances flexibility vs. coordination complexity (modular agents offer flexibility but require sophisticated coordination), training data efficiency vs. performance (using only 40% of long trajectory data), and agent independence vs. inter-dependency (balancing isolated training with necessary coordination).

- **Failure signatures**: Error accumulation in traditional pipelined approaches, performance degradation when agents are missing (without trajectory token training), and inability to handle diverse instruction semantics and formats.

- **First 3 experiments**: 
  1. Compare performance with and without trajectory tokens to validate their coordination effectiveness
  2. Test framework performance with different agent combinations missing to verify flexibility claims
  3. Measure training data efficiency by comparing performance with 20%, 40%, and 60% of long trajectory data

## Open Questions the Paper Calls Out

1. **Iterative optimization for multi-hop problems**: The framework currently executes sequentially without iterative optimization between Fact Locator and Intent Reconstructor agents, which may lead to insufficient knowledge retrieval for multi-hop problems. The paper suggests adding loop arrows between these agents but lacks empirical evidence on how this would perform or what modifications would be needed.

2. **Joint training of retrieval subsystem**: While the paper acknowledges that the retriever could be trained jointly with the SMART framework using existing techniques, it chose not to do so. The impact of joint training on performance, training stability, and computational overhead remains unexplored.

3. **Scalability to complex scenarios**: Although the framework shows strong performance on five knowledge-intensive tasks, the paper envisions extending it to more complex scenarios beyond knowledge-intensive tasks. However, evidence is lacking on how the approach scales to scenarios with longer trajectories or more agents.

## Limitations

- Limited empirical validation of flexibility claims when agents are missing during inference
- Dependency on GPT-4 for trajectory data construction without specified prompt templates
- Performance tightly coupled to external knowledge sources (Wikipedia, Retriever-MSMARCO)

## Confidence

**High confidence**: The two-stage Long-Short Trajectory Learning approach effectively separates agent capability development from inter-agent coordination; trajectory tokens serve as effective training signals and inference guides; the modular architecture with specialized agents addresses key challenges in knowledge-intensive tasks.

**Medium confidence**: The framework achieves significant improvements across accuracy, fluency, and factuality metrics compared to baseline methods; using only 40% of long trajectory data substantially reduces development costs while maintaining performance; the framework handles diverse instruction semantics and formats effectively.

**Low confidence**: Performance claims when agents are missing during inference are fully validated across all agent combinations; the framework generalizes effectively to knowledge domains beyond Wikipedia and Retriever-MSMARCO; the trajectory token approach scales to more complex multi-agent workflows with additional specialized agents.

## Next Checks

1. **Ablation study across all agent combinations**: Systematically test framework performance with each possible combination of missing agents (1, 2, 3, and 4 agents absent) to validate flexibility claims and identify which agent combinations are most critical for maintaining performance.

2. **Knowledge source generalization experiment**: Replace the Wikipedia corpus and Retriever-MSMARCO with alternative knowledge sources (different domains, different retrieval models) to test whether performance improvements are tied to specific knowledge infrastructure or generalize across knowledge-intensive tasks.

3. **Trajectory data efficiency analysis**: Conduct a detailed study varying the percentage of long trajectory data used (10%, 20%, 40%, 60%, 80%, 100%) while measuring performance and training costs to precisely quantify the trade-offs between data efficiency and model capability.