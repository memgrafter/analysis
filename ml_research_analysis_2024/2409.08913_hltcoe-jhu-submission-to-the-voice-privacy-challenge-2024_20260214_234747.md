---
ver: rpa2
title: HLTCOE JHU Submission to the Voice Privacy Challenge 2024
arxiv_id: '2409.08913'
source_url: https://arxiv.org/abs/2409.08913
tags:
- system
- speaker
- anonymization
- wavlm
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper describes multiple approaches to voice anonymization
  for the Voice Privacy Challenge 2024. The authors developed systems based on voice
  conversion (kNN-VC, WavLM conversion) and cascaded ASR-TTS (Whisper-VITS), finding
  that voice conversion better preserves emotional content but struggles with speaker
  anonymization, while TTS methods excel at anonymization but degrade emotion preservation.
---

# HLTCOE JHU Submission to the Voice Privacy Challenge 2024

## Quick Facts
- arXiv ID: 2409.08913
- Source URL: https://arxiv.org/abs/2409.08913
- Reference count: 0
- This paper describes multiple approaches to voice anonymization for the Voice Privacy Challenge 2024, finding that random admixture systems achieve over 40% EER while maintaining 47% UAR.

## Executive Summary
This paper presents the HLTCOE JHU team's submission to the Voice Privacy Challenge 2024, developing multiple voice anonymization approaches to balance speaker anonymization against emotion preservation. The team explored voice conversion systems (kNN-VC and WavLM-based conversion) and cascaded ASR-TTS systems (Whisper-VITS), finding that voice conversion better preserves emotional content but struggles with anonymization, while TTS methods excel at anonymization but degrade emotion preservation. They propose a random admixture system combining these approaches, achieving strong performance with an EER of over 40% while maintaining UAR at 47%.

## Method Summary
The team developed three main approaches: (1) kNN-VC using WavLM features with k-nearest neighbor regression followed by HiFi-GAN vocoding, (2) cascaded ASR-TTS using Whisper for transcription and VITS for synthesis with random speaker selection, and (3) random admixture systems combining the first two approaches. The kNN-VC system uses 4-nearest neighbors in WavLM feature space to transfer target speaker characteristics while preserving emotional content. The Whisper-VITS system breaks speaker-specific prosodic patterns by converting speech to text and synthesizing with random speakers. The random admixture approach creates data poisoning effects by randomly selecting between systems during training, degrading ASV performance beyond linear combinations.

## Key Results
- kNN-VC achieves EER of 7.95% (poor anonymization) but maintains UAR of 56.7% (good emotion preservation)
- Whisper-VITS achieves EER of 48.25% (excellent anonymization) but only UAR of 30.35% (poor emotion preservation)
- Random admixture achieves EER of over 40% while maintaining UAR at 47%, balancing the tradeoff effectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: kNN-VC preserves emotional content better than TTS because it directly manipulates WavLM features without altering prosody through ASR transcription.
- Mechanism: kNN-VC uses nearest-neighbor regression in WavLM feature space to transfer target speaker characteristics while maintaining the source's emotional trajectory. This preserves fine-grained paralinguistic cues.
- Core assumption: Emotional content is encoded in WavLM features in a way that survives nearest-neighbor regression without significant distortion.
- Evidence anchors:
  - [abstract] "while voice conversion systems better preserve emotional content"
  - [section 3.3] "The kNN-VC system achieves an average EER of 7.95%, which suggests a significant exposure of the original speaker's traits. Nevertheless, the kNN-VC system performs well in preserving emotional state and linguistic content, with an average UAR of 56.7% and an average WER of 3.16%, respectively."
  - [corpus] Weak - related papers focus on general voice conversion but don't specifically validate emotional preservation in the context of privacy challenges.
- Break condition: If emotional content is encoded in prosodic features that get altered during kNN-VC (e.g., through length variation or noise injection), the emotional preservation advantage diminishes.

### Mechanism 2
- Claim: Cascaded ASR-TTS achieves superior anonymization by breaking speaker-specific prosodic patterns through intermediate text representation.
- Mechanism: The system transcribes source speech to text (removing speaker-specific prosody) then synthesizes new speech with random speaker voice, effectively eliminating speaker identity cues while preserving content.
- Core assumption: Prosodic features carry speaker identity information that can be removed by forcing transcription to text and re-synthesis.
- Evidence anchors:
  - [abstract] "TTS methods perform better at anonymization and worse at emotion preservation"
  - [section 2.3] "Although voice conversion systems can effectively alter the acoustic characteristics related to the speech production organs of source speakers, the prosodic characteristics, which reflect their acquired speaking habits and styles, remain unchanged."
  - [section 3.3] "The cascaded anonymization approach, whisper-VITS, achieves an average EER of 48.25%, which is close to 50%, demonstrating its ability to conceal the original speaker's identity."
  - [corpus] Weak - related papers don't specifically address the prosody-breaking mechanism in cascaded ASR-TTS for privacy.
- Break condition: If the TTS system inadvertently preserves speaker-specific characteristics in the synthesized voice, or if the ASR introduces transcription errors that degrade utility.

### Mechanism 3
- Claim: Random admixture creates a data poisoning effect that degrades ASV performance beyond the linear combination of individual system scores.
- Mechanism: By randomly selecting between kNN-VC and Whisper-VITS during training, the ASV model encounters inconsistent speaker representations that confuse its learning process, effectively poisoning its training data.
- Core assumption: Inconsistent speaker representations during ASV training cause the model to fail to learn robust speaker embeddings, leading to higher EER.
- Evidence anchors:
  - [abstract] "achieving a strong EER of over 40% while maintaining UAR at a respectable 47%"
  - [section 2.4] "we were able to produce systems whose performance sit in between those of the two systems... satisfying different needs for anonymization versus emotion preservation"
  - [section 2.4] "we note that while the emotion preservation performance is a linear extrapolation of that of the two source systems, the trained ASV system performed worse than the linear extrapolation of the EER of these two systems"
  - [corpus] Weak - related papers don't specifically validate the data poisoning hypothesis in this context.
- Break condition: If the ASV model can learn to distinguish between the two system types and treat them separately, the poisoning effect diminishes.

## Foundational Learning

- Concept: Voice conversion fundamentals
  - Why needed here: Understanding how kNN-VC and WavLM conversion work is essential for grasping the trade-offs between emotion preservation and anonymization.
  - Quick check question: What is the primary difference between kNN-VC and neural WavLM conversion in terms of how they handle target speaker characteristics?

- Concept: Speaker verification metrics
  - Why needed here: EER is the primary privacy metric, and understanding how it's computed helps interpret the results and design better systems.
  - Quick check question: How is the decision threshold for EER determined in the Voice Privacy Challenge setup?

- Concept: Data poisoning attacks
  - Why needed here: The random admixture mechanism relies on poisoning the ASV training data, so understanding this concept is crucial for the proposed approach.
  - Quick check question: How does random admixture create a data poisoning effect in the ASV training process?

## Architecture Onboarding

- Component map:
  - kNN-VC system: WavLM feature extraction → kNN regression → HiFi-GAN vocoder
  - WavLM conversion system: WavLM feature extraction → FastSpeech2-based encoder-decoder → HiFi-GAN vocoder
  - Whisper-VITS system: Whisper ASR → multi-speaker VITS TTS with random speaker selection
  - Random admixture system: Weighted random selection between kNN-VC and Whisper-VITS

- Critical path: For emotion preservation: kNN-VC → WavLM features → kNN regression → HiFi-GAN. For anonymization: Whisper-VITS → Whisper ASR → VITS TTS.

- Design tradeoffs: Emotion preservation vs. anonymization (voice conversion vs. TTS), model complexity vs. performance (simple kNN vs. complex neural conversion), data requirements (kNN needs target speaker data vs. TTS needs large multi-speaker corpus).

- Failure signatures: High WER indicates content degradation, low UAR indicates emotion loss, low EER indicates poor anonymization, high EER with low UAR suggests system is over-anonymizing at the cost of utility.

- First 3 experiments:
  1. Implement kNN-VC with k=4 on LibriSpeech, measure WER, UAR, and EER on development set.
  2. Implement Whisper-VITS with random speaker selection, compare metrics against kNN-VC.
  3. Implement random admixture system at 50% mixing ratio, verify EER exceeds linear combination of source systems while UAR remains above 45%.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we develop a principled framework to optimize the trade-off between emotion preservation and speaker anonymization, beyond random admixture approaches?
- Basis in paper: [explicit] The paper discusses random admixture systems achieving intermediate results between VC and TTS approaches, noting that "We call for future work to investigate if it would be possible to better the UAR-EER tradeoff curve achieved by random admixture."
- Why unresolved: The random admixture approach is described as "simple" and produces results that are linear extrapolations between the two extremes. The paper suggests this is not optimal and that a more principled approach could achieve better results.
- What evidence would resolve it: A framework that can systematically optimize the UAR-EER trade-off curve, potentially using adversarial training or multi-objective optimization techniques that outperform the linear trade-offs achieved by random admixture.

### Open Question 2
- Question: What is the equilibrium between anonymization systems and informed adversaries in the context of data poisoning and admixture approaches?
- Basis in paper: [explicit] The paper notes that "an informed adversary can effectively mitigate the impact of data-poisoning attacks at the cost of some performance degradation" and calls for future studies to "identify any possible equilibrium between the anonymizer and the adversary."
- Why unresolved: The paper identifies this as an open research direction but does not provide analysis of potential equilibria or how adversaries might adapt to admixture-based systems.
- What evidence would resolve it: Game-theoretic analysis or empirical studies showing optimal strategies for both anonymizers and adversaries when admixture systems are employed, including potential countermeasures and their effectiveness.

### Open Question 3
- Question: Can TTS-based anonymization systems be enhanced to better preserve paralinguistic features like emotion without compromising speaker anonymization?
- Basis in paper: [explicit] The paper states that "our TTS system does not support any type of controlled generation, which severely limits its capacity for preserving para-linguistic features such as emotion" and suggests investigating "the effectiveness of that line of methods in our future work."
- Why unresolved: Current TTS-based systems excel at anonymization but perform poorly on emotion preservation (UAR of 30.35%), and the paper identifies controlled generation as a key limitation.
- What evidence would resolve it: Development and evaluation of TTS systems with controllable generation capabilities that can maintain high anonymization (EER > 40%) while significantly improving emotion preservation (UAR > 40%).

## Limitations

- The paper lacks detailed implementation specifications for the WavLM conversion system, making faithful reproduction challenging.
- The data poisoning hypothesis for the random admixture system is claimed but not rigorously validated through controlled experiments.
- The evaluation methodology has gaps, particularly regarding the ECAPA-TDNN training procedure and threshold selection for EER computation.

## Confidence

**High Confidence**: The general framework and system descriptions are well-articulated. The tradeoffs between voice conversion and TTS approaches for emotion preservation versus anonymization are clearly demonstrated through the reported metrics (EER of 7.95% for kNN-VC vs. 48.25% for Whisper-VITS, UAR of 56.7% vs. 47%).

**Medium Confidence**: The mechanism explanations are plausible but not fully validated. While the paper explains why kNN-VC preserves emotion better (direct feature manipulation without transcription) and why cascaded ASR-TTS achieves better anonymization (breaking prosodic patterns), these mechanisms would benefit from ablation studies or qualitative analysis.

**Low Confidence**: The random admixture system's superiority over simple averaging is claimed but not rigorously proven. The data poisoning explanation is speculative without controlled experiments isolating this effect from other factors.

## Next Checks

1. **Ablation Study**: Implement the random admixture system at multiple mixture ratios (0.1, 0.5, 0.9) and conduct controlled experiments to verify that EER performance exceeds the linear combination of individual systems while UAR remains stable. Compare against a simple weighted average baseline.

2. **Mechanism Validation**: Conduct qualitative analysis by having human listeners rate emotion preservation in kNN-VC outputs versus cascaded ASR-TTS outputs, and analyze prosodic feature statistics to confirm that the TTS system effectively breaks speaker-specific patterns while voice conversion preserves them.

3. **Data Poisoning Isolation**: Design an experiment where the ASV model is trained on three conditions: (a) anonymized data from individual systems only, (b) mixed data from individual systems, and (c) mixed data with random admixture. Compare EERs to isolate the data poisoning effect from simple averaging.