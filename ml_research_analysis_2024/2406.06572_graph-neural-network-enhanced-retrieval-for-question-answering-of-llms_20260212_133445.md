---
ver: rpa2
title: Graph Neural Network Enhanced Retrieval for Question Answering of LLMs
arxiv_id: '2406.06572'
source_url: https://arxiv.org/abs/2406.06572
tags:
- passages
- question
- retrieval
- answer
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of retrieving relevant passages
  for complex reasoning questions in large language models (LLMs), where existing
  methods struggle to capture all necessary knowledge due to information asymmetry.
  The authors propose a novel retrieval method, GNN-Ret, which leverages graph neural
  networks (GNNs) to enhance retrieval by exploiting the relatedness between passages.
---

# Graph Neural Network Enhanced Retrieval for Question Answering of LLMs

## Quick Facts
- arXiv ID: 2406.06572
- Source URL: https://arxiv.org/abs/2406.06572
- Authors: Zijian Li; Qingyan Guo; Jiawei Shao; Lei Song; Jiang Bian; Jun Zhang; Rui Wang
- Reference count: 40
- Primary result: GNN-Ret achieves up to 10.4% accuracy improvement on 2WikiMQA dataset compared to strong baselines

## Executive Summary
This paper addresses the challenge of retrieving relevant passages for complex reasoning questions in large language models, where information asymmetry prevents existing methods from capturing all necessary knowledge. The authors propose GNN-Ret, a novel retrieval method that leverages graph neural networks to enhance retrieval by exploiting relationships between passages through structural and keyword connections. For multi-hop reasoning questions, they extend this to RGNN-Ret, which uses recurrent graph neural networks to integrate retrievals across multiple reasoning steps. Extensive experiments demonstrate that GNN-Ret outperforms strong baselines requiring multiple queries, while RGNN-Ret achieves state-of-the-art performance with up to 10.4% accuracy improvement on benchmark datasets.

## Method Summary
The authors construct a graph of passages (GoPs) by connecting passages based on structural information and shared keywords extracted via LLM prompts. A GNN is then used to integrate semantic distances between related passages, improving retrieval of supporting passages for question answering. For multi-hop reasoning, RGNN-Ret iteratively generates subquestions, answers them with retrieved passages, and uses an RGNN to integrate retrievals over multiple steps. The method is evaluated on four benchmark datasets (MuSiQue, IIRC, 2WikiMQA, Quality) containing multi-hop reasoning questions and Wikipedia documents, with performance measured by F1 score, exact match, and accuracy.

## Key Results
- GNN-Ret consistently outperforms SBERT across varying numbers of retrieval tokens (1k-20k)
- RGNN-Ret achieves state-of-the-art performance with up to 10.4% accuracy improvement on 2WikiMQA dataset
- The method demonstrates robustness for long contexts and complex reasoning tasks
- RGNN-Ret with SBERT as retriever also shows competitive performance compared to other multi-hop baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph Neural Networks integrate semantic distances of related passages to improve retrieval prioritization
- Mechanism: GNN propagates semantic distances between connected passages, allowing background knowledge to influence retrieval of inquiry passages
- Core assumption: Related passages share structural or keyword connections that reflect information relevance
- Evidence anchors:
  - [abstract] "A graph neural network (GNN) is then leveraged to exploit the relationships between passages and improve the retrieval of supporting passages"
  - [section] "With GNN, the supporting passages for inquiry information integrate with the small semantic distance from those for background information and thereby obtain smaller integrated semantic distances"
- Break condition: If passage relatedness does not reflect information asymmetry (e.g., unrelated passages share keywords by coincidence)

### Mechanism 2
- Claim: Recurrent GNN connections across multi-hop steps enable knowledge transfer between subquestions
- Mechanism: RGNN maintains and updates passage relationships across reasoning steps, allowing information from earlier steps to inform later retrievals
- Core assumption: The graph structure and relationships between passages remain relevant across different stages of multi-hop reasoning
- Evidence anchors:
  - [section] RGNN-Ret extends GNN-Ret to multi-hop reasoning by integrating graphs of passages from previous steps
- Break condition: If the passage relationships change significantly between reasoning steps or if subquestions require entirely different knowledge domains

## Foundational Learning

### Graph Neural Networks
- Why needed: To model relationships between passages and propagate semantic information across the graph structure
- Quick check: Verify that the GNN effectively reduces semantic distances between related passages while maintaining distances between unrelated passages

### Recurrent Neural Networks
- Why needed: To maintain and update information across multiple reasoning steps in multi-hop question answering
- Quick check: Confirm that the RGNN successfully integrates information from previous steps to improve retrieval accuracy in subsequent steps

### Information Asymmetry
- Why needed: The core problem being addressed - where complex questions require knowledge distributed across multiple passages
- Quick check: Ensure the method effectively identifies and retrieves all necessary supporting passages for multi-hop reasoning questions

## Architecture Onboarding

### Component Map
Documents -> Passage Splitter -> Passage Graph Construction -> GNN/RGNN -> Enhanced Retrieval -> Question Answering

### Critical Path
Question -> Semantic Distance Computation -> Graph Construction -> GNN Message Passing -> Integrated Distance Calculation -> Top-K Passage Retrieval

### Design Tradeoffs
- Graph construction vs. retrieval speed: More comprehensive graph connections improve accuracy but increase computational overhead
- Number of GNN layers: More layers allow deeper propagation but risk over-smoothing and increased computation
- Retrieval token limits: Higher limits enable better coverage but increase cost and latency

### Failure Signatures
- Poor keyword extraction leading to sparse or irrelevant graph connections
- Over-smoothing in GNN causing loss of discriminative information between passages
- Subquestion generation errors propagating through RGNN steps in multi-hop reasoning

### First Experiments
1. Implement passage graph construction and verify that structurally and keyword-related passages are correctly connected
2. Test GNN on simple retrieval tasks to confirm semantic distance integration works as expected
3. Validate RGNN step-by-step on multi-hop questions to ensure information transfer between steps

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GNN-Ret scale with increasing numbers of retrieval tokens (e.g., 1k, 3k, 5k, 10k, 20k)?
- Basis in paper: [explicit] The paper states "Our proposed GNN-Ret consistently outperforms SBERT with varying numbers of tokens for retrieval, demonstrating the robustness of our method for long contexts." However, it does not provide a detailed analysis of the scaling behavior.
- Why unresolved: The paper only mentions that GNN-Ret outperforms SBERT with varying token numbers but does not analyze the specific scaling behavior or provide insights into how performance changes with increasing token counts.
- What evidence would resolve it: Detailed experiments showing the performance of GNN-Ret and SBERT across a range of token numbers, along with an analysis of the scaling behavior and any potential bottlenecks or limitations.

### Open Question 2
- Question: How does the choice of K (number of relevant nodes sampled) and O (size of competitive node set) impact the performance of GNN-Ret and RGNN-Ret?
- Basis in paper: [explicit] The paper mentions "we conduct grid search for hyperparameters K and O, which determine the number of relevant nodes to be sampled and the size of the competitive node set, respectively." However, it does not provide a detailed analysis of the impact of different K and O values on performance.
- Why unresolved: While the paper mentions conducting grid search for K and O, it does not provide a detailed analysis of how different values of these hyperparameters affect the performance of GNN-Ret and RGNN-Ret.
- What evidence would resolve it: Detailed experiments showing the performance of GNN-Ret and RGNN-Ret with varying K and O values, along with an analysis of the impact of these hyperparameters on accuracy and any potential trade-offs or limitations.

### Open Question 3
- Question: How does the performance of RGNN-Ret compare to other multi-hop answering methods (e.g., IRCoT, ITER-RETGEN) when using different retrieval methods (e.g., SBERT, GNN-Ret)?
- Basis in paper: [explicit] The paper mentions "we supplement experiments by employing RGNN-Ret with other multi-hop baselines IRCoT and ITER-RETGEN." However, it does not provide a detailed comparison of the performance of RGNN-Ret with different retrieval methods.
- Why unresolved: While the paper mentions supplementing experiments with RGNN-Ret and other multi-hop baselines, it does not provide a detailed comparison of the performance of RGNN-Ret with different retrieval methods (e.g., SBERT, GNN-Ret).
- What evidence would resolve it: Detailed experiments comparing the performance of RGNN-Ret with different retrieval methods (e.g., SBERT, GNN-Ret) on multi-hop answering tasks, along with an analysis of the impact of the retrieval method on the overall performance of RGNN-Ret.

## Limitations
- Missing implementation details for GNN/RGNN architecture and prompt templates
- Lack of ablation studies on graph construction strategies and GNN configurations
- No analysis of computational overhead compared to standard retrieval methods
- Evaluation limited to Wikipedia-based datasets, raising generalizability concerns

## Confidence

### High confidence
- The core claim that GNN can integrate semantic distances between related passages to improve retrieval accuracy is well-supported by experimental results showing 10.4% improvement on 2WikiMQA

### Medium confidence
- The extension to multi-hop reasoning with RGNN shows promising results, but the iterative nature and dependence on subquestion generation quality introduces additional uncertainty

### Low confidence
- The specific implementation details of the GNN message passing mechanism and exact prompt templates used for keyword extraction and subquestion generation are not fully specified, limiting reproducibility

## Next Checks

1. **Reproduce keyword extraction and graph construction**: Implement the keyword extraction using the same LLM prompts and verify that the resulting passage graph captures meaningful relationships rather than coincidental keyword matches

2. **Ablation study on GNN architecture**: Test different GNN configurations (number of layers, message passing mechanisms) to determine the optimal architecture for passage integration and identify the key factors driving performance improvements

3. **Cross-domain evaluation**: Evaluate the method on non-Wikipedia datasets with different passage structures (e.g., scientific literature, news articles) to assess generalizability and identify domain-specific limitations