---
ver: rpa2
title: Attacking Misinformation Detection Using Adversarial Examples Generated by
  Language Models
arxiv_id: '2410.20940'
source_url: https://arxiv.org/abs/2410.20940
tags:
- text
- trepat
- language
- changes
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TREPAT uses large language models to generate adversarial examples
  for misinformation detection systems, overcoming query limits by splitting LLM rephrasings
  into atomic changes applied via beam search. It outperforms traditional word-replacement
  methods, especially on long texts, achieving higher semantic similarity and better
  meaning preservation while requiring fewer queries.
---

# Attacking Misinformation Detection Using Adversarial Examples Generated by Language Models

## Quick Facts
- arXiv ID: 2410.20940
- Source URL: https://arxiv.org/abs/2410.20940
- Authors: Piotr PrzybyÅ‚a; Euan McGill; Horacio Saggion
- Reference count: 16
- Primary result: TREPAT outperforms traditional word-replacement methods for adversarial attacks on misinformation detection

## Executive Summary
TREPAT introduces a novel approach to generating adversarial examples for misinformation detection systems by leveraging large language models to create semantically similar rephrasings. The method addresses LLM query limitations by splitting rephrasings into atomic changes applied through beam search, making it more efficient than traditional word-replacement techniques. TREPAT demonstrates superior performance, particularly on long texts, while maintaining better meaning preservation and naturalness compared to baseline methods.

## Method Summary
TREPAT uses large language models to generate adversarial examples by creating multiple rephrasings of input text and applying atomic changes through beam search. The approach overcomes traditional query limitations by splitting LLM outputs into smaller, manageable modifications rather than generating complete rephrasings for each query. This allows for more efficient exploration of the adversarial space while maintaining semantic similarity. The method is specifically designed to attack misinformation detection systems and shows particular effectiveness on longer text documents.

## Key Results
- TREPAT outperforms traditional word-replacement methods, especially on long texts
- Achieves higher semantic similarity and better meaning preservation with fewer queries
- Manual evaluation confirms TREPAT's superiority in maintaining meaning and naturalness
- Demonstrates effectiveness against modern large models, highlighting need for robustness testing

## Why This Works (Mechanism)
TREPAT leverages the generative capabilities of large language models to create semantically meaningful rephrasings that preserve the original intent while evading detection. By breaking down complex rephrasings into atomic changes and using beam search, the method efficiently explores the adversarial space without exhausting query limits. The LLM-generated modifications are more natural and contextually appropriate than simple word substitutions, making them harder for detection systems to identify as adversarial examples.

## Foundational Learning
- Adversarial examples in NLP: Modified inputs designed to fool machine learning models while appearing natural to humans. Needed to understand attack methodology and evaluation metrics.
- Beam search optimization: Search algorithm that explores multiple paths simultaneously to find optimal solutions. Required for understanding TREPAT's efficiency in exploring adversarial space.
- Semantic similarity metrics: Quantitative measures of meaning preservation between original and modified texts. Essential for evaluating attack effectiveness while maintaining content integrity.
- Misinformation detection systems: Machine learning models designed to identify false or misleading information. Provides context for understanding attack targets and real-world implications.

## Architecture Onboarding

**Component Map**
TREPAT -> LLM Query Generator -> Atomic Change Extractor -> Beam Search Optimizer -> Adversarial Example Generator

**Critical Path**
1. Input text fed to LLM for rephrasing
2. LLM outputs multiple rephrasings
3. Atomic changes extracted from rephrasings
4. Beam search applies changes iteratively
5. Final adversarial example generated and evaluated

**Design Tradeoffs**
- LLM query efficiency vs. attack quality: Breaking rephrasings into atomic changes reduces queries but may limit creative modifications
- Semantic preservation vs. attack success: More aggressive changes increase evasion but risk losing original meaning
- Computational cost vs. scalability: Beam search enables efficient exploration but requires significant processing for large datasets

**Failure Signatures**
- Complete loss of original meaning in generated examples
- Detection systems identifying adversarial patterns despite semantic similarity
- Excessive query consumption preventing practical deployment
- LLM safety restrictions blocking generation of certain adversarial content

**First Experiments**
1. Test TREPAT on benchmark datasets against word-replacement baselines to establish baseline performance
2. Evaluate semantic similarity and meaning preservation using multiple metrics (e.g., BERTScore, human evaluation)
3. Assess computational efficiency by measuring query counts and processing time across different text lengths

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead may limit scalability to massive social media datasets
- Potential safety restrictions in LLM outputs could block generation of sensitive adversarial content
- Real-world deployment challenges with API rate limits and processing constraints
- Limited analysis of relationship between text length and attack success rates

## Confidence
- TREPAT outperforms traditional word-replacement methods: High
- TREPAT is particularly effective for long texts: Medium
- Manual evaluation confirms TREPAT's superiority in maintaining meaning and naturalness: High

## Next Checks
1. Test TREPAT against production-level misinformation detection systems deployed by social media platforms to assess real-world effectiveness and computational feasibility
2. Evaluate TREPAT's performance across diverse content types beyond news articles, including social media posts, user comments, and multimedia content with text overlays
3. Investigate the robustness of TREPAT against detection systems that incorporate adversarial training or use large language models themselves for classification