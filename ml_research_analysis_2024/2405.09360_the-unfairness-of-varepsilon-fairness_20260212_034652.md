---
ver: rpa2
title: The Unfairness of $\varepsilon$-Fairness
arxiv_id: '2405.09360'
source_url: https://arxiv.org/abs/2405.09360
tags:
- fairness
- case
- utility
- which
- setting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper demonstrates that \u03B5-fairness can lead to outcomes\
  \ that are maximally unfair when considering real-world utility impacts. Using a\
  \ utility-based approach, the authors show that even small \u03B5 values can produce\
  \ substantial disadvantages between groups."
---

# The Unfairness of $\varepsilon$-Fairness

## Quick Facts
- arXiv ID: 2405.09360
- Source URL: https://arxiv.org/abs/2405.09360
- Authors: Tolulope Fadina; Thorsten Schmidt
- Reference count: 15
- Primary result: ε-fairness can lead to maximally unfair outcomes when considering real-world utility impacts

## Executive Summary
This paper challenges the notion that ε-fairness (allowing small probability differences between groups) ensures equitable outcomes. Using a utility-based approach, the authors demonstrate that even minimal ε values can produce substantial disadvantages between groups. The framework addresses the common issue of unavailable data on false negatives through a reduced setting, maintaining essential fairness considerations while improving tractability.

## Method Summary
The authors develop a framework that computes expected utilities for different groups based on classification outcomes. The approach uses confusion matrices to represent joint probabilities of true and predicted outcomes across two groups. They introduce a reduced setting that collapses certain cases to handle missing data, particularly for false negatives. The method evaluates fairness through utility differences rather than traditional probability-based metrics, providing sufficient conditions to ensure absence of disadvantages.

## Key Results
- ε-fairness can produce large utility differences despite small probability deviations
- The reduced setting effectively handles missing false negative data while preserving fairness analysis
- Sufficient conditions for fairness can be verified without full knowledge of underlying distributions
- Real-world examples (college admissions and credit risk) demonstrate significant fairness violations under traditional metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Utility-based fairness evaluation can reveal unfairness that traditional probability-based metrics miss.
- Mechanism: The paper shows that ε-fairness (allowing small probability differences between groups) can still produce large utility differences if the utility functions are not symmetric across groups. By computing expected utility as a weighted sum of outcome utilities, they show that even tiny probability deviations can lead to substantial utility inequalities.
- Core assumption: Utility differences across outcomes are bounded but can be large enough relative to probability deviations to create unfairness.
- Evidence anchors:
  - [abstract]: "using a utility-based approach, the authors show that even small ε values can produce substantial disadvantages between groups"
  - [section]: "Proposition 5...there exist for any K ≥ 0 parameters U00, . . . , U11 such that UD ≥ K"
  - [corpus]: Found related papers on fairness evaluation and utility-based approaches, but none directly contradict this mechanism.
- Break condition: If utility differences are very small relative to probability deviations, the mechanism fails.

### Mechanism 2
- Claim: The framework can handle missing data on false negatives through a reduced setting.
- Mechanism: By collapsing the {Y=0, Ŷ=0} and {Y=1, Ŷ=0} cases into a single "rejected" case, the framework maintains the ability to compute expected utilities without requiring data on these scenarios. This preserves the core fairness analysis capability.
- Core assumption: The collapsed "rejected" case has a single utility value that adequately represents both original scenarios.
- Evidence anchors:
  - [abstract]: "address the common issue of unavailable data on false negatives by proposing a reduced setting that still captures essential fairness considerations"
  - [section]: "To additionally capture these important situations within our framework, we introduce the reduced setting: here, both cases (00 and 01) are collapsed into the case 0"
  - [corpus]: Related papers discuss handling missing data but don't specifically address the false negative case reduction.
- Break condition: If the two collapsed cases have very different utilities, the reduced setting becomes inaccurate.

### Mechanism 3
- Claim: The framework provides sufficient conditions for ensuring absence of disadvantages.
- Mechanism: By analyzing conditional use accuracy (CUA) and independence conditions, the framework derives bounds on utility differences that guarantee fairness. These conditions are computationally tractable and don't require full knowledge of the underlying distributions.
- Core assumption: The conditional use accuracy condition can be verified or enforced in practice.
- Evidence anchors:
  - [abstract]: "sufficient conditions to ensure absence of disadvantages"
  - [section]: "Proposition 8...If the utility differences are bounded by K > 0 and |P0(Ŷ=1)=P1(Ŷ=1)| ≤ ε, then there is no disadvantage larger than (1 + 2Γ) · ε · K"
  - [corpus]: Related papers discuss sufficient conditions but typically focus on probability-based metrics rather than utility-based ones.
- Break condition: If the bounds on utility differences or probability deviations are too loose, the sufficient conditions may not be practically useful.

## Foundational Learning

- Concept: Expected utility calculation in decision theory
  - Why needed here: The entire framework relies on computing expected utilities to measure fairness, requiring understanding of how utilities combine with probabilities.
  - Quick check question: How do you compute the expected utility of a decision that has different outcomes with different probabilities and utilities?

- Concept: Confusion matrix and joint probability distributions
  - Why needed here: The framework uses confusion matrices to represent classification outcomes across groups, requiring understanding of how joint probabilities relate to conditional probabilities.
  - Quick check question: How do you convert a confusion matrix into joint probabilities for two groups?

- Concept: Conditional use accuracy and its relationship to fairness metrics
  - Why needed here: The sufficient conditions for fairness rely on conditional use accuracy, requiring understanding of how this metric differs from other fairness measures.
  - Quick check question: What is the relationship between conditional use accuracy and equalized odds?

## Architecture Onboarding

- Component map: Data → Confusion Matrix → Utility Calculation → Fairness Assessment → Sufficient Condition Check
- Critical path: Data → Confusion Matrix → Utility Calculation → Fairness Assessment → Sufficient Condition Check
- Design tradeoffs: Full confusion matrix provides more accuracy but requires more data; reduced setting is more practical but may lose some precision. Utility-based approach captures real-world impact but requires utility function specification.
- Failure signatures: If utility differences are very large relative to probability differences, the framework may flag unfairness even when traditional metrics don't. If the reduced setting is used inappropriately, it may miss important fairness violations.
- First 3 experiments:
  1. Implement the standard setting with synthetic data where ε-fairness holds but utility differences are large, to verify the core mechanism.
  2. Test the reduced setting with varying utility assignments for the collapsed case to understand sensitivity to this approximation.
  3. Apply the sufficient condition checker to real-world datasets to validate practical utility.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the exact utility bounds for different real-world scenarios, and how do these bounds affect the severity of potential disadvantages?
- Basis in paper: [explicit] The paper discusses bounded utility differences but doesn't provide concrete bounds for real-world scenarios like college admissions or mortgage lending.
- Why unresolved: The paper introduces the concept of bounded utility differences but doesn't specify how these bounds would vary across different contexts or how to practically determine them.
- What evidence would resolve it: Empirical studies that quantify utility differences in various decision-making contexts, particularly in sensitive areas like education and finance.

### Open Question 2
- Question: How can we effectively estimate and incorporate confidence intervals for probability measures in machine learning models, especially when dealing with protected groups?
- Basis in paper: [explicit] The paper mentions the challenge of estimating probabilities and the importance of confidence intervals but doesn't provide a detailed methodology for incorporating them.
- Why unresolved: While the paper acknowledges the uncertainty in probability estimates, it doesn't offer a concrete framework for integrating this uncertainty into fairness assessments.
- What evidence would resolve it: Development and validation of methods to estimate confidence intervals for machine learning predictions, particularly for sensitive attributes, and studies showing how these intervals affect fairness evaluations.

### Open Question 3
- Question: What are the long-term societal impacts of utility-based fairness measures compared to traditional statistical fairness metrics?
- Basis in paper: [inferred] The paper argues for utility-based measures over traditional statistical ones but doesn't explore the broader societal implications of this shift.
- Why unresolved: The paper focuses on the theoretical advantages of utility-based measures but doesn't investigate how these might play out in society over time.
- What evidence would resolve it: Longitudinal studies comparing the outcomes of policies based on utility-based fairness measures versus those based on traditional statistical metrics, examining both intended and unintended consequences.

## Limitations
- Framework assumes utility differences are bounded, which may not hold in all real-world scenarios
- Reduced setting's approximation of collapsing false negative cases could introduce significant errors if utilities differ substantially
- Practical applicability of sufficient conditions depends heavily on accurate probability estimates

## Confidence
- High confidence: Core mechanism that utility-based evaluation can reveal unfairness missed by probability-based metrics
- Medium confidence: Reduced setting's practical utility and effectiveness of sufficient conditions
- Medium confidence: Practical implementation challenges in real-world applications

## Next Checks
1. Test the reduced setting with synthetic data where the two collapsed cases have very different utilities to quantify approximation errors
2. Validate the sufficient conditions on real-world fairness benchmarks to assess their practical effectiveness
3. Implement uncertainty quantification methods to measure how sensitive fairness assessments are to estimation errors in probability distributions