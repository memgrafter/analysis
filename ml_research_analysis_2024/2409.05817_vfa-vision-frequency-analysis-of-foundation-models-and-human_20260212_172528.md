---
ver: rpa2
title: 'VFA: Vision Frequency Analysis of Foundation Models and Human'
arxiv_id: '2409.05817'
source_url: https://arxiv.org/abs/2409.05817
tags:
- human
- bandwidth
- vision
- humans
- frequency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how characteristics of large-scale computer
  vision models affect their alignment with human perception and robustness to distribution
  shifts. Using frequency analysis, the authors find that increasing model and data
  size, incorporating rich semantic information, and using multimodal training reduce
  models' frequency bandwidth toward human levels (1 octave).
---

# VFA: Vision Frequency Analysis of Foundation Models and Human

## Quick Facts
- arXiv ID: 2409.05817
- Source URL: https://arxiv.org/abs/2409.05817
- Authors: Mohammad-Javad Darvishi-Bayazi; Md Rifat Arefin; Jocelyn Faubert; Irina Rish
- Reference count: 19
- One-line primary result: Frequency bandwidth strongly correlates with out-of-distribution accuracy (r = -0.4), making it a better predictor than shape bias (r = 0.13)

## Executive Summary
This study investigates how characteristics of large-scale computer vision models affect their alignment with human perception and robustness to distribution shifts. Using frequency analysis, the authors find that increasing model and data size, incorporating rich semantic information, and using multimodal training reduce models' frequency bandwidth toward human levels (1 octave). Larger models show progressively narrower bandwidths, with 31B-parameter models predicted to match human performance. Training on ImageNet-22K significantly reduces bandwidth compared to ImageNet-1K alone. Bandwidth strongly correlates with out-of-distribution accuracy (r = -0.4), making it a better predictor than shape bias (r = 0.13). Models using CLIP supervision and semantic tokenization (e.g., BEiT-V2) achieve human-like bandwidth. Several architectures (CoAtNet, ConvFormer, ConvNeXt-V2) already exhibit bandwidths close to or better than humans, suggesting scaling and multimodal training are key to improving robustness and human alignment.

## Method Summary
The study evaluates more than 1200 discriminative models from HuggingFace timm and multimodal CLIP models using frequency analysis. The method applies spatial noise in various frequency bands with different noise standard deviations to input images, then measures model performance on these distorted images. A Gaussian curve is fitted to the accuracy-frequency relationship to determine the 50% accuracy threshold, and bandwidth is calculated as the logarithm of the width at half-maximum in octaves. The analysis is validated against 17 out-of-distribution datasets including sketches, edge-filtered images, silhouettes, texture-shape cue conflicts, stylized images, and datasets with parametric image degradation curated by Geirhos et al. (2021).

## Key Results
- Larger models show progressively narrower bandwidths, with 31B-parameter models predicted to match human performance
- Training on ImageNet-22K significantly reduces bandwidth compared to ImageNet-1K alone
- Bandwidth strongly correlates with out-of-distribution accuracy (r = -0.4), outperforming shape bias (r = 0.13) as a predictor
- Models using CLIP supervision and semantic tokenization (e.g., BEiT-V2) achieve human-like bandwidth
- Several architectures (CoAtNet, ConvFormer, ConvNeXt-V2) exhibit bandwidths close to or better than humans

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scaling model size reduces frequency bandwidth, bringing models closer to human performance.
- Mechanism: As model capacity increases, the model learns to focus on a narrower frequency band, similar to human visual processing, which reduces sensitivity to noise and improves robustness.
- Core assumption: Larger models can better capture and filter relevant visual features, mimicking human perceptual strategies.
- Evidence anchors:
  - [abstract]: "Increasing model and data size... enhance models' alignment with human perception and their overall robustness."
  - [section]: "Figure 2 demonstrates that with the increase of model size (X-axis), there is a reduction in bandwidth (Y-axis), signifying a progression towards human-level performance."
  - [corpus]: No direct evidence in corpus.
- Break condition: If increasing model size does not lead to reduced bandwidth, or if the model becomes overly specialized and loses generalization ability.

### Mechanism 2
- Claim: Training on larger and more diverse datasets reduces frequency bandwidth.
- Mechanism: Exposure to a wider variety of visual patterns and categories helps the model learn more efficient and human-like representations, focusing on essential features rather than overfitting to specific frequencies.
- Core assumption: Larger datasets provide richer semantic information that guides the model to develop more robust and human-aligned frequency processing.
- Evidence anchors:
  - [abstract]: "Incorporating rich semantic information... enhance models' alignment with human perception."
  - [section]: "Models trained in ImageNet-22K, a data set with 22K labels, exhibit a bandwidth closer to that of humans."
  - [corpus]: No direct evidence in corpus.
- Break condition: If training on larger datasets does not reduce bandwidth or if the model overfits to the new data.

### Mechanism 3
- Claim: Multimodal training and CLIP supervision lead to human-like bandwidth.
- Mechanism: Integrating language information and using semantic tokenization (e.g., BEiT-V2) helps models focus on more meaningful visual features, reducing reliance on spurious correlations and noise.
- Core assumption: Language supervision provides additional context that guides the model to develop more human-like perceptual strategies.
- Evidence anchors:
  - [abstract]: "Incorporating... multiple modalities enhance models' alignment with human perception."
  - [section]: "BEiT-V2 uses a semantically rich visual tokenizer (distilling knowledge from multimodal pre-trained CLIP model)... Integration of semantic tokenization... contribute to aligning the model with the human frequency bandwidth."
  - [corpus]: No direct evidence in corpus.
- Break condition: If multimodal training does not improve bandwidth or if the model becomes biased towards language-specific features.

## Foundational Learning

- Concept: Frequency analysis in human vision
  - Why needed here: Understanding how humans process visual information in different frequency bands is crucial for comparing and improving model performance.
  - Quick check question: What is the typical frequency bandwidth used by humans for object recognition, and how does it compare to that of models?

- Concept: Distribution shifts and robustness
  - Why needed here: Models often fail to generalize well under distribution shifts, while humans exhibit robust adaptation. Understanding this difference is key to improving model performance.
  - Quick check question: How do distribution shifts affect model performance, and what strategies can be used to improve robustness?

- Concept: Shape bias and texture bias
  - Why needed here: Humans rely more on shape than texture for object recognition, while models are often texture-biased. Understanding this difference can help improve model alignment with human perception.
  - Quick check question: What is shape bias, and how does it differ from texture bias in human and model object recognition?

## Architecture Onboarding

- Component map: Frequency analysis pipeline -> Noise application module -> Frequency band selection -> Performance evaluation -> Gaussian curve fitting -> Bandwidth calculation
- Critical path: Apply noise to input images → Evaluate model accuracy on distorted images → Fit Gaussian curve → Calculate bandwidth as log(width at half-maximum)
- Design tradeoffs: The main tradeoff is between model size and computational efficiency. Larger models may achieve better performance but require more resources.
- Failure signatures: If the model's bandwidth does not decrease with increasing size or if the model overfits to specific frequencies, it may indicate issues with the architecture or training process.
- First 3 experiments:
  1. Test the frequency analysis pipeline on a small set of images with varying noise levels and frequency bands.
  2. Evaluate the performance of different model sizes on the frequency analysis task to observe the effect of scaling on bandwidth.
  3. Compare the performance of models trained on different datasets (e.g., ImageNet-1K vs. ImageNet-22K) to assess the impact of data scaling on bandwidth.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between frequency bandwidth and specific robustness metrics beyond OOD accuracy, such as adversarial robustness or corruptions in ImageNet-C?
- Basis in paper: [inferred] The paper establishes a strong correlation between bandwidth and OOD accuracy (r = -0.4) and mentions various robustness aspects could be investigated, but does not explore specific correlations with other robustness metrics like adversarial robustness or common corruptions.
- Why unresolved: The study focused primarily on OOD accuracy as a measure of robustness, leaving open the question of how bandwidth relates to other important robustness dimensions in computer vision.
- What evidence would resolve it: Systematic experiments measuring the correlation between bandwidth and multiple robustness metrics (adversarial attacks, ImageNet-C corruptions, common object challenges) across diverse model architectures would clarify whether bandwidth is a general robustness indicator or specifically predictive of OOD performance.

### Open Question 2
- Question: What architectural modifications beyond scaling and multimodal training could further reduce frequency bandwidth toward human levels without compromising accuracy?
- Basis in paper: [explicit] The paper identifies that several architectures (CoAtNet, ConvFormer, ConvNeXt-V2) already exhibit bandwidths close to or better than humans, suggesting architectural innovations play a role beyond just scaling.
- Why unresolved: While the paper identifies architectures with human-like bandwidths, it does not analyze the specific architectural features responsible for this achievement or whether these can be systematically engineered.
- What evidence would resolve it: Ablation studies on the architectural components of models with human-like bandwidths (attention mechanisms, normalization layers, tokenization methods) would identify which modifications contribute most to bandwidth reduction while maintaining or improving accuracy.

### Open Question 3
- Question: How does frequency bandwidth relate to the internal representation structure of models, and can bandwidth serve as a diagnostic tool for understanding model behavior?
- Basis in paper: [explicit] The paper discusses using frequency analysis to understand model behavior and mentions investigating the relationship between bandwidth and shape bias, but does not explore deeper connections to internal representations.
- Why unresolved: The study establishes bandwidth as a behavioral metric correlated with robustness but does not examine whether it reflects fundamental differences in how models represent visual information internally.
- What evidence would resolve it: Probing studies examining the activation patterns, feature hierarchies, and representational geometry of models with varying bandwidths would reveal whether bandwidth corresponds to specific representational structures and whether it can predict model behavior in novel tasks.

## Limitations

- The bandwidth metric as a measure of human-like perception has not been independently validated across diverse model architectures and datasets.
- The frequency masking methodology assumes Gaussian-distributed performance degradation across frequency bands, which may not hold for all architectures.
- The prediction that 31B-parameter models will match human bandwidth is extrapolative and lacks empirical validation.

## Confidence

**High Confidence**: The observed correlation between larger model sizes and reduced bandwidth is well-supported by empirical evidence across multiple architectures. The finding that multimodal training (CLIP, BEiT-V2) improves bandwidth alignment with human perception is also robust, with clear mechanistic explanations.

**Medium Confidence**: The predictive value of bandwidth for OOD robustness (r = -0.4) is statistically significant but may not generalize across all distribution shifts or model families. The superiority of bandwidth over shape bias as a predictor is supported but based on a single benchmark.

**Low Confidence**: The extrapolation to 31B-parameter models matching human performance lacks empirical validation. The assumption that bandwidth reduction directly translates to perceptual alignment rather than task-specific optimization remains unproven.

## Next Checks

1. **Cross-Architecture Validation**: Apply the frequency analysis methodology to a diverse set of model architectures (including specialized models like vision transformers, hybrid CNN-transformers, and state-of-the-art architectures not covered in the study) to verify that bandwidth reduction consistently correlates with improved robustness across different architectural paradigms.

2. **Task Generalization Study**: Extend the frequency analysis to non-object-recognition vision tasks (semantic segmentation, object detection, action recognition) to determine whether bandwidth is a general measure of perceptual alignment or specific to classification tasks.

3. **Alternative Curve Fitting Validation**: Implement and compare alternative curve-fitting methods (Lorentzian, polynomial fits) for determining the 50% accuracy threshold to assess the sensitivity of bandwidth calculations to the choice of fitting function, particularly for models exhibiting non-Gaussian frequency responses.