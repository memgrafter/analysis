---
ver: rpa2
title: Towards counterfactual fairness through auxiliary variables
arxiv_id: '2412.04767'
source_url: https://arxiv.org/abs/2412.04767
tags:
- fairness
- counterfactual
- causal
- sensitive
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving counterfactual
  fairness in machine learning models while maintaining predictive accuracy. The authors
  propose EXOC (EXOgenous Causal reasoning), a novel causal reasoning framework that
  leverages auxiliary variables to uncover intrinsic properties underlying sensitive
  attributes.
---

# Towards counterfactual fairness through auxiliary variables

## Quick Facts
- arXiv ID: 2412.04767
- Source URL: https://arxiv.org/abs/2412.04767
- Reference count: 12
- Primary result: EXOC framework achieves superior counterfactual fairness while maintaining predictive accuracy on synthetic and real-world datasets

## Executive Summary
This paper addresses the challenge of achieving counterfactual fairness in machine learning models while maintaining predictive accuracy. The authors propose EXOC (EXOgenous Causal reasoning), a novel causal reasoning framework that leverages auxiliary variables to uncover intrinsic properties underlying sensitive attributes. The framework introduces an auxiliary node S' and a control node S'' to control information flow and balance fairness-accuracy trade-offs. Through systematic evaluation on synthetic and real-world datasets (Law school and Adult), EXOC demonstrates superior fairness metrics while maintaining competitive or better predictive accuracy compared to state-of-the-art approaches.

## Method Summary
EXOC is a causal reasoning framework that uses auxiliary variables to achieve counterfactual fairness. The core innovation involves introducing an auxiliary node S' that captures intrinsic properties of sensitive attributes, and a control node S'' that regulates information flow. The framework employs an ELBO-based implementation with custom loss functions controlled by hyperparameter γ, allowing dynamic balance between fairness and accuracy. The method explicitly defines causal relationships between variables and uses distribution matching techniques (MMD) to ensure counterfactual fairness while maintaining predictive performance.

## Key Results
- EXOC outperforms state-of-the-art approaches (Fair-K and CLAIRE) in achieving counterfactual fairness on both synthetic and real-world datasets
- The framework achieves better MMD and Wass distance metrics while maintaining competitive or better predictive accuracy (RMSE, MAE, and classification accuracy)
- Ablation studies show that γ=1.2 provides a good balance between fairness and accuracy across different datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Introducing auxiliary node S' improves counterfactual fairness by controlling information flow from sensitive attributes to predictions.
- Mechanism: S' acts as a mediator that can be controlled to minimize causal effects from sensitive attributes while maintaining predictive performance. The control node S'' further refines this by regulating the relationship between S' and both the sensitive attribute and target variable.
- Core assumption: The sensitive attribute S can be effectively separated into intrinsic information captured by S' and controllable information flow managed by S''.
- Evidence anchors:
  - [abstract]: "Our framework explicitly defines an auxiliary node and a control node that contribute to counterfactual fairness and control the information flow within the model."
  - [section]: "S′ serves as a mediator, replacing the direct causal relationship between the sensitive attribute S and the target variable Y."
  - [corpus]: Weak evidence - only general papers on counterfactual fairness without specific mention of auxiliary/control node frameworks.
- Break condition: If the auxiliary node cannot effectively capture the intrinsic properties of sensitive attributes, or if the control mechanism becomes too restrictive and degrades predictive accuracy beyond acceptable thresholds.

### Mechanism 2
- Claim: The ELBO-based implementation with custom loss allows dynamic balance between fairness and accuracy through the γ parameter.
- Mechanism: By minimizing KL divergence between distributions and adding a controllable loss term Lc(S', S''), the framework can prioritize fairness (high γ) or accuracy (low γ) based on application needs.
- Core assumption: The relationship between distribution divergence and causal intensity allows meaningful control over fairness-accuracy trade-offs.
- Evidence anchors:
  - [section]: "We observe that the greater the intensity of causal functions, the fewer distribution parities between inferred and true variables."
  - [section]: "Therefore, minimizing Lc(S′,S′′) can be viewed as a maximized causal intensity in φ4 and minimized causal intensity in φ5."
  - [corpus]: Weak evidence - general references to variational inference but no specific connection to fairness-accuracy trade-offs.
- Break condition: If the relationship between γ and actual fairness/accuracy metrics becomes non-monotonic or unpredictable across different datasets.

### Mechanism 3
- Claim: The framework provides superior performance compared to existing counterfactual fairness approaches by leveraging auxiliary variables.
- Mechanism: Unlike Fair-K and CLAIRE which either ignore intrinsic information or create augmentation datasets, EXOC explicitly models the relationship between sensitive attributes and their underlying properties through auxiliary nodes.
- Core assumption: The auxiliary variables capture meaningful latent information that traditional approaches miss.
- Evidence anchors:
  - [section]: "Our evaluation, conducted on synthetic and real-world datasets, validates EXOC's superiority, showing that it outperforms state-of-the-art approaches in achieving counterfactual fairness."
  - [section]: "The results show that as γ increases from 1 to 2, we can observe the performance gradually decreases, but the counterfactual fairness gradually increases."
  - [corpus]: Weak evidence - related papers exist but none specifically validate the auxiliary variable approach.
- Break condition: If performance degradation becomes unacceptable even at optimal γ values, or if the framework fails to generalize across diverse real-world scenarios.

## Foundational Learning

- Concept: Causal structural models (Pearl's framework)
  - Why needed here: The entire framework is built on counterfactual fairness, which requires understanding causal relationships and interventions
  - Quick check question: How does the do-calculus operation differ from standard conditional probability in causal inference?

- Concept: Variational inference and ELBO
  - Why needed here: The implementation uses ELBO to approximate posterior distributions and manage the trade-off between fairness and accuracy
  - Quick check question: What role does the KL divergence term play in the ELBO objective, and how does it relate to counterfactual fairness?

- Concept: Distribution matching and Maximum Mean Discrepancy (MMD)
  - Why needed here: The framework uses MMD to ensure that auxiliary variables capture information independent of sensitive attributes
  - Quick check question: How does minimizing MMD between different sensitive subgroups contribute to achieving counterfactual fairness?

## Architecture Onboarding

- Component map: X → S' → S'' → Y, with S' also connecting to S and Y directly through controlled pathways
- Critical path: Observed non-sensitive attributes X flow through auxiliary node S' and control node S'' to produce prediction Y
- Design tradeoffs:
  - Fairness vs Accuracy: Higher γ prioritizes fairness but reduces accuracy
  - Model complexity vs Interpretability: More complex causal structures provide better fairness but are harder to interpret
  - Training stability vs Performance: ELBO-based training can be unstable but provides better counterfactual guarantees
- Failure signatures:
  - Poor convergence during training: Indicates issues with ELBO optimization or custom loss scaling
  - High variance in fairness metrics: Suggests instability in the control mechanism
  - Significant accuracy drop: Means the auxiliary variables are over-constraining the model
- First 3 experiments:
  1. Test baseline performance with γ=0 (no control) to establish reference fairness/accuracy metrics
  2. Vary γ from 0.5 to 2.0 to observe the fairness-accuracy trade-off curve
  3. Compare performance on synthetic vs real-world datasets to validate generalization

## Open Questions the Paper Calls Out
- How does the framework scale to more complex datasets beyond tabular data, particularly in domains like computer vision or natural language processing where causal relationships are less interpretable?
- What is the optimal strategy for determining the hyperparameter γ that balances fairness and accuracy, and how sensitive is the framework to its selection across different domains?
- How do the theoretical guarantees of counterfactual fairness in the framework translate to real-world fairness outcomes, particularly in domains where discrimination has complex, indirect pathways?

## Limitations
- The framework relies on auxiliary variables that must effectively capture intrinsic properties of sensitive attributes; failure to do so breaks counterfactual fairness guarantees
- The control mechanism through S'' introduces complexity that may lead to training instability, particularly with the 8000-epoch training requirement
- Real-world validation is limited to two datasets (Law school and Adult), limiting generalizability claims

## Confidence
- Fairness claims: Medium - theoretical framework is sound but real-world validation is limited
- Accuracy-fairness trade-off: High - γ parameter's effect on performance is clearly demonstrated through systematic ablation studies
- Framework generalizability: Medium - shown effective on two datasets but broader validation needed

## Next Checks
1. Conduct statistical significance testing on the fairness metric improvements over baselines using bootstrap confidence intervals
2. Test the framework's robustness to adversarial attacks that attempt to exploit the auxiliary variable mechanism
3. Evaluate performance on additional real-world datasets with different sensitive attribute types (gender, age) to assess generalization capability