---
ver: rpa2
title: Shedding Light on Problems with Hyperbolic Graph Learning
arxiv_id: '2411.06688'
source_url: https://arxiv.org/abs/2411.06688
tags:
- graph
- hyperbolic
- learning
- euclidean
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper challenges the prevailing narrative in hyperbolic graph\
  \ representation learning by demonstrating that Euclidean models with comparable\
  \ parameter counts can match or exceed the performance of state-of-the-art hyperbolic\
  \ models on most hyperbolic graph datasets, including perfect trees. The authors\
  \ identify three key issues: buggy or poorly tuned baselines, use of trivially solvable\
  \ tasks that do not require graph information, and inadequate characterization of\
  \ dataset geometry using only graph-level metrics like Gromov \u03B4-hyperbolicity."
---

# Shedding Light on Problems with Hyperbolic Graph Learning

## Quick Facts
- arXiv ID: 2411.06688
- Source URL: https://arxiv.org/abs/2411.06688
- Authors: Isay Katsman; Anna Gilbert
- Reference count: 40
- One-line primary result: Euclidean models with proper training can match or exceed hyperbolic models on most hyperbolic graph datasets

## Executive Summary
This paper challenges the prevailing narrative in hyperbolic graph representation learning by demonstrating that Euclidean models with comparable parameter counts can match or exceed the performance of state-of-the-art hyperbolic models on most hyperbolic graph datasets, including perfect trees. The authors identify three key issues: buggy or poorly tuned baselines, use of trivially solvable tasks that do not require graph information, and inadequate characterization of dataset geometry using only graph-level metrics like Gromov δ-hyperbolicity. Their experiments reveal that simple Euclidean MLPs often outperform hyperbolic models on benchmark tasks when properly trained, suggesting that many claimed advantages of hyperbolic methods are overstated.

## Method Summary
The paper conducts a comprehensive evaluation of hyperbolic graph representation learning by fixing a bug in the Euclidean MLP implementation (removing feature normalization constraints), implementing proper hyperparameter tuning across all models, and generating synthetic datasets (Tree(b,ℓ,γ,δ,D)) to systematically study when graph structure is actually needed. The authors compare multiple GNN variants (GCN, GAT, SAGE, HNN, HGCN, HAT, LGCN, HyboNet, G-RResNet Horo) on both real datasets (Disease, Disease-M, Airport) and synthetic benchmarks, using ROC AUC for link prediction and F1 score for node classification across 5 trials per configuration.

## Key Results
- Fixing a bug in the Euclidean MLP implementation improved performance from 72.6% to 98.7% ROC AUC on the Disease dataset
- Simple Euclidean MLPs can solve most hyperbolic graph tasks without using graph structure when node features contain sufficient information
- On synthetic Tree1111 datasets designed to require graph information, Euclidean models fail while hyperbolic models succeed
- Most GNNs don't use graph structure in sophisticated ways when features are uninformative, relying primarily on degree-based normalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Euclidean models can match hyperbolic models when properly trained due to buggy or poorly tuned baselines in prior work
- Mechanism: A bug in the original HGCN implementation constrained Euclidean feature representations to lie within the unit ball, artificially limiting their expressive power. When this bug is fixed, Euclidean MLPs can achieve comparable or superior performance
- Core assumption: The bug was present in the original implementation and its removal restores full parameter utilization
- Evidence anchors: The bug is manifested by a single line of code constraining Euclidean representations to the unit ball, and fixing it improves Disease dataset performance from 72.6% to 98.7% ROC AUC

### Mechanism 2
- Claim: Many graph tasks in hyperbolic literature are trivially solvable with Euclidean features alone, making geometric structure irrelevant
- Mechanism: The test tasks used in prior work have node features that contain sufficient information to solve link prediction and node classification without using graph structure. A simple Euclidean MLP that ignores the graph can solve these tasks
- Core assumption: The node features in these datasets contain redundant or sufficient information for the task without needing graph structure
- Evidence anchors: A Euclidean model with no graph information effectively solves the most hyperbolic tasks, revealing that the original tasks could not distinguish hyperbolic models from baseline Euclidean models

### Mechanism 3
- Claim: Hyperbolic representation of Euclidean features lacks theoretical justification and is not equivalent to embedding graph nodes
- Mechanism: Prior work exponentiates Euclidean features into hyperbolic space without justification, conflating the theoretical motivation for hyperbolic embeddings (which applies to graph nodes with hierarchical structure) with arbitrary feature representations
- Core assumption: The original theoretical motivation from Sarkar (2011) applies specifically to tree graph embeddings, not to arbitrary feature vectors
- Evidence anchors: The failure to distinguish between nodes and node features makes the decision to exponentiate features not methodologically principled, as the benefit from Sarkar (2011) only holds when explicitly embedding nodes in hyperbolic space

## Foundational Learning

- Concept: Riemannian geometry and hyperbolic space fundamentals
  - Why needed here: Understanding the mathematical foundations is essential for evaluating claims about hyperbolic graph representation and the theoretical motivation behind it
  - Quick check question: What is the difference between Gromov δ-hyperbolicity and Ollivier-Ricci curvature, and why does the paper argue the latter is more appropriate for characterizing graph datasets?

- Concept: Graph neural network architectures and their variants
  - Why needed here: The paper compares multiple GNN variants (GCN, GAT, SAGE) and their behavior when features are uninformative, requiring understanding of how these models use graph structure
  - Quick check question: How does a Graph Convolutional Network differ from a simple multi-layer perceptron in terms of how it processes graph data?

- Concept: Experimental design and benchmarking in machine learning
  - Why needed here: The paper identifies issues with baseline selection, dataset choice, and evaluation metrics, highlighting the importance of proper experimental methodology
  - Quick check question: Why is it problematic if a test task can be solved using only node features without any graph information?

## Architecture Onboarding

- Component map: Data preprocessing -> Model components (Euclidean MLP, GCN variants, hyperbolic models) -> Training pipeline -> Analysis tools
- Critical path: 1) Fix the Euclidean MLP bug by commenting out feature normalization lines, 2) Implement proper hyperparameter tuning for all models, 3) Generate synthetic datasets with controlled feature dependence, 4) Evaluate models on both real and synthetic datasets, 5) Analyze per-layer behavior of GNNs on uninformative feature datasets
- Design tradeoffs: Model complexity vs. performance (simple Euclidean models vs. complex hyperbolic models), feature engineering vs. model sophistication (positional embeddings vs. graph convolutions), real-world relevance vs. controlled experiments (synthetic benchmarks vs. real datasets)
- Failure signatures: Models achieving near-perfect performance on tasks that should require graph information (indicates features contain sufficient information), inconsistent results between different implementations of the same model (indicates bugs or implementation issues), poor performance on synthetic datasets designed to require graph information (indicates models not properly utilizing graph structure)
- First 3 experiments: 1) Fix the Euclidean MLP bug and compare performance on Disease dataset with original results, 2) Generate Tree1111 dataset and evaluate Euclidean MLP vs. GCN vs. HyboNet on link prediction, 3) Create Tree1111γ datasets with varying γ values and analyze when Euclidean models can solve the task without graph information

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical basis for why hyperbolic embeddings outperform Euclidean ones on datasets with high tree-likeness?
- Basis in paper: The paper mentions Sarkar (2011) showing trees can be embedded with arbitrarily low distortion in hyperbolic space, but doesn't fully explain why this translates to better performance on graph tasks
- Why unresolved: The paper demonstrates that Euclidean models can match or exceed hyperbolic models on supposedly "most hyperbolic" datasets, suggesting the theoretical connection between tree-likeness and hyperbolic advantage is incomplete or context-dependent
- What evidence would resolve it: A formal analysis showing conditions under which hyperbolic embeddings provide computational or statistical advantages over Euclidean embeddings for graph tasks, beyond just distortion metrics

### Open Question 2
- Question: How can we develop a metric that properly characterizes graph datasets by jointly considering both graph structure and node features?
- Basis in paper: The paper identifies this as a key limitation, noting that Gromov δ-hyperbolicity only characterizes the graph structure while ignoring features, and suggests Ollivier-Ricci curvature is still insufficient
- Why unresolved: Current metrics either ignore features entirely or don't capture the interaction between graph structure and feature geometry that affects model performance
- What evidence would resolve it: A new metric that predicts when geometric methods (hyperbolic or otherwise) will outperform feature-only methods, validated across diverse graph datasets

### Open Question 3
- Question: Under what conditions do graph neural networks actually utilize graph structure rather than relying primarily on node features?
- Basis in paper: The paper's analysis shows that when features are uninformative (i.i.d. Gaussian), most GNNs don't use graph information in sophisticated ways beyond simple degree-based normalization
- Why unresolved: The paper demonstrates this phenomenon but doesn't provide a complete characterization of when and how GNNs leverage graph structure meaningfully
- What evidence would resolve it: A systematic study mapping dataset characteristics (feature informativeness, graph properties) to GNN behavior, showing which architectures and conditions lead to genuine graph structure utilization

## Limitations
- The analysis of per-layer behavior in GNNs relies on a single uninformative feature setting that may not generalize to all scenarios
- The synthetic dataset family provides controlled environments but may not fully capture the complexity of real-world graph data
- Verification of the bug fix across all reported results is limited, requiring further validation

## Confidence

**High Confidence**: The Euclidean MLP bug fix and its dramatic performance improvement (from 72.6% to 98.7% ROC AUC on Disease dataset) are well-documented with specific code changes and results. The observation that tasks can be trivially solved with features alone is strongly supported by experimental evidence.

**Medium Confidence**: The broader claim that most hyperbolic graph learning advantages are overstated is supported by extensive experiments but requires careful interpretation. While Euclidean models match or exceed hyperbolic models in most cases, the theoretical advantages of hyperbolic geometry for hierarchical data remain valid in principle.

**Low Confidence**: The characterization of when GNNs actually use graph structure versus features is preliminary. The analysis is based on synthetic data with uninformative features, which may not represent real-world feature distributions where some graph signal exists in features.

## Next Checks

1. Implement the Euclidean MLP bug fix across all reported datasets and verify the claimed performance improvements, documenting any discrepancies or additional considerations.

2. Generate and evaluate the complete Tree(b,ℓ,γ,δ,D) dataset family with varying parameters to systematically map the boundary between tasks solvable with features alone versus those requiring graph structure.

3. Test GNN per-layer behavior on diverse feature distributions beyond the uninformative case, including features with varying levels of graph-signal correlation, to validate the generalizability of the observed pattern.