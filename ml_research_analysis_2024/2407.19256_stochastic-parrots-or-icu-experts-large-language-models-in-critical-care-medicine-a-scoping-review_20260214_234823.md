---
ver: rpa2
title: 'Stochastic Parrots or ICU Experts? Large Language Models in Critical Care
  Medicine: A Scoping Review'
arxiv_id: '2407.19256'
source_url: https://arxiv.org/abs/2407.19256
tags:
- llms
- care
- language
- large
- critical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This scoping review systematically examined the application of
  large language models (LLMs) in critical care medicine. From 619 articles, 24 were
  selected that explored LLM use in clinical decision support, medical documentation,
  and medical education.
---

# Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review

## Quick Facts
- arXiv ID: 2407.19256
- Source URL: https://arxiv.org/abs/2407.19256
- Reference count: 40
- Primary result: LLMs show promise in critical care but face challenges including hallucinations, bias, and privacy concerns

## Executive Summary
This scoping review systematically examined the application of large language models (LLMs) in critical care medicine. From 619 articles, 24 were selected that explored LLM use in clinical decision support, medical documentation, and medical education. The review found that while LLMs show promise in handling unstructured data and reducing physician workload, they face significant challenges including hallucinations, poor interpretability, sensitivity to prompts, bias, and privacy concerns. GPT-4 was the most frequently studied model. Current applications range from diagnostic assistance to treatment planning and documentation, but performance varies significantly across tasks. The review concludes that although LLMs are not yet ICU experts, they offer more than simple pattern matching, with future research needed to enhance reliability, address ethical concerns, and develop comprehensive evaluation benchmarks specific to critical care.

## Method Summary
The scoping review followed the PRISMA-ScR methodology to identify and analyze literature on LLM applications in critical care. From an initial pool of 619 articles, 24 met the inclusion criteria after screening. The review focused on peer-reviewed publications and included studies that examined LLM applications across clinical decision support, medical documentation, and medical education domains. Data extraction covered model types, application areas, performance metrics, and reported limitations. The analysis synthesized findings to identify trends, challenges, and future research directions in LLM deployment within critical care settings.

## Key Results
- LLMs demonstrate potential for clinical decision support, medical documentation, and medical education in critical care settings
- Major challenges include hallucinations, poor interpretability, sensitivity to prompts, bias, and privacy concerns
- GPT-4 was the most frequently studied model, with applications ranging from diagnostic assistance to treatment planning

## Why This Works (Mechanism)
The effectiveness of LLMs in critical care medicine stems from their ability to process and synthesize vast amounts of unstructured medical data, including clinical notes, research literature, and patient histories. Their transformer-based architecture enables them to capture complex relationships between clinical variables and generate contextually relevant responses. The models' capacity for natural language understanding allows them to interpret physician queries and medical documentation, while their generative capabilities support the creation of clinical notes and educational content. However, their performance is highly dependent on the quality and representativeness of training data, with biases and limitations in the training corpus directly impacting their clinical reliability.

## Foundational Learning
**Clinical Decision Support**: Enables physicians to access evidence-based recommendations and diagnostic suggestions. Why needed: Critical care requires rapid, accurate decision-making. Quick check: Accuracy of LLM-generated recommendations compared to established clinical guidelines.

**Medical Documentation**: Automates generation of clinical notes and reports. Why needed: Reduces physician documentation burden and standardizes record-keeping. Quick check: Consistency between LLM-generated documentation and physician-written notes.

**Medical Education**: Creates training materials and case studies for medical learners. Why needed: Supports continuous education in fast-evolving critical care practices. Quick check: Educational content accuracy and alignment with current medical standards.

**Bias Detection**: Identifies and mitigates demographic biases in clinical recommendations. Why needed: Ensures equitable care across diverse patient populations. Quick check: Performance consistency across different demographic groups.

**Privacy Preservation**: Implements safeguards for patient data protection. Why needed: Critical care data is highly sensitive and regulated. Quick check: Compliance with HIPAA and similar healthcare privacy regulations.

**Hallucination Mitigation**: Reduces generation of false or fabricated clinical information. Why needed: False information in critical care can lead to patient harm. Quick check: False positive rate in clinical recommendations.

## Architecture Onboarding

**Component Map**: Clinical Data Sources -> LLM Processing Engine -> Output Generation -> Physician Review Interface

**Critical Path**: Patient Data Input -> Clinical Context Analysis -> Recommendation Generation -> Clinical Validation -> Implementation

**Design Tradeoffs**: Accuracy vs. speed (complex analysis takes longer), general knowledge vs. domain specificity (broad training vs. critical care specialization), automation vs. human oversight (efficiency vs. safety), data quantity vs. quality (comprehensive training vs. focused expertise).

**Failure Signatures**: Hallucinations in clinical recommendations, inconsistent responses to similar queries, biased recommendations across demographic groups, privacy violations through data exposure, failure to recognize critical care urgency patterns.

**First 3 Experiments**:
1. Compare LLM diagnostic accuracy against physician diagnoses on standardized critical care cases
2. Measure documentation time savings and accuracy when using LLM-generated clinical notes
3. Evaluate hallucination rates in LLM-generated treatment recommendations across different prompt formulations

## Open Questions the Paper Calls Out
None

## Limitations
- Review included only English-language publications, potentially missing relevant non-English research
- Rapid evolution of LLM technology means findings may quickly become outdated
- Focus on published literature may underrepresent ongoing or proprietary commercial applications

## Confidence

**High confidence**: Identification of common LLM applications and documented challenges across multiple studies
**Medium confidence**: Performance assessments showing variable effectiveness across critical care tasks
**Low confidence**: Long-term reliability and safety claims due to lack of longitudinal validation studies

## Next Checks

1. Conduct prospective clinical trials comparing LLM-assisted decision-making against standard care protocols in ICU settings, with rigorous evaluation of patient outcomes and physician workflow integration.

2. Develop and validate standardized benchmark datasets specifically for critical care applications, ensuring representation across diverse patient populations and clinical scenarios to address concerns about bias and generalizability.

3. Implement real-world deployment studies with continuous monitoring systems to assess LLM performance over extended periods, focusing on identifying and mitigating hallucination rates and ensuring consistent accuracy in high-stakes clinical environments.