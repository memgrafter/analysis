---
ver: rpa2
title: 'Scalable DP-SGD: Shuffling vs. Poisson Subsampling'
arxiv_id: '2411.04205'
source_url: https://arxiv.org/abs/2411.04205
tags:
- batch
- privacy
- poisson
- subsampling
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the privacy gaps between shuffling and
  Poisson subsampling for differentially private stochastic gradient descent (DP-SGD).
  It provides new lower bounds on the privacy guarantees of multi-epoch Adaptive Batch
  Linear Queries (ABLQ) mechanisms with both persistent and dynamic shuffling, showing
  substantial gaps compared to Poisson subsampling.
---

# Scalable DP-SGD: Shuffling vs. Poisson Subsampling

## Quick Facts
- arXiv ID: 2411.04205
- Source URL: https://arxiv.org/abs/2411.04205
- Reference count: 13
- Primary result: Poisson subsampling provides better privacy-utility trade-offs than shuffling-based DP-SGD in high privacy regimes

## Executive Summary
This paper investigates the privacy gaps between shuffling and Poisson subsampling for differentially private stochastic gradient descent (DP-SGD). Through new lower bounds on multi-epoch Adaptive Batch Linear Queries (ABLQ) mechanisms, the authors demonstrate substantial privacy advantages of Poisson subsampling over shuffling-based approaches. The paper introduces a scalable implementation of Poisson subsampling using massively parallel computation with truncation to handle variable batch sizes, making it practical for large-scale datasets. Experimental results on the Criteo Display Ads dataset show that DP-SGD with Poisson subsampling achieves similar utility to shuffling-based DP-SGD at the same noise level, while providing better privacy-utility trade-offs in high privacy regimes.

## Method Summary
The paper compares three batch sampling methods for DP-SGD: deterministic, shuffled (persistent and dynamic), and Poisson subsampling. The authors analyze privacy through the lens of Adaptive Batch Linear Queries (ABLQ) mechanisms, establishing lower bounds on shuffling privacy and demonstrating that Poisson subsampling provides tighter privacy guarantees. A key contribution is a scalable implementation of truncated Poisson subsampling using Map-Reduce operations where each example independently samples batch membership using geometric distribution, then groups by batch index and truncates/pads to fixed size. The approach is evaluated on the Criteo Display Ads dataset with 46 million examples, comparing AUC metrics and privacy parameters across different sampling methods.

## Key Results
- New lower bounds show substantial privacy gaps between shuffling and Poisson subsampling for multi-epoch ABLQ mechanisms
- Scalable Poisson subsampling implementation using parallel computation achieves practical performance on large datasets
- DP-SGD with Poisson subsampling matches shuffling-based utility at same noise level while providing better privacy-utility trade-off in high privacy regimes
- Truncated Poisson subsampling with appropriate truncation bounds (B/b ≈ 20) maintains training effectiveness while enabling efficient parallel implementation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Poisson subsampling provides better privacy amplification than shuffling-based DP-SGD when using correct privacy accounting
- Mechanism: Uses truncated Poisson subsampling where each example is included in each batch independently with probability b/n, then truncated to maximum batch size B. This process provides tighter privacy guarantees than shuffling-based approaches.
- Core assumption: Privacy loss curve of Poisson subsampling-based ABLQ is tighter than shuffling-based ABLQ for multi-epoch training
- Evidence anchors: Abstract shows substantial privacy gaps between shuffling and Poisson subsampling; section demonstrates better privacy-utility trade-off; corpus provides weak evidence on implementation details

### Mechanism 2
- Claim: Massively parallel computation enables scalable implementation of truncated Poisson subsampling for large datasets
- Mechanism: Uses Map-Reduce operations where each example independently samples which batches it belongs to using geometric distribution, then groups by batch index and truncates/pads to fixed size B.
- Core assumption: Parallel sampling approach maintains statistical properties of Poisson subsampling while being computationally efficient
- Evidence anchors: Abstract introduces practical approach using massively parallel computation; section provides scalable approach using Map-Reduce; corpus lacks details on parallel sampling implementations

### Mechanism 3
- Claim: Privacy gap between shuffling and Poisson subsampling increases with higher privacy regimes (smaller ε)
- Mechanism: Through lower bound analysis of ABLQ mechanisms, demonstrates that shuffling requires larger noise scales than Poisson subsampling for same privacy guarantee in high privacy regimes
- Core assumption: Lower bounds on shuffling privacy are tight enough to reflect practical performance gaps
- Evidence anchors: Abstract shows Poisson subsampling is viable alternative; section shows shuffling performs worse in high privacy regimes; corpus focuses on implementation rather than theoretical gaps

## Foundational Learning

- Concept: Adaptive Batch Linear Queries (ABLQ) mechanism
  - Why needed here: DP-SGD privacy analysis relies on viewing it as post-processing of ABLQ, so understanding ABLQ is fundamental to paper's privacy analysis
  - Quick check question: How does ABLQ mechanism relate to DP-SGD algorithm in terms of query responses and privacy guarantees?

- Concept: Privacy amplification by subsampling
  - Why needed here: Paper compares privacy amplification effects between Poisson subsampling and shuffling, which are different subsampling mechanisms
  - Quick check question: What is key difference in privacy amplification between independent Poisson subsampling and correlated shuffling?

- Concept: Hockey stick divergence and dominating pairs
  - Why needed here: Paper uses these concepts to establish lower bounds on privacy guarantees through analytical comparison of probability distributions
  - Quick check question: How does hockey stick divergence relate to differential privacy guarantees, and why are dominating pairs useful for establishing privacy bounds?

## Architecture Onboarding

- Component map: Data preprocessing pipeline (feature transforms, embeddings) -> Batch sampling module (deterministic, shuffled, Poisson subsampling variants) -> Privacy accounting engine (computes σ values) -> Training loop (DP-SGD with clipping and noise addition) -> Evaluation framework (AUC metrics, comparison across sampling methods)

- Critical path: Data → Batch sampling → Privacy accounting → Training → Evaluation

- Design tradeoffs:
  - Truncation vs. exact Poisson: Trade computational efficiency for minor privacy degradation
  - Parallel vs. sequential sampling: Trade implementation complexity for scalability
  - Lower bound vs. upper bound privacy accounting: Trade pessimism for practical applicability

- Failure signatures:
  - If truncation ratio (B/b) is too small: Training fails due to insufficient data coverage
  - If privacy accounting is incorrect: Reported ε values are misleading
  - If parallel implementation has race conditions: Batch membership becomes non-independent

- First 3 experiments:
  1. Verify Poisson subsampling batch size distribution matches theoretical binomial/binomial distribution
  2. Compare privacy loss curves for single-epoch ABLQ with different batch samplers
  3. Test truncated Poisson subsampling with varying B values to find acceptable truncation threshold

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can tighter upper bounds be established for privacy guarantees of multi-epoch ABLQB with persistent and dynamic shuffling batch samplers?
- Basis in paper: Paper provides lower bounds on privacy guarantees of multi-epoch ABLQB with persistent and dynamic shuffling, demonstrating substantial gaps when compared to Poisson subsampling. Privacy analysis of DP-SGD with shuffling batch samplers is obtained by analyzing ABLQ mechanism, and paper's lower bounds bring into serious question common practice of implementing shuffling-based DP-SGD while reporting privacy parameters as if Poisson subsampling was used.
- Why unresolved: Paper only provides lower bounds on privacy guarantee when using persistent/dynamic shuffled batches. While some privacy amplification results are known, providing tight (non-vacuous) upper bound on privacy guarantee in these settings remains open challenge. This is important in regimes where shuffling does provide better privacy guarantees than Poisson subsampling.
- What evidence would resolve it: Formal proof of tight upper bound on privacy guarantee of multi-epoch ABLQB with persistent and dynamic shuffling batch samplers, or empirical demonstration that lower bounds provided are indeed tight.

### Open Question 2
- Question: How does privacy-utility trade-off of DP-SGD with shuffling batch samplers compare to Poisson subsampling in regimes where shuffling provides better privacy guarantees than Poisson subsampling?
- Basis in paper: Paper's lower bounds on privacy guarantee of multi-epoch ABLQB with shuffling demonstrate substantial gaps when compared to Poisson subsampling. However, paper does not explore regimes where shuffling might provide better privacy guarantees than Poisson subsampling.
- Why unresolved: Paper focuses on demonstrating limitations of shuffling-based DP-SGD in terms of privacy guarantees and compares utility of models trained with Poisson-subsampling-based DP-SGD to optimistic estimates of utility when using shuffling. However, it does not explore regimes where shuffling might actually provide better privacy guarantees and how this affects privacy-utility trade-off.
- What evidence would resolve it: Comprehensive experimental study comparing privacy-utility trade-off of DP-SGD with shuffling batch samplers and Poisson subsampling in regimes where shuffling provides better privacy guarantees, along with theoretical analysis of privacy-utility trade-off in these regimes.

### Open Question 3
- Question: How do other forms of shuffling, such as those implemented by tf.data.Dataset.shuffle or torchdata.datapipes.iter.Shuffler, affect privacy guarantees and utility of DP-SGD?
- Basis in paper: Paper discusses limitations of shuffling-based DP-SGD in terms of privacy guarantees and compares utility of models trained with Poisson-subsampling-based DP-SGD to optimistic estimates of utility when using shuffling. However, it does not explore other forms of shuffling that are commonly used in practice.
- Why unresolved: Paper focuses on persistent and dynamic shuffling, which are natural instantiations of permutation batch sampler. However, other forms of shuffling, such as those implemented by tf.data.Dataset.shuffle or torchdata.datapipes.iter.Shuffler, are also commonly used in practice and might have different privacy guarantees and utility.
- What evidence would resolve it: Theoretical analysis of privacy guarantees of DP-SGD with other forms of shuffling, along with experimental study comparing utility of models trained with DP-SGD using these shuffling methods to utility of models trained with DP-SGD using Poisson subsampling.

## Limitations
- Theoretical lower bounds on shuffling privacy may not reflect practical performance, creating uncertainty about claimed privacy gaps
- Limited experimental scope to single dataset (Criteo) and specific model architecture may not generalize to other domains
- Implementation details for handling Criteo dataset preprocessing and hyperparameter tuning are not fully specified

## Confidence

- High confidence: Implementation of truncated Poisson subsampling using parallel computation is well-specified and utility comparison results between sampling methods are directly observable from experiments
- Medium confidence: Theoretical privacy gap analysis between shuffling and Poisson subsampling, while mathematically rigorous, relies on lower bounds that may not reflect practical performance
- Low confidence: Claim about Poisson subsampling being viable replacement for shuffling in all practical scenarios, given limited scope of experiments

## Next Checks

1. **Empirical validation of privacy gaps**: Conduct experiments measuring actual privacy loss (not just theoretical bounds) for shuffling vs. Poisson subsampling across multiple epochs and privacy regimes
2. **Scalability testing**: Verify parallel implementation's performance on datasets larger than Criteo, measuring both computational efficiency and memory usage as dataset size scales
3. **Robustness to truncation**: Systematically vary truncation parameter B and measure resulting impact on both privacy guarantees and model utility to identify optimal truncation thresholds