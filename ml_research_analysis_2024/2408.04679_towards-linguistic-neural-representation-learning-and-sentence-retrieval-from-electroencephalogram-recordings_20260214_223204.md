---
ver: rpa2
title: Towards Linguistic Neural Representation Learning and Sentence Retrieval from
  Electroencephalogram Recordings
arxiv_id: '2408.04679'
source_url: https://arxiv.org/abs/2408.04679
tags:
- encoder
- retrieval
- sentence
- sentences
- signals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ETER, a two-step pipeline for converting
  EEG signals into sentences. First, it trains a Conformer-based EEG encoder using
  masked contrastive learning to classify EEG segments into words.
---

# Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings

## Quick Facts
- arXiv ID: 2408.04679
- Source URL: https://arxiv.org/abs/2408.04679
- Authors: Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin
- Reference count: 40
- One-line primary result: EEG-to-text retrieval pipeline achieves up to 55.15% top-20 word classification accuracy and 55.55% recall@5 for sentence-level retrieval on the ZuCo dataset.

## Executive Summary
This paper introduces ETER, a two-step pipeline for converting EEG signals into sentences. First, it trains a Conformer-based EEG encoder using masked contrastive learning to classify EEG segments into words. Second, it employs a beam search retriever to identify relevant sentences based on the predicted keyword sets. Experiments on the ZuCo dataset show that the EEG encoder achieves up to 55.15% top-20 accuracy in word-level classification, and the retrieval method attains a recall@5 of up to 55.55% and a BLEU-1 score of 30.44% for sentence-level evaluation. Visualization of predictions confirms the model's ability to group EEG segments into semantically related words, validating its efficacy in learning patterns from unspoken EEG recordings.

## Method Summary
The ETER method uses a two-step pipeline: first, a Conformer-based EEG encoder is trained using masked contrastive learning to classify EEG segments into words by aligning EEG representations with word embeddings from a frozen BERT model. Second, a beam search retriever with Aho-Corasick scoring identifies relevant sentences by aggregating top-k semantically related word predictions into keyword sets. The approach is evaluated on the ZuCo dataset using word-level classification accuracy (top-1, top-5, top-10, top-15, top-20) and sentence-level retrieval performance (recall@5, precision@5, BLEU-1, BLEU-4).

## Key Results
- EEG encoder achieves up to 55.15% top-20 accuracy in word-level classification on the ZuCo dataset.
- Beam search retrieval method attains recall@5 of up to 55.55% and BLEU-1 score of 30.44% for sentence-level evaluation.
- The model successfully groups EEG segments into semantically related words, as visualized in prediction analysis.

## Why This Works (Mechanism)

### Mechanism 1
Masked contrastive learning aligns EEG representations with word semantics without relying on language model generation during inference. Conformer encoder maps EEG tokens to a representation space where similarity to word embeddings reflects semantic relevance. Masking forces the model to generalize from partial input. Core assumption: EEG patterns during reading are stable enough across subjects that a shared representation space can be learned.

### Mechanism 2
Beam search retrieval avoids dependence on single top-1 predictions by aggregating top-k semantically related words into keyword sets. For each EEG segment, top-k predictions form a keyword set; beam search explores combinations of these sets to find the most relevant sentence in the corpus. Core assumption: EEG encoder's top-k predictions are semantically coherent enough that combining them improves retrieval recall.

### Mechanism 3
Aho-Corasick scoring enables efficient, training-free matching of keyword combinations against sentence corpus. Builds a finite-state machine from keyword combinations; counts occurrences in each sentence; scores by average match count. Core assumption: Sentences in corpus contain enough keywords from the set that occurrence count is a reliable relevance signal.

## Foundational Learning

- **Conformer architecture**: Combines self-attention with local convolution to capture both global and local dependencies. Needed here because EEG signals have both long-range rhythmic patterns (captured by attention) and local channel correlations (captured by convolution). Quick check: What is the main difference between a Conformer block and a pure Transformer block?

- **Masked contrastive learning**: Aligns representations across modalities without requiring paired labels. Needed here because paired EEG-word labels are scarce; contrastive learning lets the model learn semantic alignment from a frozen language model's embeddings. Quick check: In masked contrastive learning, why is the word embedding not masked?

- **Beam search**: Trades memory for exploration by keeping top-m partial sequences. Needed here because EEG top-k predictions are imperfect; beam search explores combinations to improve sentence recall. Quick check: How does beam width m affect retrieval performance vs memory usage?

## Architecture Onboarding

- **Component map**: EEG Preprocessing → Spatial Tokenizer → Conformer Encoder → Masked Contrastive Loss → Classification Head → Top-k Predictor → Keyword Set Generator → Beam Search Retriever → Aho-Corasick Scorer → Sentence Output
- **Critical path**: EEG → Conformer Encoder → Top-k Prediction → Keyword Set → Beam Search → Retrieval
- **Design tradeoffs**: Smaller vocabulary → better balance but less scalability; Larger beam width → better recall but higher memory; More Conformer layers → richer features but overfitting risk
- **Failure signatures**: Low top-20 accuracy → encoder not learning semantic alignment; High precision but low recall → retrieval method too strict; High BLEU but low sentence recall → matching generic phrases, not exact sentences
- **First 3 experiments**: 1) Train base Conformer encoder without masking; measure top-20 accuracy; 2) Add masking with small ratio; measure change in top-20 accuracy; 3) Replace Aho-Corasick with TF-IDF scoring; compare recall@5 on held-out test set

## Open Questions the Paper Calls Out

### Open Question 1
How would the proposed ETER method perform with a significantly larger vocabulary beyond the top 100 words? The authors mention that their method's performance declines when vocabulary size exceeds 200 words due to dataset imbalance and sparsity issues. Testing the ETER method on a larger, more balanced EEG dataset with vocabulary sizes exceeding 200 words would provide concrete evidence of performance scaling.

### Open Question 2
Would incorporating more advanced retrieval methods beyond beam search significantly improve sentence retrieval accuracy? The authors compare their beam search retrieval (BSR) method with a greedy retrieval approach and note that BSR performs better, especially on unseen data. Implementing and testing more advanced retrieval methods such as dense retrieval, cross-encoder models, or learned sparse retrieval techniques on the same dataset would provide concrete comparisons to the BSR method's performance.

### Open Question 3
How would the ETER method perform on different types of reading tasks beyond sentiment analysis and biography comprehension? The authors tested their method on two specific tasks (sentiment analysis from movie reviews and entity relation extraction from biographies) and suggest exploring more diverse datasets as future work. Testing the ETER method on a diverse range of reading tasks would provide evidence of its generalizability across various linguistic and cognitive contexts.

## Limitations
- The model's performance is evaluated on a small corpus of only 12 participants from the ZuCo dataset, limiting generalizability to broader populations.
- The vocabulary restriction to 100 most frequent words substantially limits practical applicability to real-world sentence decoding tasks.
- The reliance on eye-tracking data for EEG segmentation means the approach cannot be applied to imagined speech or spontaneous thought scenarios where no visual fixation data exists.

## Confidence
- **High Confidence**: The fundamental observation that EEG signals contain word-level semantic information is well-supported by the classification accuracy results (55.15% top-20 accuracy).
- **Medium Confidence**: The claim that masked contrastive learning effectively aligns EEG representations with word semantics without requiring paired labels during inference is plausible but not definitively proven.
- **Low Confidence**: The assertion that beam search retrieval with keyword combinations significantly improves sentence recall compared to single-word predictions is weakly supported.

## Next Checks
1. **Cross-Subject Generalization Test**: Evaluate the trained model on EEG data from participants not included in the training set to quantify inter-subject variability effects.
2. **Vocabulary Scaling Experiment**: Gradually increase the vocabulary size from 100 to 1000 words while monitoring classification and retrieval performance degradation.
3. **Ablation Study on Retrieval Components**: Systematically remove or modify components of the retrieval pipeline (masking ratio, beam width, Aho-Corasick scoring) to isolate which elements contribute most to the reported performance improvements.