---
ver: rpa2
title: Text Embedding Inversion Security for Multilingual Language Models
arxiv_id: '2401.12192'
source_url: https://arxiv.org/abs/2401.12192
tags:
- text
- steps
- inversion
- multilingual
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study is the first to investigate multilingual embedding inversion
  attacks, exploring the vulnerability of multilingual language models to black-box
  text reconstruction attacks. The research demonstrates that multilingual models
  can be more susceptible to inversion attacks than monolingual models, particularly
  when English-based defenses are ineffective.
---

# Text Embedding Inversion Security for Multilingual Language Models

## Quick Facts
- **arXiv ID**: 2401.12192
- **Source URL**: https://arxiv.org/abs/2401.12192
- **Reference count**: 40
- **Primary result**: Multilingual models are more vulnerable to embedding inversion attacks than monolingual models, and English-based defenses are ineffective for non-English languages.

## Executive Summary
This paper investigates text embedding inversion attacks in multilingual settings, revealing that multilingual language models are more vulnerable to black-box reconstruction attacks than monolingual models. The study introduces cross-lingual inversion attacks, where attackers reconstruct text in languages they don't know, and proposes a novel masking defense mechanism that effectively protects both monolingual and multilingual models while preserving utility in retrieval tasks. The research highlights the inadequacy of English-based defenses for multilingual settings and calls for new evaluation metrics beyond traditional string-matching approaches.

## Method Summary
The authors train inversion models to reconstruct text from embeddings using Vec2Text architecture, testing both monolingual (English) and multilingual settings across English, French, German, and Spanish. They employ MTG dataset for training and evaluate reconstruction quality using BLEU, ROUGE, Token F1, Exact Match, and Cosine Similarity metrics. The proposed masking defense works by replacing the first dimension of embeddings with language identifiers, breaking the direct mapping between embeddings and original text while maintaining semantic relationships needed for retrieval. Cross-lingual attacks are evaluated using Ad hoc Translation to compare outputs across language pairs.

## Key Results
- Multilingual models show higher vulnerability to embedding inversion attacks than monolingual models
- English-based noise injection defenses are ineffective for multilingual settings
- The masking defense preserves retrieval performance while significantly reducing reconstruction success
- Cross-lingual inversion attacks are feasible and require new evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1
Multilingual models are more vulnerable because they encode richer cross-lingual semantic information in embeddings. The embedding space contains more recoverable information as it must represent concepts across multiple languages simultaneously. When attackers exploit overlapping semantic spaces across languages, reconstruction becomes more effective than in monolingual settings.

### Mechanism 2
English-based defenses fail for multilingual models because they don't account for cross-lingual semantic relationships and different noise tolerance across languages. The semantic preservation properties and noise tolerance of multilingual embeddings differ significantly from monolingual English embeddings, making traditional defenses inadequate.

### Mechanism 3
The masking defense effectively protects models by encoding language identifiers in the first dimension, breaking the direct mapping between embeddings and original text. This approach maintains the semantic relationships needed for retrieval tasks while making inversion attacks significantly harder, as attackers can no longer rely on consistent embedding patterns across languages.

## Foundational Learning

- **Concept**: Black-box embedding inversion attacks
  - Why needed here: The entire paper is built on understanding how attackers can reconstruct text from embeddings without knowing the model architecture
  - Quick check question: In a black-box setting, what information does an attacker have access to when attempting embedding inversion?

- **Concept**: Cross-lingual semantic relationships
  - Why needed here: The paper investigates how multilingual models encode information across languages and how this affects vulnerability to attacks
  - Quick check question: How does the embedding space of a multilingual model differ from that of a monolingual model in terms of cross-lingual semantic relationships?

- **Concept**: Evaluation metrics for cross-lingual attacks
  - Why needed here: Traditional string-matching metrics are inadequate for cross-lingual scenarios, requiring new evaluation approaches like Ad hoc Translation
  - Quick check question: Why are BLEU and ROUGE scores insufficient for evaluating cross-lingual embedding inversion attacks?

## Architecture Onboarding

- **Component map**: Embedder (ϕ) -> Inversion model (ψ) -> Defense mechanisms -> Evaluation framework (Retrieval tasks + Reconstruction metrics + Ad hoc Translation)

- **Critical path**: 
  1. Train embedder on multilingual data (MTG or NQ)
  2. Query embedder to collect (text, embedding) pairs
  3. Train inversion model on collected pairs
  4. Apply inversion model to target embeddings
  5. Evaluate reconstruction quality using appropriate metrics
  6. Test defense mechanisms and measure impact on both retrieval and reconstruction

- **Design tradeoffs**:
  - Language coverage vs. model performance: Training on more languages increases vulnerability but improves generalization
  - Defense strength vs. utility preservation: Stronger defenses reduce reconstruction success but may impact retrieval performance
  - Evaluation complexity vs. realism: Cross-lingual evaluation is more realistic but requires complex evaluation frameworks

- **Failure signatures**:
  - Low reconstruction scores across all languages suggest model training issues
  - Language-specific performance drops indicate data quality or representation problems
  - Defense mechanisms that break retrieval suggest over-aggressive protection
  - Cross-lingual evaluation failures point to metric inadequacy rather than attack failure

- **First 3 experiments**:
  1. Reproduce monolingual English inversion results using GTR-base and ME5-base on NQ dataset
  2. Train and evaluate multilingual inversion model (ME5-base) on MTG dataset across English, French, German, and Spanish
  3. Test English-based noise defense on both monolingual and multilingual models and compare effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
How effective would cross-lingual inversion attacks be on lower-resource languages with different script systems? The paper notes preliminary experiments with Finnish and Hungarian showed poorer performance, but these share the Latin script. Performance on languages with completely different scripts (Arabic, Chinese, Hindi) remains unexplored.

### Open Question 2
What is the relationship between multilingual model architecture and vulnerability to embedding inversion attacks? The paper observes multilingual models can be more vulnerable under certain conditions, suggesting architectural differences play a role, but doesn't systematically compare different multilingual model architectures.

### Open Question 3
How can evaluation metrics for cross-lingual inversion attacks be improved beyond the proposed Ad hoc Translation approach? The paper introduces Ad hoc Translation as a preliminary solution but acknowledges it depends on MT quality and calls for better evaluation metrics that don't rely on translation.

## Limitations

- The analysis of why multilingual models exhibit greater vulnerability is somewhat speculative, relying on assumptions about cross-lingual semantic relationships without fully characterizing embedding space geometry
- The cross-lingual attack evaluation using Ad hoc Translation introduces approximation error that makes quantitative comparisons less precise than monolingual evaluations
- The masking defense mechanism lacks theoretical grounding for why language identifier masking specifically disrupts inversion while preserving retrieval

## Confidence

- **High**: Multilingual models are more vulnerable than monolingual models; masking defense preserves retrieval while reducing reconstruction
- **Medium**: English-based defenses are ineffective for multilingual models; cross-lingual attacks are feasible and practical
- **Low**: The specific geometric properties of multilingual embedding spaces that enable greater vulnerability; optimal defense parameter selection across diverse languages

## Next Checks

1. **Ablation study on masking defense**: Systematically vary which embedding dimensions are masked and test whether the first dimension specifically is critical, or if any dimension masking provides similar protection. This would validate whether the defense exploits a specific architectural property or simply adds sufficient noise to disrupt inversion.

2. **Cross-lingual semantic analysis**: Perform detailed analysis of embedding space geometry across languages to quantify the degree of semantic overlap and information sharing. Use techniques like nearest-neighbor analysis and semantic similarity measurements to empirically validate the hypothesis that multilingual models encode richer cross-lingual information that enables more effective attacks.

3. **Defense transferability testing**: Evaluate whether defenses effective in monolingual settings can be adapted for multilingual models by incorporating language-specific parameters, or whether fundamentally different defense mechanisms are required. Test noise injection with language-aware noise distributions and compare to the masking approach across diverse language families.