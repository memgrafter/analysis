---
ver: rpa2
title: Self-Normalized Resets for Plasticity in Continual Learning
arxiv_id: '2410.20098'
source_url: https://arxiv.org/abs/2410.20098
tags:
- loss
- neuron
- plasticity
- then
- reset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses plasticity loss in continual learning, where
  neural networks become increasingly unable to adapt to new tasks over time. The
  authors introduce Self-Normalized Resets (SNR), an algorithm that mitigates plasticity
  loss by resetting neurons when evidence suggests they have effectively stopped firing.
---

# Self-Normalized Resets for Plasticity in Continual Learning

## Quick Facts
- arXiv ID: 2410.20098
- Source URL: https://arxiv.org/abs/2410.20098
- Reference count: 40
- Primary result: SNR mitigates plasticity loss by resetting inactive neurons based on percentile thresholds of their inter-firing time distributions

## Executive Summary
This paper addresses plasticity loss in continual learning, where neural networks become increasingly unable to adapt to new tasks over time. The authors introduce Self-Normalized Resets (SNR), an algorithm that mitigates plasticity loss by resetting neurons when evidence suggests they have effectively stopped firing. SNR works by monitoring each neuron's firing pattern and resetting it when the time since its last activation exceeds a threshold based on the neuron's typical firing rate. The algorithm consistently outperforms competing methods across multiple benchmark problems using various architectures.

## Method Summary
SNR addresses plasticity loss by resetting neurons when their firing rate effectively drops to zero. The algorithm monitors each neuron's activation pattern over time, tracking inter-firing times to estimate the neuron's typical firing rate. When the time since last activation exceeds a threshold set at the 1-α(1-α)^(-1) percentile of the neuron's inter-firing time distribution, the neuron is reset. This threshold is adaptive, allowing neurons with higher firing rates to have shorter inactivity windows while neurons with lower firing rates get longer windows. The method combines this reset mechanism with L2 regularization for optimal performance.

## Key Results
- SNR consistently outperforms competing algorithms across four benchmark problems (Permuted MNIST, Random Label MNIST, Random Label CIFAR, and Continual ImageNet) using MLP, CNN, and ViT architectures
- SNR is robust to its sole hyperparameter, the rejection percentile threshold, while competitor algorithms show significant sensitivity
- The performance gap between SNR and L2 regularization grows substantially as model scale increases from 1x to 16x

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SNR resets neurons when they stop firing based on percentile thresholds of their inter-firing time distribution
- **Mechanism:** Monitors each neuron's activation pattern over time; when time since last activation exceeds a threshold set at the 1-α(1-α)^(-1) percentile of its inter-firing time distribution, the neuron is reset
- **Core assumption:** Neurons that stop firing effectively die and need resetting to maintain network plasticity
- **Evidence anchors:**
  - [abstract] "resetting a neuron's weights when evidence suggests its firing rate has effectively dropped to zero"
  - [section 2] "reset neuron iat timetiff P(Aµt i ≥a t i)≤η"
  - [corpus] Weak - neighbor papers discuss plasticity loss but don't specifically validate SNR's percentile-based approach
- **Break condition:** If neuron firing patterns don't follow geometric-like distributions or if inter-firing times aren't good proxies for neuron utility

### Mechanism 2
- **Claim:** The percentile threshold approach adapts to individual neuron firing rates, making it more effective than fixed thresholds
- **Mechanism:** Neurons with higher firing rates get reset after shorter inactivity periods (since their expected inter-firing time is shorter), while neurons with lower firing rates get longer inactivity windows
- **Core assumption:** Different neurons have different natural firing rates, and a one-size-fits-all threshold is suboptimal
- **Evidence anchors:**
  - [section 3.2] "neurons that tend to fire frequently" vs "neurons that fire less frequently"
  - [section 3.2] Proposition 3.2 shows fixed thresholds have arbitrarily worse error rates than SNR when comparing neurons with different firing rates
  - [corpus] Moderate - neighboring papers discuss neuron reinitialization but not adaptive threshold mechanisms
- **Break condition:** If all neurons in a network have similar firing rates, or if the overhead of tracking individual thresholds outweighs benefits

### Mechanism 3
- **Claim:** SNR maintains plasticity by preventing neuron inactivity, which is correlated with loss of learning capacity
- **Mechanism:** By resetting inactive neurons, SNR restores their ability to learn new tasks, maintaining the network's overall plasticity
- **Core assumption:** Neuron inactivity is a primary cause of plasticity loss, and resetting restores plasticity
- **Evidence anchors:**
  - [abstract] "plasticity loss describes the phenomenon where... ability to adapt to a new task diminishes over time"
  - [section 4] "we see that this plasticity loss is correlated with increasing weight norms... persistent neuron inactivity"
  - [corpus] Strong - multiple neighbor papers explicitly discuss neuron inactivity as a key correlate of plasticity loss
- **Break condition:** If plasticity loss is primarily caused by factors other than neuron inactivity (e.g., weight norm explosion, feature collapse)

## Foundational Learning

- **Concept:** Hypothesis testing and optimal stopping theory
  - Why needed here: SNR is derived from an optimal hypothesis test for detecting neuron death, requiring understanding of type-1/type-2 error minimization and delay penalties
  - Quick check question: What is the optimal test for distinguishing between a Bernoulli process with rate p>0 versus rate identically zero, when minimizing error rates plus delay penalties?

- **Concept:** Point process theory and geometric distributions
  - Why needed here: The inter-firing times of neurons are modeled as geometric random variables, and the reset threshold is based on percentiles of this distribution
  - Quick check question: If a neuron fires with probability p on each training example, what is the distribution of the time between consecutive firings?

- **Concept:** Gradient descent optimization and regret analysis
  - Why needed here: The theoretical analysis compares gradient descent with and without resets using average regret as the performance metric
  - Quick check question: What is the difference between expected average regret and cumulative regret, and why is vanishing average regret important for continual learning?

## Architecture Onboarding

- **Component map:** Training loop -> Forward pass -> Activation monitoring -> Gradient computation -> Weight update -> Reset check
- **Critical path:** 1. Forward pass through network to get activations 2. Update inter-firing time counters (increment if neuron didn't fire, reset to 0 if it did) 3. Compute gradients and update weights 4. Check reset condition for each neuron using percentile threshold 5. Reset neurons that meet criteria
- **Design tradeoffs:** 
  - Tracking overhead vs. plasticity benefits: More neurons tracked = better plasticity detection but higher computational cost
  - Threshold sensitivity: Lower η = more aggressive resetting (potentially disrupting learning) vs. higher η = less intervention (potentially missing dead neurons)
  - Layer-wise vs. global tracking: Per-layer tracking reduces memory but may miss layer-specific patterns
- **Failure signatures:**
  - Too aggressive resetting: Network shows high variance in performance, frequent drops in accuracy
  - Too conservative resetting: Plasticity loss persists, neuron inactivity increases over tasks
  - Implementation bugs: Resetting doesn't actually reinitialize weights, or inter-firing counters aren't properly maintained
- **First 3 experiments:**
  1. PM (Permuted MNIST) with MLP architecture, SGD optimizer - baseline comparison to no intervention
  2. PM with varying η values (0.01, 0.05, 0.1) to test sensitivity
  3. PM with SGD vs. Adam to verify optimizer independence of SNR benefits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SNR perform on larger-scale language models (e.g., 10B+ parameters) and how does its effectiveness scale with model size?
- Basis in paper: [explicit] The paper shows SNR+L2's effectiveness on a 5M parameter transformer and demonstrates increasing performance gaps as model scale increases from 1x to 16x.
- Why unresolved: The experiments were limited to models up to 5M parameters, while practical applications typically involve much larger models. The paper notes this as a limitation and suggests the need for understanding plasticity loss in larger models.
- What evidence would resolve it: Systematic experiments on transformer models ranging from 10M to 100B+ parameters on continual learning tasks, comparing SNR+L2 to baseline methods while measuring both training and test loss.

### Open Question 2
- Question: What is the theoretical relationship between the optimal reset threshold percentile and the true neuron firing rate distribution in practice?
- Basis in paper: [explicit] The paper derives that the optimal reset threshold is the 1-λ(p-λ)^(-1) percentile of the neuron's firing rate distribution under an idealized hypothesis test.
- Why unresolved: The theoretical analysis assumes knowledge of the true firing rate distribution, but in practice SNR uses empirical histograms. The gap between theory and practice needs quantification.
- What evidence would resolve it: Empirical analysis measuring the discrepancy between the theoretically optimal percentile and the empirically determined threshold across various neurons and tasks, with quantification of the impact on reset accuracy.

### Open Question 3
- Question: How does SNR compare to other plasticity mitigation methods when applied to vision transformers and other attention-based architectures?
- Basis in paper: [explicit] The paper evaluates SNR on ViT architectures for Continual ImageNet and shows it outperforms L2 regularization, but the comparison is limited to a subset of methods.
- Why unresolved: The experiments focus on comparing SNR to a specific set of baselines, but there may be other promising approaches for attention-based architectures that weren't evaluated.
- What evidence would resolve it: Comprehensive benchmarking of SNR against all major plasticity mitigation methods (including recent approaches like Layer-wise Relevance-based Deep Networks) on vision transformers across multiple continual learning datasets.

## Limitations

- The theoretical analysis assumes idealized conditions (single neuron, adversarial targets, perfect resets) that don't directly translate to practical multi-layer networks
- The geometric distribution assumption for inter-firing times is a simplification that may not hold across all architectures and tasks
- Empirical results are limited to specific benchmark tasks and architectures, potentially missing broader applicability issues

## Confidence

- SNR outperforms baselines on benchmark tasks: High
- Plasticity loss correlates with neuron inactivity: Medium
- Theoretical regret bounds apply to practical SNR: Low
- SNR hyperparameters are robust: Medium

## Next Checks

1. Ablation study removing SNR resets to isolate the contribution of neuron reactivation vs. other SNR effects
2. Cross-architecture validation on transformer-based models with different attention mechanisms
3. Statistical test for geometric distribution fit of inter-firing times across neurons in each benchmark task