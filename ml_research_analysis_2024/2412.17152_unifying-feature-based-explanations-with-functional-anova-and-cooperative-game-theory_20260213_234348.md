---
ver: rpa2
title: Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game
  Theory
arxiv_id: '2412.17152'
source_url: https://arxiv.org/abs/2412.17152
tags:
- effects
- feature
- effect
- features
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a unified framework for interpreting feature-based
  explanations of black box machine learning models by combining functional ANOVA
  (fANOVA) from statistics and cooperative game theory. The framework provides a structured
  way to categorize local and global explanations according to the influence of feature
  distributions (via baseline, marginal, or conditional fANOVA) and higher-order interactions
  (via pure, partial, or full effects).
---

# Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game Theory

## Quick Facts
- arXiv ID: 2412.17152
- Source URL: https://arxiv.org/abs/2412.17152
- Reference count: 40
- Key outcome: Introduces a unified framework linking functional ANOVA and cooperative game theory to categorize local and global feature-based explanations by feature distribution influence and interaction levels.

## Executive Summary
This paper presents a unified theoretical framework for interpreting feature-based explanations of black box machine learning models by combining functional ANOVA (fANOVA) from statistics with cooperative game theory. The framework provides a structured way to categorize explanations according to the influence of feature distributions (baseline, marginal, or conditional fANOVA) and higher-order interactions (pure, partial, or full effects). Three types of feature influence—individual, joint, and interaction effects—are defined and linked to game-theoretic measures such as Shapley values and interactions. The authors demonstrate that many existing explanation methods can be interpreted within this framework and validate its practical utility on both synthetic and real-world datasets.

## Method Summary
The method introduces an explanation game ν that maps subsets of features to real values, enabling the application of functional ANOVA decompositions and cooperative game theory. Three fANOVA decompositions are defined—baseline (b-fANOVA), marginal (m-fANOVA), and conditional (c-fANOVA)—which determine the influence of feature distributions through different joint distributions over the feature space. The framework uses the Möbius transform to compute pure, partial, and full effects that quantify increasing influence of higher-order interactions. These effects are linked to game-theoretic measures including Shapley values, joint Shapley values, and Shapley interactions. The approach covers both local explanations for specific data points and global explanations in terms of sensitivity and risk.

## Key Results
- The framework unifies feature-based explanations by linking fANOVA decompositions with cooperative game theory values through Möbius inversion.
- Choice of imputation method (baseline, marginal, or conditional) controls the influence of feature distribution in explanations.
- Pure, partial, and full effects correspond to increasing influence of higher-order interactions, with partial effects distributing interactions equally among features.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework unifies feature-based explanations by linking fANOVA decompositions with cooperative game theory values.
- Mechanism: By defining the explanation game ν and using the Möbius transform m, the framework maps fANOVA effects f_S directly to Shapley values and interactions, enabling unified interpretation across local and global settings.
- Core assumption: The Möbius inversion theorem (Rota, 1964) applies to the constructed explanation games, ensuring that m(S) corresponds to f_S.
- Evidence anchors:
  - [abstract] "We introduce three fANOVA decompositions that determine the influence of feature distributions, and use game-theoretic measures, such as the Shapley value and interactions, to specify the influence of higher-order interactions."
  - [section 3.2] Corollary 1: "The MT m(loc)_x0 of the local explanation game ν(loc)_x0 is the fANOVA effect f_S evaluated at x0."
  - [corpus] Found 25 related papers; related works include functional decomposition and game-theoretic Shapley value explanations.
- Break condition: If the Möbius inversion fails (e.g., due to non-additive ν), then m(S) ≠ f_S, breaking the unified interpretation.

### Mechanism 2
- Claim: The choice of imputation method (baseline, marginal, conditional) controls the influence of feature distribution in explanations.
- Mechanism: Each fANOVA decomposition uses a different joint distribution P over the feature space, altering the value function F_S and thus the resulting fANOVA effects f_S.
- Core assumption: The feature distribution can be accurately modeled or sampled for marginal and conditional imputation.
- Evidence anchors:
  - [abstract] "Our framework covers local explanations for a specific data point and two global explanations in terms of sensitivity and risk. Practitioners determine the influence of feature distribution by a specific choice of fANOVA."
  - [section 3.1] Theorem 2: m-fANOVA equals b-fANOVA with b = E[X] for linear models; c-fANOVA differs when features are dependent.
  - [corpus] Weak: Related works (e.g., Lundberg & Lee 2017, Janzing et al. 2020) focus on baseline and marginal imputation but not the unified framework.
- Break condition: If feature dependencies are ignored or inaccurately modeled, m-fANOVA effects become misleading; if conditional distributions are hard to estimate, c-fANOVA becomes computationally infeasible.

### Mechanism 3
- Claim: Pure, partial, and full effects correspond to increasing influence of higher-order interactions.
- Mechanism: These effects are defined by the Möbius transform m(S) and Co-Möbius transform m̃(S), where partial effects (Shapley values) distribute higher-order terms equally among features.
- Core assumption: Higher-order interactions are captured by the Möbius transform and can be meaningfully distributed via Shapley weights.
- Evidence anchors:
  - [abstract] "Using fundamental concepts from cooperative game theory, we quantify pure, partial, and full effects that yield an increasing influence of higher-order interactions."
  - [section 3.4] Theorem 4: "Feature influence measures summarize the MT, according to Table 2."
  - [section 3.3] "The interaction ∆_S(T) := ∆_{[S]}(T) − Σ_{L⊂S} ∆_L(T) in the presence of features in T ... account for lower-order effects."
  - [corpus] Moderate: Bordt & von Luxburg 2023 discuss Shapley-GAM and interactions; however, the unified treatment across explanation types is novel.
- Break condition: If higher-order interactions are negligible, the distinction between pure, partial, and full effects becomes meaningless.

## Foundational Learning

- Concept: Functional ANOVA (fANOVA) decomposition
  - Why needed here: It provides the mathematical foundation for partitioning model predictions into main effects, interactions, and baseline.
  - Quick check question: Given F(x) = β₁x₁ + β₂x₂ + β₁₂x₁x₂, what are the main and interaction effects in b-fANOVA?

- Concept: Shapley value and Möbius transform in cooperative game theory
  - Why needed here: They offer principled ways to allocate joint contributions and interactions among features, enabling unified explanation measures.
  - Quick check question: For a 3-player game with values ν({1})=2, ν({2})=3, ν({3})=4, ν({1,2})=7, ν({1,3})=9, ν({2,3})=10, ν({1,2,3})=15, compute the Shapley value for player 1.

- Concept: Variance decomposition and Sobol' indices
  - Why needed here: They quantify global sensitivity of model predictions to input features, directly relating to the global sensitivity game.
  - Quick check question: For independent features X₁, X₂ ~ N(0,1), if F(X) = X₁ + X₂, what is the Sobol' index for feature 1?

## Architecture Onboarding

- Component map: Explanation game ν : 2^D → R (local, sensitivity, risk) -> fANOVA decomposition (b/m/c) -> Value function F_S(x) -> fANOVA effects f_S via Möbius inversion -> Influence measures ϕ (individual, joint, interaction) via Shapley values and interactions

- Critical path:
  1. Choose explanation game type (local/sensitivity/risk).
  2. Select fANOVA decomposition (baseline/marginal/conditional).
  3. Compute value function F_S(x) for all S ⊆ D.
  4. Derive fANOVA effects f_S via Möbius inversion.
  5. Apply influence measure (pure/partial/full) to obtain ϕ.

- Design tradeoffs:
  - b-fANOVA: Fast, baseline-dependent, ignores feature distribution.
  - m-fANOVA: Captures marginal dependencies, may extrapolate.
  - c-fANOVA: Fully accounts for feature distribution, computationally heavy.
  - Pure effects: Isolate main contributions, miss higher-order interactions.
  - Full effects: Capture all interactions, can be dominated by higher-order terms.
  - Partial effects: Distribute interactions, computationally expensive (2^d evaluations).

- Failure signatures:
  - Baseline dependence: Different b yields inconsistent explanations.
  - Extrapolation: m-fANOVA yields unrealistic F_S values.
  - High variance: c-fANOVA estimates noisy due to sampling.
  - Non-monotonicity: Full effects may contradict intuitive importance.

- First 3 experiments:
  1. Implement local explanation game with b-fANOVA for a simple linear model; verify that ϕ = main effects.
  2. Add interaction term; confirm that pure effects miss it, partial effects distribute it, full effects capture it.
  3. Switch to m-fANOVA; compare pure effects with and without feature correlation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed framework handle instance-based explanations like counterfactuals, which are not covered in the current model?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that "instance-based explanations, such as counterfactuals (Wachter et al., 2017), are not included."
- Why unresolved: The paper does not explore how the fANOVA and game-theoretic concepts could be extended to incorporate counterfactual reasoning or whether such an extension is theoretically feasible.
- What evidence would resolve it: A theoretical extension of the framework that incorporates counterfactual reasoning, or an empirical study showing how counterfactual explanations could be unified with the current fANOVA and game-theoretic approach.

### Open Question 2
- Question: What are the practical implications of using different imputation strategies (b-, m-, c-fANOVA) on model performance and interpretation in real-world applications?
- Basis in paper: [explicit] The authors discuss how the choice of imputation strategy influences the interpretation of feature effects but do not provide a comprehensive empirical comparison of these strategies across various real-world datasets and model types.
- Why unresolved: The paper provides theoretical insights but lacks extensive empirical evidence on how different imputation strategies affect model performance and interpretability in diverse real-world scenarios.
- What evidence would resolve it: A large-scale empirical study comparing the performance and interpretability of models using different imputation strategies across various real-world datasets and model types.

### Open Question 3
- Question: How does the framework address the computational challenges associated with calculating Shapley values and Shapley interactions for large datasets?
- Basis in paper: [explicit] The authors mention in the Limitations section that "the SV and SIs require an exponential amount of game evaluations, which also necessitates approximation methods."
- Why unresolved: The paper does not provide a detailed analysis of the computational efficiency of the framework or discuss specific approximation methods for large datasets.
- What evidence would resolve it: A detailed analysis of the computational efficiency of the framework, including specific approximation methods for large datasets, and empirical results showing the scalability of the approach.

## Limitations
- The theoretical unification between fANOVA effects and game-theoretic measures relies on the Möbius inversion theorem holding for all constructed explanation games.
- Empirical validation is limited to specific synthetic and real-world datasets with predefined feature distributions.
- The computational complexity of full effects (2^d evaluations) and c-fANOVA (conditional sampling) may limit scalability to high-dimensional problems.

## Confidence

- **High confidence**: The mathematical framework linking fANOVA decompositions with game-theoretic measures (Shapley values, interactions) is rigorously defined and internally consistent.
- **Medium confidence**: The empirical demonstration that different imputation strategies yield distinct insights is convincing for the tested datasets, but generalization to broader problem domains requires further validation.
- **Low confidence**: The practical implications of choosing between pure, partial, and full effects in real-world applications are not fully explored, particularly regarding interpretability tradeoffs.

## Next Checks

1. **Edge case validation**: Test the framework on models with non-additive value functions (e.g., max-pooling layers) to verify that Möbius inversion still yields meaningful explanations.

2. **Scalability assessment**: Benchmark the computational cost of full effects and c-fANOVA on datasets with d > 10 features to identify practical limitations.

3. **Interpretability study**: Conduct a user study comparing practitioners' understanding and trust in explanations derived from pure vs. partial vs. full effects across different domains.