---
ver: rpa2
title: Stick to your Role! Stability of Personal Values Expressed in Large Language
  Models
arxiv_id: '2402.14846'
source_url: https://arxiv.org/abs/2402.14846
tags:
- stability
- value
- llms
- different
- persona
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the stability of personal values expressed
  by large language models (LLMs) across different contexts. The researchers use the
  Schwartz Theory of Basic Personal Values and the Portrait Values Questionnaire (PVQ)
  to measure value expression.
---

# Stick to your Role! Stability of Personal Values Expressed in Large Language Models

## Quick Facts
- arXiv ID: 2402.14846
- Source URL: https://arxiv.org/abs/2402.14846
- Reference count: 11
- Major finding: Value stability varies significantly across LLM families and contexts

## Executive Summary
This study investigates the stability of personal values expressed by large language models across different contexts using Schwartz Theory of Basic Personal Values. The researchers evaluate 19 open-source LLMs from five model families in two settings: baseline responses and persona-simulated responses. They find that Mixtral, Mistral, and Qwen families exhibit higher value stability compared to LLaMa-2 and Phi families. When instructed to simulate personas, LLMs show lower Rank-Order stability, which further decreases with longer conversations. The study introduces new methodological tools for evaluating value stability and highlights the importance of context-dependence in LLM evaluation.

## Method Summary
The researchers employ the Schwartz Theory of Basic Personal Values and the Portrait Values Questionnaire (PVQ) to measure value expression in 19 open-source LLMs across five model families. Models are evaluated in two settings: baseline responses without persona instructions and persona-simulated responses with specific role instructions. The study introduces Rank-Order stability as a metric to assess consistency of value expression across contexts. To test conversation length effects, they use chain-of-thought prompting to extend interactions while maintaining context awareness. The methodology provides a systematic approach to measuring value stability and its contextual dependencies.

## Key Results
- Mixtral, Mistral, and Qwen model families exhibit higher value stability compared to LLaMa-2 and Phi families
- Persona simulation consistently reduces value stability across all model families
- Longer conversations further decrease value stability when personas are simulated
- New methodological tools for evaluating value stability introduced

## Why This Works (Mechanism)
Value stability in LLMs depends on the interaction between pre-training objectives, fine-tuning processes, and contextual prompt conditioning. The Schwartz Theory provides a structured framework for measuring abstract values, while Rank-Order stability offers a quantitative metric for consistency assessment. The observed differences between model families likely stem from variations in training data composition, architecture choices, and fine-tuning strategies. Persona simulation introduces additional contextual complexity that challenges the model's internal value representations, particularly as conversations extend and context accumulates.

## Foundational Learning

1. **Schwartz Theory of Basic Personal Values**
   - Why needed: Provides structured framework for measuring abstract human values
   - Quick check: Ensure all 10 value types (Self-Direction, Stimulation, Hedonism, Achievement, Power, Security, Conformity, Tradition, Benevolence, Universalism) are represented

2. **Rank-Order Stability Metric**
   - Why needed: Quantifies consistency of value expression across contexts
   - Quick check: Verify metric accounts for both magnitude and ranking changes

3. **Persona Simulation Techniques**
   - Why needed: Tests model's ability to maintain role-consistent value expression
   - Quick check: Validate persona instructions produce expected behavioral changes

## Architecture Onboarding

**Component Map:** Data Collection -> Value Scoring -> Stability Calculation -> Family Comparison

**Critical Path:** 
1. Collect model responses under baseline and persona conditions
2. Score responses using PVQ for value expression
3. Calculate Rank-Order stability metrics
4. Compare stability across model families

**Design Tradeoffs:**
- Framework specificity vs. generalizability (Schwartz vs. other value frameworks)
- Controlled persona simulation vs. natural persona adoption
- Model family diversity vs. sample size per family

**Failure Signatures:**
- Inconsistent value scoring across evaluators
- Context contamination between baseline and persona conditions
- Model-specific biases in value expression

**First Experiments:**
1. Test baseline value expression consistency within same model family
2. Verify persona simulation produces expected behavioral changes
3. Validate Rank-Order stability metric with synthetic data

## Open Questions the Paper Calls Out

The study does not explicitly identify open questions, though several implications emerge from the findings. The relationship between training methodology and value stability warrants further investigation, particularly regarding how different fine-tuning approaches impact consistency. The role of model architecture in maintaining stable value expression across contexts remains unclear. Additionally, the generalizability of these findings to proprietary models and real-world deployment scenarios represents an important area for future research.

## Limitations

- Relies on single value framework (Schwartz Theory) which may not capture full complexity of human values
- Simulated personas through prompts may not fully replicate real-world persona adoption scenarios
- Focus on open-source models limits generalizability to proprietary systems
- Rank-Order stability metric may not capture all relevant aspects of value expression consistency

## Confidence

- Value stability differences between model families: Medium
- Persona simulation consistently reduces stability: Medium
- Conversation length impacts stability: Medium
- New methodological tools validity: High

## Next Checks

1. Replicate findings using alternative value frameworks (e.g., Hofstede's cultural dimensions, Rokeach Value Survey) to assess framework dependency
2. Test stability across different conversation types and domains (technical, creative, social) to evaluate domain-specific effects
3. Compare open-source and proprietary model behavior under identical conditions to assess model family differences