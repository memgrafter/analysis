---
ver: rpa2
title: 'Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework
  for Emotion-Cause Pair Extraction in Conversations'
arxiv_id: '2404.16905'
source_url: https://arxiv.org/abs/2404.16905
tags:
- emotion
- causal
- arxiv
- recognition
- utterance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a multi-stage framework for the SemEval-2024
  Task 3, focusing on Emotion-Cause Pair Extraction in Conversations. The proposed
  approach involves three main stages: emotion recognition using Llama-2-based InstructERC,
  causal pair extraction using a two-stream attention model (TSAM), and causal span
  extraction using MuTEC.'
---

# Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations

## Quick Facts
- arXiv ID: 2404.16905
- Source URL: https://arxiv.org/abs/2404.16905
- Reference count: 22
- Primary result: First place in both subtasks of SemEval-2024 Task 3

## Executive Summary
This paper presents a multi-stage framework for the SemEval-2024 Task 3 focused on Emotion-Cause Pair Extraction in Conversations. The proposed approach consists of three main stages: emotion recognition using Llama-2-based InstructERC, causal pair extraction using a two-stream attention model (TSAM), and causal span extraction using MuTEC. The framework achieved first place in both subtasks of the competition, demonstrating strong performance in emotion recognition (weighted average F1 of 58.64 and accuracy of 61.45) and causal pair extraction (positive F1 of 78.0). However, the causal span extraction performance was notably lower with a weighted average proportional F1 score of 32.23.

## Method Summary
The framework employs a three-stage approach to address emotion-cause pair extraction in conversations. First, emotion recognition is performed using Llama-2-based InstructERC to identify emotional states within the conversation. Second, a two-stream attention model (TSAM) is utilized to extract causal pairs by capturing relationships between emotions and potential causes. Finally, MuTEC is applied for causal span extraction to identify the specific text spans that constitute the causes. This multi-stage design allows for specialized handling of different aspects of the emotion-cause relationship extraction task.

## Key Results
- Achieved first place in both subtasks of SemEval-2024 Task 3
- Emotion recognition: weighted average F1 of 58.64 and accuracy of 61.45
- Causal pair extraction: positive F1 score of 78.0
- Causal span extraction: weighted average proportional F1 score of 32.23

## Why This Works (Mechanism)
The multi-stage framework works effectively by decomposing the complex emotion-cause pair extraction task into specialized subtasks, each handled by an appropriate model. The Llama-2-based emotion recognition provides robust identification of emotional states, the TSAM model captures nuanced relationships between emotions and causes through its dual attention mechanism, and MuTEC handles the fine-grained task of span extraction. This modular approach allows each component to specialize in its respective task while maintaining end-to-end integration for the overall objective.

## Foundational Learning
- **Llama-2-based InstructERC**: Fine-tuned language model for emotion recognition; needed for accurate identification of emotional states in conversations; quick check: evaluate emotion classification accuracy on validation set
- **Two-stream attention model (TSAM)**: Dual attention mechanism for causal pair extraction; needed to capture complex relationships between emotions and causes; quick check: compare attention weight distributions for correct vs. incorrect pairs
- **MuTEC for span extraction**: Model specialized in extracting text spans; needed for precise identification of causal text spans; quick check: measure precision of span boundary detection
- **Multi-stage pipeline architecture**: Sequential processing approach; needed to handle different aspects of emotion-cause extraction separately; quick check: verify data flow between stages
- **Weighted average F1 metrics**: Performance evaluation metric; needed to assess model performance across different classes; quick check: examine class-wise F1 scores
- **Conversation-level processing**: Framework designed for conversational data; needed to handle turn-taking and context; quick check: test on conversations with varying lengths

## Architecture Onboarding

**Component map**: Llama-2-based emotion recognition -> Two-stream attention model (TSAM) -> MuTEC span extraction

**Critical path**: Input conversation → Emotion recognition → Causal pair extraction → Causal span extraction → Output emotion-cause pairs

**Design tradeoffs**: The framework prioritizes specialization over end-to-end training, using separate models for each stage rather than a unified approach. This allows for leveraging state-of-the-art models for each subtask but may introduce cumulative error propagation across stages.

**Failure signatures**: The framework shows particular weakness in causal span extraction (F1 of 32.23), suggesting potential issues with fine-grained span localization. Error analysis reveals that while causal relationships are identified, precise span boundaries are often incorrect, particularly in cases with overlapping or nested causal spans.

**3 first experiments**:
1. Evaluate emotion recognition performance on a held-out validation set to verify the effectiveness of the Llama-2 fine-tuning
2. Test the TSAM model's ability to capture causal relationships by examining attention weight distributions on example conversations
3. Validate the causal span extraction by comparing predicted spans against ground truth for sample conversations

## Open Questions the Paper Calls Out
None

## Limitations
- Relatively low performance on causal span extraction (weighted average proportional F1 of 32.23), indicating challenges in precise causal span localization
- Heavy reliance on large language models (Llama-2 and MuTEC) which may limit reproducibility due to computational resource requirements
- Competition-specific evaluation metrics may not fully capture real-world applicability or generalization to other conversational datasets

## Confidence
- **High confidence** in the overall framework architecture and competition results
- **Medium confidence** in the generalizability of results to non-competition settings
- **Medium confidence** in the effectiveness of the two-stream attention model for causal pair extraction

## Next Checks
1. Evaluate the framework on additional conversational datasets outside the SemEval-2024 Task 3 to assess generalization capabilities
2. Conduct ablation studies to determine the contribution of each component (Llama-2, TSAM, MuTEC) to overall performance
3. Analyze error patterns in causal span extraction to identify specific failure modes and potential improvements for this component