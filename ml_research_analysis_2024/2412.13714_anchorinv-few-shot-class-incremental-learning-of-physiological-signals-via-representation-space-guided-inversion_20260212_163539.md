---
ver: rpa2
title: 'AnchorInv: Few-Shot Class-Incremental Learning of Physiological Signals via
  Representation Space Guided Inversion'
arxiv_id: '2412.13714'
source_url: https://arxiv.org/abs/2412.13714
tags:
- classes
- session
- base
- incremental
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Few-Shot Class-Incremental
  Learning (FSCIL) for physiological time series data, where models must adapt to
  new classes with limited data while preserving prior knowledge. The proposed method,
  AnchorInv, generates synthetic samples guided by anchor points in the feature space
  instead of storing raw data, protecting privacy and regularizing the model for adaptation.
---

# AnchorInv: Few-Shot Class-Incremental Learning of Physiological Signals via Representation Space Guided Inversion

## Quick Facts
- arXiv ID: 2412.13714
- Source URL: https://arxiv.org/abs/2412.13714
- Reference count: 25
- Key outcome: AnchorInv achieves superior performance in FSCIL for physiological signals by generating synthetic samples from feature-space anchor points, improving Macro-F1 scores by 2.19% and 3.24% over best baselines on BCI and NHIE datasets respectively.

## Executive Summary
This paper addresses Few-Shot Class-Incremental Learning (FSCIL) for physiological time series data, where models must adapt to new classes with limited data while preserving prior knowledge. The proposed AnchorInv method generates synthetic samples guided by anchor points in the feature space instead of storing raw data, protecting privacy and regularizing the model for adaptation. The method was evaluated on three public physiological time series datasets (BCI, NHIE, GRABMyo) and achieved superior performance compared to state-of-the-art baselines.

## Method Summary
AnchorInv addresses FSCIL by using feature space-guided model inversion to retroactively synthesize diverse and representative samples of previously seen classes. Instead of storing raw data exemplars, the method stores representative anchor points in feature space during base training. During incremental learning, synthetic samples are generated by minimizing feature distance to these anchors, creating samples that preserve the statistical distribution of prior classes. The method protects privacy by avoiding raw data storage while maintaining model performance through effective regularization during adaptation.

## Key Results
- AnchorInv achieved 2.19% higher Macro-F1 than the best baseline on BCI dataset
- AnchorInv achieved 3.24% higher Macro-F1 than the best baseline on NHIE dataset
- The method particularly excels when the number of base classes is limited, which is common in biomedical applications
- Performance improvements were consistent across all three evaluated datasets (BCI, NHIE, GRABMyo)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Anchor point selection in feature space prevents catastrophic forgetting better than label-space inversion
- Mechanism: The method stores representative anchor points in feature space during base training, then generates synthetic samples by minimizing feature distance to these anchors. This creates samples that preserve the statistical distribution of prior classes in feature space.
- Core assumption: Feature space anchor points capture the essential distribution of class representations, and synthetic samples generated to match these anchors will regularize the model during incremental learning.
- Evidence anchors:
  - [abstract]: "We propose feature space-guided model inversion to retroactively synthesize diverse and representative samples of previously seen classes"
  - [section]: "We derive a replay set...from the selected anchor points...to regularize the adaptation of the feature extractor"
  - [corpus]: Weak/no direct evidence - related papers focus on different aspects of few-shot incremental learning
- Break condition: If anchor points fail to capture the true class distribution in feature space, or if the feature space becomes too distorted during incremental learning, the regularization effect will diminish.

### Mechanism 2
- Claim: Using anchor points instead of raw data storage protects privacy while maintaining model performance
- Mechanism: By storing only feature-space anchor points rather than raw physiological data, the method adheres to data privacy regulations while still enabling synthetic sample generation for replay.
- Core assumption: Anchor points contain sufficient information about class distributions to generate representative synthetic samples without requiring raw data storage.
- Evidence anchors:
  - [abstract]: "Instead of selecting and storing raw data, AnchorInv generates synthetic samples guided by anchor points in the feature space. This approach protects privacy"
  - [section]: "Many methods store exemplars from the base session...due to strict data regulations in a healthcare setting, direct storage of samples raises data and privacy concerns"
  - [corpus]: Weak/no direct evidence - privacy protection is mentioned but not empirically validated
- Break condition: If anchor points lose critical information about class distributions, or if regulatory requirements demand more stringent data protection than just avoiding raw data storage.

### Mechanism 3
- Claim: Multiple trials evaluation reveals true model performance in few-shot incremental learning
- Mechanism: By sampling multiple training sets for each incremental session and evaluating across all trials, the method provides a more realistic estimate of model performance in deployment scenarios.
- Core assumption: Few-shot learning performance is highly sensitive to which specific samples are selected for training, and multiple trials can capture this variability.
- Evidence anchors:
  - [section]: "We further investigate how the choice of anchor points from base classes affects few-shot class-incremental learning performance"
  - [section]: "we randomly sample multiple training sets for each incremental session and repeat the adaption process across multiple trials"
  - [corpus]: Weak/no direct evidence - multiple trials evaluation is described but not extensively validated
- Break condition: If sample selection variability is not the primary source of performance variation, or if the number of trials is insufficient to capture true performance distribution.

## Foundational Learning

- Concept: Few-Shot Class-Incremental Learning (FSCIL)
  - Why needed here: The paper addresses the challenge of learning new classes with limited data while preserving knowledge of previous classes, which is the core problem FSCIL aims to solve
  - Quick check question: What are the two main challenges FSCIL methods must address simultaneously?

- Concept: Catastrophic forgetting
  - Why needed here: The method aims to prevent catastrophic forgetting, which occurs when models lose previously learned knowledge during adaptation to new tasks
  - Quick check question: Why does naive fine-tuning lead to catastrophic forgetting in incremental learning scenarios?

- Concept: Model inversion techniques
  - Why needed here: The method uses feature space-guided model inversion to generate synthetic samples that regularize the model during incremental learning
  - Quick check question: How does model inversion differ from traditional generative methods like GANs in the context of incremental learning?

## Architecture Onboarding

- Component map: Base session -> Anchor set memory -> Inversion module -> Incremental session -> Evaluation module
- Critical path:
  1. Train feature extractor on base classes
  2. Project training data to feature space and select anchor points
  3. Store anchor points in memory
  4. For each incremental session:
     - Generate synthetic samples from anchor points
     - Fine-tune model with synthetic samples + few-shot real samples
     - Update anchor set with new class representations
  5. Evaluate across multiple trials
- Design tradeoffs:
  - Number of anchor points vs. memory/storage constraints
  - Feature space dimensionality vs. computational complexity
  - Number of trials vs. evaluation time and resources
  - Synthetic sample quality vs. model regularization effectiveness
- Failure signatures:
  - High variance across trials indicates poor generalization
  - Decreasing performance on base classes suggests catastrophic forgetting
  - Similar performance to random chance indicates feature space misalignment
  - No improvement over baseline suggests anchor point selection issues
- First 3 experiments:
  1. Validate anchor point selection algorithm on base session data
  2. Test synthetic sample generation quality against real samples
  3. Compare performance with different numbers of anchor points per class

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the traditional sense. However, several limitations and areas for future work are implied throughout the discussion, particularly regarding the need for more extensive validation on datasets with very few base classes and the potential for extending the method to continuous learning scenarios.

## Limitations
- The method's performance on datasets with very few base classes is not thoroughly validated, with only BCI dataset having 3 base classes
- No comparison with privacy-preserving methods that also use feature space representations
- Limited analysis of anchor point selection sensitivity beyond random sampling
- No investigation of how the number of anchor points per class affects performance

## Confidence
- Anchor point effectiveness in preventing catastrophic forgetting: Medium
- Privacy protection through feature space storage: Low
- Multiple trials evaluation methodology: Medium

## Next Checks
1. Conduct an ablation study comparing AnchorInv with and without the anchor point regularization to quantify its specific contribution to preventing catastrophic forgetting
2. Implement privacy metrics to empirically validate that storing anchor points provides meaningful privacy protection compared to raw data storage
3. Test the method's robustness by varying the number of anchor points per class (e.g., 10, 50, 100) and analyzing the performance tradeoff curve