---
ver: rpa2
title: Multimodal Adaptive Inference for Document Image Classification with Anytime
  Early Exiting
arxiv_id: '2405.12705'
source_url: https://arxiv.org/abs/2405.12705
tags:
- exit
- multimodal
- inference
- document
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multimodal early exit (EE) architecture for
  efficient document image classification, addressing the need to balance performance
  and efficiency in large multimodal models. The method involves inserting intermediate
  classifiers (gates or ramps) at different network layers and exploring various training
  strategies including subgraph weighting, entropy regularization, and their combination.
---

# Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting

## Quick Facts
- arXiv ID: 2405.12705
- Source URL: https://arxiv.org/abs/2405.12705
- Reference count: 34
- Primary result: Multimodal early exit architecture achieves over 20% latency reduction while fully retaining baseline accuracy

## Executive Summary
This paper introduces a multimodal early exit (EE) architecture for efficient document image classification, addressing the need to balance performance and efficiency in large multimodal models. The method involves inserting intermediate classifiers (gates or ramps) at different network layers and exploring various training strategies including subgraph weighting, entropy regularization, and their combination. A novel heuristic thresholding approach is introduced for adaptive inference. Experiments on a subset of the RVL-CDIP dataset show that the calibrated EE design achieves over 20% latency reduction while maintaining baseline accuracy. The work demonstrates that calibration and the proposed thresholding heuristic improve Pareto efficiency, with certain configurations preserving 80.75% accuracy at 20% reduced latency.

## Method Summary
The proposed method extends LayoutLMv3Base with intermediate exit classifiers (gates or ramps) at configurable layers, enabling adaptive inference based on instance difficulty. The architecture integrates visual layout and textual content through multimodal fusion, with exits triggered when confidence thresholds are met. Training employs multi-exit loss strategies including subgraph weighting (inverse parameter proportion), entropy regularization (prioritizing lower uncertainty exits), and their combination. Calibration via temperature scaling optimizes exit confidence scores using validation data. Inference employs global, multi-exit, or heuristic thresholding policies to determine early termination points, with the heuristic approach offering improved adaptability without requiring per-exit calibration.

## Key Results
- Calibrated EE design achieves over 20% latency reduction while fully retaining baseline accuracy
- Pareto-optimal configurations preserve 80.75% accuracy with 20% reduced latency
- Calibration and heuristic thresholding improve adaptive inference performance across scenarios
- Weighted-entropy regularization with gates shows promising trade-offs between accuracy and efficiency

## Why This Works (Mechanism)

### Mechanism 1
Multimodal early exit design reduces latency by terminating inference early based on instance difficulty. Intermediate classifiers (gates or ramps) are inserted at various layers of the multimodal network. Each exit branch predicts the output using a confidence score (maximum softmax probability). If the confidence exceeds a learned or heuristic threshold, the model exits early without processing deeper layers, thereby saving computation for easier samples. This works because document samples vary in classification difficulty, and simpler samples can be correctly classified with fewer network layers.

### Mechanism 2
Calibration of exit branch confidence scores improves the reliability of early exits. Temperature scaling is applied to logits of each exit branch using a validation set, minimizing cross-entropy to find optimal temperature T. This smooths the probability distribution, aligning confidence scores more closely with true accuracy, thus preventing premature or delayed exits. This works because raw logits from intermediate classifiers are miscalibrated, causing poor threshold selection.

### Mechanism 3
Training strategies that balance exit classifier importance with final classifier performance improve Pareto efficiency. Three training strategies are explored: (1) Subgraph weighting, where each exit loss is weighted by the inverse proportion of parameters it uses; (2) Exit entropy regularization, where exits with lower uncertainty (entropy) receive higher weight; (3) Weighted-entropy regularization, combining both approaches. These strategies ensure that early exits contribute meaningfully without degrading final classifier performance. This works because not all exit branches are equally informative; early exits with higher certainty should be prioritized during training.

## Foundational Learning

- **Multimodal fusion in document understanding**: Why needed here - The model must integrate visual layout and textual content for classification; understanding this fusion is key to placing exits optimally. Quick check question: In LayoutLMv3, at what stage are visual and textual modalities fused, and why is this a logical exit point?

- **Early exiting and confidence-based inference**: Why needed here - Early exits rely on confidence thresholds to decide when to terminate; understanding confidence scoring and thresholding is essential for tuning the system. Quick check question: How does maximum softmax probability (MSP) differ from entropy-based criteria for early exit decisions?

- **Pareto efficiency in model design**: Why needed here - The goal is to balance accuracy and efficiency, not just maximize one; understanding Pareto frontiers helps in evaluating model configurations. Quick check question: What does it mean for a model configuration to be Pareto-optimal in the context of accuracy vs. latency?

## Architecture Onboarding

- **Component map**: Input: Document image + OCR-extracted text + 2D bounding boxes → Backbone: LayoutLMv3Base (text and vision encoders) → Fusion: Multimodal encoder layers → Exits: Intermediate classifiers (gates or ramps) at configurable layers → Calibration: Temperature scaling per exit branch → Thresholding: Global, multi-exit, or heuristic policies → Output: Predicted class label

- **Critical path**: Image → OCR → Text + Layout → Multimodal Encoder → (Exit or Continue) → Final Classifier

- **Design tradeoffs**: Exit placement: More exits allow finer-grained adaptation but increase memory and complexity. Exit type: Gates (binary decision) vs. Ramps (multi-class prediction) affect training stability and inference flexibility. Thresholding: Global thresholds are simple but suboptimal; multi-exit or heuristic thresholds improve adaptation but require tuning or calibration.

- **Failure signatures**: Accuracy drop without latency gain: Exits too aggressive or poorly calibrated. No latency improvement: Exits rarely triggered; thresholds too high or model too deep. Training instability: Imbalance between exit and final classifier losses.

- **First 3 experiments**: 1) Implement baseline LayoutLMv3 on RVL-CDIP subset without exits; verify 80.75% accuracy. 2) Add single ramp exit after concatenation layer; apply temperature scaling; compare calibrated vs. uncalibrated accuracy/latency. 3) Add multiple exits with weighted subgraph training; test global vs. heuristic thresholding; measure Pareto trade-off.

## Open Questions the Paper Calls Out

How does the proposed early-exit architecture scale with larger training data and more complex document categories? The authors mention that experiments were conducted on a smaller subset of the RVL-CDIP dataset and acknowledge that it would be interesting to see if the results scale with larger training data or larger architectures. Why unresolved: The

## Limitations

- Generalizability uncertainty beyond the narrow RVL-CDIP subset with only 800 training samples across 16 classes
- Reliance on easyOCR for text extraction introduces variability that directly impacts multimodal fusion effectiveness
- Lack of comparison with alternative early-exit strategies or multimodal backbones makes it difficult to assess architecture-specific contributions

## Confidence

- **High confidence**: The mechanism of early exiting reducing latency through conditional termination is well-established and supported by the empirical results showing over 20% latency reduction.
- **Medium confidence**: The calibration approach using temperature scaling improves threshold reliability, but its effectiveness depends on validation set representativeness and may not generalize to out-of-distribution samples.
- **Low confidence**: The training strategies (subgraph weighting, entropy regularization) show promise in balancing exit and final classifier performance, but the results are sensitive to hyperparameter tuning (e.g., γ), and the Weighted-entropyreg - Ramp configuration underperforms, suggesting instability.

## Next Checks

1. **Generalizability test**: Evaluate the calibrated early-exit model on a larger, more diverse document dataset (e.g., FUNSD or DocVQA) to assess robustness to domain shifts and OCR noise.

2. **Ablation study**: Systematically remove or replace components (e.g., LayoutLMv3 with ViT, easyOCR with commercial OCR) to isolate the contribution of each design choice to accuracy and latency.

3. **Dynamic thresholding analysis**: Compare heuristic thresholding with learned threshold policies (e.g., reinforcement learning) to determine if the proposed approach is optimal or a reasonable heuristic.