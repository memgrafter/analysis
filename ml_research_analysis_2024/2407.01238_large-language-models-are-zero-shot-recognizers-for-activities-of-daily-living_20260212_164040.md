---
ver: rpa2
title: Large Language Models are Zero-Shot Recognizers for Activities of Daily Living
arxiv_id: '2407.01238'
source_url: https://arxiv.org/abs/2407.01238
tags:
- adl-llm
- home
- activity
- data
- activities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes ADL-LLM, a novel zero-shot method for recognizing
  Activities of Daily Living (ADLs) in smart home environments using Large Language
  Models (LLMs). ADL-LLM converts raw sensor data into natural language descriptions
  of events, which are then processed by an LLM to identify the most likely ADL.
---

# Large Language Models are Zero-Shot Recognizers for Activities of Daily Living

## Quick Facts
- arXiv ID: 2407.01238
- Source URL: https://arxiv.org/abs/2407.01238
- Reference count: 40
- Zero-shot ADL-LLM achieves F1 scores comparable to DeepConvLSTM supervised baseline

## Executive Summary
This paper introduces ADL-LLM, a novel method for recognizing Activities of Daily Living (ADLs) in smart home environments using Large Language Models (LLMs) in zero-shot and few-shot settings. The approach converts raw sensor data into natural language descriptions, which are then processed by an LLM to identify activities without requiring extensive labeled training data. The authors evaluate ADL-LLM on two public datasets and demonstrate that it achieves recognition rates comparable to or better than supervised deep learning approaches, particularly in data scarcity scenarios.

## Method Summary
ADL-LLM transforms sensor data windows into natural language descriptions through a Window2Text module, then prompts an LLM (initially GPT-3.5-turbo-0125) to classify activities. The system operates in zero-shot mode using only natural language descriptions, or in few-shot mode by retrieving semantically similar examples from a labeled pool. The approach leverages the common-sense knowledge encoded in LLMs to recognize ADLs without extensive labeled training data, making it scalable and adaptable to new environments.

## Key Results
- Zero-shot ADL-LLM reaches F1 score close to DeepConvLSTM, the best supervised baseline
- Few-shot ADL-LLM with 5% labeled data outperforms supervised baselines in data scarcity scenarios
- The method demonstrates strong performance on MARBLE and UCI ADL datasets

## Why This Works (Mechanism)

### Mechanism 1
LLMs encode common-sense knowledge about human activities implicitly from pre-training. The model maps sensor data windows transformed into natural language sentences into a latent space where activities are clustered by semantic similarity. Core assumption: LLM pretraining corpora contain sufficient examples of human activity descriptions tied to common household sensor contexts.

### Mechanism 2
Few-shot prompting via semantic similarity retrieval improves recognition accuracy under data scarcity. Textual representations of windows are embedded; top-k semantically similar examples from a labeled pool are retrieved and appended to the prompt to guide the LLM. Core assumption: The embedding space preserves semantic similarity between sensor patterns and their natural language descriptions.

### Mechanism 3
Relative temporal relationships in prompts are more effective than absolute timestamps for LLM reasoning. Window2Text converts sensor states into sentences using "after N seconds" rather than exact timestamps to match LLM strengths. Core assumption: LLMs struggle with numerical reasoning and prefer qualitative temporal cues.

## Foundational Learning

- Concept: Fixed-time window segmentation of sensor streams
  - Why needed here: Provides consistent input length for LLM prompts and aligns with traditional HAR preprocessing
  - Quick check question: What happens if the window size is too small to capture the full activity?

- Concept: Embedding similarity for semantic retrieval
  - Why needed here: Enables selection of most relevant few-shot examples without manual labeling per window
  - Quick check question: How does cosine similarity behave when two activities share many sensor states?

- Concept: Chain-of-Thought prompting
  - Why needed here: Improves LLM output interpretability and potentially accuracy by forcing intermediate reasoning steps
  - Quick check question: What changes in the LLM output if the "Reason step by step" instruction is removed?

## Architecture Onboarding

- Component map: Sensor State Generation → Segmentation → Window2Text → (Semantic-Based Example Selection) → System Prompt + User Prompt → LLM → Activity Label Extraction
- Critical path: Raw sensor events → sensor states → window segmentation → textual description → prompt construction → LLM inference → label extraction
- Design tradeoffs: Zero-shot mode avoids labeled data but may underperform on rare activities; few-shot mode improves accuracy but requires maintaining a pool of examples
- Failure signatures: Low F1 score on activities with sparse sensor events; inconsistent prompt formats causing parsing failures; high latency in cloud LLM calls
- First 3 experiments:
  1. Run zero-shot ADL-LLM on a small subset of MARBLE to verify end-to-end pipeline and measure inference time
  2. Compare zero-shot results with and without Chain-of-Thought to quantify impact on accuracy and interpretability
  3. Test few-shot mode with 5% labeled data to confirm retrieval-based example selection improves F1 score over zero-shot baseline

## Open Questions the Paper Calls Out

### Open Question 1
How would dynamic segmentation strategies based on change-point detection improve ADL recognition accuracy compared to fixed-size windows? The paper discusses dynamic segmentation as a future direction, noting that fixed-size segments may not be optimal for LLMs since they often capture transitions between activities rather than meaningful activity segments.

### Open Question 2
What is the impact of sensor noise and missing data on ADL-LLM's recognition accuracy, and how can prompting strategies be designed to mitigate these issues? The paper discusses robustness to noisy sensor data as a future work direction, noting that both ADL-LLM and classic data-driven solutions would struggle with significant noise or missing information.

### Open Question 3
How do smaller, open-source LLMs compare to proprietary models like GPT-3.5/4 in terms of ADL recognition accuracy, cost-effectiveness, and privacy considerations? The paper presents preliminary experiments with Llama-2 showing significantly lower accuracy than GPT models, and discusses the trade-offs between performance, cost, and privacy for different LLM options.

## Limitations

- Evaluation relies heavily on comparison with supervised baselines from prior work without ablation studies
- Datasets used may not represent full diversity of real-world smart home deployments
- Method's performance on rare activities remains unclear as evaluation metrics don't disaggregate by activity frequency

## Confidence

- High Confidence: Zero-shot ADL-LLM achieves F1 scores comparable to DeepConvLSTM supervised baseline
- Medium Confidence: Few-shot ADL-LLM outperforms supervised baselines in data scarcity scenarios
- Medium Confidence: LLMs encode sufficient common-sense knowledge for ADL recognition

## Next Checks

1. Component Ablation Study: Evaluate zero-shot ADL-LLM performance with systematic removal of key components to quantify their individual contributions

2. Cross-Dataset Generalization Test: Apply the trained ADL-LLM model to a third smart home dataset with different sensor types to assess true zero-shot generalization

3. Rare Activity Performance Analysis: Disaggregate F1 scores by activity frequency to identify whether zero-shot performance degrades significantly on infrequent activities