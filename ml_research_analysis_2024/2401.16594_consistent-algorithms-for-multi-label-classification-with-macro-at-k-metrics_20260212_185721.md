---
ver: rpa2
title: Consistent algorithms for multi-label classification with macro-at-$k$ metrics
arxiv_id: '2401.16594'
source_url: https://arxiv.org/abs/2401.16594
tags:
- confusion
- classifier
- top-k
- labels
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies multi-label classification with a constraint
  that exactly k labels are predicted per instance (budgeted-at-k predictions), focusing
  on macro-averaged metrics. The main theoretical result is that the optimal classifier
  can be expressed as selecting the top k labels according to an affine function of
  label probabilities, even for non-linear metrics.
---

# Consistent algorithms for multi-label classification with macro-at-$k$ metrics

## Quick Facts
- arXiv ID: 2401.16594
- Source URL: https://arxiv.org/abs/2401.16594
- Authors: Erik Schultheis; Wojciech Kotłowski; Marek Wydmuch; Rohit Babbar; Strom Borman; Krzysztof Dembczyński
- Reference count: 40
- Key outcome: Proposes Frank-Wolfe algorithm for consistent optimization of macro-at-k metrics in budgeted multi-label classification

## Executive Summary
This paper addresses the challenge of multi-label classification under a strict constraint of predicting exactly k labels per instance, focusing on optimizing macro-averaged metrics. The authors establish that optimal classifiers can be expressed as selecting the top k labels according to an affine function of label probabilities, even for non-linear metrics. They propose a Frank-Wolfe algorithm that is statistically consistent and demonstrate its effectiveness on several benchmark datasets, showing competitive performance on macro-at-k metrics while acknowledging the trade-off with instance-wise metrics.

## Method Summary
The method involves training label probability estimators on training data, then applying a Frank-Wolfe optimization algorithm to refine classifiers by optimizing linearized objectives. The algorithm iteratively computes confusion tensors, calculates gradients of target metrics, and updates classifiers using top-k selection rules. The approach handles the coupling effect of at-k constraints by treating the optimization problem as finding feasible confusion matrices rather than independent binary classifiers.

## Key Results
- Optimal classifiers under macro-at-k metrics can be expressed as top-k selection based on affine functions of label probabilities
- Frank-Wolfe algorithm provides statistically consistent optimization with convergence guarantees
- Empirical results show competitive performance on macro-at-k metrics across multiple datasets
- Simple baselines often outperform on instance-wise metrics, highlighting the trade-off between different evaluation criteria

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The optimal classifier under macro-at-k metrics can be expressed as selecting the top k labels according to an affine function of label probabilities.
- Mechanism: By transforming the optimization problem from finding optimal classifiers to finding optimal confusion matrices, the authors show that any optimal classifier must maximize a linear utility function derived from the gradient of the target metric. This linear utility has the form of a weighted sum of label probabilities, leading to the top-k selection rule.
- Core assumption: The label marginal vector η(x) is absolutely continuous with respect to the Lebesgue measure on [0,1]^m, ensuring unique sorting of scores with probability one.
- Evidence anchors:
  - [abstract]: "the optimal classifier can be expressed as selecting the top k labels according to an affine function of label probabilities"
  - [section]: "Theorem 4.1... h⋆(x) = topk(a ⊙ η(x) + b)"
  - [corpus]: Weak - the corpus papers focus on different aspects of multi-label learning but don't directly address the specific optimization mechanism
- Break condition: If the label marginals have point masses or the data distribution violates absolute continuity, the sorting may not be unique and the top-k rule may not be well-defined.

### Mechanism 2
- Claim: The Frank-Wolfe algorithm provides a consistent method for optimizing macro-at-k metrics by implicitly searching over feasible confusion matrices.
- Mechanism: The algorithm alternates between computing the current confusion tensor and finding the best linear approximation to optimize, using the fact that the optimal classifier for any linear utility has a simple top-k form. This allows efficient optimization without explicitly constructing the feasible set.
- Core assumption: The target metric Ψ is concave over the feasible set CP, L-Lipschitz, and β-smooth with respect to the 1-norm.
- Evidence anchors:
  - [abstract]: "propose a statistically consistent and practical learning algorithm based on the Frank-Wolfe method"
  - [section]: "Theorem 5.1 (Consistency of Frank-Wolfe)... ∆Ψ(hFW S) ≤ O(Ex[∥η(x) −bη(x)∥1]) + ..."
  - [corpus]: Weak - the corpus papers mention multi-label learning but don't specifically discuss Frank-Wolfe consistency for macro-at-k metrics
- Break condition: If the metric is non-concave or the smoothness assumptions are violated, the convergence guarantees of Frank-Wolfe no longer hold.

### Mechanism 3
- Claim: The macro-at-k constraint couples otherwise independent binary classification tasks, making independent optimization impossible.
- Mechanism: The requirement to predict exactly k labels per instance means that the choice of labels for one instance affects the feasible choices for other labels, creating dependencies that prevent separate optimization. The paper shows through counterexamples that changing the distribution of one label can change the optimal ordering of other labels.
- Core assumption: The budget constraint creates genuine coupling between label predictions that cannot be decomposed.
- Evidence anchors:
  - [abstract]: "the at-k constraint couples the otherwise independent binary classification tasks"
  - [section]: "The budget of k requires the prediction algorithm to choose the labels 'wisely'... cannot be optimized independently"
  - [corpus]: Moderate - some corpus papers discuss multi-label learning but don't specifically address the coupling effect of at-k constraints
- Break condition: If the budget constraint is relaxed or removed, the problems may become decomposable again.

## Foundational Learning

- Concept: Convex optimization and first-order optimality conditions
  - Why needed here: The proof that optimal classifiers maximize linear utilities relies on convex analysis and first-order conditions
  - Quick check question: Can you explain why the first-order optimality condition implies that the optimal point maximizes a linear approximation?

- Concept: VC-dimension and uniform convergence bounds
  - Why needed here: The consistency proof requires bounding the complexity of the hypothesis class of top-k classifiers to establish uniform convergence
  - Quick check question: What is the VC-dimension of the class of top-k classifiers and why does it matter for generalization bounds?

- Concept: Frank-Wolfe algorithm and its convergence properties
  - Why needed here: The proposed learning algorithm is based on Frank-Wolfe, so understanding its convergence guarantees is essential
  - Quick check question: Under what conditions does Frank-Wolfe converge to the optimal solution and at what rate?

## Architecture Onboarding

- Component map:
  - Label probability estimator (η) -> Frank-Wolfe optimizer -> Confusion tensor calculator -> Top-k selector

- Critical path:
  1. Train label probability estimator on training data
  2. Initialize classifier with top-k predictions based on estimated probabilities
  3. For each Frank-Wolfe iteration:
     - Compute confusion tensor on validation data
     - Calculate gradient of target metric at current point
     - Find optimal linear utility classifier (top-k rule)
     - Perform line search to find best step size
     - Update classifier as convex combination

- Design tradeoffs:
  - Memory vs accuracy: Using sparse marginals (k' << m) reduces memory but may lose information
  - Step size selection: Fixed schedule vs line search - line search gives better empirical results but requires more computation
  - Data splitting: Different ratios for training η vs computing confusion tensors affect final performance

- Failure signatures:
  - Poor performance on macro metrics but good on instance-wise metrics: Algorithm may be stuck in local optima or step size too small
  - Very slow convergence: Step size schedule may be too conservative or initialization far from optimum
  - High variance in results: Insufficient samples for reliable confusion tensor estimation

- First 3 experiments:
  1. Verify the top-k rule: Test that the learned classifier indeed selects top k labels by predicted scores
  2. Check convergence: Plot metric improvement vs iteration count to verify algorithm is making progress
  3. Ablation study: Compare with and without Frank-Wolfe refinement to measure improvement from optimization

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees assume continuous distributions for label marginals, which may not hold in practice
- Frank-Wolfe convergence rates depend on smoothness constants that are difficult to verify empirically
- Computational complexity scales poorly with the number of labels, particularly for dense confusion tensor computation
- Consistency proof relies on realizability assumptions that may not hold for complex label correlations

## Confidence

- **High**: The existence of optimal classifiers as top-k rules (Mechanism 1)
- **Medium**: The statistical consistency of the Frank-Wolfe algorithm (Mechanism 2)
- **Medium**: The coupling effect of at-k constraints on label dependencies (Mechanism 3)

## Next Checks

1. **Empirical verification of sorting uniqueness**: Test classifier performance when label probability estimates are very close to verify robustness to near-ties
2. **Convergence rate analysis**: Measure actual vs theoretical convergence rates of Frank-Wolfe on synthetic problems with known optima
3. **Scalability study**: Evaluate memory and runtime requirements on datasets with varying label cardinality to identify practical limits