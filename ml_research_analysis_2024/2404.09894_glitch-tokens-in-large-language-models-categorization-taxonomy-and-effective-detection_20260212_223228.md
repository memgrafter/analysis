---
ver: rpa2
title: 'Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective
  Detection'
arxiv_id: '2404.09894'
source_url: https://arxiv.org/abs/2404.09894
tags:
- glitch
- tokens
- hyphen
- token
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces \"glitch tokens\" in LLMs\u2014anomalous\
  \ tokens that cause unexpected behaviors and degrade response quality. Through systematic\
  \ experiments on seven popular LLMs and three tokenizers (covering 182,517 tokens),\
  \ they identify 7,895 glitch tokens and categorize their symptoms into five types:\
  \ spelling mistakes, incapability, hallucinatory completion, question repetition,\
  \ and random characters."
---

# Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection

## Quick Facts
- arXiv ID: 2404.09894
- Source URL: https://arxiv.org/abs/2404.09894
- Reference count: 40
- The paper identifies 7,895 glitch tokens across seven LLMs and proposes GlitchHunter, achieving up to 99.44% precision and 63.20% recall

## Executive Summary
This paper introduces the concept of "glitch tokens" in large language modelsâ€”tokens that cause unexpected behaviors and degrade response quality. Through systematic experiments on seven popular LLMs and three tokenizers covering 182,517 tokens, the authors identify 7,895 glitch tokens and categorize their symptoms into five types: spelling mistakes, incapability, hallucinatory completion, question repetition, and random characters. Notably, random characters are most common in repetition tasks, while spelling mistakes dominate in spelling tasks. Real-world datasets show glitch tokens comprise over 2% of tokens. To address detection, the authors propose GlitchHunter, an iterative clustering technique that exploits the observation that glitch tokens cluster in embedding space. GlitchHunter achieves up to 99.44% precision and 63.20% recall, outperforming three baselines by up to 30.14% and 39.27% respectively, while reducing detection time by 80.22% and token consumption by 73.40%.

## Method Summary
The paper proposes GlitchHunter, an iterative clustering technique for detecting glitch tokens in LLMs. The method builds a Token Embedding Graph (TEG) using all tokens and their embedding vectors, then applies the Leiden algorithm for community detection. Tokens from candidate clusters are sampled and validated using an oracle (repetition task), with iterative refinement until convergence. The approach exploits the observation that glitch tokens tend to cluster in embedding space, enabling efficient detection compared to exhaustive search. The method is evaluated on seven LLMs and three tokenizers, with hyperparameters including k=50 for K-nn, resolution=75 for Leiden, and a 5% sampling rate from each cluster.

## Key Results
- Identified 7,895 glitch tokens across seven LLMs and three tokenizers
- Glitch tokens comprise over 2% of tokens in real-world datasets (Alpaca-52k, ShareGPT-52k, ShareGPT-90k)
- GlitchHunter achieves up to 99.44% precision and 63.20% recall
- Outperforms three baselines by up to 30.14% in precision and 39.27% in recall
- Reduces detection time by 80.22% and token consumption by 73.40%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Glitch tokens cluster in embedding space, enabling detection via graph clustering
- Mechanism: Tokens with similar embedding vectors are likely to share anomalous behaviors. By constructing a Token Embedding Graph (TEG) using k-nearest neighbors, glitch tokens form dense subgraphs that can be isolated with community detection algorithms like Leiden
- Core assumption: Proximity in embedding space correlates with shared glitch properties
- Evidence anchors:
  - [abstract]: "Based on our observation that glitch tokens tend to cluster in the embedding space, we propose GlitchHunter..."
  - [section 4.1]: "Tokens, represented as multi-dimensional vectors, are mapped to a two-dimensional plane using the UMAP technique... revealing distinct distribution patterns of glitch tokens"
  - [corpus]: Weak corpus evidence; no related paper explicitly confirms embedding-space clustering, but the approach is validated empirically in this work
- Break condition: If glitch tokens do not form dense subgraphs in the embedding space, clustering will fail to isolate them

### Mechanism 2
- Claim: Iterative refinement of token sets increases precision in glitch token detection
- Mechanism: GlitchHunter starts with the full token set, clusters tokens using TEG, samples clusters suspected to contain glitch tokens, validates them with an oracle, and iteratively refines the candidate set. Each iteration reduces false positives and focuses the search
- Core assumption: Glitch tokens will consistently appear in the same clusters across iterations
- Evidence anchors:
  - [section 5.2]: "In GlitchHunter, we aim to pinpoint glitch tokens by continuously refining token clusters... Employing the Leiden algorithm... to amplify the glitch token density"
  - [section 6.3]: "Table 8 provides a comprehensive comparison of GlitchHunter's capability... consistently identifies the most number of glitch tokens, underscoring its effectiveness and accuracy"
  - [corpus]: No direct corpus support; the iterative refinement is a novel contribution not mirrored in related works
- Break condition: If the oracle misclassifies tokens or clustering changes drastically between iterations, precision will degrade

### Mechanism 3
- Claim: Token-level symptom taxonomy enables systematic detection and mitigation
- Mechanism: By classifying glitch token symptoms into five categories (spelling mistakes, incapacity, hallucinatory completion, question repetition, random characters), developers can design targeted detection and remediation strategies
- Core assumption: Each symptom type has distinct linguistic or embedding features that can be detected algorithmically
- Evidence anchors:
  - [abstract]: "We present categorizations of the identified glitch tokens and symptoms exhibited by LLMs when interacting with glitch tokens"
  - [section 4.1]: "We meticulously categorize LLM responses, establishing a taxonomy that outlines the unexpected outcomes resulting from glitch tokens"
  - [corpus]: Weak support; no related work focuses on systematic symptom categorization, but the taxonomy is empirically derived from 7,895 glitch tokens
- Break condition: If symptom categories overlap too much or fail to capture new glitch token behaviors, detection strategies will become ineffective

## Foundational Learning

- Concept: Tokenization and embedding spaces
  - Why needed here: Glitch tokens are identified through their embedding vectors; understanding how tokens map to vectors is critical for interpreting GlitchHunter's clustering logic
  - Quick check question: What is the dimensionality of embeddings for Llama 2 models, and how does it compare to GPT-2?

- Concept: Graph clustering and community detection
  - Why needed here: The TEG construction and Leiden algorithm are core to GlitchHunter; familiarity with these concepts is required to debug or extend the approach
  - Quick check question: How does the Leiden algorithm differ from Louvain in handling resolution and community quality?

- Concept: Precision-recall tradeoffs in detection
  - Why needed here: GlitchHunter achieves high precision but lower recall; understanding these metrics is essential for interpreting results and guiding improvements
  - Quick check question: If GlitchHunter's recall is 63%, how many true glitch tokens remain undetected in a model with 7,895 known glitch tokens?

## Architecture Onboarding

- Component map:
  Token Embedding Graph (TEG) -> Leiden community detection -> Oracle validation -> Iterative refinement

- Critical path:
  1. Build TEG from embedding matrix
  2. Run Leiden clustering with resolution parameter
  3. Sample and validate tokens from candidate clusters
  4. Update TEG with confirmed glitch tokens
  5. Repeat until no further refinement

- Design tradeoffs:
  - Resolution parameter: Higher values yield more clusters but risk fragmenting glitch tokens; lower values risk merging unrelated tokens
  - Sampling rate: Higher sampling increases recall but slows detection; lower sampling risks missing glitch tokens
  - Oracle design: Proxy tasks must be simple enough for fast validation but robust enough to avoid false positives

- Failure signatures:
  - No convergence after multiple iterations: Likely due to poor resolution choice or noise in embeddings
  - High false positive rate: Oracle may be too permissive or clusters may not be well-separated
  - Extremely low recall: Sampling rate may be too low or clustering may miss sparse glitch tokens

- First 3 experiments:
  1. Validate that TEG construction matches expected k-nearest neighbor relationships for a small subset of tokens
  2. Run Leiden clustering on a known set of anomaly tokens to confirm they cluster together
  3. Measure precision and recall on a small, manually labeled set of glitch tokens to calibrate oracle sensitivity

## Open Questions the Paper Calls Out
- None explicitly stated in the provided content

## Limitations
- The clustering-based detection mechanism relies on the assumption that glitch tokens form dense subgraphs in embedding space, which may not hold across all model architectures and tokenizers
- The iterative refinement process introduces complexity in determining convergence criteria, with no specification of how many iterations constitute sufficient convergence
- The oracle-based validation using proxy tasks may not capture all types of glitch behaviors, potentially missing tokens that exhibit other anomalous patterns

## Confidence
- High confidence: The categorization taxonomy and empirical results showing glitch tokens comprise over 2% of real-world datasets
- Medium confidence: The GlitchHunter algorithm's precision (up to 99.44%) and recall (up to 63.20%) metrics
- Low confidence: The claim that embedding-space clustering is the optimal detection strategy for all types of glitch tokens

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary the Leiden resolution parameter and k-nearest neighbor count to quantify their impact on precision, recall, and detection time
2. **Cross-Architecture Generalization Test**: Apply GlitchHunter to models with fundamentally different architectures and tokenization schemes to verify that the embedding-space clustering assumption holds across diverse model families
3. **Oracle Validation Robustness Check**: Design and implement additional proxy tasks beyond repetition, spelling, and length to test whether the current oracle captures all glitch token behaviors