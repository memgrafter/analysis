---
ver: rpa2
title: Learning Actionable Counterfactual Explanations in Large State Spaces
arxiv_id: '2404.17034'
source_url: https://arxiv.org/abs/2404.17034
tags:
- cfes
- actions
- agents
- agent
- generators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating actionable counterfactual
  explanations (CFEs) for negatively classified individuals in large state spaces.
  The authors propose three novel types of CFEs - high-level continuous, high-level
  discrete, and high-level ID - to provide more actionable recommendations compared
  to traditional low-level CFEs.
---

# Learning Actionable Counterfactual Explanations in Large State Spaces

## Quick Facts
- arXiv ID: 2404.17034
- Source URL: https://arxiv.org/abs/2404.17034
- Reference count: 36
- Key outcome: Data-driven CFE generators achieve 96.9% accuracy on 50-dimensional datasets using named CFEs

## Executive Summary
This paper addresses the challenge of generating actionable counterfactual explanations (CFEs) for negatively classified individuals in large state spaces. The authors propose three novel types of CFEs - high-level continuous, high-level discrete, and high-level ID - to provide more actionable recommendations compared to traditional low-level CFEs. They formulate single-agent CFE generation methods as weighted set cover problems and integer linear programs, and propose data-driven approaches to learn CFE generators from training data. The authors evaluate their methods using healthcare and synthetic datasets, comparing high-level CFEs to low-level CFEs.

## Method Summary
The paper proposes data-driven CFE generation approaches that learn optimal counterfactual explanations from historical agent-CFE pairs using neural network models. Three distinct neural network architectures are designed to handle different levels of information access: named-action generators for predicting which actions to include in CFEs, full-action generators for handling explicit action effects, and named CFE generators for direct CFE-to-agent mapping. The approach uses data augmentation techniques to improve generator accuracy by increasing the frequency of less common CFEs in the training set.

## Key Results
- Data-driven CFE generators achieve high accuracy (96.9%) on 50-dimensional datasets using named CFEs
- High-level CFEs offer key advantages over low-level CFEs in terms of actionability and interpretability
- Data augmentation techniques significantly improve CFE generator accuracy across various datasets and dimensions
- Accuracy of named CFE generators improves with increased frequency of CFEs in the training set

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed CFE generators can learn optimal counterfactual explanations without solving NP-hard optimization problems for each new agent.
- Mechanism: By training neural network models on historical agent-CFE pairs, the system learns a policy that maps agent states to optimal CFEs, effectively amortizing the optimization cost across training examples.
- Core assumption: The historical agent-CFE pairs are representative of the underlying decision-making process and contain sufficient information about action effects and costs.
- Evidence anchors:
  - [abstract] "we propose data-driven CFE generation approaches that, given instances of agents and their optimal CFEs, learn a CFE generator that quickly provides optimal CFEs for new agents"
  - [section] "we provide a deep-network learning procedure that we show experimentally is able to achieve strong performance at this task"

### Mechanism 2
- Claim: Different CFE generators can handle varying levels of information access, from complete knowledge of actions and effects to only named CFEs.
- Mechanism: Three distinct neural network architectures (named-action, full-action, and named CFE generators) are designed to handle progressively less information about the underlying decision process.
- Core assumption: Each type of CFE generator can extract the necessary patterns from its respective training data format to produce optimal recommendations.
- Evidence anchors:
  - [abstract] "we introduce three novel recourse types grounded in real-world actions: high-level continuous (hl-continuous), high-level discrete (hl-discrete), and high-level ID (hl-id) CFEs"
  - [section] "we propose various CFE generators based on the limited and specific information accessible to the decision-maker"

### Mechanism 3
- Claim: Data augmentation techniques can improve CFE generator accuracy by increasing the frequency of less common CFEs in the training set.
- Mechanism: The augmentation algorithm creates "worse-off" agents by modifying features where the CFE does more than required, ensuring the same CFE remains optimal for the new agent.
- Core assumption: The augmentation process preserves the validity of the CFE for the new agent state while increasing the representation of less frequent CFEs.
- Evidence anchors:
  - [section] "we employ two kinds of data augmentation using Algorithm 1... The principle we follow for Algorithm 1 is to make the agent worse off enough, such that the current CFE is still the best CFE for the worse-off agent"
  - [section] "AG2 improves the accuracy of the CFE generators as shown in Table 3 (bottom)"

## Foundational Learning

- Concept: Weighted set cover problem formulation
  - Why needed here: The optimal CFE corresponds to solving a weighted set cover problem, which is NP-hard and computationally expensive for each new agent
  - Quick check question: Given actions A = {[0,1,1], [1,0,1], [1,1,0]} with costs [2,3,4] and target t = [1,1,1], what is the optimal CFE?

- Concept: Neural network architecture for multi-label classification
  - Why needed here: The named-action CFE generator uses a neural network to predict which actions should be included in the optimal CFE
  - Quick check question: How would you modify a standard binary cross-entropy loss to handle the sparsity of CFEs where most actions are not included?

- Concept: Hamming distance for nearest neighbor search
  - Why needed here: The named CFE generator uses Hamming distance to find similar agents in the training set when generating CFEs
  - Quick check question: Given two binary vectors [1,0,1,0] and [1,1,0,0], what is their Hamming distance?

## Architecture Onboarding

- Component map: Data preprocessing -> Three CFE generator types (Named-action, Full-action, Named) -> Training pipeline -> Evaluation
- Critical path: 1. Load agent-CFE training data 2. Preprocess data based on CFE type 3. Train appropriate neural network architecture 4. Generate CFEs for test agents 5. Evaluate accuracy using zero-one loss
- Design tradeoffs: Named CFE generators offer highest accuracy but require named CFEs in training data; Named-action generators handle more limited information but may be less accurate; Full-action generators require explicit action effects but can generate more detailed recommendations
- Failure signatures: Low accuracy on test set indicates poor generalization or insufficient training data; High variance across runs suggests sensitivity to random initialization or data splits; Accuracy decreases with data dimension indicates scaling issues
- First 3 experiments: 1. Train and evaluate named CFE generator on 20-dimensional dataset with all training data 2. Compare named-action vs. full-action CFE generator accuracy on same dataset 3. Test data augmentation impact on 50-dimensional dataset accuracy

## Open Questions the Paper Calls Out

- How can the accuracy of named-action and full-action CFE generators be improved beyond the current results?
- How does the proposed approach generalize to settings where actions have stochastic effects on agent states?
- What are the ethical implications of using data-driven CFE generators, and how can potential biases in the training data be mitigated?

## Limitations
- The empirical evaluation relies on synthetic datasets where optimal CFEs are computed via exact set cover solvers, raising questions about real-world applicability
- The approach demonstrates effectiveness in up to 50 dimensions but does not address scalability challenges in much higher-dimensional spaces
- Named CFE generators achieve high accuracy but require access to named CFEs in training data, which may not always be available in practice

## Confidence
- High confidence: The core learning framework and neural network architectures are well-specified and theoretically sound
- Medium confidence: The data augmentation approach shows promising results but requires more extensive validation across diverse real-world datasets
- Medium confidence: The comparison between high-level and low-level CFEs is methodologically sound but limited by the synthetic nature of the evaluation datasets

## Next Checks
1. Apply the CFE generators to real-world datasets where optimal CFEs cannot be computed exactly, measuring how well the learned generators perform relative to approximate solutions
2. Test the scalability of the approach to much higher dimensional spaces (100+ dimensions) to identify potential computational bottlenecks
3. Conduct ablation studies to isolate the contribution of data augmentation versus the base learning architecture to accuracy improvements