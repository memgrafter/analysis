---
ver: rpa2
title: 'LLMs4Life: Large Language Models for Ontology Learning in Life Sciences'
arxiv_id: '2412.02035'
source_url: https://arxiv.org/abs/2412.02035
tags:
- subclass
- external
- ontology
- disjoint
- functional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of generating complex, domain-specific
  ontologies using large language models (LLMs) in specialized fields like life sciences,
  where existing models often struggle with hierarchical depth, domain adaptation,
  and token limitations. To overcome these limitations, the study extends the NeOn-GPT
  pipeline with advanced prompt engineering techniques, including domain-specific
  role-play personas, few-shot examples, and iterative re-prompting, as well as ontology
  reuse strategies incorporating established resources like ENVO.
---

# LLMs4Life: Large Language Models for Ontology Learning in Life Sciences

## Quick Facts
- arXiv ID: 2412.02035
- Source URL: https://arxiv.org/abs/2412.02035
- Reference count: 40
- Primary result: Extends NeOn-GPT pipeline with advanced prompt engineering and ontology reuse to generate complex, domain-specific ontologies in life sciences, achieving high concept similarity scores (0.85-0.97) with gold-standard ontologies.

## Executive Summary
This work addresses the challenge of generating complex, domain-specific ontologies using large language models (LLMs) in specialized fields like life sciences, where existing models often struggle with hierarchical depth, domain adaptation, and token limitations. To overcome these limitations, the study extends the NeOn-GPT pipeline with advanced prompt engineering techniques, including domain-specific role-play personas, few-shot examples, and iterative re-prompting, as well as ontology reuse strategies incorporating established resources like ENVO. The approach is evaluated using the AquaDiva ontology, demonstrating improved structural depth, logical consistency, and alignment with domain-specific requirements, achieving high concept similarity scores (0.85-0.97) with gold-standard ontologies. The results highlight the viability of LLMs for generating comprehensive ontologies in complex, specialized domains.

## Method Summary
The method extends the NeOn-GPT pipeline by integrating advanced prompt engineering techniques and ontology reuse strategies. Domain-specific role-play personas are employed to guide the LLM toward more contextually relevant outputs, while few-shot examples and iterative re-prompting refine the ontology's structural depth and logical consistency. Ontology reuse incorporates relevant existing resources, such as ENVO, to enhance the quality and depth of the generated ontologies. The approach is evaluated using the AquaDiva ontology as a gold standard, with metrics including structural depth, logical consistency, and concept similarity.

## Key Results
- The extended NeOn-GPT pipeline generates ontologies with improved structural depth and logical consistency compared to baseline approaches.
- High concept similarity scores (0.85-0.97) are achieved when comparing generated ontologies to the gold-standard AquaDiva ontology.
- Ontology reuse via ENVO examples significantly enhances hierarchical depth and term accuracy in the generated ontologies.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific role-play personas improve LLM-generated ontology depth in specialized domains.
- Mechanism: The persona acts as a cognitive scaffold, injecting domain expertise into the prompt context, which guides the LLM to generate more nuanced and contextually accurate ontology structures.
- Core assumption: LLMs lack sufficient domain-specific training data, so persona-driven context injection compensates by simulating expert-level knowledge.
- Evidence anchors:
  - [abstract] "we refine the role-play persona used in the prompts, building on our previous work [13] that shows that more contextually enriched personas lead to more contextually relevant outputs from LLMs."
  - [section] "We refined the role-play persona to represent an expert aquatic ecologist, leveraging domain knowledge to guide the model more effectively."
  - [corpus] Weak: No direct corpus comparison of persona vs non-persona performance in ontology learning.
- Break condition: If the persona description is too generic or misaligned with the target domain, the scaffolding effect collapses and outputs revert to shallow, domain-agnostic structures.

### Mechanism 2
- Claim: Iterative re-prompting with corrective feedback improves ontology structural depth and logical consistency.
- Mechanism: Re-prompting applies targeted refinement cycles, each iteration guided by prior output evaluation, gradually closing gaps in subclass counts, property density, and hierarchy complexity.
- Core assumption: LLMs can self-correct when explicitly instructed to refine outputs toward predefined structural metrics.
- Evidence anchors:
  - [abstract] "We employ re-prompting strategies that iteratively refine the LLM’s output, enhancing the depth and hierarchy of the generated ontology."
  - [section] "We used this approach to improve the initial output from the LLM. This iterative process involved prompting the LLM again to refine and extend the ontology, specifically emphasizing increasing the subclass count and creating a more layered hierarchy."
  - [corpus] Weak: No quantitative before/after comparison of re-prompting cycles across multiple domains.
- Break condition: If the model fails to converge within reasonable iteration limits or the refinement instructions become ambiguous, outputs plateau or degrade.

### Mechanism 3
- Claim: Ontology reuse via structured examples from external ontologies (e.g., ENVO) increases hierarchical depth and term accuracy.
- Mechanism: The LLM maps the hierarchical structure of the example ontology onto the target domain, leveraging the example’s multi-level subclass organization to inform its own generation process.
- Core assumption: The LLM can generalize structural patterns from an example ontology and apply them to a semantically related but distinct domain.
- Evidence anchors:
  - [abstract] "we introduce ontology reuse, incorporating relevant existing ontological resources to evaluate reuse enhances the quality, depth, and consistency of the generated ontologies."
  - [section] "We enhanced the reuse of existing ontological resources. Instead of using broader, generic examples, we incorporated specific components manually extracted from ENVO that closely align with the Carbon and Nitrogen domain."
  - [corpus] Moderate: ENVO is explicitly cited and its reuse described, but no ablation study comparing reuse vs no-reuse outputs.
- Break condition: If the reused ontology’s structural conventions conflict with the target domain’s semantics, the model may generate incoherent or overly generic hierarchies.

## Foundational Learning

- Concept: Token limitation constraints in LLMs
  - Why needed here: The pipeline must manage token limits to avoid truncation and preserve context for deep ontology generation.
  - Quick check question: What is the practical effect of exceeding an LLM’s token limit during ontology generation?
- Concept: Prompt engineering with few-shot examples
  - Why needed here: Few-shot examples guide the LLM’s output format and structural expectations in specialized domains.
  - Quick check question: How does increasing the number of few-shot examples affect the model’s ability to capture domain-specific nuances?
- Concept: Ontology verification using reasoners
  - Why needed here: Ensures logical consistency and detects structural pitfalls before deployment.
  - Quick check question: What types of logical inconsistencies are most common in LLM-generated ontologies?

## Architecture Onboarding

- Component map: Input Layer -> Prompt Pipeline -> External Resources -> LLM Interface -> Validation Layer
- Critical path: Domain input -> Requirements specification -> Ontology reuse (if applicable) -> Competency questions -> Entity extraction -> Conceptual model -> Implementation -> Verification -> Final output
- Design tradeoffs:
  - Token budget vs. depth: Smaller domain subsets reduce token usage but risk losing cross-domain relationships.
  - Reuse fidelity vs. domain fit: Tighter alignment to example ontology increases structural depth but may introduce irrelevant concepts.
  - Persona complexity vs. prompt clarity: Richer personas improve output quality but increase prompt length and risk confusion.
- Failure signatures:
  - Shallow hierarchies: Often caused by missing few-shot examples or insufficient domain context.
  - Inconsistent prefixes or syntax: Result of fragmented implementation prompts.
  - Missing properties: Indicates broken chaining between conceptualization and implementation phases.
- First 3 experiments:
  1. Baseline NeOn-GPT with domain keywords only (Experiment 1).
  2. Count-metric guided prompting with explicit class/property targets (Experiment 2).
  3. Ontology merging of Experiments 1 and 2 outputs (Experiment 3).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of LLM-generated ontologies compare when using domain-specific examples versus more general ontological examples from resources like ENVO?
- Basis in paper: [explicit] The paper discusses the use of ENVO examples to improve hierarchical depth and compares this approach to other experiments without such reuse.
- Why unresolved: While the paper shows improvements in specific cases, it does not provide a direct comparison of ontology quality with and without domain-specific examples.
- What evidence would resolve it: A controlled experiment comparing ontology quality metrics (e.g., precision, recall, concept similarity) when using domain-specific versus general examples.

### Open Question 2
- Question: Can the ontology generation process be fully automated by integrating Retrieval-Augmented Generation (RAG) to dynamically incorporate external domain-specific resources?
- Basis in paper: [inferred] The paper mentions the potential for future work to explore RAG to reduce manual intervention in the ontology generation process.
- Why unresolved: The paper does not implement or test RAG, so its effectiveness in automating ontology generation remains unexplored.
- What evidence would resolve it: Implementing and evaluating a RAG-based approach to ontology generation, measuring improvements in efficiency and quality.

### Open Question 3
- Question: How does the structural depth and complexity of the generated ontologies scale when generating the complete AquaDiva ontology by integrating all domain categories?
- Basis in paper: [explicit] The paper discusses the generation of ontologies for specific categories (e.g., Habitat, Role, Carbon & Nitrogen Cycling) and suggests future work to evaluate the complete AquaDiva ontology.
- Why unresolved: The paper does not present results for the complete AquaDiva ontology, so the scalability and overall quality remain unknown.
- What evidence would resolve it: Generating and evaluating the complete AquaDiva ontology, analyzing structural depth, class hierarchy, and logical consistency.

## Limitations
- The evaluation relies heavily on the AquaDiva ontology as a gold standard, without detailed comparison of structural or semantic alignment.
- The iterative re-prompting strategy lacks quantitative benchmarks showing convergence rates or iteration efficiency.
- The reliance on ENVO for reuse introduces potential bias, as its structural conventions may not transfer cleanly to other life science domains.

## Confidence
- **High**: The use of domain-specific role-play personas and iterative re-prompting demonstrably improves ontology depth and structural consistency within the AquaDiva domain.
- **Medium**: Ontology reuse via ENVO examples enhances hierarchical depth, but the transferability of this approach to other domains is uncertain without broader validation.
- **Low**: Claims about generalizability to other life science domains and the scalability of the pipeline are not yet supported by empirical evidence.

## Next Checks
1. **Cross-Domain Generalization**: Apply the extended NeOn-GPT pipeline to a different life science ontology (e.g., genomics or proteomics) and compare structural depth and consistency metrics to the AquaDiva results.

2. **Iterative Re-prompting Efficiency**: Conduct an ablation study measuring the number of re-prompting cycles required to reach target metrics, and analyze the marginal gains per iteration to identify convergence thresholds.

3. **Ontology Reuse Bias**: Generate ontologies with and without ENVO reuse in the same domain, then quantify the impact on term accuracy, structural depth, and semantic coherence to isolate the reuse effect.