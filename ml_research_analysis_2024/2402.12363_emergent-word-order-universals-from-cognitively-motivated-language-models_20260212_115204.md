---
ver: rpa2
title: Emergent Word Order Universals from Cognitively-Motivated Language Models
arxiv_id: '2402.12363'
source_url: https://arxiv.org/abs/2402.12363
tags:
- word
- order
- language
- gram
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigated whether cognitive biases influence word-order\
  \ universals by comparing language models (LMs) with and without human-like processing\
  \ constraints. Researchers trained 23 types of LMs\u2014including standard neural\
  \ networks and cognitively-motivated models\u2014on artificial languages with 64\
  \ different word-order configurations."
---

# Emergent Word Order Universals from Cognitively-Motivated Language Models

## Quick Facts
- arXiv ID: 2402.12363
- Source URL: https://arxiv.org/abs/2402.12363
- Reference count: 40
- Key finding: Cognitively-motivated LMs achieve up to 42.3% correlation with typological word order patterns vs 16.7% for standard transformers

## Executive Summary
This study investigates whether cognitive biases influence word-order universals by comparing language models with and without human-like processing constraints. Researchers trained 23 types of LMs on artificial languages with 64 different word-order configurations and found that models incorporating human-like features (syntactic biases, left-corner parsing strategies, and memory limitations) showed significantly stronger correlations with natural language word order distributions. The results demonstrate that cognitive processing constraints, rather than arbitrary statistical patterns, can explain many word-order universals.

## Method Summary
The study generated 64 artificial language corpora using probabilistic context-free grammars with different word-order configurations (ranging from LLLLLL to RRRRRR). Researchers trained 23 LM types including standard transformers, LSTMs, and SRNs, as well as cognitively-motivated variants with syntactic biases, left-corner parsing strategies, and memory limitations. Each model was trained for 10 epochs on each corpus, and perplexities were measured on held-out data. Global and local Pearson correlations were computed between natural language word-order frequencies (from WALS) and model perplexities, with statistical tests comparing performance across model types.

## Key Results
- Cognitively-motivated LMs achieved up to 42.3% local correlation with typological patterns vs 16.7% for standard transformers
- Memory-limited models and left-corner parsers consistently outperformed alternatives
- Standard transformer LMs showed significantly weaker correlations than cognitively-motivated variants
- The correlation patterns held across both global (all 64 configurations) and local analyses (excluding SOV ordering)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Left-corner parsers exhibit stronger correlations because they align with human incremental parsing behavior
- Mechanism: Left-corner parsing incrementally builds syntactic structure by processing leftmost constituents first, capturing center-embedding structures humans typically avoid
- Core assumption: Human processing involves incremental, left-to-right syntactic structure building
- Evidence anchors: [abstract] "LMs incorporating human-like features...showed significantly stronger correlations" | [section] "LC strategy...estimates more human-like cognitive loads"
- Break condition: If human processing does not involve left-to-right incremental structure building

### Mechanism 2
- Claim: Memory-limited LMs mirror human working memory constraints during sentence processing
- Mechanism: Limited context windows create bias against complex, memory-intensive word order configurations
- Core assumption: Human working memory limitations directly influence language processing preferences
- Evidence anchors: [abstract] "memory limitations" as human-like features | [section] "humans generally have limited working memory"
- Break condition: If human working memory limitations do not significantly influence word order preferences

### Mechanism 3
- Claim: Syntactic biases capture hierarchical structure, enabling better prediction of typologically frequent word orders
- Mechanism: Models predicting tokens and syntactic structures learn associations between word order configurations and underlying syntactic patterns
- Core assumption: Human processing involves simultaneous prediction of surface word order and syntactic structure
- Evidence anchors: [abstract] "syntactically-biased predictability" | [section] "jointly predict tokens and their syntactic structures"
- Break condition: If human processing does not involve simultaneous surface and structural prediction

## Foundational Learning

- Concept: Incremental language processing and surprisal theory
  - Why needed here: The study assumes humans continuously predict upcoming words during processing, measuring difficulty via predictability (perplexity)
  - Quick check question: What is the relationship between word predictability and processing difficulty according to surprisal theory?

- Concept: Word order universals and typological markedness
  - Why needed here: The study investigates how well LMs can predict the distribution of word orders across languages
  - Quick check question: What are Greenberg's implicational universals, and how do they relate to word order patterns?

- Concept: Chomsky hierarchy and formal language theory
  - Why needed here: The study uses artificial languages with context-free grammar structures
  - Quick check question: How does a probabilistic context-free grammar differ from natural language in terms of complexity and variability?

## Architecture Onboarding

- Component map: Artificial language generation -> LM training -> Perplexity calculation -> Correlation analysis -> Statistical testing
- Critical path: Artificial language generation → LM training on all 64 configurations → Perplexity calculation → Correlation analysis → Statistical testing of cognitive features
- Design tradeoffs: Artificial languages provide controlled experimental conditions but lack semantic complexity; standard LMs are computationally efficient but may miss human-like biases
- Failure signatures: Low correlations across all models indicate insufficient cognitive modeling; memory-limited models performing worse may reveal incorrect assumptions about human processing constraints
- First 3 experiments:
  1. Train standard Transformer on artificial languages and measure perplexity correlation with WALS data
  2. Implement left-corner PLM and compare correlation improvement over standard Transformer
  3. Test memory-limited SRN variant and analyze correlation changes relative to memory-unlimited counterparts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do more complex branching structures (beyond simple left/right) affect LM preferences for word order?
- Basis in paper: [inferred] The study used artificial languages with only binary branching parameters
- Why unresolved: The artificial language design only allowed for 64 configurations with binary parameters
- What evidence would resolve it: Experiments with artificial languages incorporating ternary branching or non-binary syntactic categories

### Open Question 2
- Question: Would adding semantic or pragmatic constraints to artificial languages change the relationship between LM perplexity and typological frequency?
- Basis in paper: [inferred] The study notes artificial languages lack semantic relationships between constituents
- Why unresolved: The current experimental setup deliberately stripped away semantic content to isolate word-order effects
- What evidence would resolve it: Creating artificial languages where word order affects meaning through case marking or animacy hierarchies

### Open Question 3
- Question: How would different corpus sizes or training regimes affect the observed correlations between LM perplexity and word-order universals?
- Basis in paper: [explicit] The study used 20K sentences per configuration and noted this might introduce unintended bias
- Why unresolved: The relatively small corpus size may not adequately capture long-distance dependencies
- What evidence would resolve it: Training the same models on larger corpora (100K+ sentences) to see if correlations strengthen or shift

## Limitations

- Reliance on artificial languages that lack semantic and pragmatic complexity of natural languages
- Correlation analysis does not establish causation between cognitive biases and word order preferences
- Assumes perplexity accurately reflects cognitive processing difficulty, which may not fully capture human language comprehension

## Confidence

- High confidence: Cognitively-motivated LMs outperform standard models in correlating with typological patterns
- Medium confidence: Specific mechanisms (left-corner parsing, memory limitations) contributing to improved performance
- Low confidence: Claims definitively proving cognitive biases shape word order universals

## Next Checks

1. Conduct human psycholinguistic experiments testing whether subjects show similar processing preferences to cognitively-motivated LMs for center-embedding and disharmonic word orders
2. Test the models on a diverse set of natural language corpora to verify whether artificial language results generalize to real linguistic data
3. Implement ablation studies that systematically remove each cognitive feature (parsing strategy, memory limitation, syntactic bias) to isolate their individual contributions to performance