---
ver: rpa2
title: Unsupervised Named Entity Disambiguation for Low Resource Domains
arxiv_id: '2412.10054'
source_url: https://arxiv.org/abs/2412.10054
tags:
- entity
- candidate
- entities
- disambiguation
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an unsupervised named entity disambiguation
  (NED) approach for low-resource domains that uses Group Steiner Trees (GST) to rank
  candidate entities. The method extracts a subgraph from the knowledge graph connecting
  all candidate entities, then finds minimum-cost GSTs to identify entities that are
  tightly interconnected.
---

# Unsupervised Named Entity Disambiguation for Low Resource Domains

## Quick Facts
- arXiv ID: 2412.10054
- Source URL: https://arxiv.org/abs/2412.10054
- Authors: Debarghya Datta; Soumajit Pramanik
- Reference count: 16
- Primary result: GST-based NED outperforms state-of-the-art unsupervised baselines by >40% in Precision@1 on four domain-specific datasets

## Executive Summary
This paper addresses the challenge of named entity disambiguation (NED) in low-resource domains where annotated training data is scarce. The authors propose an unsupervised approach using Group Steiner Trees (GST) to rank candidate entities from a knowledge graph. The method extracts subgraphs connecting all candidate entities and identifies densely interconnected entities that are likely to be correct (gold entities). Experiments demonstrate significant improvements over existing unsupervised baselines across multiple domain-specific datasets.

## Method Summary
The proposed GST-NED approach operates without requiring labeled training data or rich entity descriptions. It first identifies all candidate entities from a knowledge graph for each mention in a document. A subgraph is then extracted containing all these candidate entities. The algorithm finds minimum-cost Group Steiner Trees connecting candidate entities in groups, based on the intuition that correct entities (gold entities) tend to form dense, interconnected subgraphs. The ranking of candidate entities is determined by their connectivity patterns within these Steiner trees, with the GST-count ranking scheme showing the best performance.

## Key Results
- GST-NED outperforms state-of-the-art unsupervised baselines by more than 40% in average Precision@1
- GST-count ranking scheme performs best among the evaluated ranking approaches
- Strong performance across four domain-specific datasets (WWO, 1641, Artifact, Chemical)
- Effective for NED in low-resource settings without requiring annotated training data

## Why This Works (Mechanism)
The approach exploits the structural properties of knowledge graphs and the tendency of related entities to form dense interconnections. By finding Steiner trees that connect groups of candidate entities, the method identifies entities that are more likely to be contextually related and therefore correct. The unsupervised nature allows it to work without domain-specific training data, making it suitable for low-resource scenarios where such data is unavailable.

## Foundational Learning

**Knowledge Graph Structure**: Understanding how entities are interconnected in a KG is crucial for extracting meaningful subgraphs and identifying dense clusters of related entities.

**Group Steiner Tree Problem**: This NP-hard optimization problem finds minimum-cost trees connecting groups of nodes, which is central to identifying densely connected candidate entities.

**Unsupervised NED Principles**: The approach relies on the assumption that correct entities co-occur and form dense subgraphs, which differs from supervised methods that learn from labeled examples.

**Graph Subgraph Extraction**: Efficiently extracting relevant portions of large KGs is necessary to focus computation on candidate entities and their immediate connections.

## Architecture Onboarding

**Component Map**: Document Mentions -> Candidate Entity Extraction -> Knowledge Graph Subgraph Extraction -> Group Steiner Tree Computation -> Entity Ranking -> Disambiguated Entities

**Critical Path**: The core pipeline involves extracting mentions from text, finding candidate entities in the KG, extracting the relevant subgraph, computing GSTs to identify dense clusters, and ranking candidates based on their connectivity patterns.

**Design Tradeoffs**: The method trades computational complexity (solving GST problems) for the benefit of not requiring labeled training data. It assumes gold entities form dense subgraphs, which may not always hold true.

**Failure Signatures**: Poor performance may occur when: the KG has poor connectivity for domain entities, entities require cross-document context, or gold entities don't form dense subgraphs in the induced graph.

**First Experiments**:
1. Test GST-NED on additional low-resource domains (biomedical, legal, technical) to evaluate generalizability
2. Evaluate scalability on larger KGs (e.g., Wikidata) and documents with 50+ mentions
3. Compare against supervised NED models fine-tuned on small amounts of in-domain labeled data

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends on KG quality and coverage - entities not in the KB cannot be disambiguated
- Requires computing Steiner trees over potentially large subgraphs, raising scalability concerns
- Assumes gold entities form dense subgraphs, which may not hold for all domains or entity types
- Cannot leverage domain-specific patterns that supervised approaches could learn from labeled data

## Confidence
- **Core technical approach**: High confidence given strong empirical results across multiple datasets
- **Generalizability**: Medium confidence due to limited testing on only four specific datasets
- **Scalability**: Medium confidence as extensive testing on larger KGs is not reported
- **Cross-domain performance**: Low confidence as performance on entities requiring cross-document context is untested

## Next Checks
1. Test the GST-NED approach on additional low-resource domains (e.g., biomedical, legal, or technical domains) to evaluate generalizability beyond the four tested datasets.

2. Evaluate scalability by testing on larger knowledge graphs (e.g., Wikidata) and documents with 50+ mentions to assess computational efficiency and ranking performance at scale.

3. Compare against recent supervised NED models fine-tuned on small amounts of in-domain labeled data to quantify the trade-off between unsupervised and semi-supervised approaches in low-resource settings.