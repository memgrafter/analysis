---
ver: rpa2
title: Non-Exchangeable Conformal Language Generation with Nearest Neighbors
arxiv_id: '2402.00707'
source_url: https://arxiv.org/abs/2402.00707
tags:
- prediction
- coverage
- conformal
- sampling
- sets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces non-exchangeable conformal nucleus sampling,
  a novel method that applies conformal prediction to language generation using nearest
  neighbor retrieval. The method dynamically calibrates prediction sets during inference
  by retrieving similar subsequences from a datastore and using their non-conformity
  scores to compute thresholds, thus maintaining statistical coverage guarantees even
  under distributional shift.
---

# Non-Exchangeable Conformal Language Generation with Nearest Neighbors

## Quick Facts
- arXiv ID: 2402.00707
- Source URL: https://arxiv.org/abs/2402.00707
- Reference count: 40
- Primary result: Achieves coverage close to desired level while producing tighter prediction sets compared to baselines under distributional shift

## Executive Summary
This paper introduces non-exchangeable conformal nucleus sampling, a method that applies conformal prediction to language generation using nearest neighbor retrieval. The approach dynamically calibrates prediction sets during inference by retrieving similar subsequences from a datastore and using their non-conformity scores to compute thresholds. Experiments on machine translation and language modeling show the method maintains statistical coverage guarantees even under distributional shift while achieving tighter prediction sets than baselines.

## Method Summary
The method uses decoder hidden states to query a FAISS datastore containing K nearest neighbors from held-out examples. Each neighbor contributes a weighted non-conformity score based on RBF kernel distance. The weighted quantile of these scores defines the prediction set threshold. Adaptive prediction sets use cumulative probability mass to cover the true class, making hard examples have wider sets. The approach bridges the gap between conformal prediction's i.i.d. assumptions and language generation's sequential dependencies.

## Key Results
- Maintains coverage close to desired 0.90 level on both machine translation and language modeling tasks
- Achieves tighter prediction sets (smaller average width) compared to exchangeable conformal nucleus sampling
- Better coverage under input perturbations (corrupted embeddings) than baselines
- Generation quality comparable to or better than other sampling methods, though below beam search

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Nearest neighbor retrieval provides dynamic calibration sets that preserve coverage under distributional shift
- Mechanism: At each decoding step, retrieves K nearest neighbors in latent space from a datastore of held-out examples. Each neighbor contributes a non-conformity score weighted by RBF kernel based on distance. The quantile of weighted scores defines prediction set threshold, allowing adaptation on the fly
- Core assumption: Latent space embeddings meaningfully capture semantic similarity
- Break condition: If latent space doesn't capture semantic similarity, retrieved neighbors will be irrelevant and weighted quantile won't reflect true uncertainty

### Mechanism 2
- Claim: Non-exchangeable conformal prediction adjusts quantile computation to handle non-i.i.d. data via data-dependent weights
- Mechanism: Instead of fixed quantile from full calibration set, each neighbor's weight is computed as wk = exp(-||z*t - zk||^2 / τ). These weights normalize to w̃k and quantile is found using weighted empirical CDF
- Core assumption: Weighting scheme correctly captures relevance of each calibration point to test point
- Break condition: If weighting is not well-tuned (τ too high/low), method will either over-rely on distant points or ignore useful ones, breaking coverage

### Mechanism 3
- Claim: Adaptive prediction sets improve coverage by dynamically adjusting size based on input difficulty
- Mechanism: Uses cumulative probability mass needed to cover true class as non-conformity score. Hard examples get wider sets, easy examples get tighter sets
- Core assumption: Model's probability distribution reflects true uncertainty about next token
- Break condition: If model is overconfident or underconfident, cumulative probability won't reflect true uncertainty, causing under/over-coverage

## Foundational Learning

- Concept: Conformal prediction
  - Why needed here: Provides statistical coverage guarantees for prediction sets, crucial for quantifying uncertainty in generation
  - Quick check question: What is the difference between exchangeable and non-exchangeable conformal prediction?

- Concept: Nearest neighbor language modeling
  - Why needed here: Supplies dynamic set of relevant calibration examples during generation
  - Quick check question: How does FAISS improve nearest neighbor retrieval efficiency?

- Concept: Distributional shift
  - Why needed here: Explains why standard conformal prediction fails and motivates non-exchangeable methods
  - Quick check question: What are common causes of distributional shift in language generation?

## Architecture Onboarding

- Component map: Model → FAISS datastore → Retrieval step → Weight computation → Quantile computation → Prediction set creation → Sampling step
- Critical path: During generation, retrieve neighbors → compute weights → compute quantile → create prediction set → sample token
- Design tradeoffs: Larger K improves robustness but increases latency; higher τ increases neighbor influence but may oversmooth; adaptive sets improve coverage but require sorting probabilities
- Failure signatures: Trivial coverage (always full vocab), under-coverage on hard examples, slow inference due to retrieval
- First 3 experiments:
  1. Measure coverage on held-out data with varying K and τ
  2. Compare prediction set sizes and quality metrics against baselines
  3. Inject noise into embeddings and measure robustness of coverage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise coverage guarantee under distributional shift when using non-exchangeable conformal prediction with k-NN retrieval?
- Basis in paper: The paper states coverage guarantee changes to p(y* ∈ C(x*)) ≥ 1 − α − Σwiεi where εi is total variation distance between calibration and test distributions, but notes this term is hard to estimate
- Why unresolved: Paper doesn't provide empirical measurements of this coverage gap under distributional shift or methods to estimate/bound εi in practice
- What evidence would resolve it: Experimental results showing actual coverage vs. desired coverage under controlled distributional shifts with varying εi values, and proposed methods to estimate εi from data

### Open Question 2
- Question: How does performance of non-exchangeable conformal nucleus sampling compare to beam search in terms of both generation quality and uncertainty quantification?
- Basis in paper: Paper shows beam search outperforms sampling methods for MT in BLEU scores, but doesn't explore whether uncertainty quantification capabilities of conformal methods could be combined with beam search's quality advantages
- Why unresolved: Paper only compares beam search and sampling methods separately, without exploring hybrid approaches that might combine their strengths
- What evidence would resolve it: Experiments applying conformal prediction to beam search outputs or using conformal uncertainty estimates to guide beam search, comparing both quality metrics and uncertainty quantification capabilities

### Open Question 3
- Question: What is the optimal number of neighbors (K) to retrieve for non-exchangeable conformal prediction, and does this vary across different domains or tasks?
- Basis in paper: Paper shows results for K=100 neighbors but notes in Appendix A.4 that "it seems intuitive that the number of neighbors necessary to create good prediction sets would not be the same for all tokens" and leaves determining K to future work
- Why unresolved: Paper only explores limited range of K values (10-500) and doesn't provide guidance on how to select K adaptively or whether domain/task characteristics should influence this choice
- What evidence would resolve it: Systematic experiments varying K across multiple domains/tasks, analysis of how prediction set quality and coverage vary with K, and proposed methods for adaptive K selection based on input characteristics

## Limitations

- Assumes decoder hidden states meaningfully capture semantic similarity for k-NN retrieval without extensive empirical validation
- Computational overhead of k-NN retrieval at each decoding step adds latency that scales with K and datastore size
- Experiments focus on specific model-dataset combinations without exploring transfer to other architectures
- Temperature tuning via stochastic hill climbing may not generalize across different domains or model architectures

## Confidence

**High Confidence**: Core mechanism of using weighted nearest neighbors for non-exchangeable conformal prediction is well-grounded in prior work. Coverage results showing maintenance of desired confidence levels (0.90) across both machine translation and language modeling tasks are empirically validated and reproducible.

**Medium Confidence**: Claim that adaptive prediction sets improve coverage while maintaining generation quality has mixed support. While coverage is maintained, generation quality (BLEU, COMET) remains below beam search baselines, suggesting fundamental tradeoff between uncertainty quantification and generation quality that paper doesn't fully resolve.

**Low Confidence**: Assertion that method "significantly outperforms" baselines in coverage robustness under distributional shift lacks comprehensive empirical support. Experiments show improvements but don't test against full spectrum of potential distributional shifts.

## Next Checks

1. **Latent Space Relevance Validation**: Conduct ablation studies varying dimensionality and architecture of decoder embeddings to quantify how embedding quality affects neighbor relevance and, consequently, coverage accuracy. This would validate core assumption that latent space similarity corresponds to semantic relevance.

2. **Computational Overhead Benchmarking**: Measure end-to-end inference latency with varying K values (1, 5, 10, 20) and datastore sizes on different hardware configurations. Compare against theoretical complexity bounds to determine practical scalability limits.

3. **Cross-Domain Generalization Test**: Apply method to held-out domain (e.g., legal documents, scientific papers) not seen during calibration and measure coverage degradation. This would validate distributional shift robustness claims and identify failure modes when calibration data differs substantially from test data.