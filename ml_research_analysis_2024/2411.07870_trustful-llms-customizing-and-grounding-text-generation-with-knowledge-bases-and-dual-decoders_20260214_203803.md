---
ver: rpa2
title: 'Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases
  and Dual Decoders'
arxiv_id: '2411.07870'
source_url: https://arxiv.org/abs/2411.07870
tags:
- context
- knowledge
- answer
- microsoft
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of hallucination and out-of-domain
  outputs in large language models (LLMs) by proposing two methods: a post-processing
  algorithm that leverages knowledge triplets from retrieval-augmented generation
  (RAG) context to correct hallucinations, and a dual-decoder model that fuses guided
  context to improve generation. The post-processing algorithm identifies and corrects
  incorrect or incomplete statements by comparing knowledge triplets extracted from
  generated text with those from the trusted RAG context.'
---

# Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases and Dual Decoders

## Quick Facts
- arXiv ID: 2411.07870
- Source URL: https://arxiv.org/abs/2411.07870
- Authors: Xiaofeng Zhu; Jaya Krishna Mandivarapu
- Reference count: 19
- Combines dual-decoder architecture with post-processing correction to reduce hallucinations and improve grounded generation

## Executive Summary
This paper addresses the critical challenge of hallucination and out-of-domain outputs in large language models by introducing TrustfulLLM, a dual-decoder architecture that leverages knowledge bases and retrieval-augmented generation (RAG) context. The approach employs a post-processing algorithm that identifies and corrects hallucinated content by comparing knowledge triplets extracted from generated text with those from trusted RAG context. Experimental results on the M365 dataset demonstrate significant improvements across multiple evaluation metrics, including ROUGE-L, METEOR, Groundedness, GPT-Similarity, and BERTScore.

## Method Summary
The proposed approach consists of two main components: a dual-decoder TrustfulLLM model and a post-processing correction algorithm. The dual-decoder architecture shares weights between decoders for the prompt and guided context, enabling grounded generation by incorporating relevant information from knowledge bases. The post-processing algorithm extracts knowledge triplets from both the generated text and trusted RAG context using dependency parsing and lemmatization. It then identifies and corrects incorrect or incomplete statements by comparing these triplets, effectively reducing hallucinations while maintaining factual accuracy.

## Key Results
- Achieved best performance across multiple metrics: ROUGE-L, METEOR, Groundedness (5.00), GPT-Similarity (4.68), and BERTScore (0.93)
- Significantly outperformed baseline models on domain-specific M365 datasets
- Reduced eliminated entities from 18% to 6.9% through the correction algorithm

## Why This Works (Mechanism)
The dual-decoder architecture works by sharing weights between decoders for prompt and guided context, creating a synergistic relationship where the model can simultaneously attend to user instructions and relevant knowledge base information. The post-processing correction algorithm functions as a safety net, extracting knowledge triplets from both generated text and trusted RAG context, then identifying discrepancies that indicate hallucinations. By replacing incorrect or incomplete triplets with accurate ones from the trusted context, the algorithm ensures factual consistency without requiring retraining of the model.

## Foundational Learning

**Knowledge Triplets Extraction**
- Why needed: To represent factual relationships in text as structured data for comparison
- Quick check: Can accurately extract subject-predicate-object relationships from both generated and reference text

**Dual Decoder Architecture**
- Why needed: To simultaneously process prompt and guided context while sharing learned representations
- Quick check: Both decoders maintain distinct attention patterns while benefiting from shared weights

**Dependency Parsing and Lemmatization**
- Why needed: To normalize text and extract grammatical relationships for triplet extraction
- Quick check: Correctly identifies subject, predicate, and object across varied sentence structures

## Architecture Onboarding

**Component Map**
RAG Retriever -> Dual Decoder -> Knowledge Triplet Extractor -> Post-processing Correction -> Final Output

**Critical Path**
The most critical path flows from the dual decoder generation through knowledge triplet extraction to post-processing correction. The quality of generated text directly impacts the effectiveness of triplet extraction, which in turn determines the success of hallucination correction.

**Design Tradeoffs**
The dual-decoder approach trades additional computational complexity for improved grounding, while the post-processing correction adds inference time but significantly reduces hallucinations. The shared-weight design balances parameter efficiency with the need for distinct attention mechanisms for prompt and context.

**Failure Signatures**
Primary failure modes include: incorrect triplet extraction due to complex linguistic structures, over-correction leading to loss of fluency, and propagation of errors from the RAG retriever when trusted context contains inaccuracies.

**3 First Experiments to Run**
1. Test triplet extraction accuracy on sentences with nested clauses and ambiguous references
2. Evaluate the correction algorithm's impact on text fluency using human preference studies
3. Measure performance degradation when RAG context contains controlled amounts of incorrect information

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation primarily focused on M365 dataset, limiting generalizability across diverse domains
- Knowledge triplet extraction may struggle with complex linguistic structures or domain-specific terminology
- Post-processing correction assumes RAG context is always correct, potentially propagating retrieval errors

## Confidence

**High Confidence**
- Dual-decoder architecture and knowledge triplet extraction methodology are technically sound and well-explained

**Medium Confidence**
- Experimental results on M365 dataset are compelling, but external validation on diverse datasets is needed
- Claims of best performance across metrics are supported by presented data, though additional baseline comparisons would strengthen this

## Next Checks
1. Evaluate TrustfulLLM performance on multiple domain-specific datasets beyond M365 to assess generalizability and robustness
2. Conduct ablation studies to quantify individual contributions of dual-decoder architecture versus post-processing correction algorithm
3. Test knowledge triplet extraction method on datasets with varying linguistic complexity to identify potential failure modes and limitations