---
ver: rpa2
title: 'Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery'
arxiv_id: '2403.07955'
source_url: https://arxiv.org/abs/2403.07955
tags:
- rationales
- rationalization
- shortcuts
- task
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the problem of selective rationalization, where\
  \ neural networks identify a subset of input tokens that sufficiently support their\
  \ predictions. Existing methods often rely on shortcuts\u2014spurious correlations\
  \ in data\u2014to compose rationales, resulting in explanations that are not faithful\
  \ to human reasoning."
---

# Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery

## Quick Facts
- arXiv ID: 2403.07955
- Source URL: https://arxiv.org/abs/2403.07955
- Reference count: 35
- Primary result: SSR outperforms state-of-the-art baselines in both task accuracy (94.3% F1 on Movies) and rationale quality (33.2% token-level F1)

## Executive Summary
This paper tackles the problem of selective rationalization, where neural networks identify a subset of input tokens that sufficiently support their predictions. Existing methods often rely on shortcuts—spurious correlations in data—to compose rationales, resulting in explanations that are not faithful to human reasoning. To address this, the authors propose Shortcuts-fused Selective Rationalization (SSR), which explicitly discovers and exploits shortcuts to improve both prediction accuracy and rationale faithfulness. SSR introduces two strategies: one injects shortcut information into prediction to disentangle shortcuts from rationales, and another generates virtual shortcut representations to guide rationalization in low-resource settings. Additionally, two data augmentation methods replace shortcut tokens with random or semantically similar tokens to bridge the gap between labeled and unlabeled data. Experiments on five text classification datasets show that SSR outperforms state-of-the-art baselines in both task accuracy and rationale quality, while requiring fewer labeled rationales.

## Method Summary
SSR is a semi-supervised rationalization method that explicitly discovers and exploits shortcuts to improve both prediction accuracy and rationale faithfulness. The method consists of two main phases: an unsupervised phase where potential shortcuts are identified using an initial rationalization model, and a supervised phase where identified shortcuts are used to guide the rationalization process. SSR employs two strategies to mitigate shortcut reliance: (1) injecting shortcut information into prediction via uniform constraints or virtual shortcut representations, and (2) data augmentation by replacing shortcut tokens with random or semantically similar tokens. The method uses BERT as the encoder and is trained using a combination of task-specific loss and rationalization loss.

## Key Results
- SSR achieves 94.3% F1 on the Movies dataset and 33.2% token-level F1 on Movies, outperforming state-of-the-art baselines
- SSR improves rationale faithfulness by explicitly discovering and mitigating shortcuts
- SSR requires fewer labeled rationales compared to other methods, making it effective in low-resource settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SSR explicitly discovers shortcuts and uses them to disentangle shortcuts from rationales, improving both prediction accuracy and rationale faithfulness.
- Mechanism: The model first trains an unsupervised rationalization method to exploit shortcuts, then uses labeled rationales to identify shortcut tokens (tokens predicted as rationales but not in gold rationales). It then injects this shortcut information into prediction via uniform constraints or virtual shortcut representations to de-correlate shortcuts from rationales.
- Core assumption: Shortcuts are tokens that have spurious correlations with labels but are not part of human-intelligible rationales. Unsupervised rationalization inevitably includes shortcuts in predicted rationales.
- Evidence anchors:
  - [abstract]: "SSR first designs a shortcuts discovery approach to detect several potential shortcuts. Then, by introducing the identified shortcuts, we propose two strategies to mitigate the problem of utilizing shortcuts to compose rationales."
  - [section 4.2.2]: "In the supervised phase, besides the original loss Lsup, we add a 'uniform' constraint to ensure the predictor qψ identifies the shortcuts features as meaningless features..."
  - [corpus]: Weak. No corpus neighbors directly discuss shortcut discovery or injection strategies; the closest is "Boosting Explainability through Selective Rationalization in Pre-trained Language Models" which focuses on pre-trained models but not shortcut mechanisms.
- Break condition: If shortcuts cannot be reliably identified (e.g., when gold rationales are too sparse or shortcuts are subtle), the de-correlation step may fail and performance degrades.

### Mechanism 2
- Claim: Virtual shortcut representations transfer shortcut knowledge from supervised to unsupervised phases, bridging the gap when labeled rationales are limited.
- Mechanism: In the supervised phase, an external predictor captures shortcut representations from identified shortcuts. A shortcut imitator then learns to mimic these representations from the input. In the unsupervised phase, the imitator generates virtual shortcut representations that guide the predictor to ignore shortcuts.
- Core assumption: Shortcut representations can be learned and transferred across phases via shared parameters.
- Evidence anchors:
  - [section 4.2.3]: "We propose a virtual shortcuts representations strategy (SSRvirt) with transferred shortcuts knowledge from Dsup as guidance... we learn an additional shortcut imitator fa(xsup) that takes x in Dsup as the input (denoted by xsup for clarity) to align and mimic fpη (zs)..."
  - [section 5.3]: "SSRvirt performs better than SSRunif in most datasets, illustrating employing virtual shortcuts representations to rationalization may be more effective with few labeled rationales."
  - [corpus]: Weak. No direct evidence in corpus; the closest neighbor "Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization" discusses non-causal feature removal but not shortcut representation transfer.
- Break condition: If the shortcut imitator cannot accurately mimic shortcut representations, virtual guidance will be ineffective.

### Mechanism 3
- Claim: Data augmentation by replacing shortcut tokens with random or semantically similar tokens reduces shortcut reliance and improves generalization.
- Mechanism: Identified shortcut tokens in Dsup are replaced with tokens sampled from the entire dataset (random DA) or retrieved semantically similar tokens (semantic DA). This augmented data is used to train the model, reducing shortcut dependence.
- Core assumption: Replacing shortcut tokens with unrelated or semantically different tokens breaks spurious correlations while preserving task-relevant information.
- Evidence anchors:
  - [section 4.3]: "We propose two data augmentation methods by utilizing identified shortcuts in Dsup... Random Data Augmentation... Semantic Data Augmentation."
  - [section 5.3]: "SSR with semantic DA performs better than random DA, which validates that replacing shortcut tokens with semantically related tokens is more effective."
  - [corpus]: Weak. No corpus neighbor explicitly discusses shortcut-based data augmentation; closest is "Plausible Extractive Rationalization through Semi-Supervised Entailment Signal" which uses entailment signals but not shortcut replacement.
- Break condition: If augmented data introduces noise or loses task-relevant context, performance may degrade.

## Foundational Learning

- Concept: Gumbel-Softmax reparameterization for differentiable sampling of discrete tokens.
  - Why needed here: Selective rationalization requires sampling binary masks (0/1) for rationale tokens, but standard sampling is non-differentiable. Gumbel-Softmax allows gradient-based training.
  - Quick check question: What is the role of the temperature parameter τ in Gumbel-Softmax, and how does it affect the sampled masks?

- Concept: Kullback-Leibler (KL) divergence for enforcing uniform class distribution on shortcut features.
  - Why needed here: To ensure the predictor treats shortcut tokens as meaningless, SSRunif adds a KL divergence term between the predictor's output on shortcuts and a uniform distribution.
  - Quick check question: Why does minimizing KL divergence between shortcut predictions and uniform distribution help de-correlate shortcuts from rationales?

- Concept: Semantic similarity retrieval using L2 distance in embedding space.
  - Why needed here: Semantic DA replaces shortcut tokens with tokens semantically close to them, preserving task relevance while breaking spurious correlations. FAISS is used for efficient nearest neighbor search.
  - Quick check question: How does replacing a shortcut token with a semantically similar token help maintain task performance while reducing shortcut reliance?

## Architecture Onboarding

- Component map:
  - Encoder (shared): fs(·) ↔ fp(·) ↔ fssup(·) ↔ fpsup(·)
  - Selector linear layers: Wsun ↔ Wssup
  - Predictor linear layers: Wpun ↔ Wpsup
  - Shortcut generator: identifies potential shortcuts from unsupervised rationales vs. gold rationales
  - Shortcut imitator (SSRvirt only): fa(·) mimics shortcut representations
  - Data augmentation module: replaces shortcut tokens with random or semantic tokens

- Critical path:
  1. Train unsupervised rationalization (Mun) on Dsup to exploit shortcuts.
  2. Identify shortcuts using gold rationales and Mun's predicted rationales.
  3. Train SSR with identified shortcuts:
     - SSRunif: Add uniform constraint on shortcut predictions.
     - SSRvirt: Learn shortcut imitator and generate virtual shortcut representations.
  4. Apply data augmentation by replacing shortcut tokens.
  5. Evaluate on task accuracy and rationale quality.

- Design tradeoffs:
  - Shared vs. separate encoders: Sharing improves knowledge transfer but may limit specialization.
  - Random vs. semantic DA: Random is simpler but may introduce noise; semantic preserves meaning but requires retrieval.
  - Virtual shortcut representations vs. uniform constraints: Virtual representations are more effective with few labels but add complexity.

- Failure signatures:
  - Performance degrades if shortcuts are not reliably identified (e.g., sparse gold rationales).
  - Over-reliance on data augmentation may lead to overfitting or loss of task-relevant context.
  - Poor shortcut imitator learning in SSRvirt leads to ineffective virtual guidance.

- First 3 experiments:
  1. Validate shortcut discovery: Train Mun on Dsup, identify shortcuts, and check overlap with gold rationales.
  2. Test SSRunif: Implement uniform constraint and measure task accuracy and rationale faithfulness vs. Vanilla Semi-RAT.
  3. Test SSRvirt: Implement shortcut imitator and virtual representations, compare with SSRunif on datasets with limited labeled rationales.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SSR compare when using different backbone encoders, such as GPT or other transformer variants, instead of BERT?
- Basis in paper: [explicit] The paper states that SSR is model-agnostic and mentions the possibility of replacing BERT with other models like LLaMA for high performance.
- Why unresolved: The experiments in the paper are conducted using BERT as the encoder. The paper does not provide empirical results comparing SSR's performance with different backbone encoders.
- What evidence would resolve it: Conducting experiments using SSR with various backbone encoders (e.g., GPT, RoBERTa, LLaMA) and comparing their performance on the same datasets would provide insights into the impact of different encoders on SSR's effectiveness.

### Open Question 2
- Question: What is the impact of different data augmentation strategies on SSR's performance, and is there an optimal combination or ratio of random and semantic augmentation?
- Basis in paper: [explicit] The paper introduces random and semantic data augmentation methods and mentions that SSR with semantic DA performs better than random DA. However, it also notes that mixed DA does not always outperform semantic DA.
- Why unresolved: The paper does not explore different combinations or ratios of random and semantic augmentation in detail. The optimal strategy for data augmentation remains unclear.
- What evidence would resolve it: Conducting experiments with various combinations and ratios of random and semantic augmentation, and analyzing their impact on SSR's performance, would help identify the most effective augmentation strategy.

### Open Question 3
- Question: How does SSR's performance on out-of-distribution (OOD) datasets compare to other semi-supervised rationalization methods when dealing with significant distribution shifts?
- Basis in paper: [explicit] The paper demonstrates SSR's improved performance on the SST-2 dataset, which is considered an OOD dataset relative to Movies. However, the extent of distribution shift and comparison with other methods are not thoroughly explored.
- Why unresolved: The paper does not provide a comprehensive analysis of SSR's performance across datasets with varying degrees of distribution shift. The comparison with other semi-supervised methods on OOD datasets is limited.
- What evidence would resolve it: Conducting experiments with SSR and other semi-supervised rationalization methods on a range of datasets with different levels of distribution shift, and comparing their performance, would provide insights into SSR's robustness to OOD scenarios.

## Limitations

- The shortcut discovery approach relies heavily on the availability and quality of gold rationales, which may be limited in real-world applications.
- The effectiveness of virtual shortcut representations depends on the imitator's ability to accurately learn and transfer shortcut knowledge, which is not thoroughly validated.
- Data augmentation methods may introduce noise if random or semantically similar tokens disrupt task-relevant context.

## Confidence

**High Confidence:**
- SSR improves task accuracy and rationale quality compared to baselines on ERASER datasets
- Data augmentation reduces shortcut reliance and improves generalization
- Virtual shortcut representations are more effective than uniform constraints with limited labeled rationales

**Medium Confidence:**
- Shortcut discovery reliably identifies spurious correlations in text classification
- Disentangling shortcuts from rationales improves faithfulness without sacrificing accuracy
- Semantic data augmentation outperforms random augmentation in all scenarios

**Low Confidence:**
- The mechanisms generalize to non-text classification tasks
- The trade-off between rationale comprehensiveness and sufficiency is optimal
- The approach scales effectively to very large datasets or models

## Next Checks

1. **Shortcut Discovery Robustness**: Test the shortcut identification method on datasets with varying amounts of gold rationales (e.g., 10%, 25%, 50%) to determine the minimum required coverage for reliable shortcut discovery.

2. **Component Ablation Study**: Implement and evaluate each SSR component (uniform constraints, virtual representations, data augmentation) independently to quantify their individual contributions to performance gains.

3. **Cross-Domain Generalization**: Apply SSR to a non-text classification task (e.g., tabular data or multimodal classification) to assess whether the shortcut discovery and mitigation strategies transfer effectively.