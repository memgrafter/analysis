---
ver: rpa2
title: 'C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation'
arxiv_id: '2412.04947'
source_url: https://arxiv.org/abs/2412.04947
tags:
- data
- uni00000013
- uni00000011
- uni00000010
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'C2LEVA is a comprehensive bilingual benchmark for large language
  model evaluation that systematically prevents data contamination. The benchmark
  addresses two main challenges: the lack of comprehensive task coverage in existing
  contamination-free evaluations, and the risk of test data leakage through repurposing
  or unauthorized use.'
---

# C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation

## Quick Facts
- arXiv ID: 2412.04947
- Source URL: https://arxiv.org/abs/2412.04947
- Reference count: 40
- Large-scale evaluation of 15 models shows strong correlation (Spearman's 0.948) with Chatbot Arena Elo, indicating effective contamination prevention

## Executive Summary
C2LEVA is a comprehensive bilingual benchmark addressing the critical challenge of data contamination in large language model evaluation. The benchmark combines passive methods (automated test data renewal through web crawling, rule-based synthesis, and LLM-assisted generation) with active protection techniques (data watermarking and encryption) to systematically prevent both accidental and intentional contamination. With 22 tasks spanning language, knowledge, reasoning, and harms categories in both English and Chinese, C2LEVA evaluates 15 models and demonstrates that proprietary models like Claude-3.5, Gemini-1.5, and GPT-4o perform best while highlighting the need for improved data protection methods due to an average 11.59% performance loss from watermarking.

## Method Summary
C2LEVA employs a two-pronged approach to contamination prevention. Passive methods automatically renew test data by continuously crawling web data, applying contamination detection using token probability analysis (MinK%) to filter previously seen instances, and generating fresh test cases through rule-based synthesis and LLM-assisted generation. Active methods use data protection techniques like watermarking to embed stealthy signals in test data, enabling membership inference to detect unauthorized model training on test data. The benchmark includes 22 tasks with 16,115 test instances across English and Chinese, using 5-shot prompting with multiple templates per task for evaluation.

## Key Results
- Strong correlation (Spearman's 0.948) between C2LEVA rankings and Chatbot Arena Elo demonstrates effective contamination prevention
- Proprietary models (Claude-3.5, Gemini-1.5, GPT-4o) outperform open-source models across most tasks
- Data watermarking causes average 11.59% performance loss, with Chinese tasks experiencing up to 17.3% degradation
- Cross-lingual transfer capabilities remain limited, with Yi-Large excelling in Chinese knowledge tasks and DeepSeek-V2 outperforming in Chinese reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Passive prevention with automated test data renewal prevents data contamination by ensuring test data is unseen.
- Mechanism: The benchmark continuously crawls web data, applies contamination detection to filter out previously seen test cases, and uses rule-based synthesis to create new test data, ensuring the evaluation set remains uncontaminated over time.
- Core assumption: Web crawling and rule-based synthesis can generate sufficient fresh, unseen test data to replace any compromised data.
- Evidence anchors:
  - [abstract] "passive methods automatically renew test data through web crawling, rule-based synthesis, and LLM-assisted generation while filtering contaminated instances"
  - [section 3.3] "The passive solution aligns with existing work by updating benchmark data to ensure uncontaminated evaluation"
- Break condition: Web data sources become exhausted or crawling yields increasingly contaminated data due to widespread model training on web content.

### Mechanism 2
- Claim: Active prevention with data protection techniques prevents intentional data contamination by making it risky for model developers to train on test data.
- Mechanism: The benchmark applies data watermarking to embed stealthy signals in test data, making it possible to detect if models have been trained on this data, thereby deterring intentional contamination.
- Core assumption: Data watermarking can embed detectable signals without significantly degrading model performance or being easily removed by attackers.
- Evidence anchors:
  - [abstract] "active methods use data protection techniques like watermarking and encryption to prevent unauthorized access"
  - [section 3.3] "we use established data protection techniques that facilitate membership inference by embedding stealthy signals into the data"
- Break condition: Attackers develop watermark removal techniques or the watermark detection causes significant performance degradation.

### Mechanism 3
- Claim: Systematic combination of passive and active prevention methods provides comprehensive contamination protection across diverse tasks.
- Mechanism: Different tasks use different prevention strategies (crawling, rule-based, LLM-assisted) while active protection is selectively applied to high-value test data, creating layered defense against both accidental and intentional contamination.
- Core assumption: Different prevention strategies are effective for different types of tasks, and combining them provides broader coverage than any single approach.
- Evidence anchors:
  - [section 3.1] "passive prevention methods are generally applicable, active prevention strategies require customization based on the attacker type"
  - [section 3.3] "C2LEVA leverages this complementary relationship to achieve systematic prevention across a comprehensive benchmark covering various tasks"
- Break condition: One prevention layer fails completely, overwhelming the remaining defenses.

## Foundational Learning

- Concept: Contamination detection using token probability analysis
  - Why needed here: To filter out test cases that may have been seen during model training when crawling web data
  - Quick check question: What statistical method does MinK% use to estimate contamination risk in individual test instances?

- Concept: Data watermarking for membership inference
  - Why needed here: To embed detectable signals in test data that can identify if models have been trained on this data
  - Quick check question: What is the primary tradeoff when applying data watermarking to test data in terms of model performance?

- Concept: Task-specific benchmark construction
  - Why needed here: Different task types (reasoning, language, knowledge) require different data generation approaches for effective contamination prevention
  - Quick check question: Why does the fact completion task use both crawling and data augmentation while reasoning primitive tasks use only rule-based synthesis?

## Architecture Onboarding

- Component map: Data crawling → Contamination detection → Task-specific synthesis → Data augmentation → Active protection (watermarking/encryption) → Test set release
- Critical path: The end-to-end pipeline from data collection through contamination prevention to test set release
- Design tradeoffs: Comprehensive coverage vs. implementation complexity; passive renewal vs. active protection costs; detection accuracy vs. false positive rates
- Failure signatures: Performance degradation after watermarking; contamination detection failing to identify compromised test cases; insufficient fresh data from crawling
- First 3 experiments:
  1. Test contamination detection accuracy on a small sample of web-crawled data
  2. Measure performance impact of watermarking on a single task
  3. Validate that combined passive/active prevention maintains benchmark effectiveness compared to existing methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are LLM-assisted test data generation methods compared to rule-based systems for contamination prevention across different task types?
- Basis in paper: The paper mentions both LLM assistants and rule-based systems as basic methods for automating test set construction, noting that LLM assistants may generate their own training data requiring contamination detection.
- Why unresolved: The paper doesn't provide empirical comparison between these two methods' effectiveness across different task categories, only stating they are both used.
- What evidence would resolve it: A controlled study comparing contamination rates, data quality, and automation efficiency of LLM-assisted vs rule-based generation across multiple task types in C2LEVA.

### Open Question 2
- Question: What is the optimal balance between data watermarking intensity and evaluation distortion for contamination prevention?
- Basis in paper: The paper reports an average performance loss of 11.59% from watermarking and notes it deteriorates model performance, suggesting the need for improved protection methods.
- Why unresolved: The paper applies watermarking to only a small portion of data to minimize distortion but doesn't explore the trade-off between detection effectiveness and performance impact.
- What evidence would resolve it: Systematic experiments varying watermarking intensity and measuring both detection capability and performance degradation across different model sizes and task types.

### Open Question 3
- Question: How does cross-lingual transfer capability vary across different LLM architectures and training strategies?
- Basis in paper: The evaluation reveals that top models like Claude-3.5 don't maintain their English advantage in Chinese, with Yi-Large excelling in knowledge tasks and DeepSeek-V2 outperforming in reasoning tasks in Chinese.
- Why unresolved: The paper identifies this limitation but doesn't investigate which architectural or training factors contribute to cross-lingual performance differences.
- What evidence would resolve it: Comparative analysis of model architectures, training data composition, and fine-tuning strategies correlated with cross-lingual performance across the evaluated models.

## Limitations

- Computational cost and performance impact of active protection methods, particularly data watermarking causing average 11.59% performance loss
- Reliance on web crawling for passive data renewal may become increasingly difficult as web content becomes saturated with model-generated text
- Cross-lingual transfer capabilities remain limited, with top models not maintaining their English advantage in Chinese tasks

## Confidence

**High Confidence:** The core finding that C2LEVA achieves contamination-free evaluation is well-supported by the strong correlation (Spearman's 0.948) with Chatbot Arena Elo rankings and the systematic approach combining passive and active prevention methods.

**Medium Confidence:** The reported performance rankings of specific models are likely accurate, but exact performance margins may be influenced by watermarking overhead. The cross-lingual transfer capability assessment is plausible given existing literature on monolingual model bias.

**Low Confidence:** The long-term sustainability of the passive renewal approach through web crawling is uncertain, as the effectiveness depends on finding fresh, uncontaminated web data that may diminish over time.

## Next Checks

1. **Performance Impact Validation:** Conduct a controlled experiment comparing model performance on watermarked vs. non-watermarked versions of the same tasks to quantify the exact performance degradation and identify which task types are most affected.

2. **Contamination Detection Robustness:** Test the MinK% contamination detection method on a known contaminated dataset to measure false positive and false negative rates, particularly for cases where models have been trained on similar but not identical test data.

3. **Web Crawling Effectiveness Over Time:** Monitor the freshness rate of crawled data over multiple benchmark renewal cycles to empirically measure whether the pool of uncontaminated web data is diminishing as expected.