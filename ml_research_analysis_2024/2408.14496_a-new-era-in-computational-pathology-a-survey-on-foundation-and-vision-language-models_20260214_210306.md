---
ver: rpa2
title: 'A New Era in Computational Pathology: A Survey on Foundation and Vision-Language
  Models'
arxiv_id: '2408.14496'
source_url: https://arxiv.org/abs/2408.14496
tags:
- arxiv
- vision
- pathology
- image
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive overview of recent advances
  in foundation models (FMs) and vision-language models (VLMs) in computational pathology
  (CPath). FMs leverage self-supervised learning to learn rich representations that
  can be adapted to diverse downstream tasks without explicit supervision, addressing
  challenges like lack of diverse data and numerous tasks in CPath.
---

# A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models

## Quick Facts
- arXiv ID: 2408.14496
- Source URL: https://arxiv.org/abs/2408.14496
- Reference count: 40
- One-line primary result: Comprehensive survey of foundation models and vision-language models in computational pathology, highlighting their potential to revolutionize the field.

## Executive Summary
This survey provides a comprehensive overview of recent advances in foundation models (FMs) and vision-language models (VLMs) in computational pathology (CPath). FMs leverage self-supervised learning to learn rich representations that can be adapted to diverse downstream tasks without explicit supervision, addressing challenges like lack of diverse data and numerous tasks in CPath. VLMs integrate pathology reports as semantic information sources to boost model performance and generate predictions in natural language form. The survey categorizes and details various FMs and VLMs, their architectures, training schemes, and datasets used. It highlights the increasing trend of using these models in CPath and their potential to revolutionize the field by automating and expediting diagnosis and prognosis processes.

## Method Summary
The survey synthesizes information from various sources to provide a comprehensive overview of FMs and VLMs in CPath. It identifies and categorizes different types of models, their architectural components, training strategies, and datasets used. The survey also discusses the potential benefits and challenges of using these models in CPath, as well as open questions and future research directions. The information is organized into sections covering pre-training strategies, vision and language modules, vision-language alignment, and downstream tasks in CPath.

## Key Results
- FMs leverage self-supervised learning schemes to learn rich representations in a task-agnostic manner, reducing the need for large-scale annotated data in CPath.
- VLMs integrate pathology reports and other textual data as semantic information sources to improve model performance and generate predictions in natural language form.
- FMs and VLMs are trained on large and diverse datasets encompassing tissue samples from different organs, scanner types, magnification levels, stain types, and preservation methods to ensure robustness and generalizability.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Foundation models (FMs) in computational pathology (CPath) overcome the challenge of limited annotated data by leveraging self-supervised learning (SSL) schemes to learn rich representations that can be adapted to diverse downstream tasks without explicit supervision.
- **Mechanism:** FMs utilize SSL techniques like self-distillation (e.g., DINOv2), masked image modeling (e.g., MAE), and contrastive learning (e.g., MoCo) to pre-train on large-scale unlabeled histopathology images. This pre-training enables the model to learn a general vision representation space from the data itself, capturing complex tissue patterns and disease features. The learned representations can then be fine-tuned or probed with minimal labeled data for specific tasks like cancer detection or tumor classification.
- **Core assumption:** The learned representation space from unlabeled histopathology data contains sufficient information to be adapted to diverse downstream tasks with minimal additional supervision.
- **Evidence anchors:**
  - [abstract]: "FMs leverage self-supervised learning (SSL) schemes to learn a rich representation in a task-agnostic manner. Owing to self-supervised pre-training (SSPT), FMs do not require large-scale annotated data which is hard to come by in CPath."
  - [section]: "The self-distillation with no label approach uses a student-teacher network to learn a rich vision representation space... The computed loss is used in backpropagation to update the parameters of the encoder."
  - [corpus]: The corpus provides evidence of recent research focusing on SSL schemes in CPath, indicating ongoing work in this area. However, specific evidence for the effectiveness of these schemes in overcoming the challenge of limited annotated data is not explicitly provided in the corpus.
- **Break condition:** If the learned representation space does not generalize well to diverse downstream tasks or requires significant labeled data for adaptation, the mechanism breaks down.

### Mechanism 2
- **Claim:** Vision-language models (VLMs) in CPath leverage pathology reports and other textual data as rich semantic information sources to boost model performance and generate predictions in natural language form.
- **Mechanism:** VLMs integrate vision and language modalities by utilizing techniques like contrastive learning (e.g., CLIP) and generative approaches (e.g., CoCa) to align and learn a joint vision-language representation space. This allows the model to leverage the semantic information present in pathology reports, captions, and other textual data to improve its understanding of histopathology images and generate more informative outputs.
- **Core assumption:** The semantic information present in pathology reports and other textual data is complementary to the visual information in histopathology images and can be effectively integrated to improve model performance.
- **Evidence anchors:**
  - [abstract]: "VLMs allow pathology reports written in natural language to be used as a rich semantic information source to improve existing models as well as generate predictions in natural language form."
  - [section]: "The most popular vision-language SSPT approach in CPath is the CLIP approach... The computed loss is used in backpropagation to update the parameters of the encoder."
  - [corpus]: The corpus provides evidence of recent research focusing on VLMs in CPath, indicating ongoing work in this area. However, specific evidence for the effectiveness of leveraging textual data to boost model performance is not explicitly provided in the corpus.
- **Break condition:** If the semantic information in textual data is not complementary to visual information or cannot be effectively integrated, the mechanism breaks down.

### Mechanism 3
- **Claim:** FMs and VLMs in CPath are trained on large and diverse datasets that encompass tissue samples from different organs, scanner types, magnification levels, stain types, and preservation methods to ensure robustness and generalizability.
- **Mechanism:** By training on diverse datasets, FMs and VLMs can capture the representation of a wide range of tissue and disease types, as well as the variations introduced by different acquisition parameters. This ensures that the learned representations are robust to extreme variations in tissue samples and can generalize well to unseen data.
- **Core assumption:** The diversity of the training data is sufficient to capture the variations in tissue samples and acquisition parameters encountered in real-world CPath applications.
- **Evidence anchors:**
  - [abstract]: "FMs are trained using large and diverse datasets that encompass tissue samples from different organs and anatomic sites... The idea is to capture the representation of a wide range of tissue and disease types and also making sure in downstream tasks are robust."
  - [section]: "In CPath, FMs are trained using large and diverse datasets that encompass tissue samples from different organs and anatomic sites. In addition, some research [64], [65] put effort into capturing diversity in terms of scanner types, magnification levels, stain types, preservation methods, etc."
  - [corpus]: The corpus provides evidence of recent research focusing on diverse datasets in CPath, indicating ongoing work in this area. However, specific evidence for the effectiveness of training on diverse data in ensuring robustness and generalizability is not explicitly provided in the corpus.
- **Break condition:** If the diversity of the training data is insufficient to capture the variations encountered in real-world CPath applications, the mechanism breaks down.

## Foundational Learning

- **Concept: Self-supervised learning (SSL) schemes**
  - Why needed here: SSL schemes enable FMs to learn rich representations from unlabeled histopathology images, overcoming the challenge of limited annotated data in CPath.
  - Quick check question: What are some common SSL schemes used in FMs for CPath, and how do they work?

- **Concept: Vision-language pre-training**
  - Why needed here: Vision-language pre-training allows VLMs to integrate vision and language modalities, leveraging the semantic information in pathology reports and other textual data to improve model performance.
  - Quick check question: What are some common vision-language pre-training approaches used in VLMs for CPath, and how do they work?

- **Concept: Dataset diversity**
  - Why needed here: Training on diverse datasets ensures that FMs and VLMs can capture the representation of a wide range of tissue and disease types, as well as the variations introduced by different acquisition parameters, leading to robust and generalizable models.
  - Quick check question: What are some strategies for ensuring dataset diversity in CPath, and why is it important for FMs and VLMs?

## Architecture Onboarding

- **Component map:** Vision module (e.g., ViT variants, specialized encoders) -> Language module (e.g., BERT, GPT variants, caption generation modules) -> Vision-language alignment or fusion module (e.g., CLIP, custom approaches)

- **Critical path:** Pre-train vision and language modules using SSL schemes or pre-training approaches -> Vision-language pre-training to align and learn a joint representation space -> Adapt to downstream tasks through linear probing, KNN probing, or fine-tuning

- **Design tradeoffs:** Choice of SSL scheme, size and diversity of pre-training dataset, architecture of vision and language modules, approach for vision-language alignment

- **Failure signatures:** Overfitting to pre-training data, poor generalization to unseen data, difficulty in adapting to specific downstream tasks

- **First 3 experiments:**
  1. Train an FM on a diverse histopathology dataset using a self-distillation SSL scheme (e.g., DINOv2) and evaluate its performance on a downstream task like cancer detection using linear probing.
  2. Train a VLM on a dataset of histopathology images and corresponding pathology reports using a vision-language pre-training approach (e.g., CLIP) and evaluate its performance on a downstream task like report generation.
  3. Fine-tune an FM or VLM on a specific downstream task using a small amount of labeled data and compare its performance to a model trained from scratch on the same task.

## Open Questions the Paper Calls Out
No specific open questions are called out in the provided input.

## Limitations
- The paper does not provide specific evidence or quantitative measures to support the claim that dataset diversity ensures robustness and generalizability of FMs and VLMs in CPath.
- The effectiveness of leveraging pathology reports and other textual data to boost model performance is mentioned but not extensively validated.
- The paper does not address potential biases in the training data or their impact on model performance, which is a critical concern in CPath.

## Confidence
- Medium: The survey provides a good overview but lacks in-depth validation and quantitative evidence for some key mechanisms.

## Next Checks
1. Conduct experiments to quantify the impact of dataset diversity on model performance and robustness in CPath.
2. Evaluate the effectiveness of leveraging textual data by comparing the performance of VLMs with and without access to pathology reports on downstream tasks.
3. Investigate potential biases in the training data and their impact on model performance, particularly for underrepresented tissue types or disease subtypes.