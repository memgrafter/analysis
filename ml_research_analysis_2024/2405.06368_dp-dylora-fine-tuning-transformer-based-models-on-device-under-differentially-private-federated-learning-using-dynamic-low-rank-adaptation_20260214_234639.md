---
ver: rpa2
title: 'DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially
  Private Federated Learning using Dynamic Low-Rank Adaptation'
arxiv_id: '2405.06368'
source_url: https://arxiv.org/abs/2405.06368
tags:
- learning
- federated
- privacy
- dp-fl
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluates the practicality of fine-tuning large transformer-based
  models under differentially private federated learning (DP-FL). It demonstrates
  that full fine-tuning under DP-FL leads to significant performance degradation,
  which can be mitigated by using parameter-efficient fine-tuning (PEFT) methods to
  reduce the dimensionality of contributions.
---

# DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially Private Federated Learning using Dynamic Low-Rank Adaptation

## Quick Facts
- arXiv ID: 2405.06368
- Source URL: https://arxiv.org/abs/2405.06368
- Authors: Jie Xu; Karthikeyan Saravanan; Rogier van Dalen; Haaris Mehmood; David Tuckey; Mete Ozay
- Reference count: 40
- Primary result: DP-DyLoRA achieves less than 2% accuracy drop and 7% WER increase compared to non-private LoRA/DyLoRA using ε=2 privacy budget with 1 million clients

## Executive Summary
This work evaluates the practicality of fine-tuning large transformer-based models under differentially private federated learning (DP-FL). The paper demonstrates that full fine-tuning under DP-FL leads to significant performance degradation, which can be mitigated by using parameter-efficient fine-tuning (PEFT) methods to reduce the dimensionality of contributions. Comprehensive benchmarks show that DP-Low-Rank Adaptation (DP-LoRA) outperforms other DP-PEFT methods. To further improve privacy-utility trade-offs, the paper proposes DP-DyLoRA, an adaptation of Dynamic Low-Rank Adaptation (DyLoRA) that is compatible with differential privacy.

## Method Summary
The paper evaluates federated learning with secure aggregation and central DP across six datasets spanning speech recognition, computer vision, and natural language understanding. It compares full fine-tuning versus parameter-efficient fine-tuning methods including Adapter, Compacter, BitFit, LoRA, and DP-DyLoRA. The proposed DP-DyLoRA samples a rank b from a predefined range [rmin, rmax] at each round for all clients, reducing the number of parameters updated on average while maintaining expressive power equivalent to training all ranks.

## Key Results
- Full fine-tuning under DP-FL leads to huge performance degradation
- DP-LoRA outperforms other DP-PEFT methods (Adapter, Compacter, BitFit)
- DP-DyLoRA achieves less than 2% accuracy drop and 7% WER increase compared to non-private LoRA/DyLoRA
- Performance achieved using stringent privacy budget (ε=2) and 1 million clients

## Why This Works (Mechanism)

### Mechanism 1
Reducing trainable parameters in large transformer models under DP-FL reduces the magnitude of noise required for privacy. Parameter-efficient fine-tuning methods like LoRA freeze most model weights and only train small low-rank matrices. Since each client sends only these smaller matrices, the ℓ2 sensitivity of their updates is reduced, allowing less Gaussian noise to be added for the same privacy budget.

### Mechanism 2
Dynamic rank selection in DP-DyLoRA balances model expressiveness and privacy-utility trade-offs better than fixed-rank LoRA. DP-DyLoRA samples a rank b from a predefined range [rmin, rmax] at each round for all clients. This means fewer parameters are updated on average (compared to rmax), lowering noise while maintaining expressive power equivalent to training all ranks.

### Mechanism 3
Secure aggregation enables central DP in federated learning by hiding individual contributions before noise is added. Secure aggregation protocols sum encrypted client updates so the server only sees the aggregate. Each client adds their share of the global Gaussian noise to the sum, enabling central DP without local noise saturation.

## Foundational Learning

- **Differential Privacy (DP) and the Gaussian Mechanism**
  - Why needed here: DP-FL relies on adding calibrated Gaussian noise to client updates to provide privacy guarantees; understanding the privacy budget (ε, δ) and sensitivity is crucial for tuning
  - Quick check question: If the ℓ2 sensitivity of client updates doubles, by what factor must the Gaussian noise standard deviation increase to maintain the same (ε, δ) privacy guarantee?

- **Secure Aggregation in Federated Learning**
  - Why needed here: Secure aggregation is the cryptographic primitive that allows central DP in FL by summing encrypted client updates before noise is added
  - Quick check question: In secure aggregation, does the server ever learn the individual client updates, or only the aggregated sum?

- **Low-Rank Adaptation (LoRA) and Parameter-Efficient Fine-Tuning**
  - Why needed here: LoRA reduces the number of trainable parameters by learning low-rank updates to frozen pre-trained weights, which is essential for reducing noise in DP-FL
  - Quick check question: If a transformer layer has weight matrix W ∈ ℝ^(d_model × d_model) and LoRA uses rank r, how many trainable parameters does LoRA add per layer?

## Architecture Onboarding

- **Component map**: Server -> Secure Aggregation -> Noise Addition -> Global Model; Clients -> Local Training -> Gradient Clipping -> Secure Aggregation Participation
- **Critical path**: 
  1. Server samples cohort and broadcasts global model (and rank for DP-DyLoRA)
  2. Clients train on local data, clip updates, encrypt and send to aggregation
  3. Secure aggregation computes sum, each client adds noise share
  4. Server applies aggregated, noised update to global model
- **Design tradeoffs**: 
  - Larger LoRA rank → more model expressiveness, but higher noise and communication cost
  - Smaller cohort size → more noise for same privacy, but faster rounds
  - Stricter privacy budget (lower ε) → more noise, worse utility
- **Failure signatures**: 
  - Model fails to learn: noise overwhelms signal (too many parameters or too strict DP)
  - Slow convergence: high data heterogeneity or insufficient local training
  - Privacy budget exhausted: too many rounds or insufficient noise multiplier
- **First 3 experiments**: 
  1. Full fine-tuning under DP-FL with 1M clients, ε=2, compare to non-private FL on Sentiment140
  2. DP-LoRA (r=8) under same settings, measure accuracy/WER drop
  3. DP-DyLoRA (rmin=1, rmax=16) under same settings, compare to DP-LoRA and non-private DyLoRA

## Open Questions the Paper Calls Out

### Open Question 1
How does DP-DyLoRA's performance compare to DP-LoRA when the number of clients exceeds 1 million under the same privacy budget (ε=2)? The paper only evaluates up to 1 million clients, though it notes that real-world IoT systems often have millions of clients.

### Open Question 2
What is the impact of client dropout rates on DP-DyLoRA's performance compared to DP-LoRA under secure aggregation? The paper mentions secure aggregation but doesn't evaluate client dropout scenarios, which are realistic in federated learning.

### Open Question 3
How does the optimal rank range (rmin, rmax) for DP-DyLoRA vary across different types of transformer architectures and tasks? The paper fixes rmin and rmax across all experiments without exploring the sensitivity of DP-DyLoRA's performance to these hyperparameters.

### Open Question 4
What is the computational overhead of DP-DyLoRA compared to DP-LoRA when implemented on resource-constrained edge devices? The paper focuses on communication efficiency but doesn't address the computational cost difference between the two methods on edge devices.

## Limitations
- The paper relies on secure aggregation to enable central DP in FL, but the effectiveness and implementation details of secure aggregation are not fully explored
- Specific hyperparameters for DP-Adapter, DP-Compacter, and DP-LoRA (beyond rank) are not specified, which may impact reproducibility
- The paper doesn't evaluate the computational overhead of DP-DyLoRA compared to DP-LoRA on resource-constrained edge devices

## Confidence

**High Confidence**: The core claim that reducing trainable parameters through PEFT mitigates DP-FL performance degradation is well-supported by empirical results across six diverse datasets.

**Medium Confidence**: The mechanism by which DP-DyLoRA improves privacy-utility trade-offs through dynamic rank selection is theoretically sound but lacks direct empirical evidence in the corpus.

**Low Confidence**: The effectiveness of secure aggregation in practice and its interaction with the privacy analysis (moments accountant) is not fully validated in the paper.

## Next Checks

1. Verify that the Gaussian noise scale in DP-FL is indeed inversely proportional to the dimensionality of client updates by comparing full fine-tuning vs. LoRA with varying ranks.

2. Implement DP-DyLoRA and confirm that the expectation of parameter updates is the same whether rank is sampled per-client or once per round for all clients.

3. Test the impact of secure aggregation failure (e.g., by simulating a compromised client) on the privacy guarantees of the system.