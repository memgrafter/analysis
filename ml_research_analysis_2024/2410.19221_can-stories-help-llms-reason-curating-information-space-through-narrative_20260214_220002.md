---
ver: rpa2
title: Can Stories Help LLMs Reason? Curating Information Space Through Narrative
arxiv_id: '2410.19221'
source_url: https://arxiv.org/abs/2410.19221
tags:
- narrative
- reasoning
- llama
- llms
- techniques
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores whether integrating narrative elements into
  prompting techniques can improve the problem-solving abilities of large language
  models (LLMs). It introduces a novel approach, Story of Thought (SoT), which incorporates
  narrative structures into the prompting process.
---

# Can Stories Help LLMs Reason? Curating Information Space Through Narrative

## Quick Facts
- **arXiv ID**: 2410.19221
- **Source URL**: https://arxiv.org/abs/2410.19221
- **Reference count**: 25
- **Key outcome**: Story of Thought (SoT) approach outperforms Chain-of-Thought and Tree of Thoughts on physics, chemistry, math, and biology questions in GPQA and JEEBench datasets

## Executive Summary
This paper investigates whether incorporating narrative elements into prompting techniques can enhance large language models' problem-solving abilities. The authors introduce Story of Thought (SoT), a novel approach that integrates narrative structures into the prompting process through three steps: question clarification, narrative generation using various techniques, and problem-solving leveraging the generated narratives. Experimental results demonstrate that SoT consistently outperforms traditional prompting methods across multiple scientific domains, suggesting that narrative-based information curation helps LLMs better comprehend problems by contextualizing critical information and highlighting causal relationships.

## Method Summary
The Story of Thought approach implements a three-step framework for enhanced reasoning. First, it performs question clarification by generating an expanded, clarified version of the problem using zero-shot or few-shot prompting with an information gain score to measure quality. Second, it generates a narrative using one or more narrative techniques (Progressive Disclosure, Branching, Analogy, Analogical Reasoning, and Metaphor) through prompting the narrator model. Third, it employs the solver model to reason through the problem using the generated narrative. The approach combines these elements to create a "soft" narrative structure that curates information space and enhances problem comprehension through contextualization and causal relationship highlighting.

## Key Results
- SoT consistently outperforms Chain-of-Thought and Tree of Thoughts on GPQA and JEEBench datasets across physics, chemistry, math, and biology domains
- Using a combination of narrative techniques is more effective than any single technique in isolation
- Larger narrator models generate narratives that break down problems more effectively for solving
- SoT reasoning outputs show higher similarity to human explanations compared to Chain-of-Thought outputs

## Why This Works (Mechanism)
The narrative-based approach works by structuring information in a way that mimics human reasoning processes. Stories naturally organize information temporally, highlight causal relationships, and provide context that helps identify what information is relevant to solving a problem. By generating narratives around problems, SoT creates a framework that guides the model through the problem space in a more intuitive manner. The combination of multiple narrative techniques allows for richer information representation than linear reasoning chains, enabling the model to explore different perspectives and connections within the problem domain.

## Foundational Learning
- **Narrative Techniques**: Progressive Disclosure, Branching, Analogy, Analogical Reasoning, and Metaphor - these provide different ways to structure and present information, each highlighting different aspects of problems
- **Information Curation**: The process of selecting, organizing, and presenting relevant information - essential for reducing cognitive load and focusing attention on critical problem elements
- **Problem Contextualization**: Embedding problems within a broader narrative framework - helps models understand relationships between different problem components
- **Causal Relationship Mapping**: Identifying and highlighting cause-effect relationships - crucial for understanding problem structure and solution pathways
- **Zero-shot vs Few-shot Prompting**: Different prompting strategies with varying levels of guidance - affects the quality and specificity of generated narratives
- **Information Gain Scoring**: Metric for evaluating question clarification quality - ensures expanded problems retain essential information while improving clarity

## Architecture Onboarding
- **Component Map**: Question Input -> Clarification Module -> Narrator Model -> Narrative Generation -> Solver Model -> Answer Output
- **Critical Path**: Question → Clarification → Narrative Generation → Problem Solving → Answer
- **Design Tradeoffs**: Soft narrative structure vs rigid frameworks (flexibility vs control), single vs multiple narrative techniques (simplicity vs richness), narrator model size vs computational cost
- **Failure Signatures**: Poor narrative quality from narrator model leads to confused problem-solving, overly complex narratives overwhelm the solver, narrative techniques may not align with problem type
- **First Experiments**:
  1. Test SoT on a single simple physics problem comparing different narrative techniques in isolation
  2. Evaluate SoT with different narrator model sizes on the same problem set
  3. Compare SoT performance against Chain-of-Thought on a small subset of GPQA questions

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How do different narrative techniques (Progressive Disclosure, Branching, Analogy, Analogical Reasoning, and Metaphor) individually contribute to the performance of the Story of Thought (SoT) approach in solving complex problems?
- Basis in paper: The paper discusses the impact of narrative techniques in Section 6.2, stating that employing any single narrative technique at a time is notably less effective than utilizing a combination of these simultaneously.
- Why unresolved: The paper mentions that using a combination of narrative techniques is more effective than using any single technique, but it does not provide a detailed analysis of how each individual technique contributes to the overall performance. The paper also notes that it is difficult to determine how the narrative techniques relate to each other and whether the model truly comprehends the prompts it receives.
- What evidence would resolve it: A detailed ablation study that isolates each narrative technique and measures its individual contribution to the model's performance. Additionally, qualitative analysis of the generated narratives to understand how each technique is employed and its impact on problem-solving.

### Open Question 2
- Question: What is the role of the quality and choice of the narrator model (the model that generates narratives) in the effectiveness of the Story of Thought (SoT) approach?
- Basis in paper: The paper discusses the role of the narrator model in Section 6.1, stating that the choice of narrator model can impact the problem-solving results. It also mentions that larger models generate narratives that break down problems to make them more easily solvable.
- Why unresolved: The paper provides initial insights into the impact of the narrator model but does not explore the nuances of how different narrator models affect the quality of the generated narratives and the subsequent problem-solving performance. It also does not discuss the compatibility between narrator and solver models.
- What evidence would resolve it: Comparative experiments using different narrator models to generate narratives for the same problem-solving tasks, followed by analysis of the narrative quality and problem-solving performance. Additionally, studies on the compatibility between different narrator and solver model combinations.

### Open Question 3
- Question: How does the Story of Thought (SoT) approach compare to other reasoning techniques, such as Chain-of-Thought (CoT) and Analogical Reasoning, in terms of the similarity of generated explanations to human explanations?
- Basis in paper: The paper compares the similarity of SoT and CoT reasoning outputs to human explanations in Section 6.4, using metrics like BERTScore, ROUGE-L, and BLEU.
- Why unresolved: While the paper provides a comparison of SoT and CoT reasoning outputs to human explanations, it does not explore how SoT compares to other reasoning techniques like Analogical Reasoning in terms of the quality and similarity of generated explanations. The paper also does not discuss the potential benefits of combining different reasoning techniques.
- What evidence would resolve it: Comparative experiments using different reasoning techniques (SoT, CoT, Analogical Reasoning, etc.) to generate explanations for the same problem-solving tasks, followed by analysis of the similarity of generated explanations to human explanations using various metrics. Additionally, studies on the potential benefits of combining different reasoning techniques.

## Limitations
- Evaluation focuses primarily on multiple-choice science questions, leaving uncertainty about performance on open-ended reasoning tasks
- Comparison relies on relatively narrow benchmarks (GPQA and JEEBench), which may not generalize to broader problem-solving contexts
- Narrative generation introduces additional complexity and computational overhead that could impact practical deployment
- Study does not address potential biases introduced through narrative framing
- Does not examine how different narrative techniques compare in isolation

## Confidence
- Narrative-based prompting improvements: **Medium** - consistent gains across multiple datasets, but evaluation scope remains limited
- Three-step framework methodology: **High** - provides clear operational approach, though superiority over simpler alternatives needs further validation
- Narrative enhances information curation: **Medium** - experimental design supports this claim, but causal mechanisms remain underexplored

## Next Checks
1. Test SoT performance on open-ended problem-solving tasks beyond multiple-choice questions to assess generalizability
2. Conduct ablation studies comparing individual narrative techniques (analogy vs progressive disclosure vs narrative framing) to identify which components drive improvements
3. Evaluate SoT on diverse domain tasks including creative writing, code generation, and commonsense reasoning to establish broader applicability