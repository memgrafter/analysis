---
ver: rpa2
title: 'DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence
  Embeddings'
arxiv_id: '2411.16236'
source_url: https://arxiv.org/abs/2411.16236
tags:
- robustness
- text
- group
- clip
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DoubleCCA, a novel method to improve the
  group robustness of foundation models by leveraging random sentence embeddings and
  Canonical Correlation Analysis (CCA). The method addresses the issue of group-based
  biases in foundation models by generating semantically meaningful text embeddings
  that enhance the model's performance and robustness.
---

# DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings

## Quick Facts
- arXiv ID: 2411.16236
- Source URL: https://arxiv.org/abs/2411.16236
- Authors: Hong Liu; Yitong Lu
- Reference count: 40
- Primary result: DoubleCCA improves group robustness of foundation models by 1.4% average accuracy and 4.4% worst group accuracy on Waterbirds dataset

## Executive Summary
This paper introduces DoubleCCA, a novel method to improve the group robustness of foundation models by leveraging random sentence embeddings and Canonical Correlation Analysis (CCA). The method addresses the issue of group-based biases in foundation models by generating semantically meaningful text embeddings that enhance the model's performance and robustness. DoubleCCA employs two stages of CCA to align and merge different text representations, effectively enriching the text embeddings of the foundation model. The method is simple to implement and can be easily integrated into existing models, making it a practical solution for improving the robustness of foundation models. Experimental results demonstrate that DoubleCCA outperforms existing methods in terms of both group robustness and domain generalization across various datasets and backbone models.

## Method Summary
DoubleCCA improves group robustness by generating semantically meaningful text embeddings through random sentence augmentation and dual CCA alignment. Random sentences are generated by appending character sequences to original prompts. These augmented sentences are encoded using both the CLIP text encoder and an external sentence embedding model (e.g., HiT). CCA is applied twice: first to align the two embedding spaces into a common subspace, then to merge and reconstruct them back to the original representation space. This merged embedding is then used for zero-shot classification, effectively enriching the text embeddings of the foundation model and improving its robustness to group-based biases.

## Key Results
- DoubleCCA improves CLIP's average accuracy by 1.4% and worst group accuracy by 4.4% on Waterbirds dataset
- Outperforms existing methods in terms of both group robustness and domain generalization across various datasets and backbone models
- Shows significant improvements in robustness with minimal impact on average accuracy when varying the number of random sentences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DoubleCCA improves group robustness by generating semantically meaningful text embeddings through random sentence augmentation and dual CCA alignment.
- Mechanism: Random sentences are generated by appending character sequences to original prompts. These augmented sentences are encoded using both the CLIP text encoder and an external sentence embedding model (e.g., HiT). CCA is applied twice: first to align the two embedding spaces into a common subspace, then to merge and reconstruct them back to the original representation space.
- Core assumption: The external sentence embedding model provides complementary semantic information that CLIP's text encoder lacks, and CCA can effectively merge these complementary views without losing discriminative power.
- Evidence anchors:
  - [abstract] "We use an additional sentence embedding model to generate different text embeddings with respect to these random sentences. We then use CCA double twice to align the representations and reconstruct them back to the original representation space."
  - [section 3.2.1] "We first generate sentence embeddings using the sentence embedding model Φse and the CLIP text encoder Φt... We then apply CCA... to learn the transformation matrices Wx and Wse that embeds two features into a common space."
  - [corpus] Weak: No direct neighbor papers cite this specific dual-CCA approach, but there is literature on using CCA for representation alignment and sentence embedding fusion.

### Mechanism 2
- Claim: Random sentence augmentation stabilizes the first CCA by providing sufficient data for learning stable transformation matrices.
- Mechanism: Instead of using only the limited class labels (e.g., 2 classes in Waterbirds), K random sentences are generated per class. The first CCA is then trained on these K × number_of_classes sentence pairs, ensuring enough samples to learn stable transformation matrices Wx and Wse.
- Core assumption: The random sentence embeddings provide a rich, diverse set of samples that approximate the true data distribution well enough for CCA to learn meaningful alignments.
- Evidence anchors:
  - [section 3.2.1] "Since the number of class labels is usually much smaller... we propose to use the random sentence embeddings to generate more sentence embeddings... We replace Xse with Frse and X with Fr to apply CCA to learn the transformation matrices Wx and Wse."
  - [section 4.4] "The results indicate that varying the number of random sentences has minimal impact on the average accuracy but demonstrates a substantial influence on the worst group robustness... as the number of sentences increases, the model performance gradually stabilizes."
  - [corpus] Weak: No direct evidence in neighbors; this is a novel methodological detail.

### Mechanism 3
- Claim: The second CCA step merges the aligned embeddings into a single, more robust representation that improves zero-shot classification robustness.
- Mechanism: After the first CCA, two score functions Sx and Sse are obtained. The second CCA merges these into a single embedding matrix W by maximizing the correlation between the transformed features in the common space. This merged embedding is then used for classification.
- Core assumption: The merged embedding W captures complementary information from both the CLIP encoder and the external model, leading to a more robust decision boundary that is less sensitive to group-based biases.
- Evidence anchors:
  - [section 3.2.2] "Referring to [23], we employ the CCA technique to merge these two fully-connected layers into one fully-connected layer... where W can be seen as the merged text embeddings."
  - [section 4.2] "We observe that our method achieves better average accuracy and worst group robustness than the baseline CLIP model on both datasets."
  - [corpus] Weak: No direct neighbor evidence; this is a novel use of dual CCA.

## Foundational Learning

- Concept: Canonical Correlation Analysis (CCA)
  - Why needed here: CCA is used to align and merge different text embedding spaces into a common representation, which is central to DoubleCCA's approach.
  - Quick check question: What does CCA maximize, and how does it transform two feature sets into a common space?

- Concept: Sentence Embeddings and PLMs
  - Why needed here: Understanding how sentence embeddings capture semantic meaning and how they differ from CLIP's text encoder is crucial for appreciating the complementarity DoubleCCA exploits.
  - Quick check question: How do models like HiT or Sentence-BERT generate fixed-dimensional sentence embeddings, and why might they complement CLIP's text encoder?

- Concept: Group Robustness and Spurious Correlations
  - Why needed here: The motivation for DoubleCCA is to reduce sensitivity to group-based biases (e.g., background in Waterbirds), which requires understanding what group robustness means and how spurious correlations affect model performance.
  - Quick check question: What is a group attribute, and why does a model's reliance on it hurt group robustness?

## Architecture Onboarding

- Component map: Original prompts -> Random sentence generator -> CLIP text encoder Φt and external sentence embedding model Φse -> First CCA alignment -> Second CCA merge -> Merged text embeddings W for classification
- Critical path: Generate random sentences → Encode with Φt and Φse → First CCA alignment → Second CCA merge → Use merged W for classification
- Design tradeoffs:
  - Number of random sentences (K): Too few → unstable CCA; too many → computational overhead
  - CCA dimension: Too low → insufficient representation; too high → overfitting or noise
  - Choice of sentence embedding model: Different models offer different semantic coverage; HiT is recommended but others may work
- Failure signatures:
  - Poor worst group robustness despite improved average accuracy (overfitting to majority group)
  - Instability in results across runs (CCA not learning stable transformations)
  - No improvement over baseline (merged embeddings not capturing complementary information)
- First 3 experiments:
  1. Vary K (number of random sentences) from 1 to 2000 on Waterbirds; observe impact on worst group robustness.
  2. Compare different sentence embedding models (HiT, Sentence-BERT, BART) on Waterbirds; measure average and worst accuracy.
  3. Test CCA dimension sweep (e.g., 16, 32, 64, 128) on Waterbirds; identify optimal dimension for robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of sentence embedding model affect the group robustness of foundation models in DoubleCCA?
- Basis in paper: [explicit] The paper conducts an ablation study to analyze the effect of different sentence embedding models (HiT, Sentence-BERT, gte-base-en-v1.5, and BART) on the group robustness of the CLIP model.
- Why unresolved: The paper finds that different sentence embedding models have varying impacts on the model's performance, with HiT showing the most significant improvements. However, the underlying reasons for these differences and the optimal choice of sentence embedding model for different tasks remain unclear.
- What evidence would resolve it: A comprehensive comparative study across a wide range of tasks and datasets, along with an analysis of the semantic properties of different sentence embedding models, would help identify the most suitable model for improving group robustness in various scenarios.

### Open Question 2
- Question: What is the impact of the dimension of the common space in the first CCA on the group robustness of foundation models?
- Basis in paper: [explicit] The paper conducts an ablation study to analyze the effect of the dimension of the common space in the first CCA on the group robustness of the CLIP model.
- Why unresolved: The paper finds that both low and high dimensions adversely affect the results, but the optimal dimension for the common space remains unclear. The paper suggests that automatic dimension selection methods could be used to determine the optimal dimension.
- What evidence would resolve it: A systematic investigation of the relationship between the dimension of the common space and the group robustness across different tasks and datasets, along with the development and evaluation of automatic dimension selection methods, would help determine the optimal dimension for the common space in DoubleCCA.

### Open Question 3
- Question: How does the number of random sentences used in DoubleCCA affect the group robustness of foundation models?
- Basis in paper: [explicit] The paper conducts an ablation study to analyze the effect of the number of random sentences on the group robustness of the CLIP model.
- Why unresolved: The paper finds that varying the number of random sentences has minimal impact on the average accuracy but demonstrates a substantial influence on the worst group robustness. However, the optimal number of random sentences for achieving the best group robustness remains unclear.
- What evidence would resolve it: A comprehensive study of the relationship between the number of random sentences and the group robustness across different tasks and datasets, along with an analysis of the trade-off between the number of random sentences and the computational cost, would help determine the optimal number of random sentences for DoubleCCA.

## Limitations
- The method's reliance on random sentence generation introduces potential semantic ambiguity that could degrade performance on certain datasets.
- The choice of sentence embedding model appears critical but is only validated with HiT, leaving open questions about generalizability to other models or domains.
- The observed robustness gains may be due to regularization effects from the CCA process rather than complementary semantic information from the sentence embedding model.

## Confidence

- **High Confidence**: The overall methodology of using dual CCA for representation alignment and merging is sound and well-established in representation learning literature.
- **Medium Confidence**: The specific claim that random sentence embeddings provide sufficient semantic diversity for stable CCA learning needs more empirical validation across diverse datasets.
- **Low Confidence**: The assertion that DoubleCCA consistently outperforms all baseline methods across all metrics requires scrutiny, particularly given the limited number of evaluated sentence embedding models and datasets.

## Next Checks

1. **Ablation Study on Sentence Embedding Models**: Systematically compare DoubleCCA's performance using different sentence embedding models (e.g., Sentence-BERT, BART, RoBERTa) on Waterbirds to isolate whether HiT's specific characteristics are crucial for success.

2. **Random Sentence Quality Analysis**: Conduct a controlled experiment varying the semantic coherence of random sentences (from completely random characters to semantically meaningful variations) to determine the minimum quality threshold for effective CCA alignment.

3. **Group Robustness vs. Regularization Test**: Compare DoubleCCA against a simpler regularization baseline (e.g., dropout on text embeddings) on Waterbirds to determine whether the robustness gains are primarily due to the CCA mechanism or general regularization effects.