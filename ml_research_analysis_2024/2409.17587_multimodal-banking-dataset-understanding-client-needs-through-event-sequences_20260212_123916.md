---
ver: rpa2
title: 'Multimodal Banking Dataset: Understanding Client Needs through Event Sequences'
arxiv_id: '2409.17587'
source_url: https://arxiv.org/abs/2409.17587
tags:
- data
- dataset
- multimodal
- event
- dialoglast
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Multimodal Banking Dataset (MBD), a large-scale,
  publicly available dataset containing over 2 million corporate clients with multimodal
  event sequences (bank transactions, geo positions, support dialogues) and monthly
  purchase labels. The dataset addresses the lack of real-world, anonymized, multi-source
  event sequence data for financial applications.
---

# Multimodal Banking Dataset: Understanding Client Needs through Event Sequences

## Quick Facts
- arXiv ID: 2409.17587
- Source URL: https://arxiv.org/abs/2409.17587
- Reference count: 40
- Primary result: Introduces MBD, a large-scale multimodal banking dataset with over 2M clients and 2M+ monthly purchase labels, achieving up to 0.83 ROC AUC with multimodal fusion

## Executive Summary
The paper introduces the Multimodal Banking Dataset (MBD), a large-scale, publicly available dataset containing over 2 million corporate clients with multimodal event sequences (bank transactions, geo positions, support dialogues) and monthly purchase labels. The dataset addresses the lack of real-world, anonymized, multi-source event sequence data for financial applications. It introduces a benchmark for tasks like future purchase prediction and multimodal matching, comparing several state-of-the-art unimodal and multimodal methods. Experiments show that multimodal fusion, especially late fusion with supervised RNNs, consistently outperforms single-modal approaches, achieving up to 0.83 ROC AUC in campaigning tasks. Anonymization preserves model performance, and LLMs perform competitively on transactions. MBD provides a valuable resource for advancing multimodal modeling in finance.

## Method Summary
The MBD dataset contains over 2 million corporate clients with multimodal event sequences including 950M transactions, 1B geo position events, and 5M dialogue embeddings, along with monthly purchase labels for four banking products. The paper implements baseline models including Aggregation, CoLES, TabBERT, TabGPT, and supervised RNNs for each modality. Multimodal fusion is tested through blending, late fusion (concatenating embeddings after individual processing), and early fusion (cross-attention mechanisms). Five-fold cross-validation is used for evaluation with ROC AUC as the primary metric for campaigning tasks and recall metrics for multimodal matching. The dataset is publicly available on HuggingFace with proper anonymization procedures that preserve model performance.

## Key Results
- Multimodal fusion, especially late fusion with supervised RNNs, consistently outperforms single-modal approaches, achieving up to 0.83 ROC AUC in campaigning tasks
- Anonymization procedures preserve model performance while protecting client privacy, with Kendall-tau correlation of 0.94 between public and private datasets
- LLMs can match or exceed specialized event-sequence models when applied to serialized banking transaction data
- Late Fusion with Supervised RNN consistently delivers superior results, while Early Fusion achieves competitive performance but slightly lags behind

## Why This Works (Mechanism)

### Mechanism 1
Late fusion concatenates modality-specific embeddings after individual processing, allowing each modality to be represented optimally before joint classification. This preserves modality-specific temporal patterns while enabling cross-modal interactions at the decision level. Core assumption: Each modality's representation is sufficiently informative when processed separately, and concatenation preserves discriminative features for downstream tasks. Evidence: Multimodal fusion consistently outperforms single-modal approaches with 0.83 ROC AUC; Late Fusion consistently delivers superior results; Early Fusion achieves competitive but slightly lower performance. Break condition: If individual modality encoders fail to capture essential temporal dynamics, late fusion concatenation cannot recover lost information.

### Mechanism 2
Anonymization procedures preserve model performance while protecting client privacy by adding noise and hashing identifiers that disrupt exact client matching but maintain statistical properties and sequential patterns essential for model learning. Core assumption: The noise patterns introduced preserve the underlying distribution and temporal structure without altering discriminative features. Evidence: Experiments confirm anonymization saves all significant information; strong correlation (Kendall-tau 0.94) between public and private datasets; all entries are properly anonymized from real proprietary bank data. Break condition: If noise patterns distort temporal correlations or remove rare but critical events, model performance will degrade.

### Mechanism 3
LLMs can match or exceed specialized event-sequence models when applied to serialized banking transaction data by leveraging their ability to process sequential text patterns. When transactions are formatted as text, they can learn similar patterns to specialized models without domain-specific architectural constraints. Core assumption: The serialized text representation preserves sufficient information for the LLM to learn temporal and transactional patterns. Evidence: Small language models can match performance of specialized event-sequence models even without extra tuning; X-separated serialization represents transactions in text format; results show LLMs are competitive on transactions. Break condition: If the text serialization loses critical numerical relationships or temporal ordering, LLM performance will fall below specialized models.

## Foundational Learning

- **Temporal event sequence modeling**: Banking data consists of time-ordered events that must be processed while preserving temporal dependencies for prediction. Why needed here: Each banking event has a timestamp and sequence that affects prediction outcomes. Quick check question: How would you handle asynchronous events from different modalities arriving at different rates?

- **Multimodal representation learning**: Each banking data source (transactions, geo, dialogues) has different characteristics requiring specialized encoding before fusion. Why needed here: Transactions are numerical, geo positions are categorical with spatial relationships, and dialogues are sequential text requiring different encoding strategies. Quick check question: What are the tradeoffs between early, late, and intermediate fusion strategies for asynchronous event sequences?

- **Handling class imbalance in financial prediction**: Product purchase prediction typically involves rare positive events, requiring careful evaluation and sampling strategies. Why needed here: Most clients don't purchase most products, making positive examples rare and accuracy misleading. Quick check question: Why is ROC AUC preferred over accuracy for imbalanced banking prediction tasks?

## Architecture Onboarding

- **Component map**: Raw event sequences -> Specialized encoders (CoLES, TabGPT, TabBERT, Supervised RNN) -> Fusion layer (Blending, Late, Early) -> Classifier -> Output predictions
- **Critical path**: Raw event sequences -> Encoder-specific preprocessing -> Model training -> Evaluation with ROC AUC
- **Design tradeoffs**: Early fusion captures cross-modal interactions earlier but may struggle with modality-specific preprocessing needs; late fusion preserves modality-specific representations but may miss early interaction opportunities
- **Failure signatures**: Performance degradation when modality encoders are poorly matched to data characteristics; fusion layer failure when modality embeddings are incompatible
- **First 3 experiments**: 1) Train and evaluate unimodal Supervised RNN on transaction data only to establish baseline performance; 2) Implement late fusion with transaction and geo modalities to test multimodal benefits; 3) Compare late fusion against early fusion using CrossTransformer to evaluate fusion strategy effectiveness

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of multimodal models degrade when applied to real-world, live banking data streams compared to the anonymized, static datasets used in this study? Basis: Authors note anonymization preserves performance and suggest future work should include additional data sources and downstream tasks. Why unresolved: Paper only evaluates on anonymized historical data; real-time data introduces noise, latency, and evolving client behavior patterns. What evidence would resolve it: Empirical comparison of model performance on live transaction streams versus anonymized historical data with metrics tracking drift and adaptation speed.

- **Open Question 2**: What is the optimal strategy for balancing computational cost and predictive accuracy when integrating large language models with specialized event-sequence models for multimodal banking tasks? Basis: Authors compare LLM-based approaches with domain-specific methods, noting LLMs can match specialized models on transactions but struggle with high-dimensional features. Why unresolved: Paper identifies performance trade-offs but doesn't provide systematic framework for deciding when to use LLMs versus specialized models. What evidence would resolve it: Cost-benefit analysis framework with empirical benchmarks comparing inference time, memory usage, and accuracy across varying dataset sizes and modality combinations.

- **Open Question 3**: How can the multimodal matching task be improved to handle the weak compatibility observed with dialogue data, and what structural features of dialogue data contribute to this limitation? Basis: Authors observe dialogue modality exhibits significantly weaker matching performance compared to transactions and geostream. Why unresolved: Paper identifies the problem but doesn't explore underlying causes or propose architectural modifications. What evidence would resolve it: Ablation studies isolating dialogue features, comparison of matching performance with enhanced dialogue representations, and architectural experiments with cross-modal attention mechanisms tailored to dialogue data.

## Limitations

- Dataset anonymization procedure is not fully disclosed due to security requirements, creating uncertainty about exact preprocessing steps
- Multimodal matching task shows dialogue modality performance lags behind transactions and geo positions, suggesting modality compatibility remains an open challenge
- Paper focuses exclusively on corporate clients, limiting generalizability to retail banking scenarios

## Confidence

**High confidence**: Multimodal fusion (especially late fusion) outperforms single-modal approaches is well-supported by experimental results showing consistent ROC AUC improvements.

**Medium confidence**: Anonymization preserves all significant information is supported by strong correlation metrics but lacks detailed disclosure.

**Low confidence**: LLMs can match specialized event-sequence models is based on limited experimentation with X-separated serialization and may not generalize.

## Next Checks

1. **Anonymization Impact Test**: Conduct ablation studies on the anonymization procedure by testing model performance on progressively less anonymized versions of the data to quantify the exact performance trade-off.

2. **Modality Compatibility Analysis**: Systematically evaluate modality pairs in the multimodal matching task to identify which combinations work best and develop guidelines for selecting appropriate modality subsets based on task requirements.

3. **Generalization Cross-Validation**: Test the best-performing models on out-of-distribution time periods and on Alphabattle dataset to assess temporal and domain generalization capabilities beyond the MBD dataset.