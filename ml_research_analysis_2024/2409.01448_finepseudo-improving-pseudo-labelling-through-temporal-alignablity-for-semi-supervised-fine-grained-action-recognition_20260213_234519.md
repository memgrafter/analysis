---
ver: rpa2
title: 'FinePseudo: Improving Pseudo-Labelling through Temporal-Alignablity for Semi-Supervised
  Fine-Grained Action Recognition'
arxiv_id: '2409.01448'
source_url: https://arxiv.org/abs/2409.01448
tags:
- action
- recognition
- fine-grained
- video
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces FinePseudo, a novel semi-supervised framework
  for fine-grained action recognition that leverages temporal alignability. The method
  employs a frame-wise video encoder trained via alignability-verification-based metric
  learning to capture action phases, producing a learnable alignability score that
  refines pseudo-labels.
---

# FinePseudo: Improving Pseudo-Labelling through Temporal-Alignablity for Semi-Supervised Fine-Grained Action Recognition

## Quick Facts
- arXiv ID: 2409.01448
- Source URL: https://arxiv.org/abs/2409.01448
- Reference count: 40
- Primary result: Achieves 4-5% improvement in top-1 accuracy on fine-grained action datasets

## Executive Summary
FinePseudo introduces a novel semi-supervised framework for fine-grained action recognition that leverages temporal alignability. The method employs a frame-wise video encoder trained via alignability-verification-based metric learning to capture action phases, producing a learnable alignability score that refines pseudo-labels. These refined pseudo-labels, generated through a non-parametric classifier, are combined with predictions from a video encoder in a collaborative pseudo-labeling process. Evaluated on four fine-grained datasets—Diving48, FineGym99, FineGym288, and FineDiving—FinePseudo outperforms prior methods by 4-5% in top-1 accuracy.

## Method Summary
FinePseudo is a semi-supervised fine-grained action recognition framework that addresses the limitations of standard pseudo-labeling approaches. The method uses a Video Transformer Network (VTN) as an alignability encoder to capture frame-wise video representations and compute alignability scores through metric learning based on dynamic time warping (DTW) alignment costs. A separate R2plus1D-18 encoder handles high-level action semantics. The framework employs a non-parametric classifier that uses alignability scores against a gallery of labeled embeddings to generate class predictions, which are then combined with the action encoder's predictions in a collaborative pseudo-labeling process. This approach refines pseudo-labels to better capture the temporal structure and phases of fine-grained actions, resulting in improved performance compared to traditional pseudo-labeling methods.

## Key Results
- Achieves 4-5% improvement in top-1 accuracy on Diving48, FineGym99, FineGym288, and FineDiving datasets
- Demonstrates competitive performance on coarse-grained datasets (Kinetics400, Something-SomethingV2)
- Shows robustness in open-world settings with novel unlabeled classes (8 out of 48 classes in Diving48)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alignment-based distance metrics outperform standard cosine distances for fine-grained action recognition.
- Mechanism: Dynamic Time Warping (DTW) alignment cost provides phase-aware distance measures that capture temporal alignment between action phases, which is crucial for distinguishing fine-grained actions.
- Core assumption: Fine-grained actions require understanding of action phases and temporal alignment, unlike coarse-grained actions where scene bias dominates.
- Evidence anchors:
  - [abstract] "We observe that alignment distances like dynamic time warping (DTW) provide a suitable action-phase-aware measure for comparing fine-grained actions"
  - [section] "standard DTW distance is pairwise and assumes strict alignment between pairs, it is not directly suitable for classifying fine-grained actions"
  - [corpus] Weak evidence - no direct citations found for DTW alignment in fine-grained action recognition specifically
- Break condition: If actions don't have clear phase structure or if temporal alignment isn't the primary discriminative feature

### Mechanism 2
- Claim: Learnable alignability scores improve pseudo-label quality for semi-supervised fine-grained action recognition.
- Mechanism: The framework learns a binary classification task to determine if video pairs are alignable (same class) or not, creating a phase-aware distance measure that refines pseudo-labels through non-parametric classification.
- Core assumption: Videos from the same fine-grained action class are more alignable than videos from different classes, making alignability a useful supervisory signal.
- Evidence anchors:
  - [abstract] "Our learnable alignability score provides a better phase-aware measure, which we use to refine the pseudo-labels of the primary video encoder"
  - [section] "We propose an Alignability-Verification-based Metric learning technique to effectively discriminate between fine-grained action pairs"
  - [corpus] No direct evidence found for alignability-based pseudo-labeling in semi-supervised learning literature
- Break condition: If the binary classification assumption fails or if phase alignment doesn't correlate with class membership

### Mechanism 3
- Claim: Collaborative pseudo-labeling combining action-level and alignability-based predictions improves performance.
- Mechanism: The framework combines predictions from a frame-wise video encoder (focusing on action phases) and a regular video encoder (focusing on high-level action semantics) to create refined pseudo-labels.
- Core assumption: Predictions from different supervisory signals (video-level vs alignability-based) provide complementary information for better pseudo-label quality.
- Evidence anchors:
  - [abstract] "These refined pseudo-labels, generated through a non-parametric classifier, are combined with predictions from a video encoder in a collaborative pseudo-labeling process"
  - [section] "Our collaborative pseudo-labeling-based framework 'FinePseudo' significantly outperforms prior methods"
  - [corpus] No direct evidence found for collaborative pseudo-labeling combining different supervisory signals in video action recognition
- Break condition: If one prediction source consistently dominates the other or if combining predictions doesn't improve accuracy

## Foundational Learning

- Concept: Dynamic Time Warping (DTW) and softDTW
  - Why needed here: DTW provides alignment-based distance measures that capture temporal phase alignment, which is crucial for distinguishing fine-grained actions that may have different execution speeds but similar phase patterns
  - Quick check question: What's the key difference between standard DTW and softDTW, and why is softDTW preferred in this framework?

- Concept: Metric learning with triplet loss
  - Why needed here: The framework uses triplet loss with hard negative mining to learn discriminate representations based on alignment distances, which helps the model focus on action phase similarities and differences
  - Quick check question: How does the alignability-based triplet loss differ from standard triplet loss in metric learning?

- Concept: Gaussian kernel for temporal distinctiveness
  - Why needed here: The framework uses a Gaussian kernel to weight temporal distinctiveness in self-supervised pretraining, ensuring temporal coherence in frame-wise video embeddings which is crucial for capturing action phases
  - Quick check question: Why does the framework use a Gaussian kernel instead of treating all temporal misalignments equally negative?

## Architecture Onboarding

- Component map:
  - Alignability Encoder (fA) -> Video Transformer Network (VTN) for frame-wise video representations and alignability score computation
  - Action Encoder (fE) -> R2plus1D-18 for high-level action semantics and video-level predictions
  - Non-parametric classifier -> Uses alignability scores against gallery of labeled embeddings to generate class predictions
  - Collaborative pseudo-labeling module -> Combines predictions from both encoders to refine pseudo-labels

- Critical path:
  1. SSL pretraining of fA using Gaussian-infused temporal distinctiveness
  2. Alignability-verification-based metric learning to train fA
  3. Regular training of fE with cross-entropy loss
  4. Collaborative pseudo-label generation and self-training iterations

- Design tradeoffs:
  - Memory vs. performance: Using single RGB modality vs. multi-modal approaches (optical flow, temporal gradients)
  - Training efficiency: Independent training of branches vs. joint training with increased memory consumption
  - Pseudo-label quality: Confidence-based filtering vs. alignability-score verification vs. non-parametric classification

- Failure signatures:
  - Poor performance on fine-grained datasets but good on coarse-grained datasets: Indicates phase alignment isn't the primary discriminative feature
  - No improvement over supervised baseline in open-world setting: Suggests alignability score isn't effectively filtering novel classes
  - High pseudo-label noise: May indicate threshold settings are too permissive or alignability verification isn't working

- First 3 experiments:
  1. Baseline comparison: Implement regular pseudo-labeling with confidence thresholding and compare with FinePseudo's collaborative approach on Diving48
  2. Alignability verification ablation: Test different pseudo-label refinement strategies (confidence-only, uncertainty-aware, alignability-score verification, non-parametric classification) to isolate the impact of each component
  3. Distance function ablation: Compare DTW-based alignment cost with cosine distance and other alignment variants to validate the choice of softDTW for metric learning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FinePseudo's performance scale with increasing numbers of novel classes in open-world settings?
- Basis in paper: [explicit] The paper evaluates FinePseudo on Diving48 with 8 novel classes out of 48 total, showing robustness to novel classes.
- Why unresolved: The paper only tests one specific novel class ratio (8 out of 48). It's unclear how the method performs as the number of novel classes increases or decreases.
- What evidence would resolve it: Experiments varying the proportion of novel classes (e.g., 2, 4, 16, 32 novel classes) while keeping the total number of classes constant, comparing FinePseudo's performance to baseline methods across these scenarios.

### Open Question 2
- Question: Can FinePseudo's alignability-based pseudo-labeling be effectively combined with other semi-supervised learning techniques like consistency regularization or self-training?
- Basis in paper: [inferred] The paper presents FinePseudo as a pseudo-labeling-based method, but doesn't explore combinations with other semi-supervised techniques mentioned in the literature (e.g., MixMatch, FixMatch).
- Why unresolved: The paper focuses solely on the collaborative pseudo-labeling approach and doesn't investigate potential synergies or trade-offs with other semi-supervised learning paradigms.
- What evidence would resolve it: Experiments integrating FinePseudo's alignability-based pseudo-labeling with other semi-supervised methods (e.g., consistency regularization, self-training) and comparing their combined performance to FinePseudo alone.

### Open Question 3
- Question: How sensitive is FinePseudo to the choice of hyperparameters, particularly the confidence threshold θ and temperature parameter τ?
- Basis in paper: [explicit] The paper mentions using a confidence threshold θ of 0.6 and temperature parameter τ of 0.1, but doesn't provide sensitivity analysis.
- Why unresolved: The paper doesn't explore how FinePseudo's performance varies with different hyperparameter settings, which is crucial for practical deployment.
- What evidence would resolve it: A comprehensive sensitivity analysis showing FinePseudo's performance across a range of θ and τ values, identifying optimal settings and their stability.

## Limitations
- Limited evidence for DTW alignment's superiority in fine-grained action recognition specifically
- No extensive ablation studies comparing alignability-based pseudo-label refinement against alternative methods
- Reliance on single RGB modality may limit performance compared to multi-modal approaches

## Confidence
- **Mechanism 1 (DTW alignment)**: Low - Novel application without extensive prior validation
- **Mechanism 2 (Learnable alignability scores)**: Medium - Conceptually sound but limited comparative evidence
- **Mechanism 3 (Collaborative pseudo-labeling)**: Medium - Effective but needs more ablation studies
- **Overall framework performance**: Medium-High - Strong empirical results but limited methodological comparisons

## Next Checks
1. **DTW variant ablation study**: Systematically compare softDTW, DTW, and alternative alignment costs (e.g., softDTW-F, soft-DTW-S) to validate the choice of softDTW for metric learning in fine-grained action recognition.

2. **Pseudo-label refinement comparison**: Implement and compare multiple pseudo-label refinement strategies (confidence-only, uncertainty-aware, alignability-score verification, non-parametric classification) to isolate the contribution of each component to the final performance gain.

3. **Cross-dataset generalization test**: Evaluate FinePseudo on additional fine-grained action datasets (e.g., UCF101, HMDB51 fine-grained subsets) and perform cross-dataset validation to assess the framework's robustness and generalizability beyond the four tested datasets.