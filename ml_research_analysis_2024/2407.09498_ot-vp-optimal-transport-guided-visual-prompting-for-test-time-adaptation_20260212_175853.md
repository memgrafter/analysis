---
ver: rpa2
title: 'OT-VP: Optimal Transport-guided Visual Prompting for Test-Time Adaptation'
arxiv_id: '2407.09498'
source_url: https://arxiv.org/abs/2407.09498
tags:
- target
- ot-vp
- prompt
- domain
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OT-VP, a test-time adaptation method that
  aligns source and target domains through optimal transport distance, enabling prompt
  learning at test time. The approach optimizes a universal visual prompt for the
  target domain by minimizing the optimal transport distance, achieving state-of-the-art
  performance across three stylistic datasets (PACS, VLCS, OfficeHome) and one corrupted
  dataset (ImageNet-C).
---

# OT-VP: Optimal Transport-guided Visual Prompting for Test-Time Adaptation

## Quick Facts
- arXiv ID: 2407.09498
- Source URL: https://arxiv.org/abs/2407.09498
- Authors: Yunbei Zhang; Akshay Mehra; Jihun Hamm
- Reference count: 40
- Primary result: State-of-the-art test-time adaptation across stylistic and corrupted datasets using 4 learnable prompt tokens

## Executive Summary
OT-VP introduces a test-time adaptation method that aligns source and target domains through optimal transport distance, enabling prompt learning at test time. The approach optimizes a universal visual prompt for the target domain by minimizing the optimal transport distance, achieving state-of-the-art performance across three stylistic datasets (PACS, VLCS, OfficeHome) and one corrupted dataset (ImageNet-C). OT-VP demonstrates significant improvements in both single-source and multi-source settings, outperforming existing methods with fewer trainable parameters and less computational demand.

## Method Summary
OT-VP addresses test-time domain adaptation by learning a universal visual prompt that aligns source and target domain representations through optimal transport distance. The method freezes a pre-trained ViT-Base model and adds 4 learnable prompt tokens to the input sequence. For each target batch, the model generates representations that are compared to precomputed source representations using OT distance with entropic regularization. The prompt tokens are optimized to minimize this distance while incorporating label information through a penalty term. This approach enables efficient adaptation without modifying the pre-trained model or accessing the training process.

## Key Results
- Achieves state-of-the-art performance across PACS, VLCS, OfficeHome, and ImageNet-C datasets
- Requires only 4 learnable prompt tokens compared to 80-100 in baseline methods
- Demonstrates significant improvements in both single-source and multi-source adaptation settings
- Shows better computational efficiency through offline source representation computation

## Why This Works (Mechanism)

### Mechanism 1
Optimal transport distance between source and target domain representations provides a principled measure of distributional shift that can guide prompt optimization. The OT distance measures the minimal cost of transforming one probability distribution into another, using the geometry of the underlying feature space. By minimizing this distance during prompt optimization, the learned prompts adjust the target domain representations to align with the source domain distribution. Core assumption: The optimal transport distance correlates with downstream task performance and can be computed efficiently using the Sinkhorn algorithm with entropic regularization.

### Mechanism 2
Learning a universal prompt for the entire target domain is more effective than input-specific prompts for addressing domain shift. Instead of generating different prompts for each input image, OT-VP learns a single set of prompt tokens that captures the overall characteristics of the target domain. This universal prompt is optimized to minimize the OT distance across the entire target dataset. Core assumption: The target domain has sufficient consistency across samples to be represented by a single prompt, and the prompt has enough capacity to capture domain-specific features.

### Mechanism 3
Incorporating label information into the optimal transport cost function improves domain alignment compared to using only feature distances. The cost function includes a penalty term for label mismatches between source and target representations, encouraging the prompt to align not just feature distributions but also semantic categories across domains. Core assumption: The pseudo-labels generated by the pre-trained model on target data are sufficiently accurate to guide the alignment process.

## Foundational Learning

- Concept: Optimal Transport Theory
  - Why needed here: Provides the mathematical foundation for measuring and minimizing distributional differences between source and target domains
  - Quick check question: What is the difference between OT distance and simpler metrics like MMD or KL divergence in terms of capturing geometric relationships?

- Concept: Vision Transformer Architecture
  - Why needed here: Understanding how prompts interact with the self-attention mechanism and affect feature representations
  - Quick check question: How does adding prompt tokens to the input sequence influence the attention patterns in subsequent layers?

- Concept: Test-Time Adaptation Principles
  - Why needed here: Understanding the constraints and objectives of adapting pre-trained models without access to source data or training processes
  - Quick check question: What are the key differences between test-time adaptation and traditional domain adaptation approaches?

## Architecture Onboarding

- Component map: Frozen ViT -> 4 learnable prompt tokens -> OT distance computation -> Prompt optimizer (AdamW) -> Target data pipeline

- Critical path:
  1. Load frozen pre-trained ViT
  2. Initialize 4 learnable prompt tokens
  3. For each target batch:
     - Pass through ViT with prompts to get representations
     - Compute pseudo-labels using current prompts
     - Calculate OT distance between source and target representations
     - Backpropagate to update prompts
  4. Use optimized prompts for inference

- Design tradeoffs:
  - Prompt length vs. capacity: 4 tokens chosen for efficiency vs. potentially better performance with more tokens
  - OT computation frequency: Per-batch vs. per-epoch impacts runtime and convergence
  - Label incorporation: Balancing feature alignment with semantic consistency through 位 parameter

- Failure signatures:
  - No improvement over baseline ERM: Indicates prompt optimization not effective
  - Overfitting to target validation set: Suggests too many optimization steps or learning rate too high
  - Degraded performance on source-like samples: May indicate catastrophic forgetting of source knowledge

- First 3 experiments:
  1. Baseline ERM performance on target domain without adaptation
  2. OT-VP with 位=0 (no label information) to isolate feature alignment effects
  3. OT-VP with varying prompt lengths (2, 4, 6 tokens) to assess capacity requirements

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of the hyperparameter 位 in OT-VP affect its performance on different types of domain shifts (e.g., stylistic vs. corrupted datasets)? The paper discusses the impact of 位 on ImageNet-C but does not extensively explore its effects on stylistic datasets.

### Open Question 2
What is the impact of the length of visual prompts on the performance of OT-VP in scenarios with limited target data? The paper mentions that performance varies only slightly with different numbers of prompts, except for l = 2, but does not explore scenarios with limited target data.

### Open Question 3
How does OT-VP perform in online settings with non-stationary target domains where the data distribution changes over time? The paper briefly mentions adaptability to online settings but does not explore scenarios with non-stationary target domains.

### Open Question 4
How does the quality of pseudo labels affect the alignment performance of OT-VP, and what strategies can be employed to improve pseudo label reliability? The paper acknowledges reliance on pseudo labels for OT distance computation and mentions potential misalignment due to inaccurate pseudo-labeling.

## Limitations

- Evaluation scope limited to stylistic domain shifts and synthetic corruptions without testing on more challenging semantic domain shifts or real-world distribution changes
- Assumes pre-trained model's pseudo-labels are sufficiently accurate for guiding alignment without rigorous validation across domains with varying semantic complexity
- Computational efficiency claims rely on offline source representation computation, which may not be feasible in streaming or memory-constrained scenarios

## Confidence

**High Confidence**: The core mechanism of using optimal transport distance for domain alignment is well-grounded in the theoretical literature and the empirical results show consistent improvements across multiple datasets.

**Medium Confidence**: The claim of state-of-the-art performance requires scrutiny, as the paper compares against relatively simple baselines and does not extensively evaluate against the most recent TTA methods.

**Low Confidence**: The robustness of OT-VP to heterogeneous target domains is not well-established, as the paper does not test on datasets with significant within-domain variability or multi-modal distributions.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate OT-VP on a dataset with semantic domain shift (e.g., DomainNet with real-world, sketch, and clipart domains) to assess whether the method generalizes beyond stylistic variations.

2. **Pseudo-label quality analysis**: Systematically measure the accuracy of pseudo-labels generated by the pre-trained model across different target domains and correlate this with OT-VP performance to validate the assumption that pseudo-label quality drives alignment success.

3. **Ablation on OT computation frequency**: Compare the full OT-VP approach against a variant that computes OT distance only once per epoch (rather than per batch) to quantify the trade-off between computational efficiency and adaptation performance.