---
ver: rpa2
title: Modeling language contact with the Iterated Learning Model
arxiv_id: '2406.06878'
source_url: https://arxiv.org/abs/2406.06878
tags:
- language
- languages
- learning
- contact
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Iterated Learning Model is used to examine the resistance of
  languages to change during language contact. A semi-supervised version of the model
  is used to simulate language contact.
---

# Modeling language contact with the Iterated Learning Model

## Quick Facts
- arXiv ID: 2406.06878
- Source URL: https://arxiv.org/abs/2406.06878
- Reference count: 7
- Semi-supervised Iterated Learning Model simulates language contact, showing that languages maintain core traits and can re-emerge when one has an advantage

## Executive Summary
This paper applies the Iterated Learning Model to study how languages resist change during contact with other languages. Using a semi-supervised version of the model, the authors simulate language contact scenarios and find that the same dynamics that drive languages to become expressive and compositional also cause them to maintain their core traits even after mixing. The model shows that when one language has an advantage in contributing to learners' experiences, it often re-emerges after a period of destabilization during contact.

## Method Summary
The authors use a semi-supervised version of the Iterated Learning Model to simulate language contact between two languages. The model represents languages as compositional systems and simulates the learning process of a naive pupil exposed to a mixture of the two languages. The key innovation is the semi-supervised approach, which allows for different degrees of influence from each language on the learner. The authors run multiple simulations varying the mixing ratios and advantages of each language to study the dynamics of language change and stability during contact.

## Key Results
- Languages maintain their core traits during contact due to the same dynamics that drive compositionality and expressivity
- When mixing two mature languages, the resulting language often doesn't resemble either original language
- When one language has an advantage, it often re-emerges after a period of destabilization during contact

## Why This Works (Mechanism)
The Iterated Learning Model captures how languages evolve through repeated cycles of learning and use. In the context of language contact, the model shows that the pressure for languages to be expressive and compositional creates a stabilizing force that resists wholesale change. This is because radical changes would disrupt the established compositional structure that makes the language efficient for communication. When one language has an advantage, its established structure provides a scaffold that guides the re-emergence of its core traits during the contact period.

## Foundational Learning
1. Iterated Learning Model
   - Why needed: Provides a framework for understanding how languages evolve through cultural transmission
   - Quick check: Can simulate the emergence of compositional structure in languages over generations

2. Compositionality in language
   - Why needed: A key property that makes languages efficient and that resists change during contact
   - Quick check: Can be measured by the degree to which complex meanings are expressed as combinations of simpler meanings

3. Semi-supervised learning
   - Why needed: Allows modeling of asymmetric influence between languages during contact
   - Quick check: Can control the relative contribution of each language to the learner's input

## Architecture Onboarding

Component map:
Language A and B -> Semi-supervised ILM -> Mixed language -> New generation of learners

Critical path:
The critical path is the cycle of learning and use that drives language evolution. In the context of language contact, this path is modified by the semi-supervised learning mechanism that allows for asymmetric influence from each language.

Design tradeoffs:
- Simplicity vs. realism: The model abstracts away many complexities of real language contact situations for tractability
- Expressivity vs. interpretability: More complex models might capture more nuances but would be harder to interpret

Failure signatures:
- If the model fails to show any stability during language contact, it suggests that the assumed dynamics are not sufficient to capture resistance to change
- If the model always produces a blend of the two languages, it suggests that the semi-supervised learning mechanism is not effectively capturing asymmetric advantages

First experiments:
1. Vary the mixing ratio of the two languages to study the effect on the stability of core traits
2. Introduce a period of monolingual learning before contact to study the effect on re-emergence of advantaged languages
3. Simulate contact between languages with different levels of compositionality to study the interaction between compositionality and contact dynamics

## Open Questions the Paper Calls Out
None

## Limitations
- Uncertain generalizability to real-world language contact scenarios
- Focus on abstract linguistic properties may not fully capture actual linguistic features that resist change
- Assumptions about learner behavior and transmission mechanisms may oversimplify complex social and cognitive factors

## Confidence
- Language core traits maintenance during contact: Medium
- Re-emergence of advantaged language: High

## Next Checks
1. Conduct simulations with more diverse linguistic features (phonology, morphology, syntax) to assess the model's applicability across different language subsystems.
2. Compare model predictions with empirical data from documented language contact situations, focusing on cases where one language is known to have had an advantage.
3. Develop a more sophisticated learner model that incorporates social and cognitive factors influencing language acquisition and use during contact situations.