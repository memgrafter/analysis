---
ver: rpa2
title: Preserving Knowledge in Large Language Model with Model-Agnostic Self-Decompression
arxiv_id: '2406.11354'
source_url: https://arxiv.org/abs/2406.11354
tags:
- data
- arxiv
- tg-sft
- preprint
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in Large Language
  Models (LLMs) and Multimodal Large Language Models (MLLMs) during supervised fine-tuning.
  The authors introduce Tree Generation (TG), a model-agnostic self-decompression
  method that decompresses knowledge within LLMs into the training corpus.
---

# Preserving Knowledge in Large Language Model with Model-Agnostic Self-Decompression

## Quick Facts
- arXiv ID: 2406.11354
- Source URL: https://arxiv.org/abs/2406.11354
- Authors: Zilun Zhang; Yutao Sun; Tiancheng Zhao; Leigang Sha; Ruochen Xu; Kyusong Lee; Jianwei Yin
- Reference count: 16
- One-line primary result: TG-SFT (Balance-Tree) restores LLM benchmark performance from 50.60 to 53.47, slightly higher than LLaMA2-chat backbone while maintaining comparable MLLM performance

## Executive Summary
This paper addresses catastrophic forgetting in Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) during supervised fine-tuning. The authors introduce Tree Generation (TG), a model-agnostic self-decompression method that decompresses knowledge within LLMs into the training corpus. By incorporating the decompressed corpus during supervised fine-tuning for MLLMs, they significantly reduce the forgetting problem.

The primary result demonstrates that using synthetic data generated from TG, an LLM can preserve its original knowledge and perform on par with using human-generated high-quality data. Specifically, TG-SFT (Balance-Tree) restores the average score of the LLM benchmark from 50.60 to 53.47, which is slightly higher than the LLaMA2-chat backbone's performance, while maintaining comparable performance on the MLLM benchmarks.

## Method Summary
The method introduces Tree Generation (TG), a model-agnostic self-decompression technique that generates synthetic data to preserve knowledge during supervised fine-tuning. The approach uses a tree-based expansion strategy to create structured dialogue sequences, with variants including Balance-Tree and Wide-Tree for different exploration strategies. The method requires no additional manual prompts and can be applied to any LLM. For MLLMs, the approach involves aligning visual projectors using LAION-CC-SBU dataset and conducting SFT on LLaVA using Mix 665K dataset plus synthetic data generated through TG-SFT.

## Key Results
- TG-SFT (Balance-Tree) restores LLM benchmark average score from 50.60 to 53.47
- Performance slightly exceeds LLaMA2-chat backbone while maintaining MLLM benchmark comparability
- Synthetic data generation through TG-SFT preserves original knowledge effectively during fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The self-decompression method preserves knowledge by reminding the model of its original training data through synthetic data generation.
- Mechanism: By generating synthetic data that captures the original knowledge of the LLM, the model is exposed to a "snapshot" of its initial understanding during fine-tuning, preventing catastrophic forgetting.
- Core assumption: LLMs retain their original knowledge in a compressible form that can be extracted through structured generation.
- Evidence anchors:
  - [abstract] The paper states that the self-decompression method decompresses knowledge within LLMs into the training corpus, significantly reducing the forgetting problem.
  - [section] The paper explains that the process of synthesizing data with LLMs is considered a decompression process, aiming to preserve knowledge from LLMs by taking a snapshot of the LLMs and using them as offline data generators.
- Break condition: If the synthetic data generated does not accurately represent the original knowledge or if the model's capacity to retain knowledge diminishes over time, the effectiveness of the self-decompression method could be compromised.

### Mechanism 2
- Claim: The tree generation structure allows for diverse and comprehensive dialogue sequences, enhancing the model's ability to retain knowledge.
- Mechanism: The tree-based expansion strategy in TG-SFT generates structured dialogue sequences with varying depths and breadths, ensuring diverse topic exploration and detailed follow-up inquiries.
- Core assumption: A tree structure with adjustable branching factors can effectively capture and represent the breadth and depth of knowledge in a dialogue context.
- Evidence anchors:
  - [abstract] The paper introduces Tree Generation (TG) as a model-agnostic self-decompression method that decompresses knowledge into the training corpus.
  - [section] The methodology section describes the tree-based expansion strategy and its role in optimizing dialogue generation by varying the breadth and depth of the generated dialogue tree.
- Break condition: If the tree structure becomes too complex or the branching factors are not optimally set, the generation process might become inefficient or fail to capture the necessary diversity.

### Mechanism 3
- Claim: The model-agnostic nature of the self-decompression method allows it to be universally applicable across different LLMs, enhancing its effectiveness in preserving knowledge.
- Mechanism: By designing the self-decompression method to be independent of specific model architectures, it can be applied to any LLM, ensuring broad applicability and effectiveness in preserving knowledge across various models.
- Core assumption: The self-decompression process can be standardized and applied universally without being tied to specific model parameters or architectures.
- Evidence anchors:
  - [abstract] The paper emphasizes that the TG method is universally applicable to any LLMs for SFT, requiring no additional manual prompt.
  - [section] The methodology section highlights the model-agnostic nature of the TG algorithm, making it applicable to any LLM.
- Break condition: If the self-decompression process requires model-specific adjustments or if the synthetic data generation is not effective for certain LLM architectures, the universal applicability of the method could be limited.

## Foundational Learning

- Concept: Catastrophic Forgetting
  - Why needed here: Understanding catastrophic forgetting is crucial to grasp the problem that TG-SFT aims to solve.
  - Quick check question: What is catastrophic forgetting, and why is it a significant issue in training LLMs?

- Concept: Tree-based Data Structures
  - Why needed here: Knowledge of tree structures is essential to understand how TG-SFT organizes and generates dialogue sequences.
  - Quick check question: How do tree structures facilitate the organization of data in a hierarchical manner?

- Concept: Synthetic Data Generation
  - Why needed here: Understanding synthetic data generation is key to comprehending how TG-SFT creates training data that preserves original knowledge.
  - Quick check question: What are the benefits and challenges of using synthetic data in training LLMs?

## Architecture Onboarding

- Component map:
  - Tree Generation (TG) Algorithm -> Tree-Generation for Supervised Fine-Tuning (TG-SFT) -> LLaMA2-chat Model
  - Visual Projector -> LAION-CC-SBU dataset -> LLaVA MLLM

- Critical path:
  1. Initialize the TG-SFT with a general system prompt.
  2. Generate synthetic data using the tree-based expansion strategy.

- Design tradeoffs: Balance between tree depth and breadth affects knowledge coverage vs. generation efficiency.

- Failure signatures: Poor synthetic data quality leads to performance degradation; insufficient training data or improper mixing ratios cause inadequate knowledge preservation.

- First experiments:
  1. Generate synthetic data using Balance-Tree and Wide-Tree variants with different depth configurations.
  2. Compare synthetic data quality metrics (diversity, coherence) against human-generated data.
  3. Evaluate knowledge preservation on LLM benchmarks after SFT with varying ratios of synthetic to real data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the TG algorithm perform when applied to post-pretraining scenarios compared to supervised fine-tuning?
- Basis in paper: [explicit] The paper mentions that TG-PT (Tree-Generation for Post-PreTraining) is a variant of TG-SFT designed for post-pretraining, but states that a more general version is needed for future work.
- Why unresolved: The current experiments focus primarily on TG-SFT for supervised fine-tuning. While TG-PT shows promise in initial experiments, the paper acknowledges that a more comprehensive evaluation of TG-PT for post-pretraining is needed.
- What evidence would resolve it: Conducting extensive experiments comparing the performance of TG-PT with traditional post-pretraining methods across various domains and model scales would provide insights into its effectiveness and generalizability.

### Open Question 2
- Question: Can the TG algorithm effectively generate high-quality synthetic data for specialized domains like mathematics or law?
- Basis in paper: [inferred] The paper mentions that initial attempts to synthesize data for mathematics resulted in poor quality, with the model generating incorrect calculations and derivations.
- Why unresolved: The paper acknowledges the challenge of generating high-quality synthetic data for specific domains but does not provide a solution or detailed analysis of the underlying issues.
- What evidence would resolve it: Developing and testing a modified version of TG that incorporates domain-specific knowledge and constraints could potentially improve the quality of synthetic data for specialized fields.

### Open Question 3
- Question: What are the long-term effects of using synthetic data generated by TG on the performance and behavior of large language models?
- Basis in paper: [inferred] While the paper demonstrates that TG can help preserve knowledge during fine-tuning, it does not explore the potential long-term consequences of using synthetic data.
- Why unresolved: The experiments conducted are limited in duration and scope, focusing on immediate performance improvements rather than long-term effects.
- What evidence would resolve it: Conducting longitudinal studies tracking the performance and behavior of models trained with TG-generated data over extended periods would provide insights into potential issues such as data drift, overfitting, or the emergence of unintended biases.

## Limitations

- Generalization across model architectures remains unverified beyond LLaMA2-chat and LLaVA
- Synthetic data quality evaluation lacks rigorous analysis of semantic depth and potential hallucinated content
- Long-term knowledge retention through multiple fine-tuning stages is not investigated

## Confidence

- High confidence: The claim that TG-SFT can restore LLM benchmark performance from 50.60 to 53.47 is well-supported by the experimental results presented.
- Medium confidence: The assertion that TG-SFT performs "on par" with human-generated high-quality data is supported by relative comparisons but lacks absolute quality metrics for both data sources.
- Low confidence: The claim about universal applicability across all LLMs and MLLMs without additional manual prompts requires more diverse model testing.

## Next Checks

1. **Cross-architecture validation**: Test the TG-SFT method on at least two additional model families (e.g., Mistral, Mixtral, or open-source GPT-2 variants) to verify true model-agnostic behavior and identify any architecture-specific limitations.

2. **Synthetic data quality audit**: Conduct a comprehensive analysis comparing synthetic data generated by TG-SFT against human-generated data using metrics such as semantic coherence, factual accuracy, diversity coverage, and hallucination rates. This should include both automated metrics and human evaluation.

3. **Longitudinal forgetting analysis**: Implement a multi-stage fine-tuning protocol where models undergo successive fine-tuning tasks with TG-SFT protection. Track knowledge retention across multiple tasks over time to evaluate the durability of the self-decompression mechanism under realistic deployment conditions.