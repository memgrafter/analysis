---
ver: rpa2
title: Federated Learning of Socially Appropriate Agent Behaviours in Simulated Home
  Environments
arxiv_id: '2403.07586'
source_url: https://arxiv.org/abs/2403.07586
tags:
- learning
- each
- data
- fedavg
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling social robots to
  learn socially appropriate behaviors in distributed, real-world environments. It
  introduces a novel federated learning (FL) benchmark using the MANNERS-DB dataset,
  where robots predict the social appropriateness of actions based on scene descriptors.
---

# Federated Learning of Socially Appropriate Agent Behaviours in Simulated Home Environments

## Quick Facts
- arXiv ID: 2403.07586
- Source URL: https://arxiv.org/abs/2403.07586
- Authors: Saksham Checker; Nikhil Churamani; Hatice Gunes
- Reference count: 38
- One-line primary result: FedAvg is the most robust FL strategy for multi-label regression on MANNERS-DB; rehearsal-based FCL methods outperform regularization-based approaches.

## Executive Summary
This paper introduces a federated learning (FL) benchmark for socially appropriate robot behaviors using the MANNERS-DB dataset, where robots predict the social appropriateness of actions based on scene descriptors. The study evaluates multiple FL strategies, finding that Federated Averaging (FedAvg) is the most robust approach for this multi-label regression task. Additionally, it proposes a Federated Continual Learning (FCL) benchmark, adapting FedAvg with regularization-based continual learning methods. The results show that rehearsal-based methods, particularly Naive Rehearsal (NR), perform best in incremental learning settings. Overall, the work provides a foundation for distributed learning of socially appropriate robot behaviors, with implications for real-world deployment. Future work includes end-to-end learning from scene renders and more resource-efficient generative replay methods.

## Method Summary
The paper addresses the challenge of enabling social robots to learn socially appropriate behaviors in distributed, real-world environments. It introduces a novel federated learning (FL) benchmark using the MANNERS-DB dataset, where robots predict the social appropriateness of actions based on scene descriptors. The study evaluates multiple FL strategies, finding that Federated Averaging (FedAvg) is the most robust approach for this multi-label regression task. Additionally, it proposes a Federated Continual Learning (FCL) benchmark, adapting FedAvg with regularization-based continual learning methods. The results show that rehearsal-based methods, particularly Naive Rehearsal (NR), perform best in incremental learning settings. Overall, the work provides a foundation for distributed learning of socially appropriate robot behaviors, with implications for real-world deployment. Future work includes end-to-end learning from scene renders and more resource-efficient generative replay methods.

## Key Results
- Federated Averaging (FedAvg) emerges as the most robust FL strategy for multi-label regression on MANNERS-DB.
- Rehearsal-based Federated Continual Learning (FCL) methods, particularly Naive Rehearsal (NR), outperform regularization-based approaches in incremental learning settings.
- Data augmentation with Gaussian noise improves both FL and FCL performance by increasing effective sample size per client.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Federated Averaging (FedAvg) is robust for multi-label regression on MANNERS-DB due to its simplicity and ability to handle heterogeneous client data without overfitting.
- Mechanism: FedAvg aggregates model weights across clients after each round, averaging the updates to form a global model. This averaging smooths out client-specific biases and prevents any single client from dominating the learning process, which is critical in socially diverse environments.
- Core assumption: The dataset is sufficiently small and diverse that averaging weights does not lose critical client-specific information.
- Evidence anchors:
  - [abstract] "Federated Averaging (FedAvg) of weights emerges as a robust FL strategy"
  - [section] "Our evaluations presents a multi-label regression problem which is different from classification where FedAvg offers a relatively simple and robust learning methodology"
- Break condition: If client data becomes highly non-IID with extreme outliers, averaging could dilute important patterns, requiring more adaptive aggregation.

### Mechanism 2
- Claim: Naive Rehearsal (NR) outperforms regularization-based CL methods in FCL because it directly preserves task 1 samples in a replay buffer, avoiding catastrophic forgetting.
- Mechanism: NR maintains a memory buffer of previously seen samples and interleaves them with new task data during training. This simulates i.i.d. conditions locally, allowing the model to retain knowledge of socially appropriate actions from earlier contexts.
- Core assumption: The replay buffer can store a sufficient fraction of task 1 samples without exceeding memory constraints, and the dataset is small enough for this to be feasible.
- Evidence anchors:
  - [abstract] "rehearsal-based FCL enables incrementally learning the social appropriateness of robot actions, across contextual splits"
  - [section] "rehearsal-based NR approach performs better than regularisation-based approaches after witnessing both tasks as it maintains a memory buffer to store previously seen task 1 samples"
- Break condition: If the dataset grows large or high-dimensional (e.g., images), maintaining a full replay buffer becomes infeasible, necessitating generative replay or other memory-efficient methods.

### Mechanism 3
- Claim: Data augmentation improves both FL and FCL performance by increasing the effective sample size per client, especially when client data is limited.
- Mechanism: Gaussian noise is added to scene descriptors, creating synthetic variations that expose the model to a broader range of input patterns. This helps the model generalize across different social contexts and user preferences.
- Core assumption: The noise level (μ=0, σ=0.01) is small enough to preserve meaningful features while providing sufficient variation to improve robustness.
- Evidence anchors:
  - [section] "we also benchmark the different FL and FCL methods using data augmentation as well. For this, a Gaussian noise (μ = 0, σ = 0.01) is added to each feature."
  - [section] "With the relatively low number of samples in the MANNERS-DB dataset, almost all the samples from task 1 can be maintained in the memory buffer"
- Break condition: If augmentation noise is too high, it may distort the semantic meaning of scene descriptors, leading to degraded performance.

## Foundational Learning

- Concept: Federated Learning (FL)
  - Why needed here: Enables multiple robots to learn socially appropriate behaviors locally without sharing raw data, preserving privacy while allowing knowledge sharing.
  - Quick check question: What is the key difference between FL and centralized learning in terms of data privacy?

- Concept: Continual Learning (CL)
  - Why needed here: Allows robots to adapt to new social contexts (e.g., circle vs. arrow tasks) without forgetting previously learned norms, critical for open-world deployment.
  - Quick check question: How does CL prevent catastrophic forgetting when learning new tasks sequentially?

- Concept: Multi-label Regression
  - Why needed here: The task requires predicting social appropriateness scores for 8 different robot actions simultaneously, which is naturally framed as a regression problem over multiple outputs.
  - Quick check question: Why is multi-label regression more appropriate than classification for this use case?

## Architecture Onboarding

- Component map: Input → 29-dimensional scene descriptor → MLP (2x16 FC + BN) → 8-output regression head → social appropriateness scores
- Critical path: Data augmentation → client training → FedAvg aggregation → evaluation
- Design tradeoffs: FedAvg simplicity vs. FedProx/FedBN adaptability; NR memory usage vs. regularization efficiency
- Failure signatures: Low PCC scores indicate poor correlation between predicted and actual appropriateness; high RMSE suggests large prediction errors
- First 3 experiments:
  1. Run FedAvg on MANNERS-DB without augmentation to establish baseline.
  2. Add Gaussian noise augmentation and compare performance.
  3. Implement FedAvg+EWC and FedAvg+NR for FCL, evaluate forgetting after task 2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different Federated Learning (FL) aggregation strategies perform when applied to multi-label regression tasks for predicting social appropriateness of robot actions, and what factors influence their effectiveness?
- Basis in paper: [explicit] The paper compares FedAvg, FedBN, FedProx, FedOpt, and FedDistill for learning social appropriateness in MANNERS-DB, showing FedAvg as the most robust approach.
- Why unresolved: While the paper evaluates multiple FL strategies, it does not deeply analyze the factors (e.g., data heterogeneity, task complexity, client distribution) that influence their effectiveness, nor does it explore other potential aggregation strategies.
- What evidence would resolve it: A systematic study varying data distributions, task complexities, and client numbers while evaluating different FL strategies, including newer methods like FedNova or FedProx with adaptive weighting.

### Open Question 2
- Question: How does Federated Continual Learning (FCL) with rehearsal-based methods compare to regularization-based methods in maintaining long-term knowledge retention when learning socially appropriate robot behaviors across multiple tasks?
- Basis in paper: [explicit] The paper shows that rehearsal-based methods like Naive Rehearsal (NR) outperform regularization-based methods in FCL, but notes NR's high memory requirements as a limitation.
- Why unresolved: The paper does not explore trade-offs between performance and resource efficiency in depth, nor does it investigate hybrid approaches or alternative memory-efficient replay methods.
- What evidence would resolve it: Experiments comparing FCL methods under varying memory constraints, including generative replay techniques or hybrid regularization-rehearsal approaches, across multiple incremental tasks.

### Open Question 3
- Question: How can end-to-end learning from raw scene renders improve the prediction of social appropriateness compared to using pre-extracted feature descriptors in Federated and Federated Continual Learning settings?
- Basis in paper: [explicit] The authors propose future work on end-to-end learning from scene renders rather than using 29-dimensional pre-extracted descriptors.
- Why unresolved: The paper only evaluates pre-extracted features, leaving the question of whether richer visual information from raw renders would enhance learning and generalization.
- What evidence would resolve it: Direct comparison of FL and FCL performance using raw scene renders versus pre-extracted features, including ablation studies on feature representation impact.

## Limitations
- The MANNERS-DB dataset contains only ~1000 scenes, which may not be representative of the full diversity of real-world social scenarios.
- The study focuses on accuracy metrics but does not address the computational overhead of FL and FCL methods, which is critical for real-time robot deployment.
- While FL preserves data privacy, the study does not explicitly address potential privacy risks from model updates or the need for differential privacy mechanisms.

## Confidence
- High Confidence: FedAvg's effectiveness as a baseline FL method and NR's superiority in FCL are well-supported by the experimental results and align with established ML principles.
- Medium Confidence: The superiority of FedAvg over other FL methods (FedBN, FedProx, etc.) is plausible but may be dataset-specific; performance could vary with more heterogeneous client data.
- Medium Confidence: The proposed FCL benchmark is novel and theoretically sound, but its practical utility in real-world robotic systems requires further validation.

## Next Checks
1. Validate FedAvg and NR performance on a larger, more diverse dataset (e.g., with 10,000+ scenes) to assess scalability and generalization.
2. Test the FCL framework on a physical robot in a real home environment to evaluate robustness to sensor noise and dynamic social interactions.
3. Implement and compare generative replay methods (e.g., GAN-based) against NR to assess trade-offs between memory usage and performance in high-dimensional data scenarios.