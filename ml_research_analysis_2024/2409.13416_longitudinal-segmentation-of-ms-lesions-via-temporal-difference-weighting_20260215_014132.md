---
ver: rpa2
title: Longitudinal Segmentation of MS Lesions via Temporal Difference Weighting
arxiv_id: '2409.13416'
source_url: https://arxiv.org/abs/2409.13416
tags:
- longitudinal
- segmentation
- difference
- weighting
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of accurate segmentation of
  Multiple Sclerosis (MS) lesions in longitudinal MRI scans, which is crucial for
  monitoring disease progression and treatment efficacy. The authors propose a novel
  approach that explicitly incorporates temporal differences between baseline and
  follow-up scans through a unique architectural inductive bias called the Difference
  Weighting Block.
---

# Longitudinal Segmentation of MS Lesions via Temporal Difference Weighting

## Quick Facts
- arXiv ID: 2409.13416
- Source URL: https://arxiv.org/abs/2409.13416
- Reference count: 34
- Superior Dice Score and 95% Hausdorff Distance for lesion segmentation in longitudinal MRI

## Executive Summary
This paper addresses the challenge of accurate segmentation of Multiple Sclerosis (MS) lesions in longitudinal MRI scans, which is crucial for monitoring disease progression and treatment efficacy. The authors propose a novel approach that explicitly incorporates temporal differences between baseline and follow-up scans through a unique architectural inductive bias called the Difference Weighting Block. This block merges features from two timepoints, emphasizing changes between scans, and is integrated into a shared encoder-decoder architecture. Extensive experiments on two public MS datasets demonstrate that the proposed method outperforms state-of-the-art single timepoint baselines and existing longitudinal methods.

## Method Summary
The method uses a shared encoder-decoder U-Net architecture with a novel Difference Weighting Block (DWB) that merges baseline and follow-up features by emphasizing temporal differences. The DWB computes the feature difference between current and prior scan, normalizes it via Instance Normalization, and uses it as a weighting factor for current image features. The model is trained with SGD optimizer, momentum 0.99, learning rate 0.01 with polynomial decay, batch size 2, and patches of 128×160×128. It uses z-score normalization and crops images to the largest nonzero bounding box per patient.

## Key Results
- Superior Dice Score and 95% Hausdorff Distance for lesion segmentation compared to state-of-the-art baselines
- Improved lesion-based F1 score, which is clinically more relevant for lesion detection
- Cross-dataset generalization, indicating effectiveness on unseen data from the ISBI 2015 challenge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Difference Weighting Block explicitly emphasizes temporal differences between baseline and follow-up scans, improving lesion segmentation accuracy.
- Mechanism: By computing the feature difference between current and prior images, normalizing it via InstanceNorm, and using it as a weighting factor for current image features, the block guides the network to focus on regions of change.
- Core assumption: Temporal changes between scans are informative for lesion detection and segmentation.
- Evidence anchors:
  - [abstract]: "Our method introduces explicit inductive bias to leverage the information surplus from the additional baseline scan."
  - [section]: "The Difference Weighting Block acts as a mechanism to weigh and incorporate the temporal differences between images..."
  - [corpus]: Weak evidence; no direct comparisons found in the corpus for temporal difference weighting in MS lesion segmentation.
- Break condition: If temporal changes are not meaningful (e.g., due to scan misalignment or minimal lesion progression), the weighting could become noisy or misleading.

### Mechanism 2
- Claim: Shared encoder architecture allows the model to learn common and scan-specific representations simultaneously.
- Mechanism: Both baseline and follow-up images pass through the same encoder, enabling the network to learn joint features that capture anatomical structures while the Difference Weighting Block highlights temporal discrepancies.
- Core assumption: A shared representation space allows effective comparison of features across timepoints.
- Evidence anchors:
  - [section]: "Similar to a single timepoint method, our model Fθ is designed to predict a segmentation mask... However, it additionally incorporates information from a prior scan Xp by co-learning both representations."
  - [section]: "We achieve this by passing both the baseline and follow-up images through a shared encoder."
  - [corpus]: No direct evidence in the corpus; this is a standard architectural choice in multimodal learning.
- Break condition: If the encoder fails to learn a common representation (e.g., due to large domain shifts between timepoints), the difference computation becomes unreliable.

### Mechanism 3
- Claim: Late fusion of features (after encoding) is more effective than early fusion (channel-wise concatenation) for leveraging longitudinal information.
- Mechanism: By merging features in latent space via the Difference Weighting Block, the model can more effectively integrate temporal information compared to simply concatenating channels.
- Core assumption: The latent space contains richer information for temporal comparison than raw concatenated channels.
- Evidence anchors:
  - [section]: "Instead of the early fusion of longitudinal scans in the form of channel-wise concatenation, we propose a later fusion of features from the two timepoints."
  - [section]: "Our findings emphasize that leveraging representational differences outperforms naive channel-wise concatenation..."
  - [corpus]: No direct evidence in the corpus; this is a design choice supported by the paper's ablation study.
- Break condition: If the encoder does not produce meaningful features, late fusion offers no advantage over early fusion.

## Foundational Learning

- Concept: Understanding of encoder-decoder architectures (e.g., U-Net) and their skip connections.
  - Why needed here: The model uses a shared encoder-decoder architecture with skip connections that are processed by the Difference Weighting Block.
  - Quick check question: What is the role of skip connections in a U-Net architecture?
- Concept: Knowledge of feature normalization techniques (e.g., Instance Normalization).
  - Why needed here: The Difference Weighting Block applies Instance Normalization to the feature difference to create a weighting map.
  - Quick check question: How does Instance Normalization differ from Batch Normalization?
- Concept: Familiarity with medical image segmentation metrics (Dice score, Hausdorff distance, lesion-based F1 score).
  - Why needed here: These metrics are used to evaluate the model's performance on MS lesion segmentation.
  - Quick check question: Why is lesion-based F1 score clinically more relevant than Dice score for lesion detection?

## Architecture Onboarding

- Component map: Baseline + Follow-up → Shared Encoder → Feature Extraction → Difference Weighting Block → Weighted Features → Decoder → Segmentation Mask
- Critical path: Baseline → Shared Encoder → Feature Extraction → Difference Weighting Block → Weighted Features → Decoder → Segmentation Mask
- Design tradeoffs:
  - Late fusion vs. early fusion: Late fusion allows more complex integration of temporal information but may require more parameters.
  - Shared vs. separate encoders: Shared encoders enforce consistency but may limit the model's ability to capture scan-specific details.
- Failure signatures:
  - Poor performance on lesion detection: May indicate the Difference Weighting Block is not effectively highlighting changes.
  - High Hausdorff distance: Could suggest misalignment between baseline and follow-up scans or poor boundary delineation.
- First 3 experiments:
  1. Train the model with only the Difference Weighting Block disabled (equivalent to channel-wise concatenation) to confirm the benefit of the proposed mechanism.
  2. Train the model with only one timepoint (follow-up only) to establish a baseline for single-timepoint performance.
  3. Train the model with swapped timepoints (using follow-up as "baseline" and baseline as "follow-up") to test the symmetry of the approach.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Difference Weighting Block generalize to other longitudinal medical imaging tasks beyond MS lesion segmentation, such as tumor growth tracking or organ volume changes?
- Basis in paper: [inferred] The paper demonstrates effectiveness on MS lesion segmentation but only tests on two MS datasets. The authors mention future work on "additional diseases" but don't explore other imaging tasks.
- Why unresolved: The study is limited to MS lesions, so performance on other longitudinal tasks remains unknown.
- What evidence would resolve it: Testing the Difference Weighting Block on other longitudinal medical imaging datasets (e.g., tumor progression, cardiac imaging, or neurodegenerative diseases) would demonstrate its broader applicability.

### Open Question 2
- Question: How does the Difference Weighting Block perform when more than two timepoints are available, such as in datasets with three or more follow-up scans?
- Basis in paper: [inferred] The method is designed for baseline-follow-up pairs, but the Ljubljana dataset contains up to four timepoints. The paper doesn't explore multi-timepoint extensions.
- Why unresolved: The current architecture only handles two timepoints, so its behavior with longer temporal sequences is untested.
- What evidence would resolve it: Experiments using datasets with three or more timepoints (e.g., processing all timepoints sequentially or using attention mechanisms across multiple differences) would clarify performance gains or limitations.

### Open Question 3
- Question: What is the impact of different registration methods on the performance of the Difference Weighting Block, and does it require perfect alignment between timepoints?
- Basis in paper: [explicit] The authors use affine registration (FSL FLIRT) but note that registration quality could affect results. They don't test alternative registration strategies or quantify sensitivity to alignment errors.
- Why unresolved: The paper assumes good registration but doesn't analyze how registration quality affects the temporal difference features.
- What evidence would resolve it: Comparing results using different registration methods (rigid, affine, non-linear) or synthetically degrading registration quality would show the block's robustness to alignment errors.

## Limitations
- Limited sample size with only 67 follow-up scans for Ljubljana and 21 for ISBI 2015 datasets
- Assumes good alignment between timepoints through affine registration, which may not handle complex anatomical changes
- Does not validate against clinical outcomes to establish practical utility in clinical settings

## Confidence

- High confidence in the architectural novelty and general effectiveness of the Difference Weighting Block for emphasizing temporal changes
- Medium confidence in the clinical relevance of improved lesion-based F1 score, as the study does not validate against clinical outcomes
- Medium confidence in cross-dataset generalization given the limited sample size in the ISBI dataset

## Next Checks
1. Evaluate the model's performance when timepoints are misaligned or when significant anatomical changes occur between scans to test the robustness of the Difference Weighting Block
2. Conduct a larger-scale study with more patients and multiple follow-up timepoints to validate the scalability and clinical utility of the approach
3. Compare the model's performance against clinicians in a reader study to establish its practical value in clinical settings