---
ver: rpa2
title: 'Mirage: A Multi-Level Superoptimizer for Tensor Programs'
arxiv_id: '2405.05751'
source_url: https://arxiv.org/abs/2405.05751
tags:
- graph
- mirage
- block
- tensor
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Mirage is a multi-level superoptimizer for tensor programs that
  uses a novel hierarchical graph representation to capture optimizations at kernel,
  thread block, and thread levels of GPU compute hierarchy. It introduces abstract
  expressions to prune the search space while providing optimality guarantees, and
  uses probabilistic equivalence verification over finite fields to ensure correctness.
---

# Mirage: A Multi-Level Superoptimizer for Tensor Programs

## Quick Facts
- arXiv ID: 2405.05751
- Source URL: https://arxiv.org/abs/2405.05751
- Reference count: 40
- Primary result: Achieves up to 3.5× speedup over FlashDecoding for group-query attention and 3× speedup for multi-layer perceptrons

## Executive Summary
Mirage introduces a multi-level superoptimizer for tensor programs that automatically discovers novel optimizations by exploring the space of GPU kernel implementations. It uses a hierarchical graph representation (μGraphs) to capture optimizations at kernel, thread block, and thread levels, enabling joint optimization of algebraic and schedule transformations. The system introduces abstract expressions to prune the search space while providing optimality guarantees for Lax programs, and employs probabilistic equivalence verification over finite fields to ensure correctness. Evaluated on 12 DNN benchmarks, Mirage achieves significant speedups over existing approaches including FlashAttention, TensorRT, and Triton.

## Method Summary
Mirage is a superoptimizer that takes tensor programs as input and outputs optimized GPU implementations. It partitions programs into Lax subprograms and explores a space of μGraphs representing different implementations at kernel, block, and thread levels. The system uses abstract expressions to prune the search space by formalizing equivalence and subexpression relationships, while probabilistic equivalence verification over finite fields (Z_p and Z_q) ensures correctness. μGraphs are optimized for layout across the GPU hierarchy, and the best implementation is selected based on execution time. The approach automatically discovers optimizations combining algebraic transformations, schedule transformations, and custom kernel generation.

## Key Results
- Achieves 2.2× speedup over FlashDecoding for group-query attention (GQA)
- Achieves 3× speedup for multi-layer perceptrons (MLP) through automatic fusion
- Outperforms existing systems by up to 3.5× on 12 DNN benchmarks including attention mechanisms, MLPs, and mixture-of-experts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Abstract expressions enable effective pruning of the μGraph search space while preserving optimality for Lax programs.
- Mechanism: Abstract expressions abstract tensor operations into uninterpreted functions over integers, allowing pruning of graph prefixes that cannot contribute to the desired computation via SMT-based subexpression checks.
- Core assumption: For Lax programs, two graphs with equivalent abstract expressions are functionally equivalent (soundness of the abstraction).
- Evidence anchors:
  - [abstract] "Mirage introduces a pruning technique based on abstraction that significantly reduces the search space and provides a certain optimality guarantee."
  - [section 4.3] "We use abstract expressions to prune the search space of μGraphs by formalizing two relations over abstract expressions: equivalence and abstract subexpression."
  - [corpus] No direct evidence found in related papers; this appears to be a novel technique specific to Mirage.
- Break condition: If the Lax program contains operations outside the supported abstract expression theory (e.g., complex non-linear operations not supported by the axioms), the pruning may incorrectly exclude valid solutions.

### Mechanism 2
- Claim: Probabilistic equivalence verification over finite fields provides strong correctness guarantees for Lax programs.
- Mechanism: Random testing over two finite fields Z_p and Z_q (where q divides p-1) can verify equivalence of Lax programs with arbitrarily low error probability.
- Core assumption: The Lax fragment's restrictions (multi-linear operators, division, at most one exponentiation per path) ensure that random testing over finite fields has strong theoretical guarantees.
- Evidence anchors:
  - [abstract] "Mirage introduces a probabilistic equivalence verification procedure with strong theoretical guarantees."
  - [section 5.1] "We develop a random testing technique that also supports division and exponentiation, which are needed for many DNN optimizations."
  - [section 5.2] "Theorem 3 shows that this process can yield an arbitrarily low error rate."
- Break condition: If the Lax program contains operations that violate the theoretical assumptions (e.g., more than one exponentiation along a path), the probabilistic guarantees may not hold.

### Mechanism 3
- Claim: The hierarchical μGraph representation captures optimizations at all levels of the GPU compute hierarchy.
- Mechanism: μGraphs contain kernel, block, and thread-level graphs that uniformly represent computation across the GPU hierarchy, enabling joint optimization of algebraic and schedule transformations.
- Core assumption: All meaningful GPU optimizations can be expressed through the hierarchical graph structure with grid dimensions, for-loop dimensions, and their mappings.
- Evidence anchors:
  - [abstract] "A key idea in Mirage is μGraphs, a uniform representation of tensor programs at the kernel, thread block, and thread levels of the GPU compute hierarchy."
  - [section 2] "By uniformly treating the kernel, thread block, and thread levels, μGraphs can capture both algebraic and schedule transformations."
  - [section 3] "Figure 4c shows the best μGraph automatically discovered by Mirage for computing GQA."
- Break condition: If important optimizations require representations beyond the hierarchical graph structure (e.g., optimizations spanning multiple kernels not captured by the graph), the representation may be insufficient.

## Foundational Learning

- Concept: GPU memory hierarchy and compute hierarchy
  - Why needed here: Understanding how μGraphs map to GPU architecture is crucial for comprehending the optimization opportunities and the hierarchical representation.
  - Quick check question: What are the three levels of the GPU compute hierarchy that μGraphs represent, and what type of memory is associated with each level?

- Concept: Abstract interpretation and SMT solving
  - Why needed here: The pruning mechanism relies on abstract expressions and SMT solving to determine subexpression relationships.
  - Quick check question: How does the abstract expression technique abstract tensor operations, and what role does the SMT solver play in the pruning process?

- Concept: Polynomial identity testing and finite field arithmetic
  - Why needed here: The probabilistic equivalence verification relies on polynomial identity testing over finite fields.
  - Quick check question: Why does Mirage use two finite fields (Z_p and Z_q) instead of one for equivalence verification, and what mathematical property must hold between p and q?

## Architecture Onboarding

- Component map:
  Frontend -> Lax program partitioning and input processing -> μGraph Generator -> Exhaustive search with pruning via abstract expressions -> Probabilistic Equivalence Verifier -> Random testing over finite fields -> μGraph Optimizer -> Layout optimization across kernel, block, and thread levels -> Backend -> GPU kernel generation and execution

- Critical path:
  1. Input tensor program partitioning into Lax subprograms
  2. μGraph generation with abstract expression pruning
  3. Probabilistic equivalence verification
  4. Layout optimization and selection of best μGraph
  5. GPU kernel generation and execution

- Design tradeoffs:
  - Search space vs. optimality: Larger search spaces may find better optimizations but increase computation time
  - Abstraction precision vs. pruning effectiveness: More precise abstractions may prune less effectively
  - Finite field size vs. verification accuracy: Larger fields increase verification accuracy but may impact performance

- Failure signatures:
  - No valid μGraph found: Indicates issues with the abstract expression pruning or Lax program restrictions
  - Equivalence verification failures: Suggests problems with the random testing implementation or Lax program restrictions
  - Poor performance improvements: May indicate suboptimal layout optimization or insufficient search space exploration

- First 3 experiments:
  1. Verify the abstract expression pruning mechanism on a simple Lax program (e.g., matrix multiplication) by comparing search results with and without pruning
  2. Test the probabilistic equivalence verifier on equivalent and non-equivalent μGraphs to validate the error rate
  3. Profile the performance impact of different layout optimizations on a basic μGraph to understand the optimization potential

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the content, several areas remain unexplored:

### Open Question 1
- Question: Can the abstract expression pruning technique be extended to support division cancellation (e.g., div(mul(x, y), y) = x) without nullifying the pruning benefits?
- Basis in paper: [explicit] The paper explicitly states that their choice of axioms for abstract expressions does not consider cancellation, and including an axiom for cancellation would make everything a subexpression of everything, therefore nulling the desired pruning.
- Why unresolved: This represents a fundamental tradeoff between the strength of the pruning technique and its effectiveness. Adding cancellation axioms would make the pruning ineffective, but not supporting cancellation may miss some equivalent μGraphs.
- What evidence would resolve it: A formal proof showing either (1) a way to include cancellation axioms while maintaining pruning effectiveness, or (2) empirical evidence demonstrating that the missed optimizations due to lack of cancellation support are negligible in practice.

### Open Question 2
- Question: How does the performance of Mirage scale when optimizing tensor programs that exceed the memory capacity of a single GPU?
- Basis in paper: [inferred] The paper mentions that some benchmarks (like GQA) are generally parallelized across multiple GPUs using tensor model parallelism, but the evaluation focuses on single-GPU performance. The paper also discusses how Mirage handles tensors that exceed shared memory capacity by splitting computation into multiple block graphs.
- Why unresolved: The paper doesn't provide performance data for multi-GPU scenarios or discuss how the hierarchical μGraph representation would be extended to coordinate optimization across multiple devices.
- What evidence would resolve it: Performance comparisons of Mirage versus existing multi-GPU optimizers (like Megatron-LM) on large models that require model parallelism, showing scaling behavior and any overhead introduced by the multi-level optimization approach.

### Open Question 3
- Question: What is the theoretical limit of the probabilistic equivalence verification in terms of tensor size and operator complexity before the error probability becomes unacceptably high?
- Basis in paper: [explicit] The paper provides Theorem 4 showing that the probability of accepting a non-equivalent μGraph can be made arbitrarily low with repeated tests, and mentions using large enough prime numbers p and q. However, it doesn't provide concrete bounds on tensor size or operator complexity.
- Why unresolved: The theorem provides asymptotic guarantees but doesn't translate to practical limits for real-world tensor programs. The paper uses specific prime values (p=227, q=113) but doesn't analyze how these choices affect the error probability for different tensor program characteristics.
- What evidence would resolve it: A detailed analysis showing the relationship between tensor size, operator complexity, number of random tests, and resulting error probability, including recommendations for parameter selection based on program characteristics.

## Limitations
- Limited to Lax programs, which restrict the set of supported operators and may miss optimizations requiring non-Lax operations
- Single-GPU focus with no evaluation of multi-GPU scenarios or model parallelism capabilities
- Performance improvements may vary depending on specific GPU architecture and may not generalize across different hardware

## Confidence
- **High confidence**: The hierarchical μGraph representation and its ability to capture GPU optimizations at multiple levels (kernel, block, thread) is well-supported by the architectural description and examples provided.
- **Medium confidence**: The abstract expression pruning mechanism and probabilistic equivalence verification are theoretically sound based on the presented theorems and mechanisms, but the practical effectiveness depends on implementation details not fully specified in the paper.
- **Low confidence**: The claimed performance improvements (up to 3.5× speedup) are difficult to independently verify without access to the complete implementation and benchmark suite.

## Next Checks
1. **Abstract Expression Pruning Validation**: Implement a simplified version of the abstract expression pruning mechanism and test it on a basic tensor program (e.g., matrix multiplication) to verify that it correctly prunes non-optimal paths while preserving the optimal solution. Measure the reduction in search space and compare against exhaustive search results.

2. **Probabilistic Equivalence Verification Testing**: Create a test suite with both equivalent and non-equivalent μGraphs to empirically validate the error rate of the probabilistic equivalence verifier. Vary the size of the finite fields (p and q) to observe the relationship between field size and verification accuracy, confirming the theoretical guarantees presented in the paper.

3. **Cross-Architecture Performance Evaluation**: Test Mirage on multiple GPU architectures beyond the NVIDIA A100 used in the evaluation. Measure performance portability across different hardware configurations and identify any architecture-specific optimizations that may be missing from the current implementation.