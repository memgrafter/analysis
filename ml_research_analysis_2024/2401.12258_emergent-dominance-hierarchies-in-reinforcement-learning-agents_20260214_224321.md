---
ver: rpa2
title: Emergent Dominance Hierarchies in Reinforcement Learning Agents
arxiv_id: '2401.12258'
source_url: https://arxiv.org/abs/2401.12258
tags: []
core_contribution: This paper explores how dominance hierarchies can emerge naturally
  in multi-agent reinforcement learning systems. The authors formalize dominance hierarchies
  using game theory, modeling pairwise conflicts as the game of Chicken, and generalize
  it to N-player "Chicken Coop" environments.
---

# Emergent Dominance Hierarchies in Reinforcement Learning Agents

## Quick Facts
- arXiv ID: 2401.12258
- Source URL: https://arxiv.org/abs/2401.12258
- Reference count: 40
- One-line primary result: RL agents can invent, learn, enforce, and transmit dominance hierarchies without explicit incentives

## Executive Summary
This paper demonstrates that dominance hierarchies can emerge naturally in multi-agent reinforcement learning systems. Using a game-theoretic framework based on the game of Chicken, the authors show that RL agents trained in a simple environment with opponent identification can spontaneously develop hierarchical relationships resembling those observed in biological systems. The study reveals that these hierarchies are not only learnable but also enforceable and transmissible to new populations, suggesting dominance hierarchies as a natural coordination mechanism for multi-agent systems.

## Method Summary
The study employs a novel "Chicken Coop" environment that generalizes the game of Chicken to N players. Agents use PPO with a learning rate of 2Ã—10^-6, trained for 512 episodes per generation across 300 populations. The environment provides each agent with the identity of their opponent as the sole observation, and agents receive asymmetric payoffs based on whether they play aggressively (hawk) or submissively (dove). The method includes ablation experiments with noisy opponent identification and transmission experiments where experienced agents are transplanted into naive populations.

## Key Results
- RL agents spontaneously invent dominance hierarchies in the Chicken Coop environment
- Hierarchy formation requires opponent identification but no explicit incentives
- Experienced agents can successfully transmit dominance hierarchies to new populations
- Hierarchy structure resembles empirical data from chickens and mice

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dominance hierarchies emerge when agents can identify opponents and have asymmetric payoff structures.
- Mechanism: The Chicken Coop environment provides a 2-player game with stable Nash equilibria (hawk/dove). When agents observe opponent identity, they learn aggressive strategies against some and submissive against others, creating a rank structure.
- Core assumption: Agents have memory and can condition behavior on opponent identity; the environment rewards dominant/subordinate strategies asymmetrically.
- Evidence anchors:
  - [abstract] "agents, trained with minimal rules and no explicit incentives, can invent, learn, enforce, and transmit dominance hierarchies"
  - [section] "Definition 4.5 (Chicken Coop). Chicken Coop is an ð‘ -player generalization of the game of Chicken. In each episode... Each agent's sole observation is the identity of their opponent agent."
  - [corpus] Weak - no direct corpus support for opponent identity being the only driver.
- Break condition: If opponent identity is hidden or replaced with noise, rapport and hierarchy formation collapse (see Section 6.3).

### Mechanism 2
- Claim: Aggressiveness converges to discrete ranks in [0,1], forming a tournament graph.
- Mechanism: In Chicken Coop, each agent plays hawk against k others and dove against the rest, where k/N â‰ˆ aggressiveness rank. This creates dominance relationships for each pair, forming a complete directed graph (tournament).
- Core assumption: Agents converge to pure or near-pure strategies over time; the number of opponents played aggressively maps linearly to rank.
- Evidence anchors:
  - [abstract] "agents collaboratively invent dominance hierarchies" and "enforce dominance hierarchies on other agents"
  - [section] "Figure 2... agents' aggressiveness values converge to approximately equally-spaced 'ranks' in [0, 1]"
  - [corpus] Moderate - corpus neighbors discuss emergent cooperation but not rank convergence specifically.
- Break condition: High learning rates or noisy observations disrupt convergence to discrete ranks.

### Mechanism 3
- Claim: Dominance hierarchies can be transmitted to new populations via experienced agents.
- Mechanism: Experienced agents carry learned neural network weights encoding dominance strategies. When transplanted into a naive population, they enforce their learned hierarchy on others, causing the naive agents to adopt the same rank structure.
- Core assumption: The hierarchy is encoded in the weights such that the same agent always plays dominant/subordinate against the same subset of others, regardless of population.
- Evidence anchors:
  - [abstract] "agents transmit dominance hierarchies to new populations"
  - [section] "Definition 4.6 (Dominance hierarchy). A dominance hierarchy H is a complete, directed graph... where agents are represented as nodes and dominance relationships are represented as directed edges."
  - [corpus] Weak - corpus does not cover hierarchy transmission experiments.
- Break condition: If too few experienced agents are transplanted (K small), or learning rate of naive agents is too high, the transmitted hierarchy may be distorted.

## Foundational Learning

- Concept: Game Theory - Nash equilibria and payoff matrices
  - Why needed here: Understanding why Chicken Coop has stable equilibria (hawk/dove) and how asymmetric payoffs create dominance relationships.
  - Quick check question: In the 2x2 Chicken game, what are the two pure-strategy Nash equilibria and their payoffs?

- Concept: Reinforcement Learning - PPO, policy gradients, exploration vs. exploitation
  - Why needed here: The agents use PPO to learn aggressive/submissive strategies; understanding how PPO updates lead to convergence to ranks is key.
  - Quick check question: How does the PPO clipping parameter influence stability of learned dominance strategies?

- Concept: Graph Theory - Tournaments, dominance graphs
  - Why needed here: Dominance hierarchies are modeled as complete directed graphs (tournaments); analyzing transitivity and cycles requires graph concepts.
  - Quick check question: What is the maximum number of directed edges in a tournament with N nodes?

## Architecture Onboarding

- Component map:
  - Environment -> PPO Agents -> Reward Signal -> Dominance Hierarchy

- Critical path:
  1. Initialize N agents with random PPO policies
  2. Run Chicken Coop episodes (random pairing each episode)
  3. Collect rewards and observations
  4. Update PPO policies
  5. After convergence, compute aggressiveness and dominance graph
  6. (Optional) Transplant experienced agents into new population

- Design tradeoffs:
  - Learning rate: Too high â†’ unstable hierarchies; too low â†’ slow convergence
  - Opponent identity: Essential for hierarchy formation; removing it destroys structure