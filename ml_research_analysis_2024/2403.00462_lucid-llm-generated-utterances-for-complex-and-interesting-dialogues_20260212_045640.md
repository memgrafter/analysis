---
ver: rpa2
title: 'LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues'
arxiv_id: '2403.00462'
source_url: https://arxiv.org/abs/2403.00462
tags:
- user
- intent
- lucid
- slot
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LUCID is a modularized LLM-driven data generation pipeline that
  automatically creates realistic, diverse, and challenging task-oriented dialogues
  without human input. It breaks down data generation into 14 stages, including intent
  and slot generation, conversation planning, turn-by-turn dialogue generation, and
  automated validation.
---

# LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues

## Quick Facts
- arXiv ID: 2403.00462
- Source URL: https://arxiv.org/abs/2403.00462
- Reference count: 40
- LUCID achieves 69.7% joint goal accuracy on seen intents and 41.3% on unseen intents

## Executive Summary
LUCID is a comprehensive, modularized LLM-driven pipeline for automatically generating realistic and challenging task-oriented dialogues without human input. The system breaks down data generation into 14 distinct stages, covering everything from intent and slot generation to turn-by-turn dialogue creation and automated validation. The resulting dataset includes 4,277 conversations spanning 100 intents and 501 slots, with built-in support for complex conversational phenomena like sarcasm, corrections, and overheard conversations.

The system's effectiveness is demonstrated through baseline model training, achieving strong performance on both in-distribution (69.7% joint goal accuracy) and out-of-distribution (41.3%) evaluation. Human review of the generated data found only 1% of conversations contained labeling errors, indicating high quality and reliability for dialogue system development and evaluation.

## Method Summary
LUCID employs a modular pipeline approach with 14 stages for generating task-oriented dialogues. The system begins by generating intents and slots, then creates conversation plans before generating dialogues turn-by-turn using LLM prompting. Each stage includes automated validation to ensure data quality. The pipeline specifically incorporates challenging conversational phenomena through targeted prompt engineering, including sarcasm, corrections, and overheard conversations. Turn-level labeling is performed automatically throughout the generation process. The modular design allows for flexibility in adjusting individual components while maintaining overall system coherence.

## Key Results
- Generated dataset contains 4,277 conversations across 100 intents and 501 slots
- Human validation found only 1% of conversations contained labeling errors
- Baseline models achieved 69.7% joint goal accuracy on seen intents and 41.3% on unseen intents
- System successfully incorporates challenging phenomena like sarcasm and corrections with automatic turn-level labeling

## Why This Works (Mechanism)
The modular pipeline architecture enables systematic generation of complex dialogues by breaking down the task into manageable, verifiable components. Each stage can be independently validated and optimized, ensuring quality throughout the generation process. The use of LLM prompting at each stage allows for natural language generation that captures nuanced conversational phenomena. The automated validation at each step prevents error propagation and maintains dataset consistency.

## Foundational Learning
- LLM prompting techniques for dialogue generation - needed to create natural conversational flow; check by evaluating output naturalness
- Modular system design - needed for scalability and maintainability; check by assessing component independence
- Automated validation strategies - needed to ensure data quality without human intervention; check by measuring error rates
- Conversational phenomenon modeling - needed to create realistic dialogue scenarios; check by testing model performance on challenging cases
- Turn-level labeling automation - needed for efficient dataset annotation; check by comparing with manual labeling accuracy

## Architecture Onboarding

Component map: Intent/Slot Generation -> Conversation Planning -> Turn-by-Turn Generation -> Automated Validation

Critical path: The generation pipeline flows sequentially through each of the 14 stages, with each stage's output serving as input to the next. The critical path includes LLM prompting for generation and automated validation at each step.

Design tradeoffs: Modular design enables flexibility but requires careful coordination between components. Automated validation reduces human effort but may miss subtle quality issues. The balance between challenge level and data quality affects model training effectiveness.

Failure signatures: Common failures include prompt misinterpretation leading to irrelevant responses, validation rules being too strict or too lenient, and generation loops causing repetitive or nonsensical dialogue. These manifest as poor model performance or high human validation error rates.

First experiments:
1. Generate a small dataset using only basic intents without complex phenomena to establish baseline quality
2. Test individual LLM prompts with different parameter settings to optimize generation quality
3. Validate automated validation rules on a subset of manually reviewed data to calibrate accuracy thresholds

## Open Questions the Paper Calls Out
None

## Limitations
- Human validation conducted by only two reviewers, potentially missing edge cases
- Evaluation focuses primarily on joint goal accuracy, not comprehensively assessing conversational phenomena quality
- Scalability to new domains beyond the 14 covered remains untested

## Confidence
- High confidence in dataset generation methodology and modular architecture
- Medium confidence in human validation results due to limited reviewer sample size
- Medium confidence in baseline model performance, constrained to specific models and metrics
- Low confidence in generalizability of conversational phenomena generation to all dialogue scenarios

## Next Checks
1. Expand human validation to include larger and more diverse reviewer pool to ensure comprehensive error detection
2. Conduct cross-domain testing to evaluate pipeline's adaptability to new dialogue domains
3. Develop additional evaluation metrics specifically designed to assess quality of challenging conversational phenomena like sarcasm and corrections