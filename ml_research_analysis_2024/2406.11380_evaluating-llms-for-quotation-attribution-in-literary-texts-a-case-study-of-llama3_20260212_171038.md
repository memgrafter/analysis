---
ver: rpa2
title: 'Evaluating LLMs for Quotation Attribution in Literary Texts: A Case Study
  of LLaMa3'
arxiv_id: '2406.11380'
source_url: https://arxiv.org/abs/2406.11380
tags:
- memorization
- quote
- attribution
- speaker
- llama-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Llama-3 8b demonstrates state-of-the-art performance on quotation
  attribution in literary texts, improving accuracy by up to 19 points over ChatGPT
  and 12 points over BookNLP+ on the Project Dialogism Novel Corpus. By using an incremental
  Chain-of-Thought prompting strategy with a predefined character-to-alias list, the
  model accurately attributes quotes in chapters with high accuracy, especially for
  non-explicit quotes.
---

# Evaluating LLMs for Quotation Attribution in Literary Texts: A Case Study of LLaMa3

## Quick Facts
- arXiv ID: 2406.11380
- Source URL: https://arxiv.org/abs/2406.11380
- Authors: Gaspard Michel; Elena V. Epure; Romain Hennequin; Christophe Cerisata
- Reference count: 30
- Llama-3 8b achieves up to 19 points higher accuracy than ChatGPT and 12 points higher than BookNLP+ on the Project Dialogism Novel Corpus

## Executive Summary
This paper evaluates Llama-3 8b's performance on quotation attribution in literary texts, demonstrating state-of-the-art results that significantly outperform existing baselines. The study introduces a novel Corrupted-Speaker-Guessing metric to distinguish between reasoning and memorization in the model's attributions. By processing entire chapters through incremental Chain-of-Thought prompting with a predefined character-to-alias list, Llama-3 achieves particularly strong performance on non-explicit quotes that require complex reasoning about implicit narrative cues.

## Method Summary
The study evaluates Llama-3 8b on the Project Dialogism Novel Corpus (PDNC) containing 37,131 manually annotated quotes from 28 English novels. Novels are divided into chapters and processed in 4096-token chunks with 1024-token strides. The model uses Chain-of-Thought prompting with incremental attribution strategy, considering all quotes in each chunk sequentially. A gold character-to-alias list maps each character to a unique pseudonym for each novel. Performance is evaluated against ChatGPT and BookNLP+ baselines, with additional analysis using Corrupted-Speaker-Guessing (CSG) metric to assess memorization versus reasoning.

## Key Results
- Llama-3 8b improves quotation attribution accuracy by up to 19 points over ChatGPT and 12 points over BookNLP+ on PDNC
- The model shows significant performance gains on non-explicit quotes, suggesting strong reasoning capabilities for complex attribution cases
- Corrupted-Speaker-Guessing analysis indicates that performance gains are primarily driven by reasoning rather than memorization or annotation contamination
- Larger Llama-3 70b model achieves near-perfect accuracy with only 3 wrong predictions out of 1442 quotes on an unseen novel

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Llama-3 8b achieves superior quotation attribution by leveraging contextual reasoning over memorization.
- Mechanism: The model processes entire chapters using incremental Chain-of-Thought prompting, enabling it to resolve complex cases like coreference and discourse patterns rather than relying on memorized text passages.
- Core assumption: The model's reasoning ability is sufficient to handle non-explicit quotes, which require understanding implicit narrative cues.
- Evidence anchors:
  - [abstract] "We found that these types of memorization do not explain the large performance gain, making Llama-3 the new state-of-the-art for quotation attribution in English literature."
  - [section 4] "This gain is due to the large performance increase when attributing non-explicit quotes, that we also see on PDNC2. This suggests that Llama-3 might be able to solve complex cases of reasoning such as coreference resolution in a small context, or understanding discussion patterns."
- Break condition: If the model encounters a novel with significantly different discourse patterns than those in the training data, its reasoning performance may degrade.

### Mechanism 2
- Claim: The Corrupted-Speaker-Guessing (CSG) metric effectively distinguishes between memorization and reasoning.
- Mechanism: By corrupting passages and replacing speaker names with gender-matched pseudonyms, the metric forces the model to rely on contextual cues rather than memorized text, providing a measure of reasoning ability.
- Core assumption: The pseudonymization approach is effective in preventing the model from using memorized speaker names.
- Evidence anchors:
  - [abstract] "We introduce a novel measure of book memorization, Corrupted-Speaker-Guessing, that classifies a successful quote attribution into either a reasoning or memorization prediction."
  - [section 5] "When making a prediction, the LLM must decide whether to use contextual cues (reasoning) or rely on memorized information to identify the correct speaker, despite the misleading contextual information."
- Break condition: If the model has memorized enough contextual information about the speaker to identify them despite the pseudonymization, the metric may not accurately reflect reasoning ability.

### Mechanism 3
- Claim: The larger Llama-3 70b model achieves near-perfect accuracy by further enhancing reasoning capabilities.
- Mechanism: The increased model size allows for more sophisticated reasoning and pattern recognition, leading to improved attribution accuracy, especially on the unseen novel.
- Core assumption: The larger model size directly correlates with improved reasoning ability and pattern recognition.
- Evidence anchors:
  - [abstract] "We found that our approach combined with the larger Llama-3 70b reaches an almost perfect accuracy."
  - [section 4] "When increasing the model size to 70b, the performance increases to an almost perfect accuracy, and we identified only 3 wrong predictions out of 1442 quotes."
- Break condition: If the larger model's improved performance is due to increased memorization rather than enhanced reasoning, its generalization ability may be limited.

## Foundational Learning

- Concept: Chain-of-Thought prompting
  - Why needed here: This prompting strategy enables the model to break down complex attribution tasks into smaller, sequential reasoning steps, improving accuracy on non-explicit quotes.
  - Quick check question: How does Chain-of-Thought prompting differ from direct prompting in terms of the model's reasoning process?

- Concept: Context window management
  - Why needed here: The model processes entire chapters by chunking text into 4096-token segments with 1024-token strides, ensuring that all quotes in a chapter are considered within the model's context window.
  - Quick check question: What are the potential trade-offs between using larger context windows and the computational cost of processing longer text sequences?

- Concept: Speaker identification and coreference resolution
  - Why needed here: Accurate quotation attribution requires the model to identify speakers and resolve coreferences, especially for non-explicit quotes where narrative cues are minimal.
  - Quick check question: How does the model handle cases where multiple characters could potentially be the speaker based on the surrounding context?

## Architecture Onboarding

- Component map: Data preprocessing -> Prompt engineering -> Model inference -> Evaluation
- Critical path: Novels → Chapter division → Text chunking → Quote identification → Character-to-alias list creation → Chain-of-Thought prompting → Llama-3 inference → Attribution accuracy calculation → CSG memorization analysis
- Design tradeoffs:
  - Using larger context windows improves attribution accuracy but increases computational cost
  - Incremental prompting strategy improves accuracy but requires more complex prompt engineering
  - Using gold character-to-alias list improves attribution accuracy but may not reflect real-world scenarios
- Failure signatures:
  - Low attribution accuracy on non-explicit quotes may indicate insufficient reasoning ability or context window limitations
  - High memorization accuracy with low reasoning accuracy may indicate the model is relying too heavily on memorized text passages
  - Inconsistent performance across different novels may indicate the model's generalization ability is limited
- First 3 experiments:
  1. Test the model's attribution accuracy on a small set of explicit quotes to establish a baseline
  2. Test the model's attribution accuracy on a small set of non-explicit quotes to evaluate its reasoning ability
  3. Test the model's attribution accuracy with and without the gold character-to-alias list to evaluate the impact of this feature on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Corrupted-Speaker-Guessing (CSG) metric perform on other literary tasks beyond quotation attribution?
- Basis in paper: [explicit] The paper introduces CSG as a new metric for measuring book memorization and validates its effectiveness on quotation attribution.
- Why unresolved: The paper only applies CSG to quotation attribution and does not explore its applicability to other literary tasks.
- What evidence would resolve it: Testing CSG on other literary tasks such as character profiling, narrative understanding, or sentiment analysis would demonstrate its broader utility.

### Open Question 2
- Question: What is the impact of different tokenization strategies on the performance of Llama-3 for quotation attribution?
- Basis in paper: [inferred] The paper mentions using a chunk size of 4096 tokens with a stride of 1024 tokens, but does not explore the impact of different tokenization strategies.
- Why unresolved: The paper does not provide an analysis of how different tokenization strategies might affect the model's performance.
- What evidence would resolve it: Experimenting with different chunk sizes, strides, or tokenization methods and comparing the resulting attribution accuracy would clarify the impact of tokenization.

### Open Question 3
- Question: How does the performance of Llama-3 on quotation attribution compare to other large language models, such as GPT-4 or Claude?
- Basis in paper: [explicit] The paper compares Llama-3's performance to ChatGPT and BookNLP+, but does not include other large language models.
- Why unresolved: The paper only evaluates Llama-3 against two baselines and does not provide a comprehensive comparison with other LLMs.
- What evidence would resolve it: Evaluating Llama-3 alongside other LLMs on the same dataset and comparing their performance would provide a clearer picture of Llama-3's relative strengths and weaknesses.

## Limitations

- The study relies on a specific literary corpus (PDNC) and uses a gold character-to-alias list during inference, which may not reflect real-world scenarios
- While memorization analysis suggests reasoning drives performance, the study doesn't fully explore whether success stems from genuine understanding versus sophisticated pattern matching
- The Corrupted-Speaker-Guessing metric, while innovative, may not completely eliminate the possibility of contextual memorization for frequently mentioned characters

## Confidence

- **High Confidence**: Llama-3 8b's superior performance over ChatGPT and BookNLP+ baselines is well-supported by direct comparison on the same dataset with substantial accuracy improvements (up to 19 points)
- **Medium Confidence**: The attribution of success to reasoning rather than memorization is supported by CSG analysis but could benefit from additional validation
- **Medium Confidence**: The claim that larger model size (70b vs 8b) improves reasoning capabilities is supported by near-perfect accuracy results but lacks detailed analysis of why

## Next Checks

1. **Cross-genre validation**: Test Llama-3's attribution performance on contemporary novels, genre fiction, or non-Western literary traditions to verify that reasoning capabilities generalize beyond the PDNC corpus of 19th-20th century English literature

2. **Zero-shot character alias transfer**: Evaluate the model's performance without the gold character-to-alias list, using either automatically generated aliases or no aliases at all, to determine how much the predefined list contributes to reported accuracy gains

3. **Ablation on Chain-of-Thought complexity**: Systematically vary the complexity and granularity of Chain-of-Thought prompts to identify the minimum reasoning steps required for optimal performance, helping distinguish between genuine reasoning and pattern matching behaviors