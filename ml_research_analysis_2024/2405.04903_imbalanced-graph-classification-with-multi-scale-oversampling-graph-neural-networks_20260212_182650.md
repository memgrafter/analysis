---
ver: rpa2
title: Imbalanced Graph Classification with Multi-scale Oversampling Graph Neural
  Networks
arxiv_id: '2405.04903'
source_url: https://arxiv.org/abs/2405.04903
tags:
- graph
- graphs
- classification
- minority
- oversampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MOSGNN, a novel multi-scale oversampling framework
  for imbalanced graph classification that learns expressive minority graph representations
  by jointly optimizing subgraph-level, graph-level, and pairwise-graph learning tasks.
  The key idea is to perform oversampling at multiple scales - subgraph, graph, and
  pairwise graphs - to capture rich intra- and inter-graph discriminative information
  for the minority class.
---

# Imbalanced Graph Classification with Multi-scale Oversampling Graph Neural Networks

## Quick Facts
- arXiv ID: 2405.04903
- Source URL: https://arxiv.org/abs/2405.04903
- Reference count: 40
- Primary result: Achieves up to 7.8% improvement in F1 score on imbalanced graph classification tasks

## Executive Summary
MOSGNN introduces a novel multi-scale oversampling framework for imbalanced graph classification that learns expressive minority graph representations by jointly optimizing subgraph-level, graph-level, and pairwise-graph learning tasks. The key innovation is performing oversampling at multiple scales - subgraph, graph, and pairwise graphs - to capture rich intra- and inter-graph discriminative information for the minority class. Extensive experiments on 16 imbalanced graph datasets show that MOSGNN significantly outperforms five state-of-the-art models, achieving up to 7.8% improvement in F1 score.

## Method Summary
MOSGNN is a multi-scale oversampling framework for imbalanced graph classification that learns expressive minority graph representations by jointly optimizing three classification objectives. The framework uses a shared GCN backbone with MVPool, then branches into three specialized heads for subgraph-level MIL, graph-level classification, and pairwise-graph relation prediction. Each branch performs oversampling on minority class samples, with losses combined through weighted sum optimization. The method can be extended by plugging in advanced imbalanced learning loss functions.

## Key Results
- Achieves up to 7.8% improvement in F1 score on the minority class compared to five state-of-the-art models
- Shows consistent performance across 16 imbalanced graph datasets including 9 NCI chemical compound datasets and 7 TUDataset datasets
- Demonstrates that the framework can be easily extended with advanced imbalanced learning loss functions for further performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-scale oversampling captures both intra- and inter-graph discriminative semantics that single-scale methods miss.
- Mechanism: By simultaneously learning at subgraph, graph, and pairwise levels, MOSGNN extracts local patterns (via subgraphs), global graph structure, and relational patterns between graphs.
- Core assumption: Different scales of graph information are complementary and capturing them jointly yields richer representations than any single scale alone.
- Evidence anchors:
  - [abstract] "learns expressive minority graph representations based on intra- and inter-graph semantics resulting from oversampled graphs at multiple scales"
  - [section IV] "jointly optimizes subgraph-level, graph-level, and pairwise-graph learning tasks to learn the discriminative information embedded within and between the minority graphs"

### Mechanism 2
- Claim: Pairwise graph relation prediction extends minority class information by exploiting inter-graph interactions.
- Mechanism: The model pairs minority graphs with other minority graphs and majority graphs, creating balanced majority-majority vs. minority-oriented pairs, and learns to discriminate between them.
- Core assumption: Inter-graph relationships contain discriminative information that is not captured by treating each graph independently.
- Evidence anchors:
  - [abstract] "learns expressive minority graph representations based on intra- and inter-graph semantics resulting from oversampled graphs at multiple scales"
  - [section IV-B] "we leverage the interactions within the minority graphs and between the minority and majority graphs to generate a substantially large number of minority-graph-oriented pair samples"

### Mechanism 3
- Claim: Subgraph-level oversampling with multiple instance learning focuses on relevant subgraphs while filtering out noise.
- Mechanism: The model generates bags of subgraphs for each graph, treats it as a MIL problem, and uses top-k selection to focus on discriminative subgraphs.
- Core assumption: Not all parts of a graph are equally relevant to classification, and subgraph-level information can be more discriminative than full graph representations.
- Evidence anchors:
  - [abstract] "learns expressive minority graph representations based on intra- and inter-graph semantics resulting from oversampled graphs at multiple scales"
  - [section IV-C] "we use MIL to allow MOSGNN to focus on only the relevant subgraphs of each graph"

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: MOSGNN uses GCNs as the backbone for learning graph representations at all three scales
  - Quick check question: How do GCNs aggregate information from a node's neighbors, and why is this aggregation important for graph classification?

- Concept: Imbalanced Learning Techniques
  - Why needed here: MOSGNN combines multi-scale oversampling with existing imbalanced learning methods like FocalLoss and LALoss
  - Quick check question: What's the difference between re-sampling approaches (like SMOTE) and re-weighting approaches (like FocalLoss) for handling class imbalance?

- Concept: Multiple Instance Learning (MIL)
  - Why needed here: The subgraph branch uses MIL to handle the weakly-supervised setting where only graph-level labels are available
  - Quick check question: How does top-k MIL differ from standard MIL, and why is this distinction important for subgraph classification?

## Architecture Onboarding

- Component map: GCN → MVPool → Three specialized heads (subgraph MIL, graph classification, pairwise relation) → Loss aggregation → Parameter update
- Critical path: GCN → MVPool → Three specialized heads → Loss aggregation → Parameter update
- Design tradeoffs: Complexity vs. performance (three branches increase computational cost but improve accuracy), hyperparameter tuning (λ and β require careful selection), scalability (pairwise combinations grow quadratically with dataset size)
- Failure signatures: Poor performance on specific scales indicates that scale's information isn't useful for the dataset; inconsistent pairwise predictions suggest problematic graph pairing strategy
- First 3 experiments:
  1. Test each branch individually to understand its contribution and identify which scales are most informative for your dataset
  2. Vary λ and β to find optimal balance between pairwise and subgraph contributions relative to the graph branch
  3. Compare with and without MVPool to understand the impact of hierarchical pooling on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MOSGNN scale with increasing dataset size and graph complexity?
- Basis in paper: [inferred] The paper mentions that the construction of Graph-of-Graphs (GoG) in G 2GNN is computationally costly for large datasets, but does not evaluate MOSGNN's performance on very large datasets or highly complex graphs.
- Why unresolved: The paper focuses on datasets with up to 41,472 graphs and does not explore the scalability of MOSGNN to significantly larger or more complex graph datasets.
- What evidence would resolve it: Experiments evaluating MOSGNN on datasets with millions of graphs or graphs with thousands of nodes, comparing runtime and performance to other methods.

### Open Question 2
- Question: How does MOSGNN perform when the minority class represents a small fraction of the dataset (e.g., less than 1%)?
- Basis in paper: [inferred] The paper evaluates MOSGNN on datasets with various imbalanced ratios but does not specifically focus on extremely low minority class proportions.
- Why unresolved: The experiments use datasets with minority class proportions ranging from 1.7% to 24.2%, leaving the performance at extremely low proportions unexplored.
- What evidence would resolve it: Experiments using synthetic datasets with controlled minority class proportions down to 0.1% or less, comparing MOSGNN's performance to other methods.

### Open Question 3
- Question: How sensitive is MOSGNN to the choice of GNN backbone and pooling operation?
- Basis in paper: [explicit] The paper mentions that various GNNs and pooling operations can be used as the backbone, but only evaluates GCN with MVPool by default.
- Why unresolved: The paper briefly explores GIN and GAT as alternatives but does not comprehensively evaluate the impact of different GNN backbones and pooling operations on MOSGNN's performance.
- What evidence would resolve it: Systematic experiments comparing MOSGNN with different combinations of GNN backbones (e.g., GCN, GIN, GAT, GraphSAGE) and pooling operations (e.g., mean pooling, max pooling, attention-based pooling) across multiple datasets.

## Limitations

- Evaluation Scope Uncertainty: The paper reports results on 16 datasets but only provides detailed comparisons with 5 baseline methods, potentially missing relevant approaches in imbalanced graph classification.
- Hyperparameter Sensitivity: The multi-scale framework introduces several hyperparameters whose optimal values may vary significantly across datasets, with no systematic sensitivity analysis provided.
- Computational Complexity: The pairwise graph branch generates O(n²) pairs for n minority graphs, which could become computationally prohibitive for larger datasets without scalability analysis.

## Confidence

**High Confidence**: The multi-scale framework architecture is well-defined with clear mathematical formulations. The experimental methodology (3-fold cross-validation, F1 score metric) is standard and reproducible.

**Medium Confidence**: The reported performance improvements (up to 7.8% F1 score) appear substantial, but the evaluation on a limited set of baselines and lack of ablation studies on individual components reduce confidence in the claimed superiority.

**Low Confidence**: Claims about the framework being "generic" for plugging in advanced imbalanced learning losses lack empirical validation, as the paper mentions this capability but doesn't demonstrate it with multiple loss functions beyond the two mentioned.

## Next Checks

1. **Ablation Study Validation**: Run controlled experiments removing each of the three scales (subgraph, graph, pairwise) to quantify their individual contributions to performance and verify whether the multi-scale approach genuinely provides complementary information.

2. **Hyperparameter Robustness Testing**: Systematically vary λ, β, and top-k values across multiple orders of magnitude to identify stable regions and potential failure modes, revealing whether the framework requires extensive tuning or has robust default settings.

3. **Scalability Assessment**: Evaluate the framework on progressively larger graph datasets (increasing both graph count and graph size) to measure computational scaling and identify practical limits for real-world deployment.