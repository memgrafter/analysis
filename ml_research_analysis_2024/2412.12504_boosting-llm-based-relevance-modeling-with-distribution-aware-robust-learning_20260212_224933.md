---
ver: rpa2
title: Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning
arxiv_id: '2412.12504'
source_url: https://arxiv.org/abs/2412.12504
tags:
- relevance
- modeling
- fine-tuning
- search
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses limitations in LLM-based relevance modeling
  for e-commerce search, where fine-tuned models struggle with distinguishing fine-grained
  relevance degrees and generalize poorly to out-of-distribution data. The authors
  propose DaRL, a Distribution-Aware Robust Learning framework that enhances both
  generalizability and discriminability.
---

# Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning

## Quick Facts
- arXiv ID: 2412.12504
- Source URL: https://arxiv.org/abs/2412.12504
- Reference count: 40
- Primary result: Framework improves LLM relevance modeling, achieving F1 0.9349 on ID and 0.6678 on OOD test sets, with 3.04% conversion rate increase in online A/B test

## Executive Summary
This paper addresses key limitations in LLM-based relevance modeling for e-commerce search, where fine-tuned models struggle to distinguish fine-grained relevance degrees and generalize poorly to out-of-distribution data. The authors propose DaRL, a Distribution-Aware Robust Learning framework that enhances both generalizability and discriminability. DaRL introduces three key components: Distribution-Aware Sample Augmentation (DASA) to enrich training data with relevant OOD samples using Mahalanobis distance and nearest neighbor metrics; Linear-Probing then Fine-Tuning (LPFT), a multi-stage training strategy to balance in-distribution and out-of-distribution performance; and Over-Confidence Calibration (OCC), which applies KL divergence-based loss to improve prediction calibration across relevance degrees. Experiments on real-world Alipay insurance search data show DaRL outperforms baselines, achieving F1 scores of 0.9349 on in-distribution and 0.6678 on out-of-distribution test sets. Online A/B testing demonstrated a 3.04% increase in conversion rate and 3.17% improvement in highly relevant item ranking, validating the framework's effectiveness in production.

## Method Summary
The paper proposes DaRL, a Distribution-Aware Robust Learning framework to improve LLM-based relevance modeling for e-commerce search. The method consists of three components: DASA for enriching training data with OOD samples using Mahalanobis distance and kNN metrics, LPFT as a multi-stage fine-tuning strategy to balance ID and OOD performance, and OCC for KL divergence-based calibration to reduce overconfidence across relevance degrees. The framework is evaluated on Alipay insurance search data using AntGLM-0.3B, with experiments showing improved F1 scores and online performance.

## Key Results
- DaRL achieves F1 scores of 0.9349 on in-distribution and 0.6678 on out-of-distribution test sets
- Online A/B testing shows 3.04% increase in conversion rate and 3.17% improvement in highly relevant item ranking
- OCC significantly reduces overconfidence in relevance predictions while maintaining high accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distribution-Aware Sample Augmentation (DASA) improves OOD generalization by enriching the training set with relevant out-of-distribution samples.
- Mechanism: DASA uses Mahalanobis distance and nearest neighbor metrics to identify OOD samples from unlabeled data, then manually labels and adds them to the training set, expanding the data distribution coverage.
- Core assumption: The unlabeled dataset contains meaningful OOD samples that, when added to training, improve model robustness without introducing excessive noise.
- Evidence anchors:
  - [section]: "This module utilizes out-of-distribution (OOD) detection techniques to actively select appropriate samples that are not well covered by the original training set for model fine-tuning."
  - [abstract]: "To improve the generalizability of LLM-based relevance modeling, we first propose the Distribution-Aware Sample Augmentation (DASA) module."
  - [corpus]: Weak evidence; no direct corpus match, but similar works exist on OOD detection in search.
- Break condition: If OOD detection thresholds are poorly tuned, DASA may select samples that are too distant from the task domain, degrading model performance.

### Mechanism 2
- Claim: Linear-Probing then Fine-Tuning (LPFT) balances in-distribution and out-of-distribution performance by mitigating catastrophic forgetting.
- Mechanism: LPFT first trains only the classifier head (linear probing) while freezing the LLM backbone, then fine-tunes all parameters, and finally interpolates the weights to blend ID and OOD capabilities.
- Core assumption: Freezing the backbone during initial probing preserves useful pre-trained features, while full fine-tuning later adapts them to the augmented data.
- Evidence anchors:
  - [section]: "we employ the adapted Linear-Probing then Fine-Tuning (LPFT) method... to train the model."
  - [abstract]: "Furthermore, we adopt a multi-stage fine-tuning strategy to simultaneously improve in-distribution (ID) and OOD performance."
  - [corpus]: Weak evidence; LPFT is adapted from prior work but not directly cited in corpus.
- Break condition: If the interpolation coefficient is poorly chosen, the model may revert too much toward either ID or OOD performance, reducing overall effectiveness.

### Mechanism 3
- Claim: Over-Confidence Calibration (OCC) improves discriminability across fine-grained relevance degrees by regularizing prediction distributions.
- Mechanism: OCC introduces a KL divergence-based auxiliary loss that forces the model's predicted probability distributions to align with a predefined smooth prior over relevance labels, reducing overconfidence.
- Core assumption: The model's raw predictions are overconfident and collapse toward a single class, harming fine-grained relevance distinction.
- Evidence anchors:
  - [section]: "we introduce a method to calibrate over-confidence in relevance models, aiming to enhance their performance and reliability."
  - [abstract]: "Specifically, we design an effective loss function to enhance the discriminability of LLM-based relevance modeling across various fine-grained degrees of query-item relevance."
  - [corpus]: No direct match; this calibration approach appears novel to the paper.
- Break condition: If the smoothing factor ρ is set too high or too low, the calibration may either overly flatten predictions or fail to correct overconfidence.

## Foundational Learning

- Concept: Out-of-distribution (OOD) detection
  - Why needed here: Identifying samples from data distributions not well represented in the training set is crucial for augmenting the model with diverse, relevant examples.
  - Quick check question: How does Mahalanobis distance help in distinguishing OOD samples from ID ones in representation space?

- Concept: Catastrophic forgetting in fine-tuning
  - Why needed here: Understanding how fine-tuning can erase useful pre-trained knowledge is essential for designing strategies like LPFT that preserve ID performance.
  - Quick check question: Why might fine-tuning an LLM on a narrow dataset cause it to perform worse on general or OOD data?

- Concept: KL divergence for probability calibration
  - Why needed here: KL divergence measures the difference between predicted and target probability distributions, making it suitable for adjusting overconfident predictions.
  - Quick check question: What does it mean for a model's predicted distribution to have low entropy, and why is this problematic for fine-grained relevance modeling?

## Architecture Onboarding

- Component map:
  - LLM backbone (AntGLM-0.3B)
  - MLP classification head (added for relevance scoring)
  - DASA module (OOD detection + sample selection)
  - LPFT pipeline (linear probing → fine-tuning → weight interpolation)
  - OCC loss (KL divergence regularization)
- Critical path:
  - Input → LLM encoding → MLP → OCC regularization → loss aggregation → LPFT fine-tuning
- Design tradeoffs:
  - Larger LLMs (e.g., 10B) improve performance but are infeasible for online serving due to latency.
  - Manual labeling of OOD samples adds cost but ensures quality; automated labeling risks noise.
  - OCC smoothing factor ρ must be tuned per dataset to avoid under- or over-correction.
- Failure signatures:
  - Overfitting to OOD samples → poor ID performance
  - Insufficient OOD augmentation → limited generalization gains
  - Incorrect ρ in OCC → either under-confident or still overconfident predictions
- First 3 experiments:
  1. Validate that DASA-selected OOD samples are semantically relevant to the task by manual inspection.
  2. Test LPFT interpolation coefficient α across [0, 1] to find the sweet spot balancing ID and OOD F1.
  3. Measure the effect of OCC on prediction entropy distribution to confirm reduced overconfidence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DaRL's framework be adapted to handle even finer-grained relevance degrees beyond the three-point scale (strong, weak, irrelevant) currently used?
- Basis in paper: [explicit] The paper discusses DaRL's effectiveness in handling three relevance degrees and mentions that "Discerning fine-grained relevance degrees in e-commerce search could be a nuanced and subjective task" but does not explore finer granularity.
- Why unresolved: The current framework and evaluation are based on a three-point scale. Extending to more granular scales would require modifications to the loss functions, sample augmentation strategies, and evaluation metrics.
- What evidence would resolve it: Experiments comparing DaRL's performance on datasets with more than three relevance degrees, along with analysis of how the framework components (DASA, LPFT, OCC) need to be adjusted for finer granularity.

### Open Question 2
- Question: What is the optimal balance between in-distribution and out-of-distribution samples for maximizing relevance modeling performance across different e-commerce domains?
- Basis in paper: [explicit] The paper mentions that "increasing the proportion of OOD samples may further improve the model's performance" but doesn't provide a definitive answer on the optimal ratio.
- Why unresolved: The optimal balance likely depends on the specific characteristics of each e-commerce domain, including the diversity of products, query patterns, and user behavior. The paper only explores this empirically for insurance search.
- What evidence would resolve it: Systematic experiments across multiple e-commerce domains varying the ratio of ID to OOD samples, measuring performance trade-offs and identifying domain-specific optimal balances.

### Open Question 3
- Question: How does DaRL's performance compare to human annotators in terms of consistency and accuracy for relevance assessment in specialized domains?
- Basis in paper: [inferred] The paper mentions that "Discerning fine-grained relevance degrees in e-commerce search could be a nuanced and subjective task" and uses human crowdsourcing for annotations, but doesn't compare model performance to human consistency.
- Why unresolved: While DaRL shows improved performance over baselines, it's unclear how it compares to the inherent variability and potential biases in human relevance assessment, especially in specialized domains like insurance.
- What evidence would resolve it: Direct comparison studies where DaRL's relevance assessments are evaluated against multiple human annotators' judgments, measuring inter-annotator agreement and comparing model consistency to human consistency.

## Limitations
- DASA requires manual labeling of OOD samples, raising scalability concerns for production deployment
- Optimal hyperparameters (OOD detection thresholds, LPFT interpolation coefficient) appear dataset-specific and require tuning
- The framework's effectiveness on more than three relevance degrees remains unexplored

## Confidence

**High Confidence**: The OCC mechanism (KL divergence calibration) is well-specified with clear mathematical formulation and shows consistent improvements in both ID and OOD performance. The calibration effect is directly observable through entropy distribution changes.

**Medium Confidence**: LPFT's multi-stage approach is theoretically sound and shows measurable benefits, but the optimal interpolation point (α=0.6) appears dataset-specific. The mechanism's generalizability to other domains needs validation.

**Low Confidence**: DASA's effectiveness heavily depends on OOD detection thresholds that aren't specified. While the concept is sound, reproducing the exact performance gains requires additional experimentation to find appropriate thresholds.

## Next Checks

1. **OOD Detection Sensitivity Analysis**: Systematically vary Mahalanobis distance and kNN thresholds in DASA to determine their impact on model performance. Document the relationship between threshold values and both ID/OOD F1 scores to identify robust parameter ranges.

2. **Cross-Dataset LPFT Transferability**: Apply LPFT with the optimal α=0.6 to a different e-commerce search dataset (e.g., Amazon product search) to test whether the interpolation coefficient generalizes or requires domain-specific tuning.

3. **Automated OOD Labeling Experiment**: Compare manual vs. automated OOD sample labeling (using LLM-based relevance scoring) on a subset of the unlabeled logs. Measure the performance degradation and labeling cost reduction to assess scalability trade-offs.