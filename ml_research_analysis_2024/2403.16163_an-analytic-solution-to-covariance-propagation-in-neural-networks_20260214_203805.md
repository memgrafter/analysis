---
ver: rpa2
title: An Analytic Solution to Covariance Propagation in Neural Networks
arxiv_id: '2403.16163'
source_url: https://arxiv.org/abs/2403.16163
tags:
- networks
- neural
- covariance
- mean
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an analytic method for propagating mean vectors
  and covariance matrices through neural networks, enabling uncertainty quantification
  without costly sampling. The core contribution is Theorem 1, which provides an exact
  formula for the covariance of Gaussian inputs passed through nonlinear activation
  functions like Heaviside, ReLU, and GELU.
---

# An Analytic Solution to Covariance Propagation in Neural Networks

## Quick Facts
- arXiv ID: 2403.16163
- Source URL: https://arxiv.org/abs/2403.16163
- Reference count: 40
- Primary result: Analytic covariance propagation method achieves 3.74×10^-4 max error vs numerical calculation for neural network uncertainty quantification

## Executive Summary
This paper presents an analytic method for propagating mean vectors and covariance matrices through neural networks, enabling uncertainty quantification without costly sampling. The core contribution is Theorem 1, which provides an exact formula for the covariance of Gaussian inputs passed through nonlinear activation functions like Heaviside, ReLU, and GELU. Experiments demonstrate the method's accuracy: a 4th-order Taylor expansion achieves maximum absolute error of 3.74×10^-4 compared to numerical calculation, outperforming existing approximations. When characterizing trained networks, the method achieves mean and variance estimation ratios close to 1.0 with low standard deviation, better than piecewise-linear approximations. Applied to Bayesian neural network training on UCI regression datasets, the method yields test log-likelihoods comparable to Monte Carlo variational inference, with modest improvements in some cases.

## Method Summary
The paper introduces an analytic approach to uncertainty propagation through neural networks by deriving closed-form expressions for the covariance matrix of network outputs given Gaussian inputs. The key innovation is Theorem 1, which provides an exact formula for the covariance of a nonlinear activation function applied to a multivariate Gaussian random variable. The authors develop a Taylor series approximation scheme to handle the computational complexity of this formula, showing that a 4th-order expansion provides excellent accuracy while remaining computationally tractable. This enables sample-free uncertainty quantification throughout the network, which is then leveraged for Bayesian neural network training using a variational inference framework that replaces Monte Carlo sampling with the analytic covariance propagation method.

## Key Results
- 4th-order Taylor expansion achieves maximum absolute error of 3.74×10^-4 compared to numerical calculation
- Mean and variance estimation ratios close to 1.0 with low standard deviation when characterizing trained networks
- Test log-likelihoods comparable to Monte Carlo variational inference on UCI regression datasets
- Outperforms piecewise-linear approximations in uncertainty quantification accuracy

## Why This Works (Mechanism)
The method works by exploiting the mathematical structure of Gaussian distributions and nonlinear activation functions. When a multivariate Gaussian random variable passes through a nonlinear activation function, the output distribution can be characterized analytically through moment calculations. The key insight is that the covariance of the output depends on both the input covariance and the derivatives of the activation function, which can be computed exactly for standard activation functions. By truncating the Taylor expansion at an appropriate order (4th order in practice), the method balances computational efficiency with approximation accuracy. This analytic formulation enables direct computation of uncertainty propagation without requiring sampling, making it both faster and more precise than Monte Carlo methods for the same task.

## Foundational Learning

**Multivariate Gaussian distributions**: Why needed - The method assumes Gaussian inputs and relies on properties of multivariate normal distributions for covariance propagation. Quick check - Verify understanding of mean vectors, covariance matrices, and how transformations affect Gaussian distributions.

**Taylor series expansions**: Why needed - The analytic formula involves integrals that must be approximated computationally, with Taylor expansion providing the practical solution. Quick check - Confirm ability to derive and truncate Taylor series for common activation functions.

**Variational inference for Bayesian neural networks**: Why needed - The method is applied to train Bayesian neural networks by propagating uncertainty analytically rather than through sampling. Quick check - Understand the ELBO objective and how analytic covariance propagation integrates with variational inference.

## Architecture Onboarding

Component map: Input distribution -> Layer 1 (analytic propagation) -> Layer 2 (analytic propagation) -> ... -> Output distribution
Critical path: Gaussian input → Covariance propagation formula → Taylor approximation → Uncertainty quantification → Bayesian training
Design tradeoffs: Accuracy vs. computational complexity in Taylor expansion order; Gaussian assumption vs. flexibility for non-Gaussian inputs
Failure signatures: Breakdown when input distributions significantly deviate from Gaussian; numerical instability in matrix operations for very deep networks
First experiments:
1. Verify analytic covariance propagation on simple 2-layer network with synthetic Gaussian data
2. Compare approximation error across different Taylor expansion orders on standard activation functions
3. Test scalability by measuring computation time vs. network depth and input dimensionality

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Computational complexity of matrix operations may limit scalability to very deep networks
- Gaussian input assumption may not hold for many real-world applications
- Limited validation across diverse domains and network architectures
- Only three datasets tested for Bayesian neural network training application

## Confidence

| Claim | Confidence |
|-------|------------|
| Theoretical framework and analytic derivations | High |
| Experimental accuracy of covariance approximation | High |
| UCI dataset performance | Medium |
| Scalability claims | Low |

## Next Checks

1. Benchmark computational complexity scaling with network depth and input dimensionality on standard architectures
2. Validate performance on non-Gaussian input distributions and non-regression tasks
3. Compare against ensembling and other uncertainty quantification methods on diverse real-world datasets