---
ver: rpa2
title: Understanding Likelihood Over-optimisation in Direct Alignment Algorithms
arxiv_id: '2410.11677'
source_url: https://arxiv.org/abs/2410.11677
tags:
- better
- training
- steps
- diversity
- likelihood
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies likelihood over-optimisation as a critical
  issue in Direct Alignment Algorithms (DAAs) like DPO and IPO, where higher likelihood
  of better completions and larger margins between better and worse completion likelihoods
  do not necessarily lead to better model performance. Through experiments on 7B and
  35B models using ULTRAFEEDBACK and BINARIZED PREF datasets, the authors find that
  lower completion likelihood can improve output diversity and generalisation, while
  higher likelihood improves factual knowledge memorisation.
---

# Understanding Likelihood Over-optimisation in Direct Alignment Algorithms

## Quick Facts
- arXiv ID: 2410.11677
- Source URL: https://arxiv.org/abs/2410.11677
- Reference count: 40
- Primary result: Higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better performance in DAAs

## Executive Summary
This paper identifies likelihood over-optimisation as a critical issue in Direct Alignment Algorithms (DAAs) like DPO and IPO, where higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better model performance. Through experiments on 7B and 35B models using ULTRAFEEDBACK and BINARIZED PREF datasets, the authors find that lower completion likelihood can improve output diversity and generalisation, while higher likelihood improves factual knowledge memorisation. Two key indicators are identified for detecting over-optimisation: decreasing entropy over top-k tokens and diminishing top-k probability mass. The study shows that optimal performance occurs at intermediate likelihood values rather than at the extremes of the Pareto frontier, challenging the common assumption that maximising better completion likelihood is always beneficial.

## Method Summary
The study trains 7B and 35B parameter models using DPO, IPO, and Hinge loss methods with varying hyperparameters (β, τ, α) on ULTRAFEEDBACK and BINARIZED PREF datasets. Models are trained with batch size 32, learning rate 5×10⁻⁶ to 1×10⁻⁵, Adam optimizer, and gradient clipping. Training is monitored every 50 steps, tracking better/worse completion likelihoods, win probability against GPT-3.5-Turbo, entropy over top-10 tokens, and distinct N-grams. Performance is evaluated using an LLM-as-a-Judge framework with top-p=0.75, temperature=0.5, max tokens=2048, and factuality scores on NQ and TriviaQA datasets.

## Key Results
- Higher likelihood of better completions does not consistently improve model performance
- Decreasing entropy over top-k tokens reliably indicates over-optimization
- Diminishing top-k probability mass leads to degraded output quality
- IPO and Hinge methods show better performance-diversity balance than standard DPO

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher likelihood of better completions does not necessarily lead to better performance in DAAs
- Mechanism: The relationship between completion likelihood and model performance follows a non-linear curve where optimal performance occurs at intermediate likelihood values rather than extremes
- Core assumption: The model's performance metrics (win probability, generalization) have a complex relationship with likelihood that cannot be captured by simple monotonic relationships
- Evidence anchors:
  - [abstract] "higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better performance"
  - [section 4.2] "our analysis reveals that simply increasing the likelihood of better completions does not consistently result in performance improvements"
  - [corpus] Weak - only 0 citations for related papers, suggesting this is a novel finding

### Mechanism 2
- Claim: Decreasing entropy over top-k tokens signals over-optimization of diversity
- Mechanism: When entropy decreases while completion likelihood is still dropping, it indicates the model is over-prioritizing certain tokens at the expense of overall diversity, leading to less human-aligned outputs
- Core assumption: Entropy of top-k token distribution is a reliable proxy for output diversity and over-optimization
- Evidence anchors:
  - [abstract] "Decreasing Entropy over Top-k Tokens" as one of the two key indicators
  - [section 4.4] "When Per-Input Diversity (entropy) starts decreasing, the model begins to over-prioritise certain tokens"
  - [corpus] Weak - related papers don't discuss this specific entropy-based indicator

### Mechanism 3
- Claim: Diminishing top-k probability mass leads to random outputs and code-switching
- Mechanism: As probability mass concentrates on fewer tokens, the model increasingly selects tokens outside the top-k, resulting in less coherent and more random outputs
- Core assumption: Probability mass distribution in top-k tokens correlates with output coherence and quality
- Evidence anchors:
  - [abstract] "Diminishing Top-k Probability Mass" as the second key indicator
  - [section 4.4] "the probability mass of all top-10 tokens diminishes, leading to more random outputs"
  - [corpus] Weak - no direct citations supporting this specific mechanism

## Foundational Learning

- Concept: Likelihood optimization in language models
  - Why needed here: Understanding how likelihood relates to model performance is central to the paper's findings about over-optimization
  - Quick check question: What is the relationship between likelihood maximization and model performance in standard language model training?

- Concept: Entropy as a measure of diversity
  - Why needed here: The paper uses entropy of top-k token distributions as a key indicator of over-optimization
  - Quick check question: How does entropy of a probability distribution relate to the diversity of possible outcomes?

- Concept: Probability mass distribution
  - Why needed here: The paper identifies diminishing probability mass in top-k tokens as an indicator of over-optimization
  - Quick check question: What happens to sampling behavior when probability mass shifts from top tokens to lower-ranked tokens?

## Architecture Onboarding

- Component map: DAA algorithms (DPO, IPO, Hinge) -> Likelihood tracking for better/worse completions -> Entropy calculation for top-k tokens -> Probability mass calculation for top-k tokens -> Performance evaluation (win probability, diversity metrics, factuality scores)

- Critical path: 1) Train DAA model with different hyperparameters 2) Track completion likelihood for better/worse completions 3) Calculate entropy and probability mass for top-k tokens 4) Evaluate performance using win probability and diversity metrics 5) Identify optimal operating point avoiding over-optimization

- Design tradeoffs: Higher likelihood vs. better diversity and generalization, Simple likelihood maximization vs. more complex multi-objective optimization, Computational cost of tracking multiple metrics vs. benefits of early stopping

- Failure signatures: Increasing win probability with decreasing entropy (over-prioritization), Decreasing win probability with increasing entropy (excessive diversity), Declining factuality scores with increasing diversity, Code-switching or incoherent outputs when probability mass diminishes

- First 3 experiments: 1) Train DPO with varying β values and track likelihood vs. win probability relationship 2) Add NLL regularization with different weights and observe impact on likelihood and diversity 3) Compare entropy and probability mass trends across DPO, IPO, and Hinge methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mechanism by which likelihood over-optimisation degrades model performance in DAAs?
- Basis in paper: [explicit] The paper identifies likelihood over-optimisation as a critical issue but does not fully explain the underlying mechanism.
- Why unresolved: The authors observe that higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better performance, but the specific reasons for this degradation are not clearly articulated.
- What evidence would resolve it: Detailed ablation studies or theoretical analysis showing how specific aspects of the likelihood landscape affect downstream performance metrics.

### Open Question 2
- Question: How do the two identified indicators (decreasing entropy over top-k tokens and diminishing top-k probability mass) interact with each other and with other model properties?
- Basis in paper: [explicit] The paper identifies these two indicators but does not explore their relationships or interactions.
- Why unresolved: The authors note these as separate warning signs but do not investigate whether they are correlated, whether one typically precedes the other, or how they relate to other model characteristics.
- What evidence would resolve it: Empirical studies examining the correlation between these indicators and their relationship to other model properties like perplexity, coherence, or factual accuracy.

### Open Question 3
- Question: What is the optimal balance between likelihood and diversity for different types of tasks and model sizes?
- Basis in paper: [inferred] The paper suggests a trade-off between likelihood and diversity but does not provide task-specific or model-size-specific guidelines.
- Why unresolved: The authors demonstrate that slightly lower completion likelihood tends to improve output diversity and generalization, but they do not specify how this balance should vary across different applications or model scales.
- What evidence would resolve it: Systematic experiments across diverse task categories and model sizes to identify optimal likelihood-diversity trade-offs for different use cases.

### Open Question 4
- Question: How can adaptive regularisation techniques be designed to prevent likelihood over-optimisation while maintaining task performance?
- Basis in paper: [explicit] The paper mentions the potential for adaptive regularisation but does not provide specific methods or evaluate their effectiveness.
- Why unresolved: The authors suggest that fixed coefficients for NLL loss may be insufficient and propose adaptive methods, but they do not develop or test specific implementations.
- What evidence would resolve it: Implementation and evaluation of adaptive regularisation schemes that adjust based on the identified indicators (entropy and probability mass) during training.

### Open Question 5
- Question: Does likelihood over-optimisation manifest differently in other alignment methods beyond DAAs, such as RLHF or instruction tuning?
- Basis in paper: [inferred] The paper focuses on DAAs but the concept of over-optimisation could apply to other alignment approaches.
- Why unresolved: The authors limit their analysis to DAAs and do not explore whether similar likelihood-related issues occur in alternative alignment paradigms.
- What evidence would resolve it: Comparative studies examining likelihood dynamics and performance degradation across multiple alignment methods including RLHF, instruction tuning, and other preference optimization techniques.

## Limitations

- Analysis based primarily on synthetic binary preference datasets rather than naturally occurring human preference data
- LLM-as-a-Judge framework may not fully capture human judgment quality
- Entropy and probability mass indicators derived from top-10 token distributions may not capture all aspects of output diversity

## Confidence

*High Confidence Claims:*
- Higher likelihood of better completions does not consistently improve model performance
- Decreasing entropy over top-k tokens reliably indicates over-optimization
- Diminishing top-k probability mass leads to degraded output quality
- IPO and Hinge methods show better performance-diversity balance than standard DPO

*Medium Confidence Claims:*
- The optimal operating point lies at intermediate likelihood values
- Better completion likelihood correlates with factuality memorization
- Different likelihood components (better, worse, difference) have distinct impacts on performance

*Low Confidence Claims:*
- The specific threshold values for over-optimization indicators
- The generalizability to non-binary preference datasets
- The exact relationship between likelihood and performance across all model scales

## Next Checks

1. **Human Evaluation Validation**: Conduct direct human preference comparisons on a subset of outputs to verify that the LLM-as-a-Judge framework accurately captures human preferences, particularly for outputs showing signs of over-optimization.

2. **Dataset Generalization Test**: Replicate the key experiments using naturally occurring preference datasets (rather than binarized versions) to validate that the likelihood-over-optimization phenomenon persists across different data distributions.

3. **Architecture Scalability Analysis**: Test the entropy and probability mass indicators on smaller model architectures (3B and below) to determine if the over-optimization detection methods remain reliable across different model scales.