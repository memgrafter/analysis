---
ver: rpa2
title: 'MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation'
arxiv_id: '2408.08600'
source_url: https://arxiv.org/abs/2408.08600
tags:
- segmentation
- image
- mm-unet
- ophthalmic
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MM-UNet is a mixed MLP architecture designed for ophthalmic image
  segmentation, addressing the limitations of CNNs in capturing long-range dependencies
  and the computational overhead of transformer-based models. The core method introduces
  a Multi-Scale MLP (MMLP) module that groups features at various depths and applies
  local token-mixing operations to simultaneously capture global and local information
  while preserving location details.
---

# MM-UNet: A Mixed MLP Architecture for Improved Ophthalmic Image Segmentation

## Quick Facts
- arXiv ID: 2408.08600
- Source URL: https://arxiv.org/abs/2408.08600
- Authors: Zunjie Xiao; Xiaoqing Zhang; Risa Higashita; Jiang Liu
- Reference count: 23
- Key outcome: MM-UNet achieves 98.20% accuracy and 92.64% mIoU on AS-OCT, and 93.91% accuracy and 80.41% mIoU on REFUGE2 with only 12.98M parameters

## Executive Summary
MM-UNet introduces a mixed MLP architecture specifically designed for ophthalmic image segmentation, addressing the limitations of both convolutional neural networks (CNNs) and transformer-based models. The architecture combines a UNet encoder-decoder with Multi-Scale MLP (MMLP) modules that use local token-mixing operations to capture both global and local information while preserving spatial details. Extensive experiments on private AS-OCT and public REFUGE2 datasets demonstrate state-of-the-art performance with significantly lower parameter counts than competing approaches.

## Method Summary
MM-UNet is a hybrid architecture that integrates convolutional UNet components with Multi-Scale MLP (MMLP) modules. The MMLP modules group features at various depths and apply local token-mixing operations (LTM) within defined blocks, enabling simultaneous capture of global and local information while maintaining spatial context. The architecture uses a hybrid design that leverages the inductive bias of convolutional operations for local pattern recognition while utilizing MLP capabilities for long-range dependencies. The model is trained with SGD optimizer, cross-entropy loss, and specific learning rate scheduling for 150 epochs on 256×256 images.

## Key Results
- Achieves 98.20% accuracy and 92.64% mIoU on private AS-OCT dataset
- Achieves 93.91% accuracy and 80.41% mIoU on public REFUGE2 dataset
- Uses only 12.98M parameters, significantly fewer than competing models
- Outperforms state-of-the-art deep segmentation networks including UNet++, DeepLabV3+, and nnUNet

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-Scale MLP (MMLP) modules preserve spatial information while enabling long-range interactions
- Mechanism: By grouping channels and applying local token-mixing within blocks, the MMLP restricts mixing to defined scales (si × si patches) rather than global mixing, thereby retaining positional context critical for segmentation
- Core assumption: Segmentation performance benefits from maintaining local spatial relationships even while modeling long-range dependencies
- Evidence anchors:
  - [abstract] "facilitates the interaction of features at various depths through a grouping strategy, enabling simultaneous capture of global and local information"
  - [section 2.2] "Unlike the global correlations established by the token mixing mentioned above, LT M(·) is a local token-mixing operator which divides the entire space into ni × ni blocks and then establishes interactions within each block"
  - [corpus] Weak/no direct evidence for MMLP module effectiveness; this is novel architecture
- Break condition: If ni=1 (pure global mixing), positional information degrades and segmentation accuracy drops

### Mechanism 2
- Claim: Hybrid UNet + MLP architecture leverages strengths of both inductive biases
- Mechanism: Convolutional encoder captures image-specific local patterns; MLP decoder establishes long-range dependencies without requiring large-scale pretraining
- Core assumption: Combining convolutional inductive bias with MLP's long-range modeling yields better segmentation than either alone
- Evidence anchors:
  - [abstract] "The hybrid design, integrating convolutional and MLP components, aims to leverage the strengths of both approaches"
  - [section 2.3] "This hybrid architecture leverages the inductive bias of images inherent in convolutional operations to avoid the need for large-scale pre-training, while also utilizing the MLP's capability to capture long-range relationships"
  - [corpus] Limited corpus evidence; comparison to pure MLP approaches not available in neighbors
- Break condition: If convolution layers are removed, model performance degrades due to loss of image-specific inductive bias

### Mechanism 3
- Claim: Local token-mixing (LTM) operators improve segmentation accuracy compared to global token-mixing
- Mechanism: By constraining mixing to ni × ni blocks rather than entire feature maps, LTM preserves fine-grained spatial relationships while still enabling cross-block information flow
- Core assumption: Segmentation tasks require fine spatial precision that global mixing disrupts
- Evidence anchors:
  - [section 2.2] "only local dependencies are established, resembling a convolution operator"
  - [section 3.4] "Our LTM demonstrates improvements in both mIoU and Acc compared to the token-mixing methods in both AS-OCT and REFUGE2"
  - [corpus] No direct corpus evidence for LTM vs global token-mixing comparison
- Break condition: If si is reduced to 1×1, mixing becomes ineffective and performance matches pure CNN baseline

## Foundational Learning

- Concept: U-Net architecture with skip connections
  - Why needed here: Provides hierarchical feature extraction and preserves spatial resolution for precise pixel-level segmentation
  - Quick check question: How do skip connections in U-Net help maintain boundary information between encoder and decoder?

- Concept: Multi-layer perceptron (MLP) token-mixing mechanisms
  - Why needed here: Enables modeling of long-range dependencies without the computational cost of transformers
  - Quick check question: What is the key difference between channel-mixing MLP and token-mixing MLP in the original MLP-Mixer architecture?

- Concept: Local vs global receptive fields in convolutional networks
  - Why needed here: Understanding why MMLP uses local token-mixing rather than global mixing for segmentation tasks
  - Quick check question: How does the receptive field size affect the model's ability to preserve positional information in segmentation?

## Architecture Onboarding

- Component map: Input → UNet encoder (conv layers) → MMLP blocks (grouped channel mixing with local token-mixing) → UNet decoder (conv layers) → Output segmentation map
- Critical path: Image features flow through convolutional layers for local feature extraction, then through MMLP blocks for long-range modeling, finally through decoder for precise localization
- Design tradeoffs: Local token-mixing preserves spatial information but limits global context; hybrid design balances inductive bias with long-range modeling capability
- Failure signatures: Degraded boundary precision indicates insufficient local token-mixing; poor global consistency indicates insufficient long-range modeling
- First 3 experiments:
  1. Replace MMLP blocks with global token-mixing MLP to verify local mixing importance
  2. Remove UNet encoder and use pure MLP architecture to test inductive bias contribution
  3. Vary ni and si parameters in MMLP blocks to find optimal balance between local and global information capture

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MM-UNet perform on ophthalmic datasets with fewer labeled examples than AS-OCT or REFUGE2?
- Basis in paper: [inferred] The paper states that ophthalmic datasets are typically small and MLP-based models require large-scale pre-training, but MM-UNet is designed to leverage the inductive bias of convolutional operations to avoid this need.
- Why unresolved: The experiments only evaluate MM-UNet on two relatively large datasets (1844 AS-OCT images and 1200 REFUGE2 images). The paper does not report performance on smaller datasets.
- What evidence would resolve it: Experimental results showing MM-UNet's accuracy and mIoU on datasets with fewer than 500 labeled images, comparing it to CNN and transformer baselines under the same conditions.

### Open Question 2
- Question: Can the MMLP module be effectively integrated into other UNet variants or segmentation architectures beyond the standard UNet?
- Basis in paper: [explicit] The paper states "Our objective is to harness the strengths of both convolutional and MLP mechanisms" and uses a mixed MLP architecture that combines MLP and UNet, but does not explore other architectures.
- Why unresolved: The study only evaluates MM-UNet, a specific hybrid of UNet and MMLP, without testing whether MMLP blocks provide similar benefits when integrated into other segmentation backbones like UNet++, DeepLabV3+, or nnUNet.
- What evidence would resolve it: Comparative experiments showing MMLP integration into multiple segmentation architectures with performance metrics (mIoU, parameter count) relative to their standard versions.

### Open Question 3
- Question: What is the computational complexity of the MMLP module in terms of FLOPs compared to global token-mixing MLP and convolutional operations?
- Basis in paper: [explicit] The paper states that "the MMLP module reduces computational consumption compared to the MLP-mixer" and contrasts local versus global token-mixing, but does not provide quantitative FLOPs analysis.
- Why unresolved: While the paper mentions computational advantages qualitatively and provides parameter counts (#P), it does not report actual FLOPs measurements or runtime comparisons between MMLP, global token-mixing MLP, and convolutional alternatives.
- What evidence would resolve it: Detailed FLOPs calculations and wall-clock inference time measurements for the MMLP module versus global token-mixing MLP and standard convolutional layers under identical hardware conditions.

## Limitations

- The private AS-OCT dataset prevents independent verification of results and limits reproducibility
- Limited ablation studies make it difficult to isolate the specific contribution of the MMLP module versus the overall hybrid architecture
- No evaluation on smaller ophthalmic datasets to demonstrate performance when labeled data is scarce
- Lack of comparison to other local token-mixing approaches that might achieve similar results

## Confidence

- **High confidence**: The hybrid architecture design combining UNet with MLP components is well-established conceptually and the reported performance metrics on REFUGE2 (93.91% accuracy, 80.41% mIoU) align with state-of-the-art results for fundus segmentation.
- **Medium confidence**: The claim that local token-mixing outperforms global mixing is supported by experimental results but lacks theoretical justification and direct comparison to other local mixing approaches.
- **Low confidence**: The assertion that the MMLP module specifically enables simultaneous capture of global and local information without compromising either is not fully substantiated by the ablation studies provided.

## Next Checks

1. **Ablation study**: Implement and compare three variants - pure CNN, pure global MLP-Mixer, and MM-UNet - on the same REFUGE2 dataset to isolate the contribution of the MMLP module and local token-mixing mechanism.

2. **Parameter sensitivity analysis**: Systematically vary the {si, ni} parameters in MMLP blocks to identify optimal configurations and verify that the reported performance is robust across parameter choices rather than tuned to specific values.

3. **Cross-dataset validation**: Test the trained MM-UNet model on multiple independent ophthalmic segmentation datasets beyond REFUGE2 to evaluate generalization performance and confirm that the architecture's advantages extend beyond the specific datasets used in training.