---
ver: rpa2
title: Stylometric Watermarks for Large Language Models
arxiv_id: '2405.08400'
source_url: https://arxiv.org/abs/2405.08400
tags:
- what
- watermark
- features
- text
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel watermarking method for large language
  models (LLMs) based on manipulating token probabilities to embed stylometric features.
  The method dynamically updates a semantic key derived from each generated sentence,
  using zero-shot classification to parameterize stylometric features like acrostics
  and sensorimotor norms.
---

# Stylometric Watermarks for Large Language Models

## Quick Facts
- arXiv ID: 2405.08400
- Source URL: https://arxiv.org/abs/2405.08400
- Reference count: 19
- Watermarking method achieves 98% detection accuracy for 3+ sentences with 0.02 false positive/negative rates

## Executive Summary
This paper introduces a novel watermarking method for large language models that embeds stylometric features by manipulating token probabilities during text generation. The approach uses dynamic semantic keys derived from each generated sentence to parameterize stylometric features like acrostics and sensorimotor norms. Experiments with Mistral 7B demonstrate high detection accuracy and resilience against translation attacks, while requiring no additional model training or LLM for watermark detection.

## Method Summary
The method embeds watermarks by manipulating token probabilities during generation based on semantic keys derived from preceding sentences. Zero-shot semantic classification generates keys that control stylometric feature injection, specifically acrostic patterns and sensorimotor word usage. Probability manipulation uses small weight boosts on marked tokens to bias generation toward target features while maintaining text quality. Detection employs statistical hypothesis testing on stylometric patterns across sentences, achieving high accuracy without requiring an LLM for detection.

## Key Results
- Achieves 98% detection accuracy (0.02 false positive and false negative rates) for 3+ sentences
- Resilient against cyclic translation attacks, maintaining detection for 7+ sentences
- Requires no additional model training or LLM for watermark detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Watermark detection achieves high accuracy (>98% for ≥3 sentences) by combining statistical stylometric features with dynamic semantic keys.
- Mechanism: Each generated sentence is parameterized by a key derived from the previous sentence using zero-shot semantic classification. This key controls token probability manipulation for acrostic and sensorimotor features, producing detectable stylometric signals.
- Core assumption: Stylometric features parameterized by semantically relevant keys produce statistically significant deviations from human text distributions.
- Evidence anchors:
  - [abstract] "Experiments with Mistral 7B show that for three or more sentences, the watermark achieves a false positive and false negative rate of 0.02."
  - [section 5.3] "Most results of the unaltered base results are centred at score between 0.1 and 0.7... The watermarked answers are clustered... with only three false negatives."
  - [corpus] Weak: No direct corpus evidence of stylometric distributions; relies on internal detection scores.
- Break condition: If semantic key generation fails to produce distinguishable categories, stylometric features become indistinguishable from random text.

### Mechanism 2
- Claim: Dynamic semantic keys enhance watermark resilience against text manipulation attacks.
- Mechanism: Keys are generated from full preceding sentences using semantic zero-shot classification rather than simple hash functions. This fuzzy hashing approach ensures keys remain stable under minor text edits.
- Core assumption: Semantic meaning of sentences is preserved under common editing attacks (e.g., translation, paraphrasing), maintaining key consistency.
- Evidence anchors:
  - [section 4.1] "Our approach is not limited to a specific type of key generation... we propose a fuzzy hashing approach based on the semantics of the sentence."
  - [section 5.5] "The attack was unable to change the semantic classification of sentences to destroy enough keys... The bound for detection moved from three sentences before to seven sentences for detection with similar confidence."
  - [corpus] Weak: No external validation of semantic stability across attack types.
- Break condition: If attacks significantly alter sentence semantics (e.g., extreme paraphrasing), key derivation fails and watermark detection breaks.

### Mechanism 3
- Claim: Probability manipulation of token logits enables controlled stylometric feature injection without degrading text quality.
- Mechanism: Marked tokens (matching desired stylometric features) receive small weight boosts during sampling. This biases generation toward target features while preserving semantic coherence.
- Core assumption: Small probability adjustments can reliably bias token selection toward desired features without causing noticeable quality degradation.
- Evidence anchors:
  - [section 4.1] "The mask is then used to slightly shift the probabilities of the tokens, based on a weight factor. This factor should be relatively small as to not influence the output of the model too much."
  - [section 4.2] "The overall p-value then is P = ps ∗ pa" - shows statistical combination of features.
  - [corpus] Weak: No quantitative analysis of quality impact or human evaluation.
- Break condition: If weight factors are too large, generated text becomes unnatural; if too small, feature detection