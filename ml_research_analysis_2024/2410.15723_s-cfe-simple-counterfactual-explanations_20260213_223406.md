---
ver: rpa2
title: 'S-CFE: Simple Counterfactual Explanations'
arxiv_id: '2410.15723'
source_url: https://arxiv.org/abs/2410.15723
tags:
- data
- cfes
- plausibility
- sparsity
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces S-CFE, a method for generating sparse, manifold-aligned
  counterfactual explanations (CFEs) for classifiers. Existing methods often struggle
  to balance sparsity and plausibility, resulting in unrealistic or impractical explanations.
---

# S-CFE: Simple Counterfactual Explanations

## Quick Facts
- arXiv ID: 2410.15723
- Source URL: https://arxiv.org/abs/2410.15723
- Reference count: 40
- Key outcome: Introduces S-CFE, a method for generating sparse, manifold-aligned counterfactual explanations using accelerated proximal gradient optimization.

## Executive Summary
This paper introduces S-CFE, a method for generating sparse, manifold-aligned counterfactual explanations (CFEs) for classifiers. Existing methods often struggle to balance sparsity and plausibility, resulting in unrealistic or impractical explanations. S-CFE addresses this by using the accelerated proximal gradient (APG) method to solve a canonical formulation of the CFE problem, handling non-convex objectives and non-smooth ℓp regularizers. This enables seamless incorporation of various classifiers and plausibility measures while producing sparser solutions. Experiments on real-world datasets demonstrate that S-CFE effectively produces sparse, manifold-aligned CFEs while maintaining proximity to the factual data and computational efficiency, outperforming existing methods in sparsity and adherence to the data manifold.

## Method Summary
S-CFE generates counterfactual explanations by optimizing a composite objective that balances classifier loss, proximity to the factual data, sparsity constraints, and plausibility regularization. The method uses the accelerated proximal gradient (APG) algorithm to handle both smooth (classifier loss, proximity) and non-smooth (ℓp sparsity regularizers, indicator functions) components of the objective. Differentiable density estimators (KDE, GMM, kNN-based) provide plausibility terms that guide the search toward high-density regions of the target class manifold. The algorithm supports explicit sparsity constraints via indicator functions and box constraints for actionable feature ranges, producing counterfactuals that are valid, sparse, plausible, and close to the original data.

## Key Results
- S-CFE achieves sparser counterfactual explanations than existing methods while maintaining validity and plausibility
- The method produces counterfactuals with lower LOF (Local Outlier Factor) scores, indicating better alignment with data manifolds
- Computational efficiency is maintained through the APG algorithm, with runtime comparable to or better than DCFE and CEM baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using the accelerated proximal gradient (APG) method allows the optimization to handle both smooth non-convex objectives and non-smooth ℓp regularizers (where 0 ≤ p < 1), enabling seamless integration of complex classifiers and plausibility measures while producing sparser solutions.
- Mechanism: APG performs iterative updates by making a quadratic approximation of the smooth part of the objective and applying a proximal operator to the non-smooth part. This decouples the handling of the differentiable classifier loss and the non-differentiable sparsity-inducing regularizer, allowing efficient optimization even with non-convex components.
- Core assumption: The smooth part of the objective (classifier loss + proximity term) has gradients with bounded Lipschitz constants, and the proximal operator for the sparsity-inducing term can be computed efficiently (or approximated).
- Evidence anchors:
  - [abstract] "we tackle the canonical formulation using the accelerated proximal gradient (APG) method, a simple yet efficient first-order procedure capable of handling smooth non-convex objectives and non-smooth ℓp (where 0 ≤ p < 1) regularizers."
  - [section 4] "Assuming h(·, ycf) is a smooth, possibly non-convex function, whose gradient has Lipschitz constant L, we make a quadratic approximation..."
- Break condition: If the Lipschitz constant of the smooth part is too large or unknown, step sizes become unstable and convergence fails. If the proximal operator cannot be computed efficiently for the chosen ℓp norm, the method becomes computationally infeasible.

### Mechanism 2
- Claim: Incorporating differentiable plausibility terms (KDE, GMM, or kNN-based density estimates) into the objective function guides the search toward high-density regions of the target class manifold, producing counterfactual explanations that are both sparse and aligned with realistic data distributions.
- Mechanism: The plausibility term acts as a differentiable penalty that pulls generated counterfactuals toward regions of high conditional density for the target class. By optimizing this term jointly with sparsity and validity constraints, the method finds solutions that balance all three desiderata rather than treating plausibility as a post-hoc constraint.
- Core assumption: The density estimates used (KDE, GMM, kNN-based) are differentiable and provide meaningful gradients that point toward high-density regions of the target class manifold.
- Evidence anchors:
  - [abstract] "This enables our approach to seamlessly incorporate various classifiers and plausibility measures while producing sparser solutions."
  - [section 4.1.1] "We consider an estimate ˆq(·, ycf) for the density of target class ycf... The only requirement for the plausibility term ˆq(·, ycf) is to be differentiable so that we are able to learn from its gradient information."
- Break condition: If the density estimates are poor (e.g., KDE with inappropriate bandwidth, GMM with wrong number of components), the plausibility gradients may point in wrong directions, leading to unrealistic counterfactuals. If the density estimates are not differentiable, the APG method cannot be applied.

### Mechanism 3
- Claim: Using indicator functions for both box constraints and sparsity constraints (instead of penalty terms) provides explicit control over the number of altered features while ensuring the generated counterfactuals remain actionable within valid feature ranges.
- Mechanism: Indicator functions create hard constraints that are enforced through the proximal operator. For sparsity, this means projecting onto the intersection of the sparsity constraint (ℓ0 ball) and the box constraints, which can be done efficiently using greedy selection of the most impactful features to change.
- Core assumption: The proximal operator for the intersection of the sparsity constraint and box constraints can be computed efficiently, and this hard constraint approach leads to better sparsity control than penalty-based regularization.
- Evidence anchors:
  - [abstract] "Our algorithm only requires differentiable data-manifold regularizers and supports box constraints for bounded feature ranges, ensuring the generated counterfactuals remain actionable."
  - [section 4.2.1] "Since g0(x) := IA(x) + βIθ0(x,xf)≤m(x) is a proper and lower semicontinuous function, the convergence of APG to a critical point... can be assured..."
- Break condition: If the proximal operator for the sparsity constraint becomes computationally expensive (e.g., with very high-dimensional data), the method loses its efficiency advantage. If the box constraints are too restrictive, feasible counterfactuals may not exist.

## Foundational Learning

- Concept: Accelerated Proximal Gradient (APG) Method
  - Why needed here: The optimization problem involves both smooth (classifier loss) and non-smooth (ℓp sparsity regularizers, indicator functions) components, making standard gradient descent inadequate. APG efficiently handles this composite structure.
  - Quick check question: How does APG handle the non-smooth part of the objective differently from standard gradient descent?

- Concept: Proximal Operators
  - Why needed here: The proximal operator provides a way to incorporate non-differentiable regularization terms (like ℓ0 or ℓ1 norms) into the optimization framework, enabling the explicit control of sparsity that would be impossible with standard gradient methods.
  - Quick check question: What is the proximal operator for an indicator function, and how does it relate to projection onto a constraint set?

- Concept: Density Estimation and Differentiable Plausibility
  - Why needed here: Simple sparsity constraints can produce counterfactuals that are mathematically valid but unrealistic (e.g., adversarial examples). Differentiable density estimates ensure the generated counterfactuals align with the target class's data manifold.
  - Quick check question: Why must the plausibility term be differentiable for the APG method to work, and what are common choices for differentiable density estimates?

## Architecture Onboarding

- Component map: Data → Classifier training → Density estimator training → APG optimization loop → Output counterfactual
- Critical path: Data → Classifier training → Density estimator training → APG optimization loop → Output counterfactual
- Design tradeoffs:
  - ℓp norm choice: ℓ0 gives explicit sparsity control but requires efficient proximal operator; ℓ1 is easier but less sparse; ℓ1/2, ℓ2/3 offer intermediate options
  - Density estimator choice: KDE is simple but bandwidth-sensitive; GMM provides probabilistic interpretation but requires component selection; kNN is non-parametric but sensitive to k
  - Step size scheduling: Square-root decay works well but requires tuning of initial step size
- Failure signatures:
  - Divergence: Step sizes too large, Lipschitz constant underestimated
  - Poor sparsity: ℓp norm too smooth (e.g., ℓ1 instead of ℓ0), regularization parameter too small
  - Unrealistic counterfactuals: Poor density estimates, implausible regions of feature space
  - Slow convergence: Poorly conditioned problem, inappropriate extrapolation parameters
- First 3 experiments:
  1. Binary classification on Boston Housing with logistic regression classifier, KDE plausibility, ℓ0 sparsity constraint (m=1), validate that all generated counterfactuals are valid and sparse
  2. Multi-class MNIST with CNN classifier, GMM plausibility, ℓ1/2 regularization, compare ℓ2 proximity and LOF plausibility against DCFE baseline
  3. Robustness test: Generate counterfactuals for original data, then for perturbed versions (small Gaussian noise), measure ℓ2 distance between counterfactuals to verify stability

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The method's performance with very high-dimensional data remains uncertain due to potential computational bottlenecks in density estimation and proximal operator computation
- The approach relies heavily on differentiable classifiers, limiting applicability to models like decision trees or random forests
- Runtime efficiency may degrade with complex classifiers where density estimation dominates computation

## Confidence
- **High Confidence:** The core mechanism of using APG for composite optimization (smooth + non-smooth) is well-established and correctly applied
- **Medium Confidence:** The sparsity and plausibility results are convincing for the tested datasets, but generalizability to very high-dimensional or sparse data remains uncertain
- **Low Confidence:** The runtime efficiency claims relative to DCFE and CEM baselines may not hold for larger datasets or more complex models where density estimation dominates computation

## Next Checks
1. Test S-CFE on a high-dimensional dataset (e.g., CIFAR-10) to verify scalability and identify computational bottlenecks
2. Conduct ablation studies varying the density estimator parameters (bandwidth for KDE, number of components for GMM) to quantify their impact on counterfactual plausibility
3. Evaluate S-CFE's performance when the classifier loss is non-differentiable or has ill-conditioned gradients to test robustness limits