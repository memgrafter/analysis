---
ver: rpa2
title: 'Transolver: A Fast Transformer Solver for PDEs on General Geometries'
arxiv_id: '2402.02366'
source_url: https://arxiv.org/abs/2402.02366
tags:
- transolver
- mesh
- which
- slices
- pdes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Transolver, a transformer-based solver for
  partial differential equations (PDEs) on general geometries. The key challenge addressed
  is capturing intricate physical correlations in large-scale meshes with complex
  geometries.
---

# Transolver: A Fast Transformer Solver for PDEs on General Geometries

## Quick Facts
- arXiv ID: 2402.02366
- Source URL: https://arxiv.org/abs/2402.02366
- Reference count: 40
- Key outcome: 22% relative gain in state-of-the-art performance on PDE benchmarks with linear complexity Physics-Attention

## Executive Summary
Transolver introduces a transformer-based solver for partial differential equations on general geometries that overcomes the quadratic complexity bottleneck of standard attention mechanisms. The core innovation is Physics-Attention, which adaptively splits the discretized domain into learnable slices where mesh points under similar physical states are grouped together. This enables efficient capture of intricate physical correlations while maintaining linear computational complexity. Extensive experiments on six standard benchmarks and two industrial-level simulations demonstrate consistent state-of-the-art performance with a 22% relative gain.

## Method Summary
Transolver employs a novel Physics-Attention mechanism that overcomes the quadratic complexity bottleneck of standard attention by adaptively splitting the domain into learnable slices of flexible shapes. Mesh points with similar physical features are assigned to the same slice, which are then encoded into physics-aware tokens. Attention is calculated among these tokens rather than individual mesh points, enabling efficient capture of intricate physical correlations while maintaining linear computational complexity. The method uses an eight-layer transformer with 128-256 channels, learnable slice count M ∈ {32,64}, and is trained with L2 loss plus gradient regularization for certain problems.

## Key Results
- Achieves 22% relative gain in state-of-the-art performance across six standard PDE benchmarks
- Demonstrates superior performance on large-scale industrial simulations (Shape-Net Car, AirfRANS)
- Excels in car and airfoil design tasks with improved drag/lift coefficients and Spearman's rank correlation
- Maintains linear computational complexity while capturing complex spatiotemporal correlations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning physics-aware tokens by adaptive slicing captures intrinsic physical states better than direct attention on mesh points
- Mechanism: The method decomposes the discretized domain into learnable slices where mesh points under similar physical states are assigned to the same slice. These slices are then encoded into physics-aware tokens, and attention is applied among these tokens rather than individual mesh points
- Core assumption: Mesh points with similar physical states will have similar features, making them suitable for grouping into slices
- Evidence anchors: [abstract] "we propose a new Physics-Attention to adaptively split the discretized domain into a series of learnable slices of flexible shapes, where mesh points under similar physical states will be ascribed to the same slice"

### Mechanism 2
- Claim: Linear complexity Physics-Attention enables efficient computation on large-scale meshes
- Mechanism: By replacing standard quadratic attention with a linear-complexity Physics-Attention that operates on a fixed number of physics-aware tokens (M slices), the overall complexity becomes O(NM + M²C) instead of O(N²C)
- Core assumption: M can be kept small (≪ N) while still capturing sufficient physical correlations
- Evidence anchors: [abstract] "which also empowers the solver with endogenetic geometry-general modeling capacity and can be efficiently computed in linear complexity"

### Mechanism 3
- Claim: Attention among physics-aware tokens captures intricate physical correlations better than attention among mesh points
- Mechanism: By encoding physical states into tokens first, the attention mechanism focuses on high-level physical interactions rather than low-level geometric details, reducing noise and enabling better capture of complex spatiotemporal correlations
- Core assumption: Physical correlations are more meaningful and stable than direct geometric correlations for solving PDEs
- Evidence anchors: [abstract] "By calculating attention to physics-aware tokens encoded from slices, Transolver can effectively capture intricate physical correlations under complex geometrics"

## Foundational Learning

- Concept: Fourier transforms and spectral methods
  - Why needed here: Understanding why Fourier neural operators work and their limitations with complex geometries
  - Quick check question: Why do Fourier-based methods struggle with non-periodic boundary conditions?

- Concept: Attention mechanisms and their computational complexity
  - Why needed here: Understanding the quadratic complexity problem and why linear attention methods are needed
  - Quick check question: What is the computational complexity of standard attention and how does it scale with input size?

- Concept: Geometric deep learning and graph neural networks
  - Why needed here: Understanding the landscape of methods for handling irregular geometries and their limitations
  - Quick check question: How do graph neural networks handle irregular geometries differently from grid-based methods?

## Architecture Onboarding

- Component map: Input geometry → Linear embedding → Physics-Attention (slice learning + token encoding + attention) → Feedforward layers → Output projection
- Critical path: Slice learning → Token encoding → Physics-Attention → Prediction
- Design tradeoffs: Number of slices (M) vs. performance vs. efficiency; slice shape flexibility vs. implementation complexity
- Failure signatures: Degenerate slice weights (uniform distribution), attention maps that don't capture meaningful patterns, poor performance on complex geometries
- First 3 experiments:
  1. Test slice learning on simple 2D geometry (e.g., circle) to verify that similar physical states are grouped together
  2. Compare Physics-Attention vs. standard attention on small mesh (100-200 points) to verify improved correlation capture
  3. Measure runtime and memory usage vs. input size to verify linear complexity scaling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Transolver scale with increasing model depth (layers) beyond the tested 40 layers?
- Basis in paper: [explicit] The paper demonstrates scalability by increasing layers from 8 to 40, showing improved performance, but does not test beyond this point
- Why unresolved: The paper focuses on demonstrating the effectiveness of the proposed Physics-Attention mechanism and does not explore the limits of model depth scaling
- What evidence would resolve it: Experiments with Transolver models having more than 40 layers on the same benchmarks would show whether the performance continues to improve or plateaus/saturates

### Open Question 2
- Question: Can Transolver effectively handle Lagrangian PDE-solving tasks, where the geometry of the input data is dynamic?
- Basis in paper: [inferred] The paper focuses on Eulerian settings with fixed geometries, but acknowledges Lagrangian settings as a future direction and provides preliminary experiments on a WaterDrop dataset
- Why unresolved: The paper only presents preliminary results on a specific Lagrangian task and does not comprehensively evaluate Transolver's performance across various Lagrangian PDE-solving problems
- What evidence would resolve it: Extensive experiments on diverse Lagrangian PDE datasets, comparing Transolver's performance against state-of-the-art Lagrangian solvers, would demonstrate its effectiveness in handling dynamic geometries

### Open Question 3
- Question: How does Transolver perform on out-of-distribution (OOD) PDE-solving tasks with significantly different coefficients or boundary conditions compared to the training data?
- Basis in paper: [explicit] The paper conducts OOD experiments on the AirfRANS dataset, showing promising results, but does not explore other OOD scenarios or quantify the extent of OOD generalization
- Why unresolved: The paper only tests OOD generalization on a specific dataset and does not provide a comprehensive analysis of Transolver's ability to handle diverse OOD scenarios
- What evidence would resolve it: Systematic experiments on multiple PDE datasets with varying degrees of OOD generalization, including different coefficients, boundary conditions, and initial conditions, would quantify Transolver's OOD performance and compare it to other models

## Limitations

- Assumes physical states can be effectively captured through learnable slicing, which may not hold for all PDE types or boundary conditions
- Trades geometric fidelity for computational efficiency, potentially losing important local geometric details for certain PDEs
- Limited validation on highly irregular or dynamic geometries where slice boundaries might need to adapt during simulation

## Confidence

- **High confidence**: Linear complexity claims and efficiency improvements demonstrated through runtime analysis
- **Medium confidence**: Performance gains on benchmark datasets, though limited to specific PDE types and geometries
- **Low confidence**: Generalization claims to arbitrary geometries without extensive validation on highly complex or dynamic meshes

## Next Checks

1. **Slice learning validation**: Test the slice learning mechanism on a controlled 2D problem with known physical states (e.g., heat diffusion with hotspots) to verify that mesh points with similar physical states are consistently grouped into the same slices, and that slice boundaries adapt to physical features rather than just geometric proximity

2. **Sensitivity analysis for slice count**: Systematically vary M from 16 to 256 on the same benchmark problems to quantify the performance-efficiency tradeoff, identifying at what point additional slices stop providing meaningful accuracy improvements while increasing computational cost

3. **Boundary condition robustness test**: Apply Transolver to problems with discontinuous boundary conditions or sharp gradients (e.g., shock wave simulation) to evaluate whether the slice-based approach maintains accuracy when physical states change rapidly across slice boundaries