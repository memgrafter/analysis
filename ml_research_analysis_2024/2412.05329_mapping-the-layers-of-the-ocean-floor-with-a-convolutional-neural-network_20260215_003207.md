---
ver: rpa2
title: Mapping The Layers of The Ocean Floor With a Convolutional Neural Network
arxiv_id: '2412.05329'
source_url: https://arxiv.org/abs/2412.05329
tags:
- network
- seismic
- physics
- data
- velocity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of mapping ocean floor layers
  in the oil industry, where traditional seismic methods are computationally expensive
  and complex. The proposed solution employs Convolutional Neural Networks (UNet)
  to predict velocity models from seismic data.
---

# Mapping The Layers of The Ocean Floor With a Convolutional Neural Network

## Quick Facts
- arXiv ID: 2412.05329
- Source URL: https://arxiv.org/abs/2412.05329
- Reference count: 17
- The study shows stable model predictions with Sørensen-Dice values above 70% for automated velocity model inversion

## Executive Summary
This study addresses the challenge of mapping ocean floor layers in the oil industry by employing Convolutional Neural Networks, specifically UNet architectures, to predict velocity models from seismic data. Traditional seismic methods are computationally expensive and complex, making automated solutions attractive for industry applications. The research demonstrates that UNet models can effectively learn to invert seismic shots into velocity models, achieving Sørensen-Dice coefficients above 70%, which indicates promising potential for automated velocity model inversion.

## Method Summary
The research employed two UNet architectures trained and validated using simulated seismic shots and velocity models generated with the DeepWave package. Seismic data were generated through forward modeling and backpropagation calculations, creating paired input-output datasets. The models were evaluated using the Sørensen-Dice coefficient and loss functions, with 10-fold cross-validation (64% train, 16% validation, 20% test) and a batch size of 8. Two datasets were used: 300 elements with simple models and 1,000 elements with complex models containing geological features like faults and folds.

## Key Results
- UNet architectures achieved Sørensen-Dice values above 70% for velocity model predictions
- Modified UNet demonstrated greater stability and reduced overfitting compared to standard UNet
- Artifacts were observed in predictions, particularly circular patterns in the upper right region, but did not significantly impact overall accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UNet architecture captures spatial hierarchies needed for velocity model segmentation by leveraging encoder-decoder with skip connections.
- Mechanism: The encoder compresses spatial information into semantic features while the decoder reconstructs spatial resolution. Skip connections preserve fine-grained details lost in pooling, enabling precise boundary delineation.
- Core assumption: Velocity model boundaries are spatially coherent and can be reconstructed from intermediate feature maps.
- Evidence anchors:
  - [abstract] "The introduction of artificial neural networks, specifically UNet, to predict velocity models based on seismic shots reflected from the ocean floor shows promise"
  - [section] "Another significant difference is the use of skip connections. As observed in Figure 1, these connections link the layers of the encoding and decoding blocks, allowing for the recovery of spatial information lost through pooling layer operations"
  - [corpus] No direct corpus evidence supporting this specific mechanism for seismic inversion
- Break condition: If geological features are too subtle or buried in noise that the skip connections cannot recover, segmentation accuracy degrades significantly.

### Mechanism 2
- Claim: Simulated seismic data generation using DeepWave provides sufficient training signal for the network to learn velocity model inversion.
- Mechanism: Forward modeling creates paired input-output datasets where seismic shots (input) are generated from known velocity models (output). The network learns the inverse mapping by minimizing reconstruction error between predicted and actual velocity models.
- Core assumption: The physics of wave propagation is sufficiently captured by the simulation to enable meaningful learning of the inverse relationship.
- Evidence anchors:
  - [section] "The seismic data were generated using DeepWave, a wave propagation simulation package, which allows for forward modelling and backpropagation to calculate the gradient of the outputs relative to the inputs"
  - [abstract] "two UNet architectures were trained and validated using simulated seismic shots and velocity models generated with the DeepWave package"
  - [corpus] Weak evidence; related papers mention physics-informed neural networks but no direct validation of DeepWave's sufficiency
- Break condition: If the simulation model doesn't capture real-world complexities like anisotropy or attenuation, the learned mapping won't generalize to field data.

### Mechanism 3
- Claim: Sørensen-Dice coefficient effectively measures segmentation quality for velocity models despite non-binary boundaries.
- Mechanism: DSC measures overlap between predicted and ground truth regions, providing intuitive similarity assessment even when boundaries are gradual rather than sharp.
- Core assumption: Even with gradient-based predictions instead of sharp interfaces, the degree of overlap correlates with practical utility for velocity model interpretation.
- Evidence anchors:
  - [section] "The Sørensen–Dice Coefficient (DSC) was chosen as the metric, designed to assess the similarity rate between two images. It was selected for its intuitive visualisation, as it provides values between 0.0 and 1.0, which can be easily converted into percentages"
  - [abstract] "Results showed stable model predictions with Sørensen-Dice values above 70%, indicating promising potential for automated velocity model inversion"
  - [corpus] No corpus evidence evaluating DSC specifically for velocity model inversion tasks
- Break condition: If velocity model accuracy requires precise boundary locations rather than regional overlap, DSC may overestimate practical performance.

## Foundational Learning

- Concept: Convolutional Neural Networks
  - Why needed here: CNNs extract spatial features from seismic data which has strong local correlation patterns
  - Quick check question: What property of seismic data makes CNNs particularly effective compared to fully connected networks?

- Concept: Transfer learning and domain adaptation
  - Why needed here: The model must generalize from simulated data to real-world seismic data with different noise characteristics
  - Quick check question: What validation approach would best test whether the model generalizes beyond the simulated dataset?

- Concept: Inverse problem regularization
  - Why needed here: Seismic inversion is ill-posed; regularization helps stabilize predictions and prevent overfitting to noise
  - Quick check question: How might the circular artifacts in predictions relate to insufficient regularization in the network architecture?

## Architecture Onboarding

- Component map: Input layer (128x128 seismic shots) -> Encoder blocks (convolution + downsampling) -> Bottleneck -> Decoder blocks (upsampling + convolution) -> Skip connections -> Output layer (128x128 velocity model prediction)
- Critical path: Data generation -> Preprocessing -> Model training -> Validation with DSC -> Artifact analysis -> Performance assessment
- Design tradeoffs: Skip connections preserve detail but increase parameter count and risk overfitting; deeper architectures capture more complex features but require more data
- Failure signatures: Circular artifacts in upper right region, loss of fault detail in complex models, gradient-based predictions instead of sharp interfaces
- First 3 experiments:
  1. Train with reduced dataset (100 samples) to test overfitting sensitivity and establish baseline performance requirements
  2. Compare modified vs standard UNet architectures on simple models only to isolate effect of skip connection modification
  3. Introduce synthetic noise to training data to test robustness and identify failure modes in noisy conditions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What causes the circular artifact consistently appearing in the upper right region of predicted models by the modified UNet?
- Basis in paper: [explicit] The paper notes that "the models predicted by the modified UNet, when compared with the actual models, exhibit a circular artifact consistently positioned in the upper right region of the images" and suggests this may be related to geological faults near that region.
- Why unresolved: The paper identifies the artifact's presence but does not investigate its origin or develop methods to eliminate it.
- What evidence would resolve it: Systematic analysis of model predictions across different geological configurations, comparison of skip connection architectures, and controlled experiments varying network parameters could identify the artifact's source and potential solutions.

### Open Question 2
- Question: How would increasing the dataset size and complexity affect the network's ability to identify geological features like folds and faults?
- Basis in paper: [explicit] The authors state that "increasing the number of input models should improve network efficiency" and suggest that "further training of the network with more epochs and a larger dataset containing more samples with faults and folds could enhance the identification of these structures."
- Why unresolved: The current study used a limited dataset (300-1000 elements), and the authors acknowledge this as a limiting factor for training and validation.
- What evidence would resolve it: Training the same network architectures on progressively larger and more diverse datasets, then comparing performance metrics and prediction accuracy for complex geological features.

### Open Question 3
- Question: How would incorporating Physics Informed Neural Networks (PINNs) optimize the network for complex velocity models?
- Basis in paper: [explicit] The authors suggest that "introducing a Physics Informed stage to optimise the network for complex models" could be a next step in their research.
- Why unresolved: The current study uses standard UNet architectures without incorporating physical constraints or governing equations into the learning process.
- What evidence would resolve it: Implementation and comparison of PINN-based architectures against standard UNets on the same velocity model datasets, measuring improvements in prediction accuracy and physical consistency.

## Limitations
- Reliance on simulated data using DeepWave introduces uncertainty about real-world performance
- Limited dataset size (300-1000 elements) may not capture full complexity of geological variations
- Artifacts in predictions, particularly circular patterns, suggest potential architectural limitations

## Confidence

**Confidence Labels:**
- **Medium**: Claims about UNet effectiveness for velocity model prediction are supported by empirical results but lack external validation
- **Low**: Assertions about DeepWave's sufficiency for realistic data generation have minimal supporting evidence
- **Medium**: DSC metric utility is justified by intuitive interpretation but lacks domain-specific validation

## Next Checks
1. Test model performance on real seismic data from known geological formations to assess generalization beyond simulated environments
2. Compare DSC results with alternative metrics specifically designed for seismic velocity model evaluation
3. Conduct ablation studies to isolate the contribution of skip connections to performance and artifact formation