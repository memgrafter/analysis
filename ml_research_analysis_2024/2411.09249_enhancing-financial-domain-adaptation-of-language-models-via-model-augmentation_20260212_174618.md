---
ver: rpa2
title: Enhancing Financial Domain Adaptation of Language Models via Model Augmentation
arxiv_id: '2411.09249'
source_url: https://arxiv.org/abs/2411.09249
tags:
- financial
- calm
- language
- domain
- anchor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the effectiveness of Composition to Augment
  Language Models (CALM) in adapting large language models to the financial domain.
  CALM connects an anchor model with strong language capabilities to a financial-specialized
  model using cross-attention, enabling adaptation without modifying original model
  parameters.
---

# Enhancing Financial Domain Adaptation of Language Models via Model Augmentation

## Quick Facts
- arXiv ID: 2411.09249
- Source URL: https://arxiv.org/abs/2411.09249
- Authors: Kota Tanabe; Masanori Hirano; Kazuki Matoya; Kentaro Imajo; Hiroki Sakaji; Itsuki Noda
- Reference count: 38
- Key outcome: CALM achieves 0.711 on Japanese financial benchmark vs LoRA's 0.521 and individual models below 0.19

## Executive Summary
This study introduces Composition to Augment Language Models (CALM), a method for adapting large language models to the financial domain without modifying original model parameters. CALM connects an anchor model with strong language capabilities to a financial-specialized model using cross-attention layers. The approach was tested on Japanese financial benchmarks, demonstrating superior performance compared to both individual models and LoRA-based fine-tuning methods. The key finding is that connecting middle layers between models provides optimal adaptation for financial tasks.

## Method Summary
CALM connects two separate Japanese language models—a general-purpose anchor model (nekomata-14b-instruction) and a financial-specialized augmenting model (nekomata-14b-pfn-qfin)—using cross-attention layers. The anchor model processes text as usual, but cross-attention layers allow it to selectively incorporate financial knowledge from the augmenting model during generation. Only the cross-attention parameters are trained (for 20 epochs), while the original models remain frozen. The method was evaluated on a Japanese financial benchmark consisting of 360 dialogues across 12 categories, scored on a 10-point scale by GPT-4.

## Key Results
- CALM achieved 0.711 score on Japanese financial benchmark, outperforming LoRA (0.521) and individual models (below 0.19)
- Middle layer connections proved most effective, with scores: middle (0.711) > tail (0.673) > head (0.669)
- CALM requires minimal additional parameters compared to full fine-tuning while achieving superior performance
- The approach successfully avoided the <endoftext> generation failure observed in the augmenting model-only case

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-attention enables selective integration of financial knowledge without altering base model parameters
- Mechanism: The anchor model uses cross-attention layers to selectively access and incorporate financial knowledge from the augmenting model during text generation, rather than directly using its representations
- Core assumption: Cross-attention can effectively bridge representations between models while preserving the original model's language generation capabilities
- Evidence anchors:
  - [abstract]: "CALM connects an anchor model with strong language capabilities to a financial-specialized model using cross-attention, enabling adaptation without modifying original model parameters"
  - [section III]: "The operation of the cross-attention can be expressed as follows: fcross(HAi, HBj) = Concat.k(headk)W O"
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.509, average citations=0.0. Weak corpus evidence for cross-attention specific mechanisms.

### Mechanism 2
- Claim: Middle layer connections provide optimal abstraction level for financial domain adaptation
- Mechanism: Connecting middle layers allows information to be represented at an optimal level of abstraction, neither too raw (early layers) nor too specific (late layers), facilitating effective feature integration for financial tasks
- Core assumption: Middle layers capture features that are sufficiently abstract yet retain enough detail for domain-specific adaptation
- Evidence anchors:
  - [section V.A]: "The results show that the model with the connection at the middle layer achieved the highest score, followed by the model with the connection at the tail, and then the model with the connection at the head"
  - [section V.A]: "This effectiveness can be attributed to the fact that the middle layers capture features obtained from earlier processing stages while being sufficiently distant from the final layers"
  - [corpus]: Limited corpus evidence for middle-layer connection optimization in cross-attention architectures

### Mechanism 3
- Claim: CALM outperforms LoRA because it accesses broader financial knowledge through model bridging rather than parameter fine-tuning
- Mechanism: Instead of embedding limited financial knowledge into additional parameters, CALM facilitates seamless integration with the augmenting model which possesses extensive financial expertise, allowing adaptation to wider task ranges
- Core assumption: The augmenting model contains more comprehensive and diverse financial knowledge than what can be captured in a limited fine-tuning dataset
- Evidence anchors:
  - [section V.A]: "CALM updates its parameters not by embedding financial knowledge into additional parameters, but by facilitating a more seamless integration with the augmenting model"
  - [section V.A]: "Consequently, CALM is able to adapt to a wider range of tasks in the financial domain without relying solely on the limited knowledge of the training dataset"
  - [corpus]: Weak corpus evidence for comparative effectiveness of CALM vs LoRA approaches

## Foundational Learning

- Concept: Cross-attention mechanism in transformer architectures
  - Why needed here: CALM relies on cross-attention to connect two separate models, so understanding how cross-attention works is fundamental to grasping the approach
  - Quick check question: How does cross-attention differ from self-attention, and what role do the weight matrices WQ, WK, WV play in the computation?

- Concept: Catastrophic forgetting in model fine-tuning
  - Why needed here: The paper explicitly contrasts CALM with traditional approaches that suffer from catastrophic forgetting, so understanding this concept helps appreciate CALM's advantages
  - Quick check question: What causes catastrophic forgetting in fine-tuning, and how does freezing base model parameters help prevent it?

- Concept: Domain adaptation vs general fine-tuning
  - Why needed here: The study focuses on adapting models specifically to the financial domain, which requires understanding how domain-specific knowledge differs from general language capabilities
  - Quick check question: What distinguishes domain adaptation from general fine-tuning, and why might domain-specific approaches be necessary for financial tasks?

## Architecture Onboarding

- Component map: nekomata-14b-instruction (anchor) -> cross-attention layers -> nekomata-14b-pfn-qfin (augmenting) -> residual connections -> anchor model layers

- Critical path:
  1. Forward pass through anchor model generates intermediate representations
  2. Cross-attention layers process these representations with augmenting model inputs
  3. Residual connections integrate cross-attention outputs back into anchor model flow
  4. Training updates only cross-attention parameters based on financial task performance

- Design tradeoffs:
  - Parameter efficiency vs performance: CALM uses fewer parameters than full fine-tuning but requires careful connection design
  - Knowledge transfer vs independence: Models remain separate but must work cohesively through cross-attention
  - Training complexity vs inference simplicity: Training requires coordination but inference is straightforward

- Failure signatures:
  - <endoftext> token generation: Indicates model failure to generate meaningful responses (observed in augmenting model only case)
  - Performance plateau: Suggests cross-attention connections aren't effectively transferring knowledge
  - Task-specific failures: May indicate suboptimal connection layer placement or insufficient financial knowledge in augmenting model

- First 3 experiments:
  1. Test different connection layer configurations (head, middle, tail) to verify the middle layer advantage
  2. Compare CALM with various LoRA rank settings to quantify parameter efficiency benefits
  3. Evaluate cross-attention attention weight patterns to ensure financial knowledge is being selectively incorporated

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural modifications to CALM could further improve its performance on financial domain tasks?
- Basis in paper: [inferred] The paper mentions that connecting middle layers is most effective, but does not explore other architectural modifications.
- Why unresolved: The paper focuses on comparing different connection points but does not investigate other potential architectural improvements.
- What evidence would resolve it: Experiments comparing CALM with other architectural modifications (e.g., different attention mechanisms, layer normalization, etc.) would provide evidence.

### Open Question 2
- Question: How does CALM perform when adapting LLMs to other specialized domains beyond finance?
- Basis in paper: [inferred] The paper only tests CALM on financial domain adaptation.
- Why unresolved: The paper does not explore CALM's effectiveness in other domains.
- What evidence would resolve it: Testing CALM on other specialized domains (e.g., legal, medical, technical) and comparing its performance to other adaptation methods would provide evidence.

### Open Question 3
- Question: What is the optimal training dataset size for CALM to achieve effective financial domain adaptation?
- Basis in paper: [explicit] The paper mentions using a financial dataset for training CALM, but does not explore the impact of dataset size.
- Why unresolved: The paper does not investigate the relationship between dataset size and CALM's performance.
- What evidence would resolve it: Experiments varying the size of the training dataset while keeping other factors constant would provide evidence.

## Limitations

- The study's findings are limited to Japanese language models and Japanese financial datasets, limiting generalizability to other languages and cultural contexts
- The proprietary nature of the augmenting model's training data prevents full replication and independent verification
- Evaluation methodology relies on GPT-4 scoring rather than human expert evaluation, introducing potential subjectivity

## Confidence

**High Confidence**: The CALM architecture's basic mechanism of using cross-attention to connect models without modifying original parameters is well-supported by experimental results and aligns with established transformer principles.

**Medium Confidence**: The specific claim about middle-layer connections being optimal for financial domain adaptation is supported by presented results but could vary depending on specific models and domains used.

**Low Confidence**: The claim that CALM can adapt to "a wider range of tasks in the financial domain" is based on theoretical reasoning rather than extensive empirical testing across diverse financial scenarios.

## Next Checks

1. **Cross-Attention Analysis**: Perform attention weight visualization and analysis to verify that CALM is indeed selectively incorporating financial knowledge rather than just averaging or blending representations.

2. **Zero-Shot Transfer Testing**: Evaluate CALM on financial tasks completely disjoint from the training data to verify the claim about adaptation to wider task ranges.

3. **Layer Sensitivity Analysis**: Systematically test CALM with cross-attention connections at every possible layer (not just head, middle, tail) to map the full performance landscape and confirm whether middle layers are genuinely optimal.