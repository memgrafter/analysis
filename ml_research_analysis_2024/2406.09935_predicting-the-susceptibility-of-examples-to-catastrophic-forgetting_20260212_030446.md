---
ver: rpa2
title: Predicting the Susceptibility of Examples to Catastrophic Forgetting
arxiv_id: '2406.09935'
source_url: https://arxiv.org/abs/2406.09935
tags:
- learning
- buffer
- examples
- task
- forgetting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the connection between learning speed and
  catastrophic forgetting in continual learning. The authors observe that examples
  learned more quickly during training are less susceptible to forgetting when new
  tasks are introduced, a phenomenon they term "last-in-first-out forgetting." They
  demonstrate that the composition of the replay buffer significantly affects forgetting,
  with selectively sampling examples based on learning speed improving performance.
---

# Predicting the Susceptibility of Examples to Catastrophic Forgetting

## Quick Facts
- arXiv ID: 2406.09935
- Source URL: https://arxiv.org/abs/2406.09935
- Reference count: 40
- Primary result: Examples learned more quickly during training are less susceptible to catastrophic forgetting in continual learning

## Executive Summary
This work investigates the connection between learning speed and catastrophic forgetting in continual learning. The authors observe that examples learned more quickly during training are less susceptible to forgetting when new tasks are introduced, a phenomenon they term "last-in-first-out forgetting." They demonstrate that the composition of the replay buffer significantly affects forgetting, with selectively sampling examples based on learning speed improving performance. The proposed Speed-Based Sampling (SBS) method consistently improves the performance of multiple continual learning algorithms across various benchmarks.

## Method Summary
The method involves tracking per-example accuracy across training epochs to calculate a "learning speed" metric for each example. During continual learning, SBS removes the quickest and slowest learned examples from the replay buffer (removing q% of quickest and s% of slowest), then samples uniformly from the remaining examples. The hyperparameters q and s are tuned using an auxiliary rotation classification task. The approach is tested with Experience Replay (ER) and other buffer-based continual learning methods on CIFAR-10, CIFAR-100, and TinyImageNet datasets using ResNet-18 architectures with 100 epochs per task.

## Key Results
- Examples learned more quickly during training are less prone to catastrophic forgetting (r = 0.995 correlation for CIFAR-100-2)
- The optimal replay buffer composition shifts from quickly-learned examples (small buffers) to slowly-learned examples (large buffers) as buffer size increases
- SBS significantly improves the performance of multiple continual learning algorithms, advancing state-of-the-art results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Examples learned more quickly during training are less susceptible to catastrophic forgetting when new tasks are introduced.
- Mechanism: Neural networks exhibit a "last-in-first-out forgetting" pattern where recently learned examples (which are often more complex) are forgotten first when learning new tasks, while quickly learned examples (which are simpler) are retained.
- Core assumption: Learning speed serves as a proxy for example complexity, with simpler examples being learned faster.
- Evidence anchors: [abstract] "examples learned more quickly are less prone to forgetting"; [section] "examples learned more quickly during the first task tend to remain correctly classified throughout the second task, whereas slower-learned examples are prone to immediate misclassification"
- Break condition: If learning speed does not correlate with complexity, or if the network architecture fundamentally changes how learning speed relates to retention.

### Mechanism 2
- Claim: The optimal replay buffer composition shifts from quickly-learned examples (in small buffers) to slowly-learned examples (in large buffers) as buffer size increases.
- Mechanism: Small buffers must prioritize the most critical examples for retention (quickly-learned, simpler ones), while larger buffers can afford to store more complex, slowly-learned examples that benefit more from replay.
- Core assumption: Buffer size constrains which examples can be stored, and different examples benefit differently from replay based on their learning speed.
- Evidence anchors: [section] "With bigger buffers, the networks can remember gradually slower-to-learn examples"; [section] "when the buffer size is smaller, it is more beneficial to remove slowly-learned examples, focusing mainly on the easier examples learned quickly by the models. In contrast, with larger buffers, the optimal focus in the buffer shifts towards harder, slowly-learned examples"
- Break condition: If buffer size doesn't affect which examples are most valuable to retain, or if all examples benefit equally from replay regardless of learning speed.

### Mechanism 3
- Claim: Speed-Based Sampling (SBS) improves performance across diverse continual learning algorithms by selectively prioritizing examples based on their learning speed.
- Mechanism: By removing q% of the quickest and s% of the slowest learned examples and sampling uniformly from the remainder, SBS creates a buffer focused on moderately difficult examples that benefit most from replay while excluding extremes.
- Core assumption: A middle range of learning speeds contains examples that are neither too simple (already well-learned) nor too complex (unlikely to benefit from limited replay).
- Evidence anchors: [abstract] "SBS integrates easily with existing buffer-based continual learning methods and consistently improves performance across various competitive benchmarks"; [section] "We find that selecting moderately fast-learning examples – the simplest and quickest to learn, which are still complex enough to benefit from replay – is particularly effective"
- Break condition: If the middle range of learning speeds doesn't consistently contain the most beneficial examples, or if the q/s parameters can't be effectively tuned.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: This is the core problem the paper addresses - understanding why neural networks forget previously learned tasks when learning new ones
  - Quick check question: What is the difference between catastrophic forgetting and general forgetting in neural networks?

- Concept: Simplicity bias in neural network learning
  - Why needed here: The paper relies on the observation that neural networks learn simple patterns before complex ones, which underpins the learning speed metric
  - Quick check question: How does simplicity bias relate to the order in which examples are learned during training?

- Concept: Experience replay in continual learning
  - Why needed here: The proposed SBS method is a sampling strategy for replay buffers, which are fundamental to many continual learning approaches
  - Quick check question: What is the primary purpose of replay buffers in continual learning, and how do they typically function?

## Architecture Onboarding

- Component map:
  - Learning speed calculator: Tracks per-example accuracy across epochs during task training
  - SBS parameter tuner: Determines q and s parameters using auxiliary rotation task
  - Buffer manager: Handles sampling from filtered dataset D' based on learning speed thresholds
  - Integration layer: Wraps around existing CL algorithms to replace uniform sampling

- Critical path:
  1. Train on task t while recording epoch-wise classifications
  2. Calculate learning speeds for all examples
  3. Filter dataset by removing extreme learning speed examples
  4. Sample uniformly from remaining examples for replay buffer
  5. Continue training with modified buffer

- Design tradeoffs:
  - Memory vs. accuracy: Storing full epoch-wise classification matrix vs. running mean
  - Computational overhead: Additional forward passes for learning speed calculation vs. performance gains
  - Hyperparameter tuning: RotNet-based parameter selection vs. default (q=s=20%) values

- Failure signatures:
  - SBS degrades performance: q and s parameters poorly tuned or learning speed metric ineffective
  - No improvement over uniform sampling: Buffer too small/large or examples not benefiting from replay
  - Increased computational cost without benefit: Learning speed calculation overhead outweighs gains

- First 3 experiments:
  1. Implement basic SBS with fixed q=s=20% on CIFAR-10-2 with ER algorithm, compare to uniform sampling
  2. Vary buffer sizes (1k, 3k, 10k) to observe optimal learning speed ranges
  3. Test different q/s parameter combinations using RotNet auxiliary task to find optimal settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does learning speed relate to example complexity in more diverse datasets beyond CIFAR and TinyImageNet?
- Basis in paper: [explicit] The authors demonstrate that faster-learned examples are less prone to forgetting across various datasets and architectures, suggesting a link between learning speed and example complexity.
- Why unresolved: The study focuses on image classification datasets. It remains unclear whether the observed relationship holds for other data modalities like text, audio, or graphs.
- What evidence would resolve it: Empirical studies applying SBS and measuring learning speed on diverse datasets across different domains would clarify the generalizability of the learning speed-complexity relationship.

### Open Question 2
- Question: Can the learning speed metric be adapted for scenarios with minimal or single training epochs?
- Basis in paper: [inferred] The authors acknowledge that learning speed is computed over multiple epochs, making it less suitable for streaming or single-pass settings.
- Why unresolved: The paper highlights this as a limitation but does not propose alternative metrics or adaptations for single-epoch scenarios.
- What evidence would resolve it: Developing and validating alternative complexity measures that work with limited training passes would address this gap.

### Open Question 3
- Question: Does the optimal replay buffer composition change based on task similarity or domain shift?
- Basis in paper: [explicit] The authors test different task sequences (e.g., CIFAR-100 → rotated, CIFAR-100 → random labels) and find the optimal buffer composition remains consistent, suggesting robustness to task dissimilarity.
- Why unresolved: While the paper shows consistency across some task variations, it does not explore gradual domain shifts or highly dissimilar tasks systematically.
- What evidence would resolve it: Experiments varying task similarity and domain shift while monitoring buffer composition effects would clarify whether the observed robustness holds broadly.

## Limitations
- The observed correlation between learning speed and forgetting resistance may not generalize across different architectures or domains
- The mechanism explanations rely heavily on the assumed link between learning speed and example complexity, which lacks direct validation beyond correlation studies
- The auxiliary task approach for hyperparameter tuning requires careful implementation and may not transfer perfectly across different problem domains

## Confidence
- Learning speed correlates with forgetting resistance: High
- SBS improves performance across algorithms: High
- Optimal buffer composition shifts with buffer size: Medium
- RotNet-based hyperparameter tuning is effective: Medium

## Next Checks
1. Test SBS on non-image domains (text or tabular data) to verify the learning speed-forgetting relationship holds beyond visual datasets
2. Implement ablation studies varying the q and s parameters systematically to identify their sensitivity and optimal ranges for different buffer sizes
3. Compare learning speed metrics based on running means versus epoch-wise classification matrices to assess computational efficiency tradeoffs