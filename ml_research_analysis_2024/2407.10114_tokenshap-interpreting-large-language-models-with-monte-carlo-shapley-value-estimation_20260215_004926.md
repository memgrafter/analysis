---
ver: rpa2
title: 'TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value
  Estimation'
arxiv_id: '2407.10114'
source_url: https://arxiv.org/abs/2407.10114
tags:
- shapley
- values
- tokenshap
- importance
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TokenSHAP introduces a novel approach for interpreting large language
  models (LLMs) by attributing importance to individual tokens using Monte Carlo Shapley
  value estimation. The method addresses the challenge of understanding how different
  parts of an input prompt contribute to a model's response, which is crucial for
  applications in critical domains like healthcare and legal analysis.
---

# TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation

## Quick Facts
- arXiv ID: 2407.10114
- Source URL: https://arxiv.org/abs/2407.10114
- Reference count: 18
- Primary result: TokenSHAP introduces Monte Carlo Shapley value estimation for interpreting LLMs by attributing importance to individual tokens

## Executive Summary
TokenSHAP introduces a novel approach for interpreting large language models (LLMs) by attributing importance to individual tokens using Monte Carlo Shapley value estimation. The method addresses the challenge of understanding how different parts of an input prompt contribute to a model's response, which is crucial for applications in critical domains like healthcare and legal analysis. Experiments demonstrate TokenSHAP's effectiveness across diverse prompts and LLM architectures, showing consistent improvements over existing baselines in alignment with human judgments, faithfulness to model behavior, and consistency.

## Method Summary
TokenSHAP adapts Shapley values from cooperative game theory to natural language processing, treating input tokens as players and assessing their contribution to model outputs. The method employs Monte Carlo sampling to efficiently estimate Shapley values, making it computationally feasible for variable-length text inputs. TokenSHAP defines a value function based on cosine similarity between TF-IDF vectors of model responses, providing a quantitative measure of token importance. The approach leverages Monte Carlo sampling for computational efficiency while maintaining interpretability through rigorous mathematical foundations.

## Key Results
- TokenSHAP significantly excels at distinguishing between relevant and irrelevant tokens with realistic and lower SHAP values for injected words
- The method shows consistent improvements over existing baselines in alignment with human judgments, faithfulness to model behavior, and consistency
- Including first-order omission conditions in Monte Carlo sampling maintains stable similarity to true Shapley values even at low sampling ratios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TokenSHAP provides more accurate token importance attribution than baseline methods like random assignment or prompt engineering.
- Mechanism: TokenSHAP uses Shapley value estimation via Monte Carlo sampling, which considers all possible subsets of tokens and their marginal contributions to the model output. This rigorous mathematical framework captures both individual and interactive effects of tokens.
- Core assumption: The Shapley value framework correctly models token contributions in the context of language models, and Monte Carlo sampling provides a sufficiently accurate approximation.
- Evidence anchors:
  - [abstract] "We demonstrate its efficacy across diverse prompts and LLM architectures, showing consistent improvements over existing baselines in alignment with human judgments, faithfulness to model behavior, and consistency."
  - [section] "TokenSHAP significantly excelled, effectively distinguishing between relevant and irrelevant tokens with its realistic and lower SHAP values for injected words"
  - [corpus] Weak evidence - no directly comparable papers found in corpus
- Break condition: If the Monte Carlo sampling ratio is too low or if the value function doesn't adequately capture semantic similarity, the approximation becomes unreliable.

### Mechanism 2
- Claim: TokenSHAP's use of cosine similarity between TF-IDF vectors of model responses provides a quantitative measure of token importance.
- Mechanism: By comparing the TF-IDF representation of responses to subsets of tokens versus the full prompt, TokenSHAP measures how much each token contributes to the semantic content of the output.
- Core assumption: TF-IDF vectors provide a meaningful representation of semantic similarity between model responses that correlates with token importance.
- Evidence anchors:
  - [section] "We define the value function v(S) as the cosine similarity between the TF-IDF vectors of the model's response to the subset S and the response to the full prompt."
  - [abstract] "This approach adapts Shapley values from cooperative game theory to natural language processing, offering a rigorous framework for understanding how different parts of an input contribute to a model's response."
  - [corpus] Weak evidence - no directly comparable papers found in corpus
- Break condition: If the model's response semantic content doesn't align well with TF-IDF representations, or if cosine similarity doesn't capture meaningful differences in token contributions.

### Mechanism 3
- Claim: Including first-order omission conditions in Monte Carlo sampling improves approximation accuracy at low sampling ratios.
- Mechanism: By always including subsets that omit exactly one token, TokenSHAP ensures a consistent baseline for comparison and reduces noise in the approximation at low sampling ratios.
- Core assumption: First-order omissions provide critical information that stabilizes the approximation process, especially when sampling resources are limited.
- Evidence anchors:
  - [section] "Figure 6 presents the results, indicating significant differences in approximation accuracy depending on the presence of the first-order omission condition. With this condition, even at lower sampling ratios such as 0.1 and 0.0, the similarity between the estimated and true Shapley values remains relatively stable"
  - [abstract] "TokenSHAP leverages Monte Carlo sampling for computational efficiency, providing interpretable, quantitative measures of token importance."
  - [corpus] Weak evidence - no directly comparable papers found in corpus
- Break condition: If the computational cost of including first-order omissions outweighs the accuracy benefits, or if the model's behavior is insensitive to single-token omissions.

## Foundational Learning

- Concept: Shapley value theory from cooperative game theory
  - Why needed here: Provides the mathematical foundation for attributing importance to tokens based on their marginal contributions across all possible subsets
  - Quick check question: How does the Shapley value formula ensure fair attribution of credit among cooperative players (tokens)?

- Concept: Monte Carlo sampling techniques
  - Why needed here: Enables efficient approximation of Shapley values by sampling from the exponential space of token subsets rather than exhaustive enumeration
  - Quick check question: What is the relationship between sampling ratio and approximation accuracy in Monte Carlo methods?

- Concept: TF-IDF vector representation and cosine similarity
  - Why needed here: Provides a quantitative measure of semantic similarity between model responses that serves as the value function for Shapley value computation
  - Quick check question: How does cosine similarity between TF-IDF vectors capture the semantic relationship between two text documents?

## Architecture Onboarding

- Component map:
  Tokenization module -> Monte Carlo sampler -> Model interface -> TF-IDF processor -> Cosine similarity calculator -> Shapley value estimator -> Visualization module

- Critical path:
  1. Tokenize input prompt
  2. Generate baseline response for full prompt
  3. Sample token subsets using Monte Carlo method
  4. Query model with each subset and compute response
  5. Calculate cosine similarity between subset responses and baseline
  6. Estimate Shapley values for each token
  7. Normalize and visualize importance scores

- Design tradeoffs:
  - Sampling ratio vs. computational cost: Higher ratios improve accuracy but increase runtime
  - Token granularity (token vs. substring): Affects interpretability and computational complexity
  - Value function choice (TF-IDF vs. alternatives): Impacts sensitivity to semantic content
  - First-order omission inclusion: Improves stability at low sampling ratios but adds computational overhead

- Failure signatures:
  - Low variance in importance scores: May indicate insufficient sampling or poor value function choice
  - Inconsistent results across runs: Suggests need for higher sampling ratio or better random seed management
  - High computational cost: Could benefit from parallel processing or optimized sampling strategy
  - Poor alignment with human judgments: May require revisiting value function or tokenization approach

- First 3 experiments:
  1. Run TokenSHAP on a simple prompt with known important tokens to verify basic functionality
  2. Compare importance scores across different sampling ratios to assess approximation stability
  3. Test with different value functions (e.g., simple string matching vs. TF-IDF) to evaluate impact on results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of first-order omission conditions affect the accuracy and computational efficiency of TokenSHAP across different sampling ratios?
- Basis in paper: [explicit] The paper discusses the impact of first-order omission conditions on Monte Carlo Shapley value approximation, noting that including these conditions maintains stable similarity to true Shapley values even at low sampling ratios.
- Why unresolved: The paper provides experimental results showing the benefits of including first-order omissions, but does not explore the trade-offs between accuracy and computational cost across a wide range of sampling ratios or model sizes.
- What evidence would resolve it: A comprehensive study comparing TokenSHAP's performance with and without first-order omissions across various sampling ratios, model architectures, and input lengths, measuring both accuracy and computational time.

### Open Question 2
- Question: How does TokenSHAP's performance compare to other interpretability methods when applied to multi-turn conversational contexts?
- Basis in paper: [inferred] The paper mentions extending TokenSHAP to multi-turn conversations as a potential future work, suggesting that its performance in such contexts has not been evaluated.
- Why unresolved: The paper focuses on single-turn prompts and does not address the unique challenges of interpreting token importance in conversational AI, where context and history play crucial roles.
- What evidence would resolve it: Experiments applying TokenSHAP to multi-turn conversations, comparing its interpretability results with other methods like attention mechanisms or conversational probing techniques, and evaluating its ability to capture evolving context.

### Open Question 3
- Question: Can alternative value functions, such as those based on semantic similarity or contextual alignment, improve TokenSHAP's interpretability accuracy compared to the current TF-IDF cosine similarity approach?
- Basis in paper: [explicit] The paper mentions exploring alternative value functions as future work, suggesting that the current TF-IDF cosine similarity may not capture all nuances of semantic relationships.
- Why unresolved: The paper uses TF-IDF cosine similarity as the value function but does not compare its performance to other potential functions like semantic embeddings or context-aware similarity measures.
- What evidence would resolve it: Comparative studies using different value functions within TokenSHAP, evaluating their impact on interpretability accuracy, computational efficiency, and alignment with human judgments across diverse NLP tasks and model architectures.

## Limitations
- TokenSHAP's performance heavily relies on the Monte Carlo sampling ratio, with optimal ratios varying across different LLM architectures and prompt types
- The TF-IDF-based value function may not fully capture nuanced semantic relationships between token subsets and model responses
- The method requires multiple LLM queries for each prompt analysis, which could become prohibitive for very long prompts or multiple prompt analyses

## Confidence

**High Confidence Claims**:
- TokenSHAP provides a rigorous mathematical framework for token importance attribution based on Shapley value theory
- The method effectively distinguishes between relevant and injected words in prompts
- Including first-order omission conditions improves approximation stability at low sampling ratios

**Medium Confidence Claims**:
- TokenSHAP consistently outperforms baseline methods across diverse prompts and LLM architectures
- The TF-IDF-based value function adequately captures semantic relationships between model responses
- The method generalizes well to different LLM architectures without significant modification

**Low Confidence Claims**:
- Specific sampling ratios that guarantee optimal performance across all use cases
- The method's effectiveness with extremely long prompts (>1000 tokens)
- Performance in specialized domains requiring domain-specific tokenization or value functions

## Next Checks
1. **Sampling Ratio Sensitivity Analysis**: Systematically vary the Monte Carlo sampling ratio from 0.01 to 1.0 across different prompt lengths and LLM architectures to determine the relationship between sampling ratio, approximation accuracy, and computational cost. Measure the point of diminishing returns where additional samples provide negligible improvement.

2. **Cross-Architecture Robustness Test**: Evaluate TokenSHAP's performance across at least five different LLM architectures (including both decoder-only and encoder-decoder models) using identical prompts and baselines. Compare not just the importance rankings but also the computational efficiency and sensitivity to sampling parameters.

3. **Domain-Specific Adaptation Validation**: Test TokenSHAP in specialized domains (medical, legal, technical) where domain-specific terminology and tokenization rules may affect performance. Compare results with domain experts' assessments of token importance and evaluate whether the TF-IDF value function needs modification for optimal performance in these contexts.