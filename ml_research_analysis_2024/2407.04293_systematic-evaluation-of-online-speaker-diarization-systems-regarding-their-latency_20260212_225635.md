---
ver: rpa2
title: Systematic Evaluation of Online Speaker Diarization Systems Regarding their
  Latency
arxiv_id: '2407.04293'
source_url: https://arxiv.org/abs/2407.04293
tags:
- speaker
- latency
- diarization
- online
- audio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluates latency of online speaker diarization systems
  on identical hardware. DIART framework models, UIS-RNN-SML clustering, and FS-EEND
  end-to-end systems are tested.
---

# Systematic Evaluation of Online Speaker Diarization Systems Regarding their Latency

## Quick Facts
- **arXiv ID**: 2407.04293
- **Source URL**: https://arxiv.org/abs/2407.04293
- **Reference count**: 21
- **Key outcome**: DIART with pyannote/embedding and pyannote/segmentation achieved lowest latency (0.057s), FS-EEND similar (0.058s), UIS-RNN-SML latency increases linearly with stream length

## Executive Summary
This work systematically evaluates the latency of three online speaker diarization systems on identical hardware. The DIART framework, UIS-RNN-SML clustering, and FS-EEND end-to-end systems are tested using the same audio chunks and test data. Latency is measured as the time from audio chunk input to speaker label output. Results show that DIART with specific embedding and segmentation models achieves the lowest latency, while FS-EEND performs similarly with constant latency. UIS-RNN-SML shows linear latency increase with stream length due to beam search decoding, making it unsuitable for long streams.

## Method Summary
The study compares three online speaker diarization systems: DIART framework, UIS-RNN-SML, and FS-EEND. DIART uses a modular approach with embedding, segmentation, and incremental clustering components. UIS-RNN-SML employs a unified RNN-based approach with beam search decoding. FS-EEND uses an end-to-end transformer architecture. All systems are evaluated on VOXConverse testset files processed in 250ms chunks. Latency measurements are taken using Python's time.perf_counter on an Intel Xeon Gold 5215 CPU. The UIS-RNN-SML and FS-EEND models are trained on the TIMIT dataset, while DIART uses pretrained models.

## Key Results
- DIART with pyannote/embedding and pyannote/segmentation achieved the lowest latency at 0.057s mean
- FS-EEND maintained constant latency at 0.058s mean, regardless of stream length
- UIS-RNN-SML latency increased linearly with stream length due to beam search decoding
- Embedding model choice significantly impacts DIART latency, with pyannote/embedding being the fastest
- All systems achieved acceptable latency for real-time applications, except UIS-RNN-SML for long streams

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DIART framework achieves lowest latency due to optimal embedding and segmentation model pairing
- Mechanism: The DIART pipeline's latency is dominated by the embedding model size and depth. pyannote/embedding, being based on a small TDNN architecture (~4.3 million parameters), processes audio chunks fastest. Combined with pyannote/segmentation, which uses lightweight convolutional and LSTM layers (~1.4 million parameters), the overall latency remains low (0.057s mean).
- Core assumption: Embedding model complexity is the primary latency driver; segmentation model impact is secondary.
- Evidence anchors:
  - [abstract] "The lowest latency is achieved for the DIART-pipeline with the embedding model pyannote/embedding and the segmentation model pyannote/segmentation."
  - [section] "It is also noticeable that the embedding models are primarily decisive for the latency."
  - [corpus] Weak correlation: no direct latency comparison with other embedding combinations in corpus papers.
- Break condition: If embedding model complexity were not the main driver, other DIART model combinations with similar segmentation models would show comparable latencies.

### Mechanism 2
- Claim: FS-EEND maintains constant latency due to self-attention architecture
- Mechanism: FS-EEND uses self-attention modules that can process past frames without increasing latency as stream length grows. Unlike RNN-based systems that add beam states per chunk, self-attention maintains constant processing time per chunk (0.058s mean).
- Core assumption: Self-attention modules do not accumulate state linearly with stream length.
- Evidence anchors:
  - [abstract] "The FS-EEND system shows a similarly good latency."
  - [section] "The latency remains constant regardless of the length of the audio stream."
  - [corpus] No corpus evidence of self-attention latency behavior; inference based on architecture description.
- Break condition: If self-attention modules accumulated state similarly to RNN beam search, latency would increase with stream length.

### Mechanism 3
- Claim: UIS-RNN-SML latency increases linearly with stream length due to beam search
- Mechanism: UIS-RNN-SML performs beam search on label space for each new chunk, adding one beam state per chunk. This creates O(t²) total runtime complexity, causing latency to increase proportionally with stream length.
- Core assumption: Beam search state accumulation is linear with chunk count.
- Evidence anchors:
  - [section] "For each new chunk a further beam state is added to the beam search. This increases the decoding time per chunk linearly O(t)."
  - [section] "The latency per chunk increases with the length of the audio stream."
  - [corpus] No corpus papers explicitly discuss UIS-RNN-SML beam search latency; evidence from system description.
- Break condition: If beam search could be truncated or optimized, latency growth would be sublinear.

## Foundational Learning

- Concept: Speaker Diarization Pipeline Components
  - Why needed here: Understanding the three sub-tasks (SAD, Segmentation, Clustering) is essential to grasp why different systems have varying latency profiles.
  - Quick check question: Which component of the speaker diarization pipeline is most likely to introduce latency in online systems?

- Concept: Online vs. Offline Diarization
  - Why needed here: The distinction determines system design choices that directly impact latency measurement and comparison methodology.
  - Quick check question: What is the primary constraint that makes online diarization systems inherently more complex than offline systems?

- Concept: Beam Search Complexity
  - Why needed here: Understanding beam search O(t²) complexity explains why UIS-RNN-SML becomes unsuitable for long streams.
  - Quick check question: If beam search adds one state per chunk, what is the total number of states after processing t chunks?

## Architecture Onboarding

- Component map: DIART = Embedding + Segmentation + Incremental Clustering; UIS-RNN-SML = SAD + Segmentation + RNN Clustering; FS-EEND = End-to-end Transformer
- Critical path: Input → Feature Extraction → Diarization Processing → Output; latency measured from input to label output
- Design tradeoffs: DIART balances modularity with latency (embedding choice critical); FS-EEND sacrifices speaker flexibility for constant latency; UIS-RNN-SML provides good accuracy for short streams but poor scalability
- Failure signatures: DIART: embedding model too large; UIS-RNN-SML: latency grows linearly with stream length; FS-EEND: maximum speaker count exceeded
- First 3 experiments:
  1. Measure latency of DIART with different embedding models on same hardware to confirm embedding model dominance
  2. Test FS-EEND with varying maximum speaker counts to observe accuracy-latency tradeoff
  3. Run UIS-RNN-SML on increasingly long streams to verify O(t²) complexity empirically

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does latency scale with the number of speakers in DIART framework when using longer audio streams?
- Basis in paper: [explicit] The authors note that the DIART framework's latency should theoretically increase with the number of speakers due to incremental clustering, but this correlation was not observed in their test setup.
- Why unresolved: The evaluation setup used a limited number of speakers, preventing observation of this correlation.
- What evidence would resolve it: Testing DIART framework with audio streams containing a larger number of speakers to measure latency scaling.

### Open Question 2
- Question: What is the accuracy-latency tradeoff for UIS-RNN-SML and FS-EEND when trained with comparable quality models to DIART?
- Basis in paper: [explicit] The authors note they lacked sufficient training data to achieve comparable model quality for UIS-RNN-SML and FS-EEND as the pretrained DIART models, making accuracy-latency comparisons difficult.
- Why unresolved: Insufficient training data prevented achieving comparable model quality for these systems.
- What evidence would resolve it: Training UIS-RNN-SML and FS-EEND models with sufficient data to match DIART's accuracy, then measuring both latency and accuracy.

### Open Question 3
- Question: What is the maximum practical number of speakers for real-time online speaker diarization systems?
- Basis in paper: [inferred] The paper shows UIS-RNN-SML's latency increases linearly with stream length due to beam search decoding, and FS-EEND requires knowing maximum speakers in advance, suggesting practical limitations exist.
- Why unresolved: The paper doesn't test these systems with streams containing many speakers, only evaluating latency over time for individual speakers.
- What evidence would resolve it: Testing these systems with audio streams containing progressively more speakers while measuring both latency and accuracy to determine practical limits.

## Limitations

- Latency measurements are based on a single hardware configuration without considering GPU acceleration, which could significantly impact absolute latency values.
- The study uses only four VOXConverse files totaling approximately 20 minutes of audio, which may not adequately represent diverse diarization scenarios.
- UIS-RNN-SML latency characterization relies on theoretical beam search complexity without empirical verification of the linear increase with stream length.

## Confidence

- **High Confidence**: DIART pipeline latency being primarily driven by embedding model choice
- **Medium Confidence**: FS-EEND maintaining constant latency due to self-attention architecture
- **Medium Confidence**: UIS-RNN-SML latency increasing linearly with stream length due to beam search

## Next Checks

1. **Hardware Variation Test**: Measure latency of all three systems on both CPU and GPU configurations to quantify hardware dependency and verify the absolute latency advantage of FS-EEND under different processing environments.
2. **Stream Length Scalability Test**: Systematically evaluate UIS-RNN-SML on progressively longer audio streams (from 1 minute to 60+ minutes) to empirically verify the predicted linear increase in per-chunk latency and identify the practical stream length limit.
3. **Embedding Model Impact Validation**: Conduct controlled experiments varying only the embedding model in the DIART framework while keeping segmentation and clustering components constant to definitively establish the quantitative relationship between embedding model size and latency.