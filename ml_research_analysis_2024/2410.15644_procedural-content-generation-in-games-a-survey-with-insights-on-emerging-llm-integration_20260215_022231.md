---
ver: rpa2
title: 'Procedural Content Generation in Games: A Survey with Insights on Emerging
  LLM Integration'
arxiv_id: '2410.15644'
source_url: https://arxiv.org/abs/2410.15644
tags:
- games
- content
- generation
- game
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper comprehensively reviews procedural content generation
  (PCG) methods in games, categorizing algorithms into search-based, machine learning-based,
  other methods, large language models (LLMs), and combined approaches. The paper
  analyzes 207 recent publications from 2019-2023, finding that level generation remains
  the dominant research focus, particularly for 2D platformers like Super Mario Bros.
---

# Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration

## Quick Facts
- arXiv ID: 2410.15644
- Source URL: https://arxiv.org/abs/2410.15644
- Reference count: 26
- Key outcome: Comprehensive survey of PCG methods from 2019-2023, identifying LLM integration as a disruptive trend in procedural content generation for games

## Executive Summary
This survey paper systematically reviews 207 publications on procedural content generation (PCG) in games from 2019-2023, categorizing algorithms into search-based, machine learning-based, other methods, LLMs, and combined approaches. The analysis reveals that level generation remains the dominant research focus, particularly for 2D platformers, while machine learning methods have gained significant traction. A notable finding is the surge in LLM usage starting in 2023 following the release of ChatGPT, representing a major shift in PCG research trajectory. The paper identifies key gaps including limited research on 3D level generation and the disconnect between academic work and industry applications.

## Method Summary
The survey analyzes papers from five conference series (AIIDE, FDG, ACG, CHI-PLAY, CoG) using systematic review methodology with inclusion/exclusion criteria. Papers are categorized by algorithm type and content generation focus, then analyzed for trends in publication patterns, algorithm usage, and content types. The methodology identifies 207 recent publications and examines the evolution of PCG approaches over the five-year period, with particular attention to the emergence of LLM-based methods and combined approaches.

## Key Results
- Level generation remains the dominant research focus, especially for 2D platformers like Super Mario Bros
- Machine learning methods, particularly deep learning approaches, have gained significant traction since 2019
- LLM usage surged dramatically in 2023 following ChatGPT release, marking a disruptive shift in PCG research
- Combined methods integrating LLMs with other algorithms represent an emerging research direction
- Limited research exists on 3D level generation despite its importance in the games industry

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Search-based methods provide structured exploration of content space by evaluating candidate content using fitness functions and iteratively improving upon previous candidates.
- Mechanism: Search-based PCG operates on a generate-and-test paradigm where content is evaluated using a fitness function that assigns real values to measure acceptability. The algorithm then uses this feedback to modify and improve subsequent content generation attempts, creating a directed search through the content space rather than random generation.
- Core assumption: The fitness function accurately captures what makes content acceptable or playable, and the search space is navigable through incremental modifications.
- Evidence anchors:
  - [section] "A search-based PCG refers to a special case of generate-and-test PCG. A generate-and-test PCG does not directly dish out content it generates but instead tests the content first using a test function. Depending on the test result, the PCG can either accept the content or reject it and create new content. A search-based PCG is a test-and-generate PCG that satisfies two criteria..."
  - [section] "In many cases, search-based algorithms use some form of evolutionary algorithm as the main search mechanism, as evolutionary computation has so far been the method of choice among search-based PCG practitioners."
- Break condition: The fitness function fails to capture essential playability requirements, or the search space becomes too large/complex for incremental improvements to be effective.

### Mechanism 2
- Claim: Machine learning methods, particularly deep learning approaches, learn patterns from existing game content to generate new, novel content that maintains structural and aesthetic coherence.
- Mechanism: ML-based PCG algorithms analyze large datasets of existing game content (levels, textures, mechanics) and learn statistical patterns, distributions, and relationships. These learned representations are then used to generate new content that shares similar properties while being novel. The approach is particularly effective when dealing with complex, high-dimensional data like images or sequences.
- Core assumption: The training data is representative of the desired content space and captures sufficient diversity to enable meaningful generation.
- Evidence anchors:
  - [abstract] "While recent advances in deep learning approaches in PCG have enabled researchers and practitioners to create more sophisticated content, it is the arrival of Large Language Models (LLMs) that truly disrupted the trajectory of PCG advancement."
  - [section] "Machine learning methods have gained a lot of popularity during the last decade... They have provided us with new ways for generating audio, images, 3D objects, network layouts, and other content types across a range of domains, including games."
- Break condition: Insufficient or biased training data leads to generation of repetitive or unplayable content that fails to generalize beyond the training distribution.

### Mechanism 3
- Claim: Large Language Models enable procedural content generation through natural language understanding and generation, allowing for creation of narrative elements, dialogue, and even level designs described in text form.
- Mechanism: LLMs process and generate text sequences using transformer architectures with self-attention mechanisms. This allows them to understand complex relationships between concepts and generate coherent, contextually appropriate content. When fine-tuned on game-related data, LLMs can generate game narratives, dialogue, quest descriptions, and even level specifications that can be interpreted by game engines.
- Core assumption: The LLM has been sufficiently trained on relevant game content and can generalize to produce meaningful, playable content beyond simple pattern matching.
- Evidence anchors:
  - [abstract] "it is the arrival of Large Language Models (LLMs) that truly disrupted the trajectory of PCG advancement"
  - [section] "Language models are also used in role-playing board games as an assistant for the game masters... LLMs can also be used to create game levels. SCENECRAFT is a framework that transforms high-level natural language instructions from authors into dynamic game scenes..."
- Break condition: The LLM produces content that is syntactically correct but semantically meaningless or unplayable, or the generated text cannot be effectively translated into actual game content.

## Foundational Learning

- Concept: Search-based optimization algorithms
  - Why needed here: Understanding how evolutionary algorithms, Monte Carlo Tree Search, and simulated annealing work is crucial for grasping how PCG systems can systematically explore and optimize content generation.
  - Quick check question: What distinguishes a search-based PCG from a simple generate-and-test approach?

- Concept: Machine learning fundamentals (neural networks, training, evaluation)
  - Why needed here: ML-based PCG methods rely on understanding how neural networks learn from data, the difference between supervised and unsupervised learning, and how to evaluate generated content quality.
  - Quick check question: How does a GAN differ from a standard autoencoder in terms of training objectives and outputs?

- Concept: Natural language processing and transformer architectures
  - Why needed here: LLMs are built on transformer architectures with attention mechanisms, and understanding these concepts is essential for working with LLM-based PCG systems.
  - Quick check question: What is the key innovation of transformers that makes them effective for sequence generation tasks?

## Architecture Onboarding

- Component map: Content representation layer -> Algorithm selection layer -> Evaluation/fitness function layer -> Generation pipeline layer -> Integration layer
- Critical path:
  1. Define content requirements and constraints
  2. Select appropriate PCG algorithm(s) based on content type
  3. Implement content representation suitable for chosen algorithms
  4. Develop evaluation/fitness functions or training datasets
  5. Build generation pipeline with appropriate validation steps
  6. Integrate generated content into game engine
- Design tradeoffs:
  - Quality vs. diversity: More constrained generation produces higher quality but less diverse content
  - Computational cost vs. generation speed: Complex algorithms may produce better content but require more resources
  - Control vs. autonomy: More designer control limits algorithm creativity but ensures content meets requirements
- Failure signatures:
  - Repetitive or predictable content generation
  - Generated content that fails validation tests
  - Extremely long generation times or resource exhaustion
  - Generated content that cannot be integrated into game engine
- First 3 experiments:
  1. Implement a simple search-based PCG for 2D level generation using cellular automata or BSP trees, evaluate with basic playability metrics
  2. Train a simple GAN on a dataset of existing game levels to generate new levels, evaluate diversity and playability
  3. Fine-tune an existing LLM (like GPT-2) on game narrative data to generate quest descriptions, evaluate coherence and creativity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are combined methods (especially those integrating LLMs with other algorithms) compared to using single algorithms for procedural content generation?
- Basis in paper: [explicit] The paper identifies combined methods as an emerging approach and highlights specific examples like Kumaran et al. (2023a) combining GPT-3.5 with deep reinforcement learning and Volden et al. (2023) combining LLMs with genetic algorithms
- Why unresolved: While the paper mentions these combined approaches exist and have potential, it doesn't provide comparative performance metrics or systematic evaluation of when and why combining methods is more effective than single approaches
- What evidence would resolve it: Empirical studies comparing the quality, efficiency, and diversity of content generated by combined methods versus individual algorithms across multiple game types and content categories

### Open Question 2
- Question: What are the specific limitations and ethical considerations when using commercial LLM services (MaaS) versus open-source alternatives for procedural content generation?
- Basis in paper: [explicit] The paper notes that research using GPT-3 and successors is restricted by private entities, creating a "black box," and mentions ethical considerations when using LLMs for generating game content
- Why unresolved: The paper identifies these issues exist but doesn't explore the practical implications, limitations in research capabilities, or specific ethical concerns that arise from using commercial versus open-source LLMs
- What evidence would resolve it: Comparative studies of commercial vs. open-source LLM capabilities for PCG, analysis of research restrictions imposed by commercial services, and documented ethical issues in practical applications

### Open Question 3
- Question: What algorithms and approaches are most effective for generating 3D game content compared to 2D content?
- Basis in paper: [explicit] The paper identifies a significant gap in research focusing on 3D level generation, noting that "3D games are very popular in the games industry, and level generation for 3D games is a topic that needs further research"
- Why unresolved: Despite the industry demand for 3D content generation, the paper shows most research focuses on 2D content, and there's no systematic analysis of what makes 3D generation more challenging or which algorithms might be better suited for it
- What evidence would resolve it: Comparative studies of algorithm performance on 2D versus 3D content generation tasks, identification of specific technical challenges unique to 3D generation, and development of novel approaches optimized for 3D spaces

## Limitations

- The survey focuses primarily on academic publications, potentially missing important industry applications and commercial PCG tools
- The rapid evolution of LLM technology means some very recent developments may be underrepresented in the 2019-2023 timeframe
- The paper's categorization system may not capture all nuances of hybrid or emerging PCG approaches

## Confidence

- **High Confidence**: The categorization of PCG methods into search-based, ML-based, LLM-based, and combined approaches is well-supported by the corpus analysis and aligns with established research patterns
- **Medium Confidence**: The identified trends in algorithm popularity and content type focus are reasonable given the publication data, though subject to selection bias from conference series coverage
- **Low Confidence**: Specific claims about industry adoption and practical implementation challenges are largely inferential, as the survey primarily covers academic literature

## Next Checks

1. **Reproduce the categorization pipeline**: Apply the paper's inclusion/exclusion criteria to a subset of papers from different time periods to verify consistency in algorithm classification and trend identification
2. **Cross-validate with industry sources**: Compare the survey's findings with industry white papers, game developer conference talks, and commercial PCG tool documentation to assess the gap between academic research and practical application
3. **Test the combined methods hypothesis**: Implement a simple combined approach (e.g., LLM + search-based method) for a specific content type and evaluate whether the theoretical benefits described in the survey manifest in practice