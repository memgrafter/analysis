---
ver: rpa2
title: Multi-Modal Federated Learning for Cancer Staging over Non-IID Datasets with
  Unbalanced Modalities
arxiv_id: '2401.03609'
source_url: https://arxiv.org/abs/2401.03609
tags:
- data
- modalities
- institutions
- local
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-modal federated learning
  in cancer staging where institutions have access to an uneven number of data modalities.
  The proposed method, distributed gradient blending (DGB), dynamically adjusts learning
  rates for different modalities using performance metrics to balance convergence
  rates.
---

# Multi-Modal Federated Learning for Cancer Staging over Non-IID Datasets with Unbalanced Modalities

## Quick Facts
- arXiv ID: 2401.03609
- Source URL: https://arxiv.org/abs/2401.03609
- Reference count: 39
- Primary result: Up to 75.63% accuracy on TCGA cancer staging with unbalanced modalities

## Executive Summary
This paper addresses the challenge of multi-modal federated learning in cancer staging where institutions have access to an uneven number of data modalities. The proposed method, distributed gradient blending (DGB), dynamically adjusts learning rates for different modalities using performance metrics to balance convergence rates. To mitigate bias from non-IID data, proximity-aware client weighting (PCW) is introduced to weight local losses based on data quality. Experiments on TCGA datasets with three cancer types (breast, lung, liver) using mRNA sequences, histopathological images, and clinical information show that the proposed method significantly outperforms conventional multi-modal FL and hierarchical gradient blending approaches.

## Method Summary
The method introduces a novel FL architecture that accommodates heterogeneity of data samples and non-uniformity of data modalities across institutions. DGB dynamically adjusts learning rates for different modalities using overfitting and generalization metrics to balance convergence rates. PCW mitigates bias from non-IID data by weighting local losses based on similarity of local gradient trajectories to the global gradient trajectory. The system separates encoder aggregation per modality and classifier aggregation per modality combination, allowing effective training across institutions with unbalanced modalities.

## Key Results
- Achieves up to 75.63% accuracy on TCGA cancer staging datasets
- Outperforms conventional multi-modal FL approaches by 5-15% in accuracy
- Demonstrates robustness to modality imbalance with consistent performance across different cancer types

## Why This Works (Mechanism)

### Mechanism 1
DGB adjusts local learning rates for each modality using performance metrics (overfitting and generalization) to balance convergence rates. At each global aggregation round, DGB computes overfitting (O) and generalization (G) metrics per modality subset. These are used to calculate the Distributed Overfitting to Generalization Ratio (DOGR), which dynamically scales the learning rate for each modality's encoder and the classifier. This prevents faster-converging modalities from dominating and ensures more synchronized training across modalities.

### Mechanism 2
PCW mitigates bias from non-IID data by weighting local losses based on similarity of local gradient trajectories to the global gradient trajectory. PCW computes the cumulative gradient trajectory for each client's model over the local round and compares it to the global model's trajectory using an inner product similarity metric. Clients whose local gradients align closely with the global gradient (indicating data distribution closer to the global) receive higher weights when aggregating train/validation losses used for DGB calculations.

### Mechanism 3
Separating encoder aggregation per modality and classifier aggregation per modality combination allows effective training across institutions with unbalanced modalities. Each institution trains encoders for its available modalities and a classifier over its modality combination. After local training, the server separately aggregates all encoders for modality m and all classifiers for modality combination C. This ensures that encoders are trained on all data for that modality and classifiers are trained on all data for that modality combination.

## Foundational Learning

- **Federated Learning (FL) and non-IID data distribution**: The system explicitly operates over institutions with different local data distributions and varying sets of modalities. Understanding FL fundamentals and non-IID challenges is critical to grasp why DGB and PCW are necessary.
- **Multi-modal learning and encoder-decoder architectures**: The proposed architecture uses modality-specific encoders and modality-combination classifiers. Understanding how features are extracted and fused across modalities is key to following the aggregation strategy.
- **Gradient descent and learning rate tuning**: DGB modifies the local SGD step size based on computed performance metrics. Understanding how learning rates affect convergence is essential to follow the mechanism.

## Architecture Onboarding

- **Component map**: Clients (local datasets, modality-specific encoders, modality-combination classifier, local training loop) -> Server (separate aggregation of encoders/classifiers, DGB/PCW computation) -> Updated models to clients
- **Critical path**: 1) Server initializes global models, 2) Clients initialize from server, 3) Clients perform K local SGD steps, 4) Clients send updates to server, 5) Server computes PCW weights, 6) Server computes DGB weights, 7) Server updates global models, 8) Server broadcasts updated models
- **Design tradeoffs**: Separating encoder and classifier aggregation allows flexibility but increases server-side computation and communication overhead; DGB requires tracking train/validation loss per client per round; PCW requires tracking gradient trajectories over the local round
- **Failure signatures**: Imbalanced convergence (some modalities' losses plateau while others decrease rapidly); degraded accuracy over time (local model bias accumulates); high variance in global model updates (sparse modality combinations)
- **First 3 experiments**: 1) Replicate Fig. 3: Run CM-FL vs. CM-FL + DGB vs. Our Method on 9-client setup with 3 modalities, 2) Vary K (local SGD steps): Run experiments with K=1, K=5, K=20, 3) Vary modality imbalance: Run experiments with uni-modal dominant, bi-modal dominant, tri-modal dominant settings

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unexplored based on the experimental results and methodology.

## Limitations
- Data Requirements: Method requires sufficient local data to compute reliable overfitting/generalization metrics and gradient trajectories
- Computational Overhead: PCW and DGB add significant computation at server (gradient trajectory tracking, similarity computation, weighted loss aggregation)
- Generalizability: Performance may degrade if gradient similarity poorly correlates with data distribution similarity in other domains

## Confidence
- **High**: Novel architectural design separating encoder/classifier aggregation; experimental setup and methodology clearly described
- **Medium**: Claims about DGB balancing convergence rates; PCW mitigating non-IID bias; accuracy improvements over baselines
- **Low**: Claims about method's performance on datasets outside TCGA; robustness to different levels of modality imbalance

## Next Checks
1. **Sensitivity Analysis**: Systematically vary K (local SGD steps) and learning rates to identify optimal ranges and assess robustness to hyperparameter choices
2. **Modality Scalability Test**: Evaluate method with 2, 3, and 4 modalities to quantify performance degradation as modality combinations increase
3. **Cross-Domain Validation**: Apply method to non-medical multi-modal datasets (e.g., visual/audio/text) to assess generalizability beyond cancer staging