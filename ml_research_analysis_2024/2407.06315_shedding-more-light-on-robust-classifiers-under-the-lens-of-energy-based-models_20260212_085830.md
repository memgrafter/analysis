---
ver: rpa2
title: Shedding More Light on Robust Classifiers under the lens of Energy-based Models
arxiv_id: '2407.06315'
source_url: https://arxiv.org/abs/2407.06315
tags:
- energy
- samples
- robust
- adversarial
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work offers a new perspective on robust classifiers by interpreting
  them as Energy-based Models (EBMs). The analysis reveals that untargeted adversarial
  attacks generate images with significantly lower energy than natural data, while
  targeted attacks exhibit the opposite behavior.
---

# Shedding More Light on Robust Classifiers under the lens of Energy-based Models

## Quick Facts
- **arXiv ID**: 2407.06315
- **Source URL**: https://arxiv.org/abs/2407.06315
- **Reference count**: 40
- **Primary result**: Interprets robust classifiers as Energy-based Models (EBMs) and proposes Weighted Energy Adversarial Training (WEAT), achieving state-of-the-art robust accuracy and generative capabilities on multiple benchmarks.

## Executive Summary
This work offers a new perspective on robust classifiers by interpreting them as Energy-based Models (EBMs). The analysis reveals that untargeted adversarial attacks generate images with significantly lower energy than natural data, while targeted attacks exhibit the opposite behavior. This insight leads to a deeper understanding of adversarial training (AT) dynamics, showing that robust overfitting occurs due to a drastic divergence between natural and adversarial energies. The study also reinterprets TRADES as an EBM, demonstrating how it mitigates overfitting by aligning natural and adversarial energies. Based on these findings, the authors propose Weighted Energy Adversarial Training (WEAT), a novel sample weighting scheme that achieves state-of-the-art robust accuracy on multiple benchmarks, including CIFAR-10, SVHN, CIFAR-100, and Tiny-ImageNet. Additionally, the research shows that robust classifiers possess generative capabilities, which can be enhanced using a simple initialization method, achieving impressive Inception Score (IS) and FID without explicit generative modeling training.

## Method Summary
The paper reinterprets robust classifiers as Energy-based Models (EBMs) and proposes a novel sample weighting scheme called Weighted Energy Adversarial Training (WEAT). WEAT uses a weighting function based on marginal energy: w(x) = 1 / log(1 + exp(|Eθ(x)|)), with two variants—WEATNAT (weights natural examples) and WEATADV (weights adversarial examples). The method is evaluated using TRADES loss with β = 6 (or 7 for CIFAR-100) and KL divergence for inner loss. Training is conducted for 100 epochs (30 for SVHN) with SGD optimizer, cyclic learning rate, and ℓ∞ threat model (ϵ = 8/255). The approach is tested on CIFAR-10, CIFAR-100, SVHN, and Tiny-ImageNet using ResNet-18 architecture, with evaluation metrics including robust accuracy under PGD and AutoAttack (AA), as well as generative metrics like Inception Score (IS), FID, KID, and LPIPS.

## Key Results
- WEAT achieves state-of-the-art robust accuracy on CIFAR-10, SVHN, CIFAR-100, and Tiny-ImageNet.
- Robust classifiers interpreted as EBMs show generative capabilities, enhanced by PCA initialization and SGLD sampling.
- Robust overfitting is explained as a divergence between natural and adversarial energies, mitigated by aligning these energies via WEAT.

## Why This Works (Mechanism)
The paper demonstrates that robust classifiers can be reinterpreted as Energy-based Models (EBMs), where adversarial attacks manipulate the energy landscape. Untargeted attacks lower the energy of perturbed images, while targeted attacks increase it. This energy-based perspective explains robust overfitting as a divergence between natural and adversarial energies. WEAT mitigates this by weighting samples based on their marginal energy, aligning natural and adversarial energies during training. This approach not only improves robust accuracy but also enhances the generative capabilities of robust classifiers.

## Foundational Learning
- **Energy-based Models (EBMs)**: Why needed? To reinterpret robust classifiers and understand adversarial attacks as energy manipulation. Quick check: Verify that the energy function is differentiable and can be optimized via gradient-based methods.
- **Adversarial Training (AT)**: Why needed? To train models robust to adversarial attacks. Quick check: Ensure that the adversarial examples are generated using a strong attack (e.g., PGD or AutoAttack).
- **TRADES Loss**: Why needed? To balance natural and adversarial accuracy. Quick check: Confirm that the KL divergence term in TRADES aligns natural and adversarial energies.
- **Sample Weighting**: Why needed? To prioritize samples that contribute most to robust accuracy. Quick check: Validate that the weighting function (w(x) = 1 / log(1 + exp(|Eθ(x)|))) effectively reduces robust overfitting.
- **Generative Metrics (IS, FID)**: Why needed? To evaluate the generative capabilities of robust classifiers. Quick check: Ensure that the metrics are computed using a sufficient number of generated samples.

## Architecture Onboarding
- **Component map**: Input data -> Energy calculation -> Sample weighting (WEAT) -> TRADES loss -> Model update
- **Critical path**: Data preprocessing -> Adversarial example generation -> Energy-based weighting -> Loss computation -> Parameter update
- **Design tradeoffs**: Balancing natural and adversarial accuracy via energy alignment vs. computational cost of energy calculation.
- **Failure signatures**: Poor robust accuracy if energy calculation or weighting function is incorrect; degraded generative performance if PCA initialization or SGLD parameters are not tuned.
- **First experiments**:
  1. Train WEAT on CIFAR-10 with ResNet-18 and evaluate robust accuracy under PGD and AA.
  2. Compute generative metrics (IS, FID) using PCA initialization and SGLD sampling.
  3. Conduct ablation studies to isolate the impact of the energy-based weighting scheme.

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis is primarily empirical and based on specific architectures (ResNet-18, WideResNet-34-10) and datasets (CIFAR-10, CIFAR-100, SVHN, Tiny-ImageNet).
- The theoretical justification for reinterpreting TRADES as an EBM could be strengthened.
- The generative capabilities of robust classifiers, while promising, are demonstrated through qualitative and metric-based evaluation, which may not fully capture their practical utility.

## Confidence
- Claims about robust overfitting and energy divergence: Medium
- Effectiveness of WEAT in improving robust accuracy: Medium
- Generative capabilities of robust classifiers: Medium

## Next Checks
1. Reproduce the WEAT training and evaluation pipeline on CIFAR-10 with ResNet-18 to verify robust accuracy and generative metrics (IS, FID).
2. Conduct ablation studies to isolate the impact of the energy-based weighting scheme on robust overfitting and generative performance.
3. Test the proposed energy-based perspective and WEAT on additional architectures (e.g., WideResNet, EfficientNet) and datasets to assess generalizability.