---
ver: rpa2
title: A Practical Method for Generating String Counterfactuals
arxiv_id: '2402.11355'
source_url: https://arxiv.org/abs/2402.11355
tags:
- intervention
- counterfactuals
- gender
- mimic
- representation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method to generate natural language counterfactuals
  from representation-space interventions in language models. The authors build on
  Morris et al.
---

# A Practical Method for Generating String Counterfactuals

## Quick Facts
- arXiv ID: 2402.11355
- Source URL: https://arxiv.org/abs/2402.11355
- Reference count: 11
- Key result: Counterfactuals generated through representation interventions can reduce gender bias in profession classification tasks

## Executive Summary
This paper presents a method to generate natural language counterfactuals from representation-space interventions in language models. The authors build on Morris et al. (2023) by first applying interventions like LEACE, MiMiC, or MiMiC+α to model representations and then using an inversion model to convert the modified representations back into text. They demonstrate this approach on a biography dataset, showing that counterfactuals can recover known gender-related word usage biases and uncover subtle patterns like the association of words such as "recent" with male biographies. When used for data augmentation, these counterfactuals help reduce bias in a profession classification task, achieving lower True Positive Rate gaps between genders compared to models trained on the original or gender-neutralized data.

## Method Summary
The method applies representation-space interventions (LEACE, MiMiC, or MiMiC+α) to language model representations of text, then uses an inversion model to convert the modified representations back to text. The pipeline takes original text, encodes it with a model like GTR-base, applies the intervention function to modify the representations, and decodes using the inversion model to generate counterfactual text. The approach is evaluated on the BiasInBios dataset of biographies with gender and profession annotations, using the counterfactuals for bias mitigation in a downstream profession classification task.

## Key Results
- Counterfactuals successfully recover known gender-related word usage biases (e.g., prepositions) in biographies
- The method uncovers subtle patterns like "recent" being associated with male biographies
- Counterfactual data augmentation reduces gender bias in profession classification, achieving lower TPR gaps between genders compared to models trained on original or gender-neutralized data
- Human evaluation confirms counterfactuals successfully alter gender indicators while maintaining reasonable writing quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representation-space interventions (LEACE, MiMiC, MiMiC+α) can effectively alter gender-related encoding in language model representations while preserving most other information.
- Mechanism: These interventions modify the mean and/or covariance structure of representations for one gender class to match or align with the other class, effectively "erasing" or "transferring" gender information at the representation level.
- Core assumption: Gender encoding in representations is primarily captured by linear structures (means and covariances) that can be modified without destroying semantic content.
- Evidence anchors: [abstract] "Interventions performed in the representation space of LMs have proven effective at exerting control over the generation of the model"; [section 2] "LEACE achieves linear guardedness... MiMiC... ensures that both μx = μy and ΣX = ΣY while changing only one class Y"

### Mechanism 2
- Claim: The inversion model can reconstruct coherent text from modified representations with sufficient fidelity to observe meaningful changes.
- Mechanism: The inversion model (trained on text-to-representation pairs) learns to map representations back to text, and when given intervened representations, produces text that reflects the intervention while maintaining grammatical coherence.
- Core assumption: The relationship between representations and text is invertible to a useful degree, allowing meaningful counterfactuals to be generated.
- Evidence anchors: [abstract] "we leverage these methods to generate input-space counterfactuals"; [section 3] "we expect T′ to be a minimally different version of T with respect to Z"

### Mechanism 3
- Claim: Counterfactual data augmentation using these generated texts can reduce bias in downstream classification tasks.
- Mechanism: By training on original texts plus counterfactuals with reversed gender labels, the classifier learns features that are less dependent on gender-specific patterns.
- Core assumption: The counterfactuals are sufficiently similar to real data and effectively reverse gender indicators to meaningfully retrain the classifier.
- Evidence anchors: [abstract] "the resulting counterfactuals can be used to mitigate bias in classification"; [section 4.2] "We expect to mitigate the model's dependence on gender"

## Foundational Learning

- **Concept**: Representation space interventions and linear concept erasure
  - Why needed here: Understanding how LEACE and MiMiC work at the mathematical level is essential for grasping why they can modify gender encoding
  - Quick check question: What is the key difference between LEACE and MiMiC in terms of which class's representations are modified?

- **Concept**: Text inversion and reconstruction from embeddings
  - Why needed here: The entire approach depends on being able to map representations back to text, so understanding the inversion model architecture and training is crucial
  - Quick check question: What is the main challenge in training an inversion model compared to a standard text-to-text model?

- **Concept**: Counterfactual reasoning and causal inference in NLP
  - Why needed here: The paper frames its approach in terms of counterfactuals, so understanding the do-operator and causal chains is important for interpreting the results
  - Quick check question: In the causal chain Z → T → enc(T) → ˆZ, what does the intervention f(·) operate on?

## Architecture Onboarding

- **Component map**: Dataset (Biographies) → Representation encoder (GTR-base) → Intervention function (LEACE/MiMiC/MiMiC+α) → Inversion model → Counterfactual text → Classifier (for bias mitigation)
- **Critical path**: Original text → Encoder → Intervention → Inverter → Counterfactual text (the core pipeline for generating counterfactuals)
- **Design tradeoffs**: Tradeoff between intervention strength and text quality (stronger interventions may produce less coherent text); tradeoff between model size/complexity and reconstruction quality (larger inversion models may reconstruct better but be slower); tradeoff between dataset size and intervention effectiveness (more data may enable better interventions)
- **Failure signatures**: Inversion model produces gibberish or repetitive text; counterfactuals fail to change gender indicators despite intervention; classifier performance degrades significantly with counterfactual augmentation; human evaluation shows poor writing quality in counterfactuals
- **First 3 experiments**: 1) Generate counterfactuals using MiMiC with different α values and compare pronoun changes; 2) Train classifier on original data vs. data with counterfactuals and measure TPR gap; 3) Apply LEACE vs. MiMiC and analyze which produces more natural counterfactuals

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inversion model's quality impact the fidelity of counterfactuals generated through representation-space interventions?
- Basis in paper: [inferred] The paper acknowledges that the inversion model is not perfect and can introduce slight variations in the text, such as modifying numbers or geographical locations, or introducing lexical paraphrases. These changes might be undesired in certain use cases.
- Why unresolved: The paper does not provide a quantitative analysis of how the inversion model's errors affect the accuracy of the counterfactuals. It also does not explore methods to improve the inversion model's quality.
- What evidence would resolve it: Experiments that compare counterfactuals generated with a high-quality inversion model versus a lower-quality one, measuring the accuracy of the gender inversion and the preservation of other text attributes.

### Open Question 2
- Question: What are the long-term effects of using counterfactual data augmentation on model performance and fairness in real-world applications?
- Basis in paper: [explicit] The paper demonstrates that counterfactuals can be used for data augmentation to reduce bias in a profession classification task, achieving lower True Positive Rate gaps between genders. However, it does not explore the long-term effects of this approach.
- Why unresolved: The paper only presents short-term results on a specific dataset and task. It does not investigate how the model's performance and fairness evolve over time or in different domains.
- What evidence would resolve it: Longitudinal studies tracking model performance and fairness metrics across multiple datasets, tasks, and time periods, with and without counterfactual data augmentation.

### Open Question 3
- Question: How can we ensure that counterfactual generation methods do not introduce new biases or perpetuate existing ones?
- Basis in paper: [inferred] The paper acknowledges that the dataset used has binary gender labels, which is a simplification of the complex nonbinary construct of gender. It also mentions that future work should explore more nuanced examinations of how gender manifests in text.
- Why unresolved: The paper does not provide a comprehensive analysis of the potential biases introduced by the counterfactual generation process itself. It also does not propose methods to mitigate these biases.
- What evidence would resolve it: A thorough examination of the counterfactuals generated for various sensitive attributes, assessing their potential to introduce or perpetuate biases. Development and evaluation of bias mitigation techniques specifically tailored for counterfactual generation methods.

## Limitations
- The method's effectiveness depends heavily on the quality of the inversion model and assumes gender information is primarily encoded in linear structures
- Human evaluation involved only 50 samples per condition, which may not capture the full range of quality issues
- The study focuses specifically on gender bias, leaving open questions about how well the method would work for other types of bias or sensitive attributes

## Confidence

- **High Confidence**: The core methodology of combining representation interventions with inversion models is technically sound and well-grounded in prior work. The basic pipeline of applying interventions followed by inversion to generate counterfactuals is clearly demonstrated.
- **Medium Confidence**: The effectiveness of counterfactuals for bias mitigation in the profession classification task, while promising, is demonstrated on a single dataset with limited evaluation metrics. The generalizability to other tasks and domains remains to be tested.
- **Low Confidence**: The claims about discovering subtle patterns (like "recent" being associated with male biographies) are intriguing but require further validation with larger-scale analysis and cross-dataset verification.

## Next Checks

1. **Ablation Study on Inversion Quality**: Systematically vary the inversion model architecture (e.g., different backbone sizes, training data amounts) and measure the impact on counterfactual quality and bias mitigation effectiveness. This would quantify how sensitive the approach is to the inversion model's performance.

2. **Cross-Dataset Generalization**: Apply the same methodology to a different biography dataset or a completely different domain (e.g., news articles, social media posts) to test whether the subtle patterns discovered (like word associations with gender) are consistent across datasets or dataset-specific artifacts.

3. **Temporal Stability Analysis**: Generate counterfactuals for the same text at different time steps or with different random seeds and analyze the stability of both the intervention effects and the inversion outputs. This would help understand whether the method produces consistent counterfactuals or if results vary significantly with minor perturbations.