---
ver: rpa2
title: 'Bandit Learning in Matching Markets: Utilitarian and Rawlsian Perspectives'
arxiv_id: '2412.00301'
source_url: https://arxiv.org/abs/2412.00301
tags:
- matching
- stable
- algorithm
- have
- maximin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies bandit learning in two-sided matching markets,
  focusing on both utilitarian and Rawlsian welfare objectives. The authors propose
  epoch-based Explore-Then-Commit algorithms that learn unknown preferences through
  exploration and commit to optimal stable matchings.
---

# Bandit Learning in Matching Markets: Utilitarian and Rawlsian Perspectives

## Quick Facts
- arXiv ID: 2412.00301
- Source URL: https://arxiv.org/abs/2412.00301
- Reference count: 24
- Two-sided matching markets with bandit learning achieve regret bounds of Õ(N² log T) for utilitarian welfare and Õ(N log T) for Rawlsian welfare

## Executive Summary
This paper studies bandit learning in two-sided matching markets where both agents and arms have unknown preferences. The authors propose epoch-based Explore-Then-Commit algorithms that learn preferences through uniform exploration and then commit to optimal stable matchings. For utilitarian welfare objectives, the algorithm achieves a regret bound of Õ(N² log(T)), while for Rawlsian (maximin) welfare, the bound is Õ(N log(T)). The analysis leverages preference gaps to bound estimation errors and ensure stable matchings are found. Empirical results validate the algorithms' performance in terms of regret and stability, contributing to fair learning in matching markets.

## Method Summary
The paper proposes epoch-based Explore-Then-Commit algorithms for learning in two-sided matching markets with unknown preferences. The algorithm divides time into epochs, where each epoch consists of a uniform exploration phase followed by a matching phase. During exploration, agents pull arms in a round-robin manner to collect samples and estimate utilities. Based on these estimates, the algorithm computes either a utilitarian-optimal or maximin stable matching using the deferred acceptance algorithm and commits to this matching for a linear number of rounds. The approach achieves logarithmic regret bounds that depend on preference gaps and market size.

## Key Results
- Epoch ETC algorithm achieves Õ(N² log(T)) regret for utilitarian-optimal stable matchings
- Epoch ETC algorithm achieves Õ(N log(T)) regret for maximin-optimal (Rawlsian) stable matchings
- Preference gaps (within-side and cross-side) bound estimation errors and ensure stable matching identification
- Empirical validation shows the algorithm maintains stability while minimizing regret

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Epoch-based Explore-Then-Commit (ETC) algorithm achieves low regret by combining uniform exploration with optimal matching computation.
- Mechanism: The algorithm divides time into epochs. In each epoch, agents pull arms uniformly in a round-robin manner for a logarithmic number of rounds, collecting samples to estimate utilities. Then, based on these estimates, the algorithm computes either a utilitarian-optimal or maximin stable matching and commits to it for a linear number of rounds.
- Core assumption: The estimation error after sufficient exploration is small enough to correctly identify the optimal stable matching.
- Evidence anchors:
  - [abstract]: "For these metrics, we propose algorithms based on epoch Explore-Then-Commit (ETC) and analyze their regret bounds."
  - [section]: "The proposed Epoch ETC algorithm (Algorithm 2) combines the epoch-type uniform exploration and Algorithm 1."
- Break condition: If the minimum preference gap (within-side or cross-side) is too small relative to the noise level, the estimation error may not be bounded sufficiently to guarantee finding the optimal matching.

### Mechanism 2
- Claim: Preference gaps (within-side and cross-side) bound the estimation error tolerable for finding optimal matchings.
- Mechanism: The within-side minimum preference gap ensures that estimated preferences match true preferences. The cross-side minimum preference gap allows for some estimation error while still identifying the optimal stable matching. These gaps are used to bound the probability that the computed matching differs from the optimal one.
- Core assumption: The preference gaps are sufficiently large relative to the noise in the utility estimates.
- Evidence anchors:
  - [section]: "We proposed two techniques that measure the amount of error tolerable in finding the optimal matchings: the within-side minimum preference gap and the cross-side minimum preference gap."
  - [section]: "Lemma 2. If for all agent ai and arm bj, the estimation can be bounded as... then we have that ˆm = m∗, where ˆm is the matching computed by Algorithm 1 based on estimated utilities."
- Break condition: If the minimum preference gap is smaller than the noise level in the estimates, the algorithm may fail to identify the optimal matching.

### Mechanism 3
- Claim: Stability of the matching is maintained through the use of deferred acceptance (DA) algorithm.
- Mechanism: The DA algorithm guarantees that the computed matching is stable by iteratively proposing and rejecting based on preferences. The epoch ETC algorithm uses DA as a subroutine to compute the optimal stable matching after the exploration phase.
- Core assumption: The DA algorithm correctly computes a stable matching given the estimated preferences.
- Evidence anchors:
  - [section]: "The goal is to find matchings that maximize the utilitarian welfare (utilitarian-optimal) or maximize the Rawlsian welfare (maximin) among all stable solutions."
  - [section]: "The deferred-acceptance (DA) algorithm efficiently identifies a stable matching through the following process: participants on the proposing side make proposals based on their preferences to those on the receiving side."
- Break condition: If the estimated preferences are significantly different from the true preferences, the DA algorithm may compute a matching that is not stable with respect to the true preferences.

## Foundational Learning

- Concept: Stable matching and deferred acceptance (DA) algorithm
  - Why needed here: The problem is to find stable matchings that optimize either utilitarian or Rawlsian welfare when preferences are unknown.
  - Quick check question: What is the key property that defines a stable matching, and how does the DA algorithm ensure this property?

- Concept: Multi-armed bandit (MAB) problem
  - Why needed here: The preferences of agents and arms are unknown and must be learned through sampling, which is modeled as a MAB problem.
  - Quick check question: How does the exploration-exploitation tradeoff in MAB relate to the exploration and matching phases in the epoch ETC algorithm?

- Concept: Regret analysis
  - Why needed here: The performance of the algorithm is measured by regret, which is the difference between the utility of the matched partner and the optimal partner.
  - Quick check question: How is regret defined in this context, and what factors contribute to the regret bound?

## Architecture Onboarding

- Component map:
  Epoch ETC algorithm -> Exploration phase -> Matching phase -> Exploitation phase

- Critical path:
  1. Initialize epoch counter and set time horizon.
  2. In each epoch, perform the exploration phase to collect samples.
  3. Estimate utilities based on collected samples.
  4. Compute the optimal stable matching using the estimated utilities.
  5. Commit to the computed matching for the exploitation phase.
  6. Repeat until the time horizon is reached.

- Design tradeoffs:
  - Exploration vs. exploitation: More exploration leads to better estimates but reduces the time for exploitation.
  - Log-linear vs. polynomial regret: The regret bounds are logarithmic in the time horizon, but the constants depend on the preference gaps and market size.

- Failure signatures:
  - High regret: Indicates that the exploration phase is insufficient to estimate utilities accurately.
  - Instability: Suggests that the estimated preferences are significantly different from the true preferences, leading to an unstable matching.
  - Slow convergence: Implies that the preference gaps are too small relative to the noise level, making it difficult to identify the optimal matching.

- First 3 experiments:
  1. Verify the correctness of the DA algorithm in computing stable matchings.
  2. Test the epoch ETC algorithm on a small market with known preferences to validate the regret bounds.
  3. Evaluate the stability of the computed matchings on randomly generated preference profiles.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the regret bound change when extending the algorithm to many-to-one matching markets where arms can be matched to multiple agents?
  - Basis in paper: [explicit] The paper mentions this as a future direction and states that Theorem 1 can be extended to unequal sides with adjusted regret bounds
  - Why unresolved: The current analysis assumes one-to-one matching and does not address the complexity of many-to-one scenarios
  - What evidence would resolve it: Empirical or theoretical results showing regret bounds for many-to-one matching markets

- **Open Question 2**: What is the sample complexity required to achieve PAC guarantees for finding utilitarian-optimal or maximin stable matchings?
  - Basis in paper: [explicit] The paper provides sample complexity results in Appendix C but does not explore this extensively in the main analysis
  - Why unresolved: The main focus is on regret bounds over time rather than PAC-style sample complexity guarantees
  - What evidence would resolve it: Formal sample complexity bounds with PAC guarantees for both utilitarian and maximin objectives

- **Open Question 3**: How do the algorithms perform when preferences can have ties rather than being strict total orders?
  - Basis in paper: [explicit] The paper mentions this as a future direction in the concluding remarks
  - Why unresolved: The current analysis assumes strict preferences, which may not hold in all real-world applications
  - What evidence would resolve it: Modified algorithms and analysis for preference profiles with ties, including empirical validation

- **Open Question 4**: How sensitive are the results to different preference gap assumptions, particularly when cross-side gaps are much smaller than within-side gaps?
  - Basis in paper: [inferred] The regret bounds depend heavily on preference gaps, and the paper shows different bounds for utilitarian (O(N² log T)) versus maximin (O(N log T)) objectives
  - Why unresolved: The analysis assumes minimum preference gaps exist but does not explore scenarios where these assumptions might break down
  - What evidence would resolve it: Analysis of regret bounds under varying gap conditions and their impact on algorithm performance

## Limitations

- The analysis critically depends on preference gaps being sufficiently large relative to estimation noise
- Theoretical analysis assumes perfect knowledge of preference gap structure, which may not be available in practice
- Limited empirical validation to verify performance in realistic scenarios

## Confidence

- Regret bounds (O(N² log T) for utilitarian, O(N log T) for Rawlsian): **Medium**
- Stability guarantees: **High**
- Empirical validation: **Low**

## Next Checks

1. Test algorithm performance on preference distributions with varying gap sizes to identify the minimum gap threshold below which regret bounds break down.
2. Implement and validate the sparse subgraph construction and min-cut max-flow conversion for computing utilitarian-optimal stable matchings as referenced in Appendix B.
3. Conduct empirical studies comparing utilitarian vs Rawlsian objectives in terms of both efficiency and fairness metrics across different market sizes and preference distributions.