---
ver: rpa2
title: On the Hallucination in Simultaneous Machine Translation
arxiv_id: '2406.07239'
source_url: https://arxiv.org/abs/2406.07239
tags:
- hallucination
- word
- tssr
- frequency
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts a comprehensive analysis of hallucination in
  simultaneous machine translation (SiMT), focusing on understanding hallucination
  words from frequency and predictive distributions, as well as their relationship
  with target-side context usage. Experiments reveal that hallucination words have
  high frequency entropy and are difficult to memorize during training due to high
  uncertainty.
---

# On the Hallucination in Simultaneous Machine Translation

## Quick Facts
- **arXiv ID**: 2406.07239
- **Source URL**: https://arxiv.org/abs/2406.07239
- **Authors**: Meizhi Zhong; Kehai Chen; Zhengshan Xue; Lemao Liu; Mingming Yang; Min Zhang
- **Reference count**: 40
- **Primary result**: High-frequency entropy hallucination words in SiMT rely more on target-side context, with scheduled sampling showing modest improvements

## Executive Summary
This paper conducts a comprehensive analysis of hallucination in simultaneous machine translation (SiMT), focusing on understanding hallucination words from frequency and predictive distributions, as well as their relationship with target-side context usage. Experiments reveal that hallucination words have high frequency entropy and are difficult to memorize during training due to high uncertainty. The study finds that hallucination words rely more on target-side context than source-side context. By reducing target-side context usage through scheduled sampling training, modest improvements in BLEU scores and hallucination rates are achieved when latency is small, suggesting that flexible control over target-side information usage may help alleviate hallucination in SiMT.

## Method Summary
The paper analyzes hallucination in SiMT through multiple angles: frequency analysis to identify hallucination words, examination of predictive distributions during training, and investigation of context usage patterns. The authors define hallucination words based on frequency entropy and analyze their behavior during training. They then investigate whether these words depend more on source-side or target-side context. To address the issue, they propose using scheduled sampling during training to reduce reliance on target-side context. Experiments are conducted on Chinese-English and English-German translation directions using Transformer-based models with different wait-k policies.

## Key Results
- Hallucination words exhibit high frequency entropy and are difficult to memorize during training due to high uncertainty
- Hallucination words rely more on target-side context than source-side context in SiMT systems
- Scheduled sampling training achieves modest improvements (up to +0.5 BLEU and 0.2% hallucination reduction) when latency is small

## Why This Works (Mechanism)
The mechanism behind hallucination in SiMT appears to stem from the system's over-reliance on target-side context, particularly for high-entropy words that are difficult to predict from source information alone. When simultaneous translation systems face latency constraints, they may compensate for incomplete source information by generating outputs based primarily on previously generated target words. This creates a feedback loop where uncertain words (high frequency entropy) are more likely to be hallucinated based on target context rather than grounded in source content.

## Foundational Learning

**Frequency Entropy**: Measures uncertainty in word frequency distributions - needed to identify which words are inherently difficult to predict and may be prone to hallucination; quick check: compute entropy of frequency counts for top-k most common words.

**Predictive Distribution Analysis**: Examining how model predictions change during training - needed to understand why certain words are hard to memorize; quick check: track prediction entropy across training epochs for hallucination vs. non-hallucination words.

**Context Usage Analysis**: Measuring dependency on source vs. target context - needed to identify whether hallucination stems from inadequate source grounding; quick check: ablate source or target context and measure performance degradation.

**Scheduled Sampling**: Training technique that gradually replaces ground truth with model predictions - needed to reduce target-side dependency during training; quick check: implement with linear decay schedule and monitor hallucination rates.

**Wait-k Policy**: Simultaneous translation strategy where the system reads k words ahead before translating - needed to control latency-accuracy tradeoff; quick check: vary k from 1 to 5 and measure BLEU/hallucination tradeoff.

## Architecture Onboarding

**Component Map**: Transformer Encoder -> Wait-k Policy Controller -> Transformer Decoder with Context Usage Analysis -> Hallucination Detection Module -> Scheduled Sampling Training Loop

**Critical Path**: Source input → Encoder → Wait-k Buffer → Decoder with partial source context → Target output generation → Hallucination analysis

**Design Tradeoffs**: The study trades latency for accuracy by using wait-k policies, and explores the tradeoff between target-side dependency (which may help with fluency) and hallucination risk (which reduces faithfulness).

**Failure Signatures**: High frequency entropy words that are consistently mispredicted during training, target-side context over-reliance indicated by performance drops when target context is ablated, and systematic generation of content not supported by source text.

**First Experiments**:
1. Measure frequency entropy distribution across vocabulary to identify high-risk hallucination words
2. Compare source vs. target context ablation effects on hallucination word generation
3. Implement scheduled sampling with varying decay schedules to find optimal balance

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focuses primarily on Transformer-based models, limiting generalizability to other architectures
- Experiments evaluate only Chinese-English and English-German translation directions, restricting cross-linguistic claims
- Scheduled sampling approach shows modest improvements, suggesting only partial solution to hallucination problem
- Definition of hallucination words relies on frequency-based criteria, potentially missing semantic hallucinations

## Confidence

**High**: The finding that hallucination words exhibit high frequency entropy and training difficulty is well-supported by empirical evidence and statistical analysis.

**Medium**: The claim about target-side context dependency is reasonably supported but could benefit from ablation studies isolating source vs. target contributions.

**Medium**: The scheduled sampling improvement results are credible but the modest effect sizes suggest the approach is a partial solution rather than a comprehensive fix.

## Next Checks

1. Test the frequency entropy-hallucination relationship across multiple model architectures (RNN, CNN, and different Transformer variants) to verify the phenomenon's robustness.

2. Conduct human evaluation studies to validate that the frequency-based definition of hallucination words aligns with human perceptions of hallucination quality.

3. Evaluate the scheduled sampling approach on additional language pairs and domains to assess generalizability beyond the current Chinese-English and English-German benchmarks.