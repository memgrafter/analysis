---
ver: rpa2
title: 'Persuasion with Large Language Models: a Survey'
arxiv_id: '2411.06837'
source_url: https://arxiv.org/abs/2411.06837
tags: []
core_contribution: This survey systematically reviews the emerging field of LLM-based
  persuasion, documenting that Large Language Models have achieved human-level or
  even super-human persuasiveness across multiple domains including politics, public
  health, e-commerce, and charitable giving. The effectiveness of LLM Systems depends
  on factors such as personalization, model scale, interaction mode, prompt design,
  AI source labeling, and appeals to authority.
---

# Persuasion with Large Language Models: a Survey

## Quick Facts
- arXiv ID: 2411.06837
- Source URL: https://arxiv.org/abs/2411.06837
- Authors: Alexander Rogiers; Sander Noels; Maarten Buyl; Tijl De Bie
- Reference count: 40
- Large Language Models have achieved human-level or even super-human persuasiveness across multiple domains

## Executive Summary
This comprehensive survey systematically reviews the emerging field of LLM-based persuasion, documenting that Large Language Models have achieved human-level or even super-human persuasiveness across multiple domains including politics, public health, e-commerce, and charitable giving. The effectiveness of LLM Systems depends on factors such as personalization, model scale, interaction mode, prompt design, AI source labeling, and appeals to authority. Experimental designs typically employ randomized controlled trials with between-subjects conditions, measuring outcomes like opinion change, agreement, behavioral intent, and perceived effectiveness.

The rapid advancement of LLM persuasion has outpaced regulatory frameworks, necessitating urgent development of ethical guidelines and updated regulations to address challenges including misinformation spread, societal polarization, bias propagation, privacy concerns, and manipulation. While the technology shows promise for beneficial applications, significant ethical risks arise from its ability to influence human beliefs and behaviors at scale. The field requires immediate attention to establish appropriate safeguards while preserving the technology's positive potential.

## Method Summary
This survey provides a comprehensive overview of LLM-based persuasion research, synthesizing findings from multiple experimental studies across various domains. The analysis examines experimental designs, measurement approaches, and effectiveness factors while identifying ethical implications and research gaps. The survey methodology involves systematic review of existing literature to identify patterns, mechanisms, and emerging trends in LLM persuasion capabilities.

## Key Results
- Interactive dialogues outperform static content delivery for persuasion effectiveness
- Larger models show enhanced persuasion capabilities with diminishing returns
- Personalized messaging increases persuasive impact compared to generic approaches

## Why This Works (Mechanism)
LLM persuasion effectiveness stems from the models' ability to generate contextually appropriate, coherent, and personalized content that resonates with human cognitive biases and decision-making processes. The systems leverage natural language understanding to identify persuasive opportunities, adapt messaging styles, and create convincing arguments tailored to individual characteristics. Interactive dialogue modes enable real-time adaptation and relationship building, while personalization exploits demographic and behavioral targeting to maximize impact.

## Foundational Learning
- Randomized Controlled Trials: Essential for establishing causal relationships between LLM interventions and persuasion outcomes; quick check involves verifying randomization procedures and sample size calculations.
- Between-Subjects Experimental Design: Prevents contamination between treatment conditions while allowing clean comparisons; verify through proper subject assignment protocols.
- Persuasion Metrics: Standardized measures including opinion change, agreement rates, and behavioral intent are needed for cross-study comparisons; validate through established psychological scales and behavioral indicators.

## Architecture Onboarding

**Component Map:** Data Input -> Model Processing -> Interaction Engine -> Output Generation -> Feedback Loop

**Critical Path:** The persuasion pipeline follows: user profiling → message personalization → content generation → delivery → response collection → model adaptation. This sequence determines overall effectiveness.

**Design Tradeoffs:** Interactive dialogue provides higher engagement but requires more computational resources and real-time processing capabilities. Static content delivery is more scalable but less adaptive. Personalization increases effectiveness but raises privacy concerns and implementation complexity.

**Failure Signatures:** Common failure modes include generic messaging that fails to resonate, over-personalization that appears invasive, model hallucinations that undermine credibility, and inability to adapt to user resistance or counterarguments.

**3 First Experiments:**
1. Compare interactive dialogue vs. static content delivery for persuasion effectiveness using randomized controlled trials
2. Test personalization parameters (demographic vs. behavioral targeting) on persuasion outcomes
3. Evaluate the impact of AI source disclosure on user trust and persuasion success rates

## Open Questions the Paper Calls Out
The survey identifies several critical open questions including the long-term persistence of LLM persuasion effects, cross-cultural generalizability of persuasion techniques, optimal combinations of personalization parameters with different LLM architectures, and the development of effective resistance mechanisms against manipulative persuasion attempts.

## Limitations
- Most studies focus on short-term persuasion effects with limited investigation of long-term behavioral persistence
- Heterogeneity in experimental designs across studies makes direct comparisons challenging
- Rapidly evolving field with many findings based on recent studies that may not reflect mature understanding

## Confidence

**High Confidence:**
- Interactive dialogues outperform static content delivery
- Ethical risks of LLM persuasion are significant and multifaceted

**Medium Confidence:**
- Personalization effectiveness varies across contexts and domains
- Model scale relationships show diminishing returns
- Ethical risk assessments may underestimate unforeseen consequences

**Low Confidence:**
- Generalizability across all domains and cultural contexts
- Universal principles of LLM persuasion effectiveness

## Next Checks

1. Conduct longitudinal studies to assess persistence of LLM persuasion effects over extended timeframes (minimum 3-6 months), measuring both attitudinal and behavioral changes.

2. Implement cross-cultural validation studies to determine whether persuasion effectiveness generalizes across different cultural contexts and value systems.

3. Design controlled experiments specifically testing interaction effects between personalization parameters (demographic targeting, behavioral profiling) and different LLM architectures to identify optimal combinations for both effectiveness and ethical safeguards.