---
ver: rpa2
title: Mixture of Experts based Multi-task Supervise Learning from Crowds
arxiv_id: '2407.13268'
source_url: https://arxiv.org/abs/2407.13268
tags:
- worker
- truth
- ground
- data
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new paradigm for learning from crowds by
  modeling worker behavior at the item feature level rather than treating ground truth
  as hidden variables. The proposed Mixture of Experts based Multi-task Supervised
  Learning from Crowds (MMLC) uses expert modules to capture worker attention variations
  across item features, with gate modules controlling expert selection.
---

# Mixture of Experts based Multi-task Supervise Learning from Crowds

## Quick Facts
- arXiv ID: 2407.13268
- Source URL: https://arxiv.org/abs/2407.13268
- Reference count: 11
- Primary result: Proposed MMLC-owf achieves up to 81.74% accuracy on Text dataset and 79.14% on Music, outperforming state-of-the-art methods

## Executive Summary
This paper introduces a new paradigm for learning from crowds by modeling worker behavior at the item feature level rather than treating ground truth as hidden variables. The proposed Mixture of Experts based Multi-task Supervised Learning from Crowds (MMLC) uses expert modules to capture worker attention variations across item features, with gate modules controlling expert selection. Two aggregation strategies are introduced: MMLC-owf identifies an oracle worker's projection in worker spectral space to infer ground truth, while MMLC-df fills sparse crowdsourced data to enhance existing truth inference methods. Experiments show MMLC-owf outperforms state-of-the-art methods, achieving up to 81.74% accuracy on the Text dataset and 79.14% on Music. The MMLC-df framework improves learning-from-crowds methods in 100% of scenarios with 79.2% achieving best enhancement.

## Method Summary
The paper proposes a Mixture of Experts (MoE) based approach for learning from crowds that models worker behavior at the item feature level. The MMLC architecture consists of expert modules that transform item feature vectors into low-dimensional outputs, gate modules that produce worker-specific projection vectors in spectral space using attention mechanisms, and output modules that combine expert outputs according to worker attention patterns. Two aggregation strategies are introduced: MMLC-owf identifies an oracle worker's projection through clustering worker projections in spectral space, while MMLC-df fills sparse crowdsourced data with MMLC predictions to enhance existing truth inference methods.

## Key Results
- MMLC-owf outperforms state-of-the-art methods, achieving up to 81.74% accuracy on Text dataset and 79.14% on Music
- MMLC-df framework improves learning-from-crowds methods in 100% of scenarios with 79.2% achieving best enhancement
- The method demonstrates superior performance particularly on datasets with higher worker redundancy
- MMLC shows stable improvement across different aggregation methods with no degradation in any scenario

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MMLC models worker behavior at the item feature level, not as a hidden ground truth variable, which avoids the imprecision of traditional confusion-matrix-based models.
- Mechanism: Expert modules extract item feature vectors and transform them into low-dimensional outputs. Gate modules use attention to produce worker-specific projection vectors in spectral space, combining expert outputs according to worker attention patterns.
- Core assumption: Worker attention to item features varies systematically and can be modeled as a projection in a spectral space whose bases are the expert outputs.
- Evidence anchors: [abstract] "worker behavior models that rely on ground truth hidden variables overlook workers' behavior at the item feature level, leading to imprecise characterizations" [section] "The worker behavior model provides a more precise depiction of their behavior across different items by accurately modeling the workers' behavior on item features."
- Break condition: If worker attention does not correlate with feature characteristics, or if the spectral projection does not cluster around an oracle projection, the model fails to improve truth inference.

### Mechanism 2
- Claim: The oracle worker projection in spectral space can be identified by clustering worker projections, and this projection represents ground truth labels.
- Mechanism: After training, worker projections are clustered (e.g., KDE) in the worker spectral space; the center of this distribution is treated as the oracle worker's projection, whose output is taken as ground truth.
- Core assumption: The oracle worker exists as a point in spectral space, and all real workers are noisy variants of it, so their projections cluster around the oracle.
- Evidence anchors: [section] "We assume the existence of an omniscient oracle worker who possesses a projection vector in the spectral space and is capable of providing the ground truth in the MMLC model." [section] "the center of the worker's distribution projected onto the spectral space can be regarded as the projection vector of the oracle worker"
- Break condition: If the worker distribution in spectral space is too diffuse or multimodal, the cluster center may not correspond to a real oracle worker.

### Mechanism 3
- Claim: Data filling with MMLC outputs improves downstream truth inference methods by providing pseudo-labels for missing crowdsourced annotations.
- Mechanism: MMLC predicts labels for all worker-item pairs (including missing ones), creating a dense dataset D′. Existing learning-from-crowds methods can then run on D′ to improve accuracy.
- Core assumption: MMLC's predictions are more accurate than random guesses, so filling sparse crowdsourced data with them improves aggregation results.
- Evidence anchors: [abstract] "MMLC-df employs the MMLC model to fill the crowdsourced data, which can enhance the effectiveness of existing aggregation strategies" [section] "We introduce an aggregation framework called MMLC-df, which leverages the MMLC model to fill sparse crowdsourced data."
- Break condition: If MMLC's predictions are systematically wrong, filling with them will mislead downstream methods and degrade accuracy.

## Foundational Learning

- Concept: Mixture of Experts (MoE) architecture
  - Why needed here: Allows the model to capture varying worker attention patterns to different item features by letting each expert specialize in a feature subspace.
  - Quick check question: What does each expert module in MMLC do to the input item feature vector?

- Concept: Worker spectral space projection
  - Why needed here: Encodes each worker's behavior as a weighted combination of expert outputs, enabling clustering to find the oracle worker.
  - Quick check question: How is a worker's projection vector in spectral space computed from the gate module outputs?

- Concept: Kernel Density Estimation (KDE) for clustering
  - Why needed here: Used to estimate the center of worker projections in spectral space, identifying the oracle worker.
  - Quick check question: Why is KDE preferred over simple mean for finding the oracle projection in this context?

## Architecture Onboarding

- Component map: item features → expert modules → gate modules → output modules → softmax → label
- Critical path: item features → experts → gate-weighted sum → softmax → label
- Design tradeoffs:
  - More experts → richer attention modeling but higher parameter count and risk of overfitting
  - Deeper expert networks → better feature abstraction but slower training
  - KDE vs mean for oracle finding → KDE is more robust to noise but slower
- Failure signatures:
  - Oracle worker projection far from cluster center → assumption of single oracle invalid
  - MMLC predictions worse than majority vote → feature-level modeling ineffective
  - Data filling degrades downstream accuracy → MMLC predictions unreliable
- First 3 experiments:
  1. Train MMLC on LableMe dataset, visualize worker projections in 2D spectral space, check if high-accuracy workers cluster near oracle.
  2. Compare MMLC-owf oracle finding accuracy using KDE, mean, and median clustering methods on the same dataset.
  3. Apply MMLC-df data filling to Text dataset, run DS method on filled data, compare accuracy to original sparse data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MMLC-owf vary when using different clustering methods beyond KDE, Mean, and Median for identifying the oracle worker projection vector?
- Basis in paper: [explicit] The paper compares KDE, Mean, and Median methods for oracle worker finding, noting that "the quality of the ground truth generated by oracle workers using six clustering methods still slightly deviates from theoretical upper limits."
- Why unresolved: While the paper shows MMLC-owf performs well with KDE and approaches theoretical upper limits, it doesn't explore other clustering methods like DBSCAN, hierarchical clustering, or spectral clustering that might better capture the worker spectral space distribution.
- What evidence would resolve it: Systematic experiments comparing MMLC-owf accuracy across a comprehensive range of clustering algorithms on multiple datasets, including visualization of worker distribution patterns that correlate with each method's effectiveness.

### Open Question 2
- Question: What is the optimal number of expert modules in MMLC for different dataset characteristics, and how does this hyperparameter affect model performance and generalization?
- Basis in paper: [explicit] The paper notes different architectures for different datasets: "For the LableMe dataset, our model employs 16 expert modules... For the Text and Music datasets, we utilize 10 expert modules."
- Why unresolved: The paper doesn't provide systematic analysis of how varying the number of expert modules affects performance across different dataset types, redundancy levels, or feature dimensionalities. The choice appears to be heuristic rather than data-driven.
- What evidence would resolve it: Comprehensive ablation studies varying the number of expert modules across diverse datasets, measuring performance trade-offs between model capacity, computational efficiency, and accuracy, potentially revealing optimal configurations based on dataset properties.

### Open Question 3
- Question: How does MMLC-df performance change when applied to datasets with different levels of initial sparsity, and what are the diminishing returns as data density approaches 100%?
- Basis in paper: [explicit] The paper investigates "the impact of data density on the results" and shows that "as density increases, the algorithm's accuracy stabilizes rapidly and then reaches a plateau."
- Why unresolved: While the paper demonstrates that data filling improves performance, it doesn't quantify the relationship between initial data sparsity and the magnitude of improvement, nor does it identify at what density threshold the benefits of additional filling become negligible.
- What evidence would resolve it: Experiments systematically varying initial data densities across multiple datasets, measuring the performance gain from data filling at each density level, and identifying the point of diminishing returns where additional filling provides minimal accuracy improvement.

## Limitations

- The effectiveness relies heavily on the assumption that worker attention patterns to item features are consistent and can be captured by the spectral projection mechanism, which may not hold for datasets with highly variable or random worker behavior.
- The oracle worker identification through clustering assumes a unimodal distribution of worker projections, which may not always be true, potentially leading to inaccurate ground truth identification.
- The data filling approach assumes that MMLC predictions are consistently better than random guesses, but this may degrade in datasets with high noise levels or insufficient worker redundancy.

## Confidence

- **High confidence**: The architectural design of MMLC using expert and gate modules is well-defined and reproducible. The concept of modeling worker behavior at the feature level is theoretically sound.
- **Medium confidence**: The effectiveness of oracle worker identification through clustering is supported by experimental results but depends heavily on the assumption of a unimodal worker distribution in spectral space.
- **Low confidence**: The generalization of data filling improvements across all learning-from-crowds methods is claimed but may vary significantly depending on the specific method and dataset characteristics.

## Next Checks

1. **Dataset diversity test**: Apply MMLC to datasets with varying levels of worker redundancy and noise to validate if the oracle worker identification remains stable across different worker distribution patterns.

2. **Oracle sensitivity analysis**: Systematically vary the number of experts and observe how it affects the stability of oracle worker identification and overall accuracy, particularly focusing on the trade-off between model complexity and oracle finding reliability.

3. **Data filling robustness check**: Test MMLC-df on datasets where worker behavior is deliberately randomized to assess whether the method degrades gracefully or catastrophically when worker projections do not cluster meaningfully.