---
ver: rpa2
title: 'Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph
  Neural Networks'
arxiv_id: '2408.03669'
source_url: https://arxiv.org/abs/2408.03669
tags:
- deep
- gradient
- graph
- gnns
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper systematically analyzes the dominant problem in deep
  graph neural networks (GNNs) and identifies that the trainability issue of deep
  multilayer perceptrons (MLPs), rather than over-smoothing, is the main cause of
  performance degradation. Through empirical experiments and theoretical gradient
  analysis, the authors prove that various existing methods targeting over-smoothing
  actually improve the trainability of MLPs, which is the key to their performance
  gains.
---

# Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph Neural Networks

## Quick Facts
- **arXiv ID:** 2408.03669
- **Source URL:** https://arxiv.org/abs/2408.03669
- **Reference count:** 40
- **Key outcome:** Deep GNN performance degradation is dominated by trainability issues of deep MLPs rather than over-smoothing, with GCNII achieving 85.5% accuracy on Cora with 64 layers

## Executive Summary
This paper challenges the prevailing assumption that over-smoothing is the primary obstacle to deep Graph Neural Networks (GNNs). Through systematic empirical experiments and theoretical gradient analysis, the authors demonstrate that trainability issues in deep MLPs are actually the dominant cause of performance degradation in deep GNNs. The study reveals that existing methods targeting over-smoothing (like GCNII, Batch Normalization, and DropEdge) actually work by improving MLP trainability rather than addressing the smoothing process itself. The findings are supported by experiments on Cora, Citeseer, and Pubmed datasets, showing that properly constrained gradient flow upper bounds significantly enhance GNN trainability.

## Method Summary
The authors employ SGC-MLP experiments to decouple graph propagation and training processes, allowing them to isolate the trainability challenges of deep MLPs. They incrementally increase MLP depths while keeping graph propagation fixed, and apply various techniques (GCNII, Batch Normalization, DropEdge) separately to either process. Theoretical gradient flow analysis is performed to understand how different factors affect trainability. The experiments use standard citation network datasets with typical training/validation/testing splits, evaluating node classification accuracy and gradient flow stability.

## Key Results
- Trainability problems of deep MLPs dominate performance degradation in deep GNNs, not over-smoothing
- GCNII achieves 85.5% test accuracy on Cora with 64 layers, while standard GCN drops to 28.7% under the same conditions
- Properly constrained smaller upper bounds of gradient flow notably enhance GNN trainability
- Techniques targeting over-smoothing actually work by improving MLP trainability through gradient regulation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Trainability problem of deep MLPs, not over-smoothing, is the dominant cause of performance degradation in deep GNNs
- **Mechanism:** Deep MLPs suffer from vanishing/exploding gradients as depth increases, which severely limits learning ability. This trainability issue manifests earlier and more severely than over-smoothing in most real-world graph structures.
- **Core assumption:** Real-world graphs have small spectral gaps, leading to slow over-smoothing convergence rates
- **Evidence anchors:** Abstract states various methods targeting over-smoothing actually improve MLP trainability as main reason for performance gains
- **Break condition:** Extremely dense graphs with large spectral gaps could make over-smoothing dominant before trainability issues manifest

### Mechanism 2
- **Claim:** Properly constrained smaller upper bounds of gradient flow enhance trainability and performance of deep GNNs
- **Mechanism:** Gradient flow upper bound reflects stability of gradient updates during training. When properly constrained, the model maintains stable learning dynamics and better performance.
- **Core assumption:** Gradient flow stability directly correlates with model trainability and performance
- **Evidence anchors:** Abstract mentions properly constrained smaller upper bounds notably enhance GNN trainability
- **Break condition:** Excessively constraining gradient upper bound could lead to gradient vanishing

### Mechanism 3
- **Claim:** Methods targeting over-smoothing actually work by improving MLP trainability rather than addressing smoothing process
- **Mechanism:** Techniques like GCNII, Batch Normalization, and DropEdge were designed for over-smoothing but primarily improve deep MLP trainability through gradient regulation and training dynamics improvements.
- **Core assumption:** Performance improvements from these methods stem from effects on MLP trainability rather than intended smoothing mitigation
- **Evidence anchors:** Abstract states various methods that supposedly tackle over-smoothing actually improve MLP trainability
- **Break condition:** If method fundamentally changes graph propagation process rather than training dynamics, it might work through over-smoothing mitigation

## Foundational Learning

- **Concept:** Spectral graph theory and normalized Laplacian matrices
  - Why needed here: Understanding spectral gap and its relationship to smoothing convergence rates is crucial for analyzing why over-smoothing is not dominant problem
  - Quick check question: How does spectral gap of a graph affect convergence rate of Laplacian smoothing process?

- **Concept:** Gradient flow analysis and upper bounds
  - Why needed here: Theoretical framework for analyzing gradient stability in deep networks is essential for understanding why properly constrained gradient upper bounds improve trainability
  - Quick check question: What is relationship between gradient flow upper bounds and stability of training dynamics in deep neural networks?

- **Concept:** Trainability challenges in deep MLPs
  - Why needed here: Understanding fundamental difficulties of training deep MLPs (vanishing/exploding gradients) is necessary to grasp why this becomes dominant problem in deep GNNs
  - Quick check question: What are primary causes of trainability issues in deep MLPs and how do they manifest during training?

## Architecture Onboarding

- **Component map:** Graph features → Spectral convolution → MLP processing → Classification output, with gradient flow stability maintained throughout training

- **Critical path:** Graph features → Spectral convolution → MLP processing → Classification output, with gradient flow stability maintained throughout training

- **Design tradeoffs:**
  - Deeper architectures offer greater expressivity but exacerbate trainability issues
  - Stronger regularization improves stability but may limit model capacity
  - More sophisticated gradient control mechanisms add complexity but enable deeper models

- **Failure signatures:**
  - Rapid performance degradation with depth indicates trainability issues
  - Stable training but poor convergence suggests inadequate gradient constraints
  - Over-smoothing only becomes apparent at extreme depths (100+ layers) in most real graphs

- **First 3 experiments:**
  1. Implement SGC-MLP baseline with varying MLP depths to reproduce trainability vs over-smoothing tradeoff
  2. Add gradient flow monitoring to measure upper bounds across different depths and architectures
  3. Test GCNII and Batch Normalization with decoupled graph propagation/training processes to verify primary mechanism of action

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does performance of deep GNNs vary across different graph datasets with varying structural properties (e.g., different levels of sparsity, average node degrees, and community structures)?
- **Basis in paper:** [inferred] Paper analyzes impact of trainability on deep GNN performance but doesn't extensively explore how graph structural properties affect severity of trainability issues
- **Why unresolved:** Empirical experiments on citation networks may not represent full spectrum of graph structures; different properties could lead to varying degrees of trainability challenges
- **What evidence would resolve it:** Experiments on diverse graph datasets with varying structural properties and analysis of how gradient upper bounds and model performance change

### Open Question 2
- **Question:** What is impact of different activation functions on trainability of deep GNNs, and how does this compare to their impact on deep MLPs?
- **Basis in paper:** [inferred] Paper assumes ReLU activation function but doesn't explore effects of other activation functions on trainability and gradient flow
- **Why unresolved:** Activation functions play crucial role in controlling gradient flow and can have different effects on GNNs compared to traditional MLPs due to graph convolution operations
- **What evidence would resolve it:** Experiments with different activation functions (LeakyReLU, ELU, GELU) in deep GNNs and comparison of their effects on gradient flow, trainability, and model performance

### Open Question 3
- **Question:** How does initialization strategy of weight matrices in deep GNNs affect trainability and performance, and are there specific initialization techniques more effective for deep GNNs compared to traditional MLPs?
- **Basis in paper:** [inferred] Paper mentions possibility of adjusting weight initialization strategies but doesn't explore specific initialization techniques or their impact
- **Why unresolved:** Weight initialization is critical for ensuring stable gradient flow and trainability in deep networks; unique structure of GNNs may require specialized initialization techniques
- **What evidence would resolve it:** Experiments with various weight initialization strategies (Xavier, He, orthogonal) in deep GNNs and analysis of their impact on gradient flow, trainability, and model performance

## Limitations
- Generalizability to non-homophilic graphs and graphs with different spectral properties remains uncertain
- Gradient flow upper bound analysis requires further validation across diverse graph structures and larger-scale datasets
- Findings based primarily on citation network datasets which may have specific structural characteristics

## Confidence
- **High Confidence:** Empirical evidence showing MLP trainability issues dominate performance degradation in deep GNNs on citation networks
- **Medium Confidence:** Theoretical gradient flow analysis and its connection to trainability improvements
- **Medium Confidence:** Reinterpretation of existing methods' effectiveness as primarily improving MLP trainability rather than addressing over-smoothing

## Next Checks
1. **Cross-dataset validation:** Test SGC-MLP experiments on non-homophilic graphs (Amazon co-purchase networks, protein-protein interaction networks) to verify if trainability remains dominant issue
2. **Spectral gap analysis:** Systematically vary spectral gap of synthetic graphs and measure relative impact of trainability vs over-smoothing across different gap sizes
3. **Transfer learning evaluation:** Apply identified techniques (GCNII, BatchNorm, DropEdge) to downstream tasks like graph classification and link prediction to test if trainability improvements generalize beyond node classification