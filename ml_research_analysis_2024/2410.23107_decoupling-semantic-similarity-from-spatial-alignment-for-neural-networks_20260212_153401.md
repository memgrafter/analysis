---
ver: rpa2
title: Decoupling Semantic Similarity from Spatial Alignment for Neural Networks
arxiv_id: '2410.23107'
source_url: https://arxiv.org/abs/2410.23107
tags:
- similarity
- semantic
- rsms
- spatial
- spatio-semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper revisits the definition of similarity for neural network
  representations, identifying that existing Representational Similarity Matrices
  (RSMs) couple semantic content with spatial alignment. The authors propose semantic
  RSMs that are invariant to spatial permutations by finding optimal alignment between
  semantic concept vectors using bipartite matching.
---

# Decoupling Semantic Similarity from Spatial Alignment for Neural Networks

## Quick Facts
- arXiv ID: 2410.23107
- Source URL: https://arxiv.org/abs/2410.23107
- Reference count: 40
- Key outcome: Semantic RSMs improve image retrieval and better correlate with classifier output similarity by decoupling spatial alignment from semantic content.

## Executive Summary
This paper addresses a fundamental limitation in how neural network similarity is measured: existing Representational Similarity Matrices (RSMs) couple semantic content with spatial alignment, making them sensitive to object location rather than just semantic meaning. The authors propose semantic RSMs that are invariant to spatial permutations by finding optimal alignment between semantic concept vectors using bipartite matching. Experiments show semantic RSMs significantly improve image retrieval performance across multiple architectures and better correlate with classifier output similarity compared to traditional spatio-semantic RSMs. The computational complexity is addressed through approximation algorithms that reduce runtime by up to 36× while maintaining accuracy within 8% of optimal matching.

## Method Summary
The method constructs semantic RSMs by extracting semantic concept vectors from neural network representations, then finding optimal spatial permutations between these vectors using bipartite matching (Hungarian algorithm). For each pair of representations, an affinity matrix is built and optimal permutation is found to maximize semantic similarity while neutralizing spatial effects. To handle computational complexity, three approximation algorithms are introduced: Batch-Optimal (reduces complexity from O(S³) to O(S)), TopK-Greedy, and Greedy. These approximations maintain high accuracy while enabling application to large-scale representations.

## Key Results
- Semantic RSMs improve image retrieval performance (F1@1) across all tested architectures, with greater improvements for models with larger spatial extent like CLIPSeg and SAM.
- Permutation-invariant similarities better predict classifier output similarity, showing consistently negative Pearson correlation with Jensen-Shannon divergence across architectures.
- Computational efficiency: approximation algorithms reduce runtime by up to 36× while maintaining accuracy within 8% of optimal matching.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic RSMs disentangle spatial alignment from semantic content, improving retrieval and classifier similarity prediction.
- Mechanism: By finding optimal bipartite matching between semantic concept vectors, spatial permutations are neutralized, so only semantic similarity drives the similarity measure.
- Core assumption: The spatial position of semantic features in an image is irrelevant to both human perception and classifier outputs.
- Evidence anchors:
  - [abstract] "we argue that the spatial location of semantic objects does neither influence human perception nor deep learning classifiers."
  - [section 3.1.1] "we propose to make Kij invariant to all spatial permutations of the semantic concept vectors v."
- Break condition: If classifiers or humans do rely on spatial structure, or if semantic concept vectors are not truly independent of position, the assumption fails.

### Mechanism 2
- Claim: Permutation invariance leads to improved retrieval performance.
- Mechanism: When semantic content is decoupled from location, retrieval based on similarity finds semantically similar scenes even under different viewpoints or object positions.
- Core assumption: Retrieval datasets (like EgoObjects) contain scenes where the same semantic content appears in different spatial arrangements.
- Evidence anchors:
  - [section 4.2] "across all architectures and metrics, the inclusion of permutation invariance (PI) for the similarity calculation improves retrieval performance relative to the non-invariant similarity."
  - [section 4.2] "models with a greater spatial extent (CLIPSeg and SAM) show greater improvement in retrieval performance."
- Break condition: If retrieval performance is dominated by other factors (e.g., global features, low spatial variance), permutation invariance will not yield gains.

### Mechanism 3
- Claim: Semantic RSMs better predict classifier output similarity.
- Mechanism: By aligning semantic concept vectors optimally, semantic RSMs more closely reflect the similarity in predicted class probabilities, as both capture semantic relationships.
- Core assumption: The similarity structure of internal representations should correlate with the similarity of classifier outputs.
- Evidence anchors:
  - [section 4.3] "permutation invariant similarities are better at capturing the notion of what a classifier deems similar."
  - [section 4.3] "consistently negative for all architectures tested" (Pearson correlation with JSD).
- Break condition: If internal representations contain confounding factors unrelated to semantic content, or if classifier outputs are not driven by the same semantic features, correlation will not improve.

## Foundational Learning

- Concept: Representational Similarity Matrices (RSMs)
  - Why needed here: RSMs are the foundational tool for quantifying similarity between neural network representations; the paper's contribution hinges on how RSMs are constructed.
  - Quick check question: What does each entry in an RSM measure, and how is it traditionally computed for CNNs?

- Concept: Permutation invariance
  - Why needed here: The paper's key innovation is making similarity measures invariant to spatial permutations of semantic concept vectors.
  - Quick check question: How does permutation invariance differ from translation invariance, and why is it more general?

- Concept: Bipartite matching (Hungarian algorithm)
  - Why needed here: Optimal permutation between semantic concept vectors is found using bipartite matching, crucial for constructing semantic RSMs.
  - Quick check question: What is the computational complexity of finding the optimal permutation, and how does it scale with spatial resolution?

## Architecture Onboarding

- Component map:
  Input -> Extract representations -> Compute affinity matrices -> Find optimal permutation via bipartite matching -> Apply kernel to aligned vectors -> Assemble semantic RSM

- Critical path:
  1. Extract representations from model
  2. Compute affinity matrices Aij for all pairs
  3. Find optimal permutation Pij via bipartite matching
  4. Apply kernel k to aligned vectors
  5. Assemble full semantic RSM

- Design tradeoffs:
  - Exact optimal matching: Accurate but O(S^3) per pair, prohibitive for large S
  - Approximations: Faster but may lose accuracy; Batch-Optimal balances speed and quality
  - Kernel choice: RBF, linear, cosine; affects boundedness and sensitivity

- Failure signatures:
  - Very low or very high similarity values across all pairs (possible normalization or kernel issues)
  - Retrieval or correlation metrics not improving with PI (may indicate dataset lacks spatial variance or semantic concept vectors not well-aligned)
  - Runtime explosion for large spatial resolutions (need to switch to approximations)

- First 3 experiments:
  1. Verify translation sensitivity on a toy dataset with partially overlapping crops (as in Fig. 2)
  2. Run retrieval on EgoObjects with and without PI, check F1@1 improvement
  3. Compute correlation between semantic RSMs and JSD of classifier outputs for a ResNet on ImageNet

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do semantic RSMs compare to other established retrieval techniques when applied to neural network representations?
- Basis in paper: [inferred] The authors note that "we have not yet compared our method to more established retrieval techniques" and acknowledge that "Traditional retrieval methods are often not applied to representations directly but utilize a lower-dimensional non-spatial, global vector representing the entire sample."
- Why unresolved: The retrieval experiments only compared permutation-invariant vs non-invariant similarity calculations using the same representations, without benchmarking against traditional retrieval methods like PCA-based approaches or global feature pooling.
- What evidence would resolve it: Comparative experiments showing retrieval performance of semantic RSMs versus traditional retrieval methods (e.g., global average pooling + PCA, VLAD encoding) on the same datasets and architectures.

### Open Question 2
- Question: Does the improvement from permutation invariance vary systematically with dataset characteristics like object scale, viewpoint diversity, or image resolution?
- Basis in paper: [explicit] The authors observe that "models with a greater spatial extent (CLIPSeg and SAM) show greater improvement in retrieval performance over models with a lower spatial extent" and note that "this effect should generalize to other datasets where objects are not heavily centered."
- Why unresolved: While qualitative patterns are observed, there's no systematic analysis of how retrieval improvements correlate with specific dataset properties like object size variation, viewpoint diversity, or image resolution.
- What evidence would resolve it: Quantitative analysis showing correlation between retrieval improvement from permutation invariance and dataset characteristics across multiple datasets with controlled variations in object scale, viewpoint diversity, and image resolution.

### Open Question 3
- Question: What is the optimal batch size for the Batch-Optimal approximation algorithm across different architectures and spatial resolutions?
- Basis in paper: [explicit] The authors state "we utilize the Batch-Optimal approximation with windows size b 512" but also note that "its complexity scales linearly with S due to the fixed batch size."
- Why unresolved: The choice of batch size 512 appears arbitrary, and the authors acknowledge that "application to large-scale representations at higher resolution... would be too costly" but don't explore how batch size affects the trade-off between runtime and approximation quality.
- What evidence would resolve it: Systematic experiments varying batch size across different architectures, spatial resolutions, and datasets to determine optimal batch sizes that maximize the trade-off between computational efficiency and approximation quality.

### Open Question 4
- Question: How do semantic RSMs affect the interpretation of neural network similarity in transfer learning and model compression scenarios?
- Basis in paper: [explicit] The authors mention that "CKA was used in various applications, to measure the similarity between Transformers and CNNs or wide and deep networks and to understand catastrophic forgetting or transfer learning" but don't investigate how semantic RSMs would affect these applications.
- Why unresolved: While the paper demonstrates benefits for image retrieval and output similarity prediction, it doesn't explore how the semantic RSM construction would affect established applications of representational similarity analysis like transfer learning or model compression.
- What evidence would resolve it: Experiments showing how semantic RSMs affect conclusions in transfer learning scenarios (e.g., which layers transfer best) and model compression (e.g., which neurons can be pruned) compared to spatio-semantic RSMs.

## Limitations

- The approach assumes semantic concept vectors are independent of spatial position, which may not hold for all architectures or tasks.
- The paper does not compare semantic RSMs against traditional retrieval methods, limiting understanding of their relative performance.
- The optimal batch size for approximation algorithms is not systematically explored, and kernel parameter choices are not thoroughly validated.

## Confidence

- Claim: Semantic RSMs improve retrieval performance and classifier output correlation -> Medium
- Claim: The mechanism of spatial permutation invariance works as described -> Low-Medium
- Claim: Approximation algorithms maintain accuracy while improving efficiency -> Medium

## Next Checks

1. Test semantic RSMs on a dataset with strong spatial priors (e.g., object detection) to check if the assumption of spatial irrelevance breaks down.
2. Compare the proposed approximation algorithms against other methods (e.g., random sampling, sketching) to assess their efficiency and accuracy.
3. Perform an ablation study on kernel parameters and semantic concept vector normalization to quantify their impact on retrieval and correlation performance.