---
ver: rpa2
title: 'CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network'
arxiv_id: '2408.10919'
source_url: https://arxiv.org/abs/2408.10919
tags:
- domain
- scenario
- samples
- similarity
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CrossFi addresses the challenge of cross-domain Wi-Fi sensing by
  proposing a siamese network-based framework. The core method idea involves using
  a sample-similarity calculation network (CSi-Net) with an attention mechanism and
  a Weight-Net for adaptive template generation.
---

# CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network

## Quick Facts
- arXiv ID: 2408.10919
- Source URL: https://arxiv.org/abs/2408.10919
- Reference count: 40
- Primary result: Achieves 98.17% accuracy in in-domain gesture recognition and strong cross-domain performance

## Executive Summary
CrossFi introduces a novel Siamese network-based framework for cross-domain Wi-Fi sensing that addresses the challenge of maintaining performance when sensing environments change. The framework leverages sample-similarity calculation with an attention mechanism and adaptive template generation to achieve state-of-the-art results across multiple challenging scenarios. The approach demonstrates exceptional adaptability, performing well in in-domain, few-shot, zero-shot, and few-shot new-class settings.

## Method Summary
CrossFi employs a Siamese network architecture centered around a sample-similarity calculation network (CSi-Net) enhanced with attention mechanisms. The framework uses a Weight-Net component for adaptive template generation, enabling effective cross-domain adaptation. The method processes Channel State Information (CSI) data through this architecture to recognize gestures across different sensing environments. The attention mechanism helps focus on relevant signal features while the Weight-Net dynamically adjusts templates based on domain differences.

## Key Results
- Achieves 98.17% accuracy in in-domain gesture recognition
- Demonstrates 91.72% accuracy in one-shot cross-domain scenarios
- Shows 64.81% accuracy in zero-shot cross-domain settings
- Performs 84.75% accuracy in one-shot new-class recognition

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to learn discriminative features that are invariant to domain shifts while maintaining sensitivity to task-relevant variations. The Siamese architecture enables direct comparison between template and input signals, while the attention mechanism identifies critical signal components that contribute most to recognition accuracy. The Weight-Net dynamically adjusts template weights based on domain characteristics, allowing the system to adapt without requiring extensive retraining on new domain data.

## Foundational Learning
- **Channel State Information (CSI)**: Why needed: Core input signal representing wireless channel characteristics. Quick check: Verify CSI extraction accuracy across different hardware.
- **Siamese Network Architecture**: Why needed: Enables direct comparison between reference and test samples. Quick check: Confirm network properly learns similarity metrics.
- **Attention Mechanisms**: Why needed: Identifies most relevant signal features for recognition. Quick check: Validate attention weights align with human-interpretable signal features.
- **Few-shot Learning**: Why needed: Enables recognition with minimal training examples per class. Quick check: Test performance with varying numbers of training samples.
- **Cross-domain Adaptation**: Why needed: Maintains accuracy across different sensing environments. Quick check: Evaluate performance across distinct environmental conditions.
- **Template Generation**: Why needed: Creates reference patterns for comparison. Quick check: Verify template quality affects recognition accuracy.

## Architecture Onboarding
**Component Map**: CSI Input -> CSi-Net with Attention -> Similarity Calculation -> Weight-Net -> Output Classification
**Critical Path**: CSI acquisition → Feature extraction (CSi-Net) → Attention-weighted similarity scoring → Template adaptation (Weight-Net) → Classification
**Design Tradeoffs**: The framework balances computational complexity with accuracy by using attention to reduce feature dimensionality while maintaining discriminative power. The adaptive template approach trades storage requirements for improved cross-domain performance.
**Failure Signatures**: Poor CSI quality manifests as reduced attention focus and similarity scores. Domain shifts too large for adaptation cause systematic classification errors across multiple classes. Template mismatch results in consistently low similarity scores regardless of input.
**First Experiments**:
1. Baseline CSI quality assessment across target environments
2. Attention mechanism visualization to verify feature focus
3. Cross-domain similarity score distribution analysis

## Open Questions the Paper Calls Out
None

## Limitations
- Performance evaluation limited to gesture recognition scenarios, may not generalize to other sensing applications
- Computational overhead of attention mechanism and Weight-Net not quantified for real-time deployment feasibility
- Cross-domain evaluation scope limited, robustness to extreme domain shifts unclear
- Scalability to larger gesture vocabularies and complex activity recognition untested

## Confidence
- Cross-domain adaptability claims: Medium confidence
- State-of-the-art performance claims: High confidence
- Siamese network architecture effectiveness: High confidence

## Next Checks
1. Conduct extensive real-world deployment tests across diverse environments (residential, commercial, outdoor) to validate cross-domain performance under varying conditions including interference, mobility, and device heterogeneity.
2. Perform detailed computational analysis measuring latency, memory usage, and power consumption during real-time operation to assess practical deployment feasibility on resource-constrained devices.
3. Expand evaluation to include larger gesture vocabularies (50+ classes) and complex activity recognition tasks to test scalability and robustness of few-shot and zero-shot learning capabilities.