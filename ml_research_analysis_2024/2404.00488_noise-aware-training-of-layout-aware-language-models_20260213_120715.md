---
ver: rpa2
title: Noise-Aware Training of Layout-Aware Language Models
arxiv_id: '2404.00488'
source_url: https://arxiv.org/abs/2404.00488
tags:
- training
- document
- documents
- extractor
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the problem of training information extractors
  for thousands of visually rich document types efficiently in enterprise settings.
  The core approach, called NAT, uses a three-phase workflow: pre-training with transfer
  learning, noise-aware fine-tuning on weakly labeled documents, and fine-tuning on
  synthetic data.'
---

# Noise-Aware Training of Layout-Aware Language Models

## Quick Facts
- arXiv ID: 2404.00488
- Source URL: https://arxiv.org/abs/2404.00488
- Reference count: 9
- This paper tackles training information extractors for thousands of visually rich document types efficiently in enterprise settings.

## Executive Summary
This paper introduces NAT (Noise-Aware Training), a three-phase workflow for training robust information extractors on visually rich documents when human-labeled data is scarce. The approach combines transfer learning initialization, noise-aware fine-tuning on weakly labeled data, and synthetic data augmentation to achieve state-of-the-art performance while significantly reducing human labeling effort. NAT demonstrates up to 6% macro-F1 improvement over transfer-learning baselines and reduces human labeling requirements by up to 73% across four benchmark datasets.

## Method Summary
NAT employs a three-phase training workflow: (1) Pre-training using L1-transfer from models pre-trained on large document datasets like IIT-CDIP, (2) Noise-aware fine-tuning on weakly labeled documents generated by multiple models trained on limited human-labeled samples, where sample weights are assigned based on supervision source confidence, and (3) Fine-tuning on synthetically augmented documents created through rule-based transformations of human-labeled examples. The method uses confidence-based sample weighting, weight thresholding, and noise-aware loss functions to handle label noise, all while maintaining training within ~1.5 hours on a single GPU.

## Key Results
- NAT-trained models outperform transfer-learning baselines by up to 6% macro-F1
- Reduces human labeling effort by up to 73% across four datasets
- Achieves training completion within ~1.5 hours on single GPU
- Sequential fine-tuning on multiple weak supervision sources shows consistent benefits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sample re-weighting based on supervision source confidence reduces training noise impact.
- Mechanism: Each training sample gets a weight c (0 < c < 1) equal to the softmax probability from its weak supervision source; human-labeled samples get weight 1.0.
- Core assumption: The supervision source's softmax probability is a reliable proxy for true label accuracy.
- Evidence anchors:
  - [abstract] "NAT estimates the confidence of each training sample and incorporates it as uncertainty measure during training"
  - [section 4.2] "we assign it a weight 0 < c < 1 equal to the softmax probability of its label inferred by the corresponding weak supervision source"
- Break condition: If supervision source confidence estimates are systematically miscalibrated (e.g., overconfident predictions), re-weighting could amplify errors rather than suppress them.

### Mechanism 2
- Claim: Sequential fine-tuning on multiple weak supervision sources improves model robustness compared to single-source training.
- Mechanism: The extractor is fine-tuned first on weakly labeled corpus from source W1, then on corpus from source W2, allowing progressive refinement of learned representations.
- Core assumption: Different weak supervision sources have complementary error patterns, so sequential exposure helps the model learn to handle diverse noise types.
- Evidence anchors:
  - [section 4.5] "we sequentially fine-tune the model on weakly augmented corpus inferred by each weak supervision source"
- Break condition: If supervision sources have highly correlated errors, sequential training may simply propagate the same mistakes rather than correct them.

### Mechanism 3
- Claim: Synthetic data augmentation compensates for limited human-labeled samples by expanding the training distribution.
- Mechanism: Rule-based transformations (synonym substitution, format substitution, coordinate transformation, bounding-box expansion) generate synthetic documents from human-labeled ones.
- Core assumption: The rule-based transformations preserve semantic meaning while sufficiently diversifying the input space to improve generalization.
- Evidence anchors:
  - [section 5.1] Describes four augmentation rules and their purposes
  - [section 6.3] "Removing fine-tuning on the synthetically augmented corpus from our workflow... worsens extraction performance"
- Break condition: If synthetic transformations introduce artifacts that don't appear in real documents, the model may overfit to synthetic patterns that don't transfer.

## Foundational Learning

- Concept: Semi-supervised learning with weak supervision
  - Why needed here: The core problem is insufficient human-labeled documents for thousands of document types; weak supervision provides scalable labeling without human effort
  - Quick check question: Why can't we just use more unlabeled documents with self-training instead of multiple weak supervision sources?

- Concept: Noise-aware loss functions and sample weighting
  - Why needed here: Weak labels are inherently noisy; standard cross-entropy would treat all samples equally, allowing errors to corrupt the model
  - Quick check question: How does the noise-aware loss differ mathematically from standard cross-entropy, and why does this difference help?

- Concept: Transfer learning and L1-transfer initialization
  - Why needed here: Pre-training on large document datasets is too time-consuming (30+ hours) given strict training time bounds; L1-transfer allows leveraging pre-trained weights without full pre-training
  - Quick check question: What's the difference between L1-transfer and full fine-tuning in terms of parameter updates and computational cost?

## Architecture Onboarding

- Component map: Pre-trained backbone (LayoutLMV2 or FormNet) -> Weak supervision sources (FormNet + bi-LSTM) -> Sample weighting module -> Noise-aware loss layer -> Synthetic data generator -> Sequential fine-tuning controller
- Critical path: Pre-trained model initialization → Weak label generation → Sample weighting → Noise-aware fine-tuning (Phase II) → Synthetic augmentation → Final fine-tuning (Phase III)
- Design tradeoffs: Sample weighting vs. sample filtering (thresholding) - weighting preserves more data but requires accurate confidence estimates; filtering is simpler but may discard useful borderline cases
- Failure signatures: 
  - High variance in macro-F1 across runs suggests unstable weak supervision
  - Performance degrades significantly when removing synthetic augmentation indicates over-reliance on limited human data
  - Minimal improvement from sequential fine-tuning suggests weak supervision sources have similar error patterns
- First 3 experiments:
  1. Train with single weak supervision source only - compare macro-F1 to NAT's two-source approach
  2. Remove sample weighting (use uniform weights) while keeping all other NAT components - measure degradation
  3. Test different confidence threshold values (C) in weight thresholding - find optimal balance between noise reduction and data retention

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unexplored based on the limitations identified in the analysis.

## Limitations
- Weak supervision quality assumptions: The effectiveness of sample weighting depends on softmax probabilities accurately reflecting label reliability, but no systematic calibration analysis is provided
- Synthetic data validity: While synthetic augmentation shows benefits, the paper lacks analysis of whether synthetic examples truly match real document distribution characteristics
- Limited weak supervision exploration: The paper only uses two weak supervision sources without investigating the impact of adding more sources or varying their error patterns

## Confidence
- High Confidence: Overall three-phase NAT workflow structure and superiority over transfer-learning baselines (6% macro-F1 improvement, 73% reduction in labeling effort)
- Medium Confidence: Noise-aware sample weighting mechanism's effectiveness, dependent on unverified confidence calibration assumptions
- Medium Confidence: Synthetic data augmentation's contribution, given limited analysis of synthetic-to-real distribution alignment

## Next Checks
1. **Calibration Analysis**: Evaluate whether supervision source softmax probabilities are well-calibrated by comparing confidence scores against actual weak label accuracy on a held-out validation set.
2. **Synthetic Distribution Analysis**: Compare synthetic document statistics (entity diversity, format variations) against real document distributions using coverage metrics to verify synthetic augmentation adds meaningful diversity.
3. **Sequential Training Ablation**: Compare macro-F1 performance when training with single vs. multiple weak supervision sources to validate whether sequential exposure to diverse noise patterns provides measurable benefits.