---
ver: rpa2
title: Enabling Explainable Recommendation in E-commerce with LLM-powered Product
  Knowledge Graph
arxiv_id: '2412.01837'
source_url: https://arxiv.org/abs/2412.01837
tags:
- product
- recommendation
- llm-pkg
- user
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLM-PKG is a novel framework that distills LLM knowledge into a
  product knowledge graph for explainable e-commerce recommendations. The approach
  builds a knowledge graph by using LLM to generate product relationships and then
  maps these to real enterprise products.
---

# Enabling Explainable Recommendation in E-commerce with LLM-powered Product Knowledge Graph

## Quick Facts
- arXiv ID: 2412.01837
- Source URL: https://arxiv.org/abs/2412.01837
- Reference count: 4
- Primary result: +5.91% CTR, +7.20% conversion rate, +7.59% 1-day transactions, +7.55% 7-day transactions in A/B test

## Executive Summary
LLM-PKG introduces a novel framework that leverages large language models to construct a product knowledge graph for explainable e-commerce recommendations. The approach generates product relationships and rationales using LLM, validates and prunes the graph to address hallucination risks, then maps the knowledge to real enterprise products for serving. A large-scale A/B test demonstrated significant improvements over existing methods, achieving +5.91% click-through rate, +7.20% conversion rate, and +7.59% transactions (1-day maturity).

## Method Summary
The framework constructs a product knowledge graph by using LLM to generate product relationships and rationales through carefully designed prompts. The generated graph undergoes validation and pruning by LLM to ensure quality and mitigate hallucination risks. The cleaned knowledge graph is then mapped to real enterprise products using a fine-tuned BERT model and KNN indexing. Recommendations are served with accompanying rationale messages to provide explainability. The system operates offline for KG construction and caches results for efficient online serving.

## Key Results
- Click-through rate increased by +5.91% compared to baseline
- Conversion rate improved by +7.20% in A/B testing
- Transactions increased by +7.59% (1-day maturity) and +7.55% (7-day maturity)

## Why This Works (Mechanism)

### Mechanism 1
LLM-generated product relationships provide semantic connections that traditional data mining cannot capture. LLM distills world knowledge about product relationships into structured triples forming the knowledge graph. Core assumption: LLMs trained on vast textual data understand most use cases of products and user intentions behind purchases. Evidence: "LLM is assumed to own world knowledge" and "it is extremely difficult to mine this kind of relation from data collected by e-commerce website." Break condition: If LLM lacks domain-specific knowledge or generates factually incorrect relationships.

### Mechanism 2
Knowledge graph structure enables explainable recommendations by explicitly showing rationale edges. Recommendations are generated by traversing KG edges, where each edge contains a rationale phrase that explains the connection. Core assumption: Users value transparent explanations that accompany recommendations. Evidence: "providing explainable recommendations by displaying rationale messages alongside products" and "LLM-PKG can provide explanations of its recommendations to attract users." Break condition: If displayed rationales don't align with user expectations or are perceived as irrelevant.

### Mechanism 3
Iterative validation and pruning by LLM ensures KG quality despite hallucination risks. LLM evaluates each edge with scoring and reason assessment, then prunes low-quality nodes/edges and refines prompts based on feedback. Core assumption: LLM can reliably self-evaluate its own generated knowledge graph quality. Evidence: "LLM has excellent role-play capabilities we ask LLM to evaluate the quality of nodes and edges" and "we removed some nodes and edges" after evaluation. Break condition: If LLM self-evaluation is inconsistent or fails to detect hallucinations.

## Foundational Learning

- Concept: Knowledge Graph construction and RDF triple format
  - Why needed here: The entire framework relies on converting LLM responses into structured KG format for downstream use
  - Quick check question: Can you explain how (subject, predicate, object) triples represent product relationships?

- Concept: Prompt engineering with contextual components
  - Why needed here: Effective KG construction depends on carefully designed prompts that guide LLM to generate accurate recommendations and rationales
  - Quick check question: What are the four key components of prompts used in this framework?

- Concept: Vector search and KNN indexing for product mapping
  - Why needed here: Mapping LLM-generated products to enterprise inventory requires semantic similarity matching using embeddings
  - Quick check question: How does the fine-tuned BERT model help in finding the closest internal products?

## Architecture Onboarding

- Component map: Prompt Design Engine → LLM API → KG Construction Module → Validation Module → Pruning Module → Product Mapping Engine → Caching Layer → Online Serving API
- Critical path: Prompt → LLM → KG → Validation → Pruning → Mapping → Caching → Serving
- Design tradeoffs:
  - Offline vs online LLM calls: Offline construction trades freshness for speed/cost
  - RDF vs other formats: RDF chosen for triple structure but may be verbose
  - One-shot learning: Improves format correctness but adds prompt complexity
- Failure signatures:
  - Low average edge scores after validation indicate prompt quality issues
  - High relation imprecise rate suggests LLM hallucination problems
  - Empty cache responses indicate mapping failures
  - Performance degradation during high traffic suggests caching inefficiencies
- First 3 experiments:
  1. Test prompt variations with different seed products to measure format correctness rate
  2. Validate LLM self-evaluation by comparing its scores with human-labeled ground truth
  3. Measure mapping accuracy by checking if KNN search returns semantically similar products

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of LLM-PKG compare when using different LLM models or prompt engineering techniques? Basis: The paper uses a specific LLM and prompt design without exploring impact of different models or prompt variations. Why unresolved: The paper focuses on single implementation without comparing alternatives. What evidence would resolve it: Experiments comparing performance using different LLM models or various prompt engineering techniques.

### Open Question 2
How does the performance of LLM-PKG scale with increasing knowledge graph size and complexity? Basis: The paper presents results for specific knowledge graph size but doesn't explore performance changes with larger or more complex graphs. Why unresolved: Scalability is not addressed, leaving questions about effectiveness in handling massive product catalogs. What evidence would resolve it: Experiments evaluating performance on knowledge graphs of varying sizes and complexities.

### Open Question 3
How does LLM-PKG handle cold-start scenarios where limited user behavior data is available? Basis: The paper focuses on item-based recommendations but doesn't address performance in cold-start situations with sparse user data. Why unresolved: Effectiveness in recommending products to new users or for new products with limited interaction history is not explored. What evidence would resolve it: Experiments comparing performance in cold-start scenarios versus traditional collaborative filtering or content-based methods.

## Limitations

- Limited transparency in LLM configuration and validation methodology
- Scalability challenges with offline KG construction requiring significant compute resources
- Heavy dependency on LLM availability and performance, creating potential bottlenecks

## Confidence

- High confidence in reported A/B test metrics as concrete business outcomes from real production deployment
- Medium confidence in proposed mechanisms due to limited transparency in LLM configuration and validation methodology
- Key limitations include lack of details about specific LLM model, prompt templates, and scoring thresholds for pruning

## Next Checks

1. Compare LLM self-evaluation scores with human-labeled ground truth to assess hallucination detection reliability
2. Test KG construction with different seed products to measure format correctness rate consistency
3. Measure mapping accuracy by checking if KNN search returns semantically similar products across diverse product categories