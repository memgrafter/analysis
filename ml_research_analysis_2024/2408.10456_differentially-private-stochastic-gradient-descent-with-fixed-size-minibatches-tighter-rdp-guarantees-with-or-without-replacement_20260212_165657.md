---
ver: rpa2
title: 'Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches:
  Tighter RDP Guarantees with or without Replacement'
arxiv_id: '2408.10456'
source_url: https://arxiv.org/abs/2408.10456
tags:
- bound
- subsampling
- bounds
- adjacency
- fixed-size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of tracking privacy loss in differentially
  private stochastic gradient descent (DP-SGD) when using fixed-size minibatches,
  a setting not well covered by existing RDP accountants. The authors present a new
  holistic RDP accountant for DP-SGD with fixed-size subsampling both without and
  with replacement, considering both add/remove and replace-one adjacency relationships.
---

# Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement

## Quick Facts
- **arXiv ID**: 2408.10456
- **Source URL**: https://arxiv.org/abs/2408.10456
- **Reference count**: 40
- **Primary result**: New holistic RDP accountant for DP-SGD with fixed-size subsampling, showing tighter privacy guarantees and lower memory usage than existing methods

## Executive Summary
This paper addresses the problem of tracking privacy loss in differentially private stochastic gradient descent (DP-SGD) when using fixed-size minibatches, a setting not well covered by existing RDP accountants. The authors present a new holistic RDP accountant for DP-SGD with fixed-size subsampling both without and with replacement, considering both add/remove and replace-one adjacency relationships. Their key method uses Taylor expansion with integral remainder bounds to derive tight non-asymptotic RDP guarantees. For fixed-size subsampling without replacement under replace-one adjacency, their bounds improve on the best existing computable bound by a factor of 4. They show that fixed-size subsampling without replacement under replace-one adjacency has the same privacy guarantees as widely-used Poisson subsampling to leading order in the sampling probability, while offering constant memory usage and lower gradient variance. They also provide the first non-asymptotic upper and lower bounds for fixed-size subsampling with replacement. Experimental results on CIFAR10 confirm their theoretical findings, showing tighter privacy guarantees and better accuracy than existing methods, with substantially lower memory usage compared to Poisson subsampling implementations.

## Method Summary
The paper develops a new holistic RDP accountant for DP-SGD with fixed-size subsampling. The core method uses Taylor expansion with integral remainder bounds to derive tight non-asymptotic RDP guarantees for both fixed-size subsampling without replacement (FSwoR) and with replacement (FSwR). For FSwoR under replace-one adjacency, they show the privacy guarantees match Poisson subsampling to leading order in the sampling probability. They provide explicit bounds for all combinations of subsampling method (with/without replacement) and adjacency relation (add/remove, replace-one). The approach extends to any quasiconvex divergence, though the paper focuses on Gaussian noise. Experiments on CIFAR10 with a simple CNN architecture validate the theoretical results, comparing against Opacus's Poisson subsampling implementation.

## Key Results
- Fixed-size subsampling without replacement under replace-one adjacency has identical leading-order privacy guarantees to Poisson subsampling
- Fixed-size subsampling (with or without replacement) provides lower gradient variance compared to Poisson subsampling
- Fixed-size subsampling with replacement exhibits nontrivial |B| dependence with a "phase transition" behavior in privacy loss
- Experimental results on CIFAR10 show tighter privacy guarantees and better accuracy than existing methods, with substantially lower memory usage compared to Poisson subsampling implementations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fixed-size subsampling without replacement (FSwoR) under replace-one adjacency has the same leading-order privacy guarantees as Poisson subsampling.
- Mechanism: The variance of the gradient difference between adjacent datasets scales with the clipping threshold C in both cases, leading to identical Rényi divergence behavior to leading order in q.
- Core assumption: The difference between the gradient sums of adjacent datasets under replace-one adjacency is proportional to the difference between two clipped gradients.
- Evidence anchors:
  - [abstract]: "We also show for the first time that the widely-used Poisson subsampling and FSwoR with replace-one adjacency have the same privacy to leading order in the sampling probability."
  - [section 4.2]: "when using replace-one adjacency we find that DP-SGD with fixed-size subsampling yields the same privacy guarantees as Poisson subsampling to leading order"
  - [corpus]: Found 25 related papers; some discuss privacy amplification under subsampling but none provide the specific equivalence claim between FSwoR and Poisson subsampling under replace-one adjacency.
- Break condition: If the gradient difference scaling deviates significantly from the assumed behavior, or if higher-order terms become dominant.

### Mechanism 2
- Claim: Fixed-size subsampling (with or without replacement) reduces gradient estimator variance compared to Poisson subsampling.
- Mechanism: The variance of the subsampled gradient estimator is lower for fixed-size methods due to reduced randomness in minibatch composition.
- Core assumption: The variance reduction holds away from local minima and is significant when the dataset size is large.
- Evidence anchors:
  - [section 4.1]: "Therefore, from the perspective of the variance, we conclude that fixed-size subsampling (with or without replacement) is generally preferable over Poisson subsampling."
  - [section 4.1]: "This calculation suggests that fixed-sized minibatches are better to use when one is away from the optimizer, as they lead to a (potentially substantial) reduction in variance"
  - [corpus]: Found 25 related papers; some discuss gradient variance in DP-SGD but none provide the specific comparison between fixed-size and Poisson subsampling variance.
- Break condition: If the dataset size is small, or if the model is very close to a local minimum where the gradient variance advantage diminishes.

### Mechanism 3
- Claim: Fixed-size subsampling with replacement (FSwR) has nontrivial |B| dependence even for fixed q, unlike FSwoR.
- Mechanism: The probability of selecting the same element multiple times in FSwR increases with |B|, leading to a "phase transition" in privacy loss.
- Core assumption: The element distinguishing adjacent datasets can be selected multiple times in a single minibatch, overwhelming the noise.
- Evidence anchors:
  - [section 3.3]: "This behavior is also illustrated numerically in Figure 8, where we show the exact value of the lower bound (116) as a function of |B| for α = 2... there is a threshold value of |B| as which there is a 'phase transition'"
  - [section 3.3]: "In contrast, the FSwoR-RDP lower bound in Appendix E.2 depends on |B| and |D| only through q"
  - [corpus]: Found 25 related papers; some discuss subsampling with replacement but none provide the specific analysis of |B| dependence for FSwR-RDP.
- Break condition: If the noise level is sufficiently high to counteract the effect of multiple selections, or if the dataset size is extremely large.

## Foundational Learning

- Concept: Rényi Differential Privacy (RDP)
  - Why needed here: The paper uses RDP to track privacy loss in DP-SGD, requiring understanding of RDP definitions and properties.
  - Quick check question: What is the relationship between RDP and standard differential privacy (DP)?

- Concept: Subsampling and Privacy Amplification
  - Why needed here: The paper analyzes different subsampling methods (fixed-size vs. Poisson, with/without replacement) and their impact on privacy amplification.
  - Quick check question: How does subsampling amplify privacy in DP-SGD?

- Concept: Adjacency Relations in Differential Privacy
  - Why needed here: The paper considers both add/remove and replace-one adjacency relations, requiring understanding of their implications for privacy analysis.
  - Quick check question: What is the difference between add/remove and replace-one adjacency relations?

## Architecture Onboarding

- Component map:
  - RDP Accountant -> Gradient Variance Analysis -> Privacy Comparison -> Memory Usage Analysis

- Critical path:
  1. Implement the new FS-RDP bounds for FSwoR and FSwR with different adjacency relations.
  2. Integrate the bounds into the RDP accountant used in DP-SGD implementations.
  3. Conduct experiments comparing the privacy guarantees and gradient variance of fixed-size and Poisson subsampling methods.
  4. Analyze the memory usage of different subsampling implementations.

- Design tradeoffs:
  - Tightness vs. Computability: The new bounds aim for tighter privacy guarantees while remaining computationally tractable.
  - Add/Remove vs. Replace-One Adjacency: The paper provides bounds for both adjacency relations, requiring different analysis techniques.
  - Fixed-Size vs. Poisson Subsampling: The paper compares the privacy and variance properties of both methods, highlighting the advantages of fixed-size subsampling.

- Failure signatures:
  - Inaccurate Privacy Bounds: If the new bounds do not accurately capture the privacy loss, the DP-SGD implementation may provide weaker privacy guarantees than expected.
  - Excessive Gradient Variance: If the variance reduction of fixed-size subsampling is not significant, the learning performance may suffer.
  - High Memory Usage: If the fixed-size subsampling implementation does not provide memory usage benefits, it may not be practical for resource-constrained settings.

- First 3 experiments:
  1. Implement the new FS-RDP bounds for FSwoR under replace-one adjacency and compare the privacy guarantees with Poisson subsampling on a small dataset.
  2. Analyze the gradient variance of fixed-size and Poisson subsampling methods on a synthetic dataset with known gradient properties.
  3. Compare the memory usage of fixed-size and Poisson subsampling implementations on a deep learning model trained on a standard benchmark dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the privacy guarantees of fixed-size subsampling without replacement compare to Poisson subsampling under the replace-one adjacency definition for different batch sizes and noise levels?
- Basis in paper: [explicit] The authors compare the privacy guarantees of fixed-size and Poisson subsampling under replace-one adjacency and show they are equivalent to leading order in the sampling probability.
- Why unresolved: The paper provides a theoretical comparison but does not provide a comprehensive empirical study across a wide range of batch sizes and noise levels to determine if there are any practical differences.
- What evidence would resolve it: A large-scale empirical study comparing the privacy guarantees of fixed-size and Poisson subsampling under replace-one adjacency across a wide range of batch sizes and noise levels would provide concrete evidence of any practical differences.

### Open Question 2
- Question: Can the Taylor expansion approach used in this paper be extended to other types of noise distributions beyond Gaussian noise?
- Basis in paper: [explicit] The authors develop a Taylor expansion approach to derive tight RDP bounds for fixed-size subsampling with Gaussian noise. They note that their method can be applied to other divergences that are quasiconvex in their arguments.
- Why unresolved: The paper focuses on Gaussian noise and does not explore the applicability of their Taylor expansion approach to other noise distributions.
- What evidence would resolve it: Applying the Taylor expansion approach to derive RDP bounds for fixed-size subsampling with other noise distributions, such as Laplacian or uniform noise, and comparing the results to existing methods would provide evidence of its broader applicability.

### Open Question 3
- Question: What is the impact of using fixed-size subsampling with replacement on the convergence and generalization performance of DP-SGD compared to Poisson subsampling and fixed-size subsampling without replacement?
- Basis in paper: [inferred] The paper introduces RDP bounds for fixed-size subsampling with replacement but does not explore its practical implications on convergence and generalization performance.
- Why unresolved: The paper focuses on theoretical privacy guarantees and does not investigate the practical impact of fixed-size subsampling with replacement on training dynamics.
- What evidence would resolve it: Conducting experiments comparing the convergence and generalization performance of DP-SGD with fixed-size subsampling with replacement, Poisson subsampling, and fixed-size subsampling without replacement on various datasets and models would provide insights into its practical implications.

## Limitations

- The analytical bounds may become less tight for extreme parameter values (very large or very small sampling probabilities)
- The variance analysis assumes certain properties of gradient differences that may not hold uniformly across all model architectures
- Experimental validation is limited to a single CNN architecture on CIFAR10, which may not generalize to other domains

## Confidence

**High Confidence**: The analytical bounds for FSwoR under replace-one adjacency matching Poisson subsampling to leading order, the variance reduction advantage of fixed-size subsampling, and the memory usage benefits.

**Medium Confidence**: The phase transition behavior in FSwR-RDP bounds, the non-asymptotic bounds for FSwR, and the experimental results showing the privacy-accuracy tradeoff.

**Low Confidence**: Generalization of the variance analysis to all model architectures and datasets, and the robustness of the bounds for extreme parameter regimes.

## Next Checks

1. **Bound Tightness Validation**: Systematically compare the new FS-RDP bounds against Monte Carlo simulations for a range of parameters (|B|, |D|, q, σ) to quantify the tightness gap and identify regimes where the bounds may be loose.

2. **Gradient Variance Analysis Extension**: Conduct a comprehensive analysis of gradient variance for fixed-size vs. Poisson subsampling across multiple architectures (CNN, Transformer, MLP) and datasets (CIFAR10, ImageNet, IMDB) to verify the generality of the variance reduction claim.

3. **Memory Usage Benchmarking**: Implement a controlled benchmark comparing memory usage of fixed-size and Poisson subsampling implementations across different DP-SGD libraries (Opacus, TensorFlow Privacy, PyTorch Opacus) under identical conditions to validate the claimed memory advantages.