---
ver: rpa2
title: A Practical Theory of Generalization in Selectivity Learning
arxiv_id: '2409.07014'
source_url: https://arxiv.org/abs/2409.07014
tags:
- selectivity
- generalization
- query
- queries
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a new generalization theory for query-driven
  selectivity learning. The theory establishes that selectivity predictors induced
  by signed measures are learnable and exhibits bounded out-of-distribution (OOD)
  generalization error under mild assumptions.
---

# A Practical Theory of Generalization in Selectivity Learning

## Quick Facts
- **arXiv ID**: 2409.07014
- **Source URL**: https://arxiv.org/abs/2409.07014
- **Reference count**: 40
- **Primary result**: NeuroCDF and SeConCDF significantly improve out-of-distribution generalization for selectivity learning models while maintaining strong in-distribution performance

## Executive Summary
This paper presents a new generalization theory for query-driven selectivity learning that extends beyond probability measures to signed measures. The authors establish that selectivity predictors induced by signed measures are learnable and exhibit bounded out-of-distribution (OOD) generalization error under mild assumptions. They design two practical strategies—NeuroCDF (which models cumulative distribution functions using neural networks) and SeConCDF (which incorporates CDF self-consistency regularization)—to improve OOD generalization for existing query-driven models. Experiments on benchmark datasets demonstrate significant improvements in OOD generalization performance in terms of prediction accuracy and query latency while maintaining strong in-distribution performance.

## Method Summary
The paper introduces two practical strategies to improve OOD generalization in query-driven selectivity learning. NeuroCDF models cumulative distribution functions (CDFs) using neural networks, leveraging the fact that selectivity can be expressed as a linear combination of CDFs at hyper-rectangle vertices. SeConCDF incorporates CDF self-consistency regularization into training existing query-driven models by enforcing that model predictions align with CDFs extracted from the model itself across sampled queries. Both approaches ensure predictions are induced by signed measures, which have bounded generalization error under mild assumptions. The training methodology involves integrating these approaches into existing selectivity models like LW-NN and MSCN, with evaluation on both in-distribution and OOD test queries using metrics like RMSE and Qerror.

## Key Results
- NeuroCDF and SeConCDF significantly improve OOD generalization performance compared to existing query-driven models
- Both approaches maintain strong in-distribution performance while improving out-of-distribution accuracy
- The theoretical framework establishes that selectivity predictors induced by signed measures have bounded generalization error under mild assumptions

## Why This Works (Mechanism)

### Mechanism 1: Signed Measure Generalization
NeuroCDF achieves OOD generalization because its CDF modeling ensures predictions are induced by signed measures, which have bounded generalization error under mild assumptions. Since selectivity can be expressed as a linear combination of CDFs at hyper-rectangle vertices, NeuroCDF's predictions inherit the signed measure property.

### Mechanism 2: CDF Self-Consistency Regularization
SeConCDF improves OOD generalization by enforcing CDF self-consistency regularization during training. It adds losses for CDF prediction and consistency checking, ensuring model predictions align with CDFs extracted from the model across sampled queries. This soft constraint mimics the signed measure property without requiring direct CDF modeling.

### Mechanism 3: Broader Function Class
Signed measures generalize better than probability measures because they relax positivity and sum-to-unity constraints. By allowing negative values while maintaining countable additivity, signed measures can represent a broader class of selectivity functions that still exhibit bounded generalization error.

## Foundational Learning

- **Concept**: Measure theory and signed measures
  - Why needed here: The entire theoretical framework relies on understanding how selectivity functions can be induced by measures, and signed measures relax constraints of probability measures
  - Quick check question: Can you explain the difference between a probability measure, a measure, and a signed measure in terms of their defining properties?

- **Concept**: PAC learning framework and fat-shattering dimension
  - Why needed here: The paper uses fat-shattering dimension to prove learnability of signed measure-induced functions, extending PAC learning beyond probability measures
  - Quick check question: How does fat-shattering dimension differ from VC dimension, and why is it needed for real-valued (not binary) functions?

- **Concept**: Out-of-distribution (OOD) generalization
  - Why needed here: The paper's main contribution is characterizing OOD generalization error bounds, which requires understanding how training and testing distributions can differ
  - Quick check question: What are the key assumptions (Assumptions 4.1-4.3) that enable the OOD generalization error bound, and why are they necessary?

## Architecture Onboarding

- **Component map**: Query batch → Selectivity predictions → CDF conversion → CDF predictions → Consistency checking → Backpropagation
- **Critical path**: 
  1. For NeuroCDF: Query → CDF vertices → Multiple CDF predictions → Linear combination → Selectivity estimate
  2. For SeConCDF: Query batch → Selectivity predictions → CDF conversion → CDF predictions → Consistency checking → Backpropagation
- **Design tradeoffs**: 
  - NeuroCDF vs direct selectivity modeling: Better OOD generalization but cannot use Qerror loss and requires 2^n_c CDF predictions per query
  - SeConCDF hyperparameters: Balancing ω1 and ω2 affects regularization strength vs original task performance
  - Query sampling for consistency loss: More diverse sampling improves regularization but increases computational cost
- **Failure signatures**: 
  - NeuroCDF: Negative selectivity estimates, poor performance on selective queries (due to Qerror incompatibility)
  - SeConCDF: Inconsistent CDFs extracted from model, training instability from poorly tuned regularization weights
  - Both: OOD generalization fails if training/test distributions have disjoint support or CDFs cannot be meaningfully learned
- **First 3 experiments**: 
  1. Verify NeuroCDF predictions satisfy signed measure property on synthetic data with known ground truth CDFs
  2. Test SeConCDF with varying ω1, ω2 values on a small dataset to find optimal regularization balance
  3. Compare NeuroCDF vs SeConCDF OOD generalization on datasets with known distribution shifts (center move and granularity shift scenarios)

## Open Questions the Paper Calls Out

1. **Can the OOD generalization theory be extended beyond signed measures to more general function classes?**
   - Basis in paper: The authors explicitly state exploring generalization bounds beyond signed measures could yield interesting insights and inspire new model designs
   - Why unresolved: The current framework specifically relies on signed measure properties; extending to broader classes requires new mathematical tools
   - What evidence would resolve it: A formal extension proving generalization bounds for broader selectivity predictors with empirical validation

2. **How can NeuroCDF be modified to work with Qerror and other relative error metrics while maintaining theoretical guarantees?**
   - Basis in paper: The authors note NeuroCDF is not compatible with Qerror and attempted solutions showed significant performance degradation
   - Why unresolved: The framework relies on absolute error metrics due to potential negative selectivity estimates; enforcing valid CDFs while supporting relative error metrics requires addressing non-differentiability and capacity constraints
   - What evidence would resolve it: A modified NeuroCDF architecture successfully training with Qerror while maintaining both theoretical guarantees and competitive empirical performance

3. **How can the SeConCDF framework be adapted to guide query generation for more efficient and effective training?**
   - Basis in paper: The authors mention applying their theory to guide query generation poses an interesting opportunity
   - Why unresolved: Current query generation uses simple random sampling; leveraging theoretical insights could lead to more sophisticated strategies that maximize generalization while minimizing training time
   - What evidence would resolve it: An adaptive query generation algorithm using the theoretical framework to optimize the trade-off between in-distribution accuracy and OOD robustness

## Limitations

- NeuroCDF's incompatibility with Qerror and other relative error metrics limits its applicability in scenarios where relative error is critical
- The theoretical framework assumes testing distributions are contained within training distribution support, which may not hold in real-world scenarios
- NeuroCDF's scalability with high-dimensional queries (requiring 2^n_c CDF predictions) may become prohibitive for large numbers of columns

## Confidence

- **Theoretical claims**: Medium confidence - relies on strong assumptions about bounded VC dimensions
- **NeuroCDF effectiveness**: High confidence - well-supported by empirical results across multiple datasets
- **SeConCDF effectiveness**: High confidence - demonstrated improvements in OOD generalization
- **Scalability**: Low confidence - computational feasibility for high-dimensional queries not fully validated

## Next Checks

1. **Scalability validation**: Test NeuroCDF on high-dimensional datasets (n_c > 10) to empirically verify computational feasibility and assess whether 2^n_c CDF predictions become prohibitive

2. **Assumption relaxation study**: Systematically relax Assumptions 4.1-4.3 (bounded VC dimensions) on synthetic datasets to understand theoretical bounds' sensitivity to these constraints

3. **Cross-model consistency**: Apply SeConCDF regularization to diverse query-driven model architectures beyond LW-NN and MSCN to verify the approach's generality across different model families