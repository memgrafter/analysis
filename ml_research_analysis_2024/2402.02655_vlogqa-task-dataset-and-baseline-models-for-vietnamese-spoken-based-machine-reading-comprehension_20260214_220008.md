---
ver: rpa2
title: 'VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based Machine
  Reading Comprehension'
arxiv_id: '2402.02655'
source_url: https://arxiv.org/abs/2402.02655
tags:
- language
- vietnamese
- dataset
- question
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VlogQA, a Vietnamese spoken language corpus
  for machine reading comprehension (MRC) tasks. The corpus contains 10,076 question-answer
  pairs based on 1,230 transcripts sourced from YouTube, covering food and travel
  topics.
---

# VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based Machine Reading Comprehension

## Quick Facts
- arXiv ID: 2402.02655
- Source URL: https://arxiv.org/abs/2402.02655
- Reference count: 15
- Primary result: Introduces VlogQA dataset with 10,076 QA pairs from 1,230 Vietnamese YouTube transcripts for machine reading comprehension

## Executive Summary
This paper introduces VlogQA, a Vietnamese spoken language corpus for machine reading comprehension (MRC) tasks. The corpus contains 10,076 question-answer pairs based on 1,230 transcripts sourced from YouTube, covering food and travel topics. The development process includes data collection, QA pair creation, corpus modification, and quality assurance. Baseline transformer-based models are evaluated, with XLM-R achieving the highest F1 score of 75.34% and exact match score of 53.97%. The dataset provides a valuable resource for future research in Vietnamese spoken language understanding and has potential applications in developing QA systems for spoken content like meeting recordings.

## Method Summary
The VlogQA dataset was constructed through a multi-stage process involving YouTube transcript collection, manual QA pair creation, and corpus refinement. The authors collected 1,230 transcripts from Vietnamese food and travel vlogs, then generated 10,076 question-answer pairs through human annotation. The dataset was cleaned and standardized to ensure consistency. Several transformer-based baseline models were evaluated on the dataset, including multilingual models fine-tuned for Vietnamese. The evaluation focused on standard MRC metrics: F1 score and exact match accuracy. The XLM-R model demonstrated superior performance compared to other baselines, establishing a reference point for future research on Vietnamese spoken language understanding.

## Key Results
- VlogQA contains 10,076 question-answer pairs derived from 1,230 YouTube transcripts
- XLM-R achieved the highest performance with F1 score of 75.34% and exact match of 53.97%
- Dataset focuses specifically on Vietnamese food and travel domain content
- Baseline models show significant room for improvement, particularly on exact match metric

## Why This Works (Mechanism)
The VlogQA approach leverages the rich, contextual nature of spoken language transcripts to create authentic question-answer pairs that reflect real-world language use. By using YouTube vlog content from specific domains (food and travel), the dataset captures domain-specific vocabulary and conversational patterns typical of Vietnamese spoken discourse. The transformer-based models, particularly XLM-R, can effectively leverage multilingual pretraining to handle Vietnamese linguistic features while benefiting from cross-lingual transfer. The combination of authentic spoken content with structured QA pairs creates a challenging yet practical benchmark for evaluating Vietnamese MRC systems.

## Foundational Learning

**Vietnamese language processing**: Why needed - Vietnamese is an isolating language with tonal features requiring specialized handling; Quick check - Verify model tokenization properly handles Vietnamese diacritical marks and compound words.

**Spoken language understanding**: Why needed - Transcripts contain disfluencies, repetitions, and informal expressions not found in written text; Quick check - Evaluate model robustness to transcript-specific noise patterns.

**Machine reading comprehension**: Why needed - Requires both language understanding and reasoning capabilities to answer questions based on context; Quick check - Test model performance across different question types (factual, inferential, etc.).

**Transformer architectures**: Why needed - Foundation for modern NLP with attention mechanisms that capture long-range dependencies; Quick check - Verify attention patterns focus on relevant context for QA tasks.

**Multilingual pretraining**: Why needed - Enables knowledge transfer across languages, particularly useful for low-resource languages like Vietnamese; Quick check - Compare monolingual vs multilingual model performance.

## Architecture Onboarding

**Component map**: Transcript preprocessing -> Question-Answer pair creation -> Dataset cleaning -> Model fine-tuning -> Evaluation

**Critical path**: YouTube transcript collection → Manual QA pair annotation → Quality assurance → Model training → Performance evaluation

**Design tradeoffs**: The dataset focuses on two specific domains (food/travel) to ensure quality and consistency, but this limits generalizability to other domains. The choice of transformer models balances computational efficiency with performance, though larger models might achieve better results at higher computational cost.

**Failure signatures**: Models may struggle with domain-specific terminology, cultural references, or questions requiring reasoning beyond surface-level text matching. Performance degradation is likely when questions require combining information from multiple transcript segments.

**First experiments**: 
1. Evaluate model performance on questions requiring single vs multiple evidence spans
2. Test zero-shot transfer to out-of-domain Vietnamese spoken content
3. Analyze attention visualization to understand which transcript segments models focus on for different question types

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation methodology lacks transparency regarding inter-annotator agreement scores
- Dataset size (10,076 QA pairs) may be insufficient for training complex deep learning models
- Narrow domain focus (food and travel only) limits applicability to broader spoken language tasks
- Missing details about speaker demographics and transcript quality metrics

## Confidence
**High confidence**: Dataset construction methodology and basic corpus statistics (10,076 QA pairs, 1,230 transcripts)

**Medium confidence**: Reported baseline model performance metrics and their comparison across different transformer architectures

**Low confidence**: Generalizability of results to other Vietnamese spoken language domains and robustness of evaluation methodology

## Next Checks
1. Conduct inter-annotator agreement analysis to establish reliability scores for the QA pair creation process and validate annotation quality
2. Expand evaluation to include additional Vietnamese-specific transformer models and conduct cross-domain testing to assess generalization beyond food and travel topics
3. Perform speaker and demographic analysis of the YouTube sources to evaluate the representativeness of the spoken language corpus across different Vietnamese dialects and speaker profiles