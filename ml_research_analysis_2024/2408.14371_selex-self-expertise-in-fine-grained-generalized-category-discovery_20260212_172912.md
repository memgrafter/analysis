---
ver: rpa2
title: 'SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery'
arxiv_id: '2408.14371'
source_url: https://arxiv.org/abs/2408.14371
tags:
- categories
- category
- learning
- novel
- known
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SelEx introduces self-expertise for fine-grained generalized category
  discovery by combining hierarchical pseudo-labeling with unsupervised and supervised
  contrastive learning. The method refines category distinctions using hard negatives
  from the same cluster and abstract positive/negative samples, enabling better generalization
  to novel categories.
---

# SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery

## Quick Facts
- arXiv ID: 2408.14371
- Source URL: https://arxiv.org/abs/2408.14371
- Reference count: 40
- Primary result: Achieves up to 73.6% overall accuracy on fine-grained datasets, outperforming state-of-the-art methods

## Executive Summary
SelEx introduces self-expertise for fine-grained generalized category discovery by combining hierarchical pseudo-labeling with unsupervised and supervised contrastive learning. The method refines category distinctions using hard negatives from the same cluster and abstract positive/negative samples, enabling better generalization to novel categories. It employs a balanced semi-supervised k-means approach to generate hierarchical pseudo-labels and uses label smoothing to modulate uncertainty in negatives. Evaluated on fine-grained datasets like CUB-200, FGVC-Aircraft, Stanford-Cars, and Oxford-IIIT Pet, SelEx achieves up to 73.6% overall accuracy, outperforming state-of-the-art methods. It also demonstrates strong performance on coarse-grained datasets, showcasing adaptability beyond fine-grained tasks.

## Method Summary
SelEx combines hierarchical pseudo-label extraction with two self-expertise strategies: unsupervised and supervised contrastive learning. The method first generates hierarchical pseudo-labels using Balanced Semi-Supervised K-means (BSSK) and Hierarchical Semi-Supervised K-means (HSSK), which initialize cluster centers using known categories and balance cluster sizes. Unsupervised self-expertise treats within-cluster samples as hard negatives, forcing finer distinctions, while supervised self-expertise uses abstract pseudo-labels to create weaker positives and stronger negatives at different hierarchical levels. The combined loss function balances these approaches with a weighting parameter λ, and the model uses a pre-trained ViT-B/16 backbone with frozen early blocks and fine-tuned later blocks.

## Key Results
- Achieves up to 73.6% overall accuracy on fine-grained datasets (CUB-200, FGVC-Aircraft, Stanford-Cars, Oxford-IIIT Pet)
- Outperforms state-of-the-art methods including GCD, SimGCD, and InfoSieve
- Demonstrates strong performance on coarse-grained datasets (CIFAR10, CIFAR100, ImageNet-100)
- Shows particular strength in novel category discovery while maintaining known category performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hierarchical semi-supervised k-means initialization improves cluster purity for both known and novel categories.
- **Mechanism:** Uses known category data to initialize cluster centers, then selects novel category centers from remaining data while balancing cluster sizes. This avoids contaminating known category clusters and provides a cleaner starting point for subsequent contrastive learning.
- **Core assumption:** Known category clusters are already well-formed and can be reliably initialized from labeled data; novel categories can be reasonably initialized by sampling from the unlabeled set.
- **Evidence anchors:**
  - [abstract] "Initially, hierarchical pseudo-labeling is used to provide 'soft supervision', improving the effectiveness of self-expertise."
  - [section 4] "We propose the Balanced Semi-Supervised K-means (BSSK) algorithm. This algorithm generates pseudo-labels for the initial level of the subsequently established pseudo-label hierarchy."
- **Break condition:** If labeled data is insufficient to form reliable known category centers, or if the unlabeled data distribution is too sparse to select meaningful novel category centers.

### Mechanism 2
- **Claim:** Unsupervised self-expertise improves fine-grained discrimination by treating samples from the same cluster as hard negatives.
- **Mechanism:** Instead of standard contrastive learning where positives are augmentations and negatives are all other samples, this method treats within-cluster samples as hard negatives at each hierarchical level, forcing the model to make finer distinctions.
- **Core assumption:** Samples within the same cluster are visually similar but semantically distinct, making them ideal hard negatives for learning fine-grained differences.
- **Evidence anchors:**
  - [abstract] "Meanwhile, our unsupervised strategy encourages the model to sharpen its category distinctions by considering within-category examples as 'hard' negatives."
  - [section 4] "To address these concerns, we adopt a strategy where the model is instructed to exclusively distance samples within the same clusters (pseudo-labels)."
- **Break condition:** If clusters are too pure (few hard negatives) or too impure (negatives not semantically similar enough to be useful).

### Mechanism 3
- **Claim:** Supervised self-expertise uses abstract pseudo-labels to create weaker positives and stronger negatives, facilitating rapid cluster formation and generalization.
- **Mechanism:** Instead of using only ground truth labels for supervision, the method uses hierarchical pseudo-labels where higher levels provide weaker supervision (treating all samples from the same parent category as partial positives) and lower levels provide stronger supervision.
- **Core assumption:** Hierarchical labels at different abstraction levels provide useful supervisory signals for learning both coarse and fine-grained distinctions simultaneously.
- **Evidence anchors:**
  - [abstract] "Our supervised technique differs from traditional methods by utilizing more abstract positive and negative samples, aiding in the formation of clusters that can generalize to novel categories."
  - [section 4] "Our supervised self-expertise, which utilizes abstract pseudo-labels to generate weaker positive and stronger negative instances, facilitating rapid initial category clustering and enhancing generalization to novel categories."
- **Break condition:** If pseudo-labels at higher abstraction levels are too noisy to provide useful supervision, or if the model cannot effectively learn from weaker supervisory signals.

## Foundational Learning

- **Concept:** Contrastive learning with positive/negative pairs
  - **Why needed here:** The method fundamentally relies on learning representations by pulling similar samples together and pushing dissimilar ones apart, which is the core of both supervised and unsupervised self-expertise.
  - **Quick check question:** What are the typical positive and negative pairs in standard contrastive learning, and how does this method modify them?

- **Concept:** Hierarchical clustering and multi-level abstraction
  - **Why needed here:** The method creates pseudo-labels at multiple levels of abstraction to provide supervisory signals at different granularities, which is essential for both supervised and unsupervised self-expertise.
  - **Quick check question:** How does clustering at different levels of abstraction help the model learn both coarse and fine-grained distinctions?

- **Concept:** Semi-supervised learning with limited labeled data
  - **Why needed here:** The method operates in a setting with few labeled examples for known categories and many unlabeled examples including novel categories, requiring techniques that can leverage both effectively.
  - **Quick check question:** What are the challenges of learning from both labeled and unlabeled data when the unlabeled data contains both known and novel categories?

## Architecture Onboarding

- **Component map:** Images → Backbone (ViT-B/16) → Embedding space → Hierarchical Pseudo-Label Extraction (BSSK + HSSK) → Unsupervised Self-Expertise (LUSE) → Supervised Self-Expertise (LSSE) → Combined Loss → Classification predictions

- **Critical path:**
  1. Generate hierarchical pseudo-labels using BSSK and HSSK
  2. Apply unsupervised self-expertise with hard negatives from same cluster
  3. Apply supervised self-expertise with abstract pseudo-labels
  4. Combine losses with appropriate weighting (λ)
  5. Train backbone with frozen blocks + fine-tuning

- **Design tradeoffs:**
  - Freezing first 10 blocks vs fine-tuning all: More frozen blocks = more stability but less adaptability to novel categories
  - Label smoothing hyperparameter α: Higher α = better novel category performance but worse known category performance
  - Number of hierarchical levels: More levels = finer distinctions but potentially more noise in pseudo-labels

- **Failure signatures:**
  - Known categories performance drops significantly: Likely too much unsupervised learning emphasis (λ too low) or overly aggressive label smoothing
  - Novel categories performance poor: Likely insufficient hierarchical pseudo-labeling or incorrect cluster initialization
  - Overall performance plateau: May need to adjust λ or α hyperparameters, or verify cluster quality

- **First 3 experiments:**
  1. Verify hierarchical pseudo-label generation works correctly by visualizing cluster assignments at different levels
  2. Test unsupervised self-expertise in isolation by comparing standard contrastive vs within-cluster hard negatives
  3. Test supervised self-expertise with different λ values to find optimal balance between known and novel category performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SelEx scale with increasingly large and diverse fine-grained datasets?
- Basis in paper: [inferred] The paper demonstrates strong performance on four fine-grained datasets but does not explore scaling to larger or more diverse datasets.
- Why unresolved: The study focuses on a limited set of fine-grained datasets and does not address the potential challenges or performance changes when applied to significantly larger or more varied datasets.
- What evidence would resolve it: Conducting experiments on larger fine-grained datasets (e.g., iNaturalist, ImageNet subsets with fine-grained categories) and analyzing performance metrics (accuracy, computational efficiency) as dataset size and diversity increase.

### Open Question 2
- Question: Can SelEx's hierarchical pseudo-labeling approach be effectively adapted for non-image data types, such as text or audio?
- Basis in paper: [inferred] The method is specifically designed for image classification tasks and does not explore its applicability to other data modalities.
- Why unresolved: The paper does not investigate whether the hierarchical pseudo-labeling and self-expertise concepts can be translated to different data types that may have different characteristics and challenges.
- What evidence would resolve it: Applying SelEx to text classification (e.g., document categorization) or audio classification (e.g., environmental sound classification) tasks and comparing its performance against baseline methods for those modalities.

### Open Question 3
- Question: What is the impact of varying the number of hierarchy levels on SelEx's performance for datasets with different levels of category granularity?
- Basis in paper: [explicit] The paper discusses the effect of hierarchy levels on performance but does not systematically explore the optimal number of levels for datasets with varying granularity.
- Why unresolved: While the paper shows that hierarchy levels improve performance, it does not investigate how the optimal number of levels changes based on the inherent granularity of the dataset's categories.
- What evidence would resolve it: Conducting experiments on datasets with different levels of category granularity (e.g., coarse-grained vs. fine-grained) and analyzing SelEx's performance as the number of hierarchy levels is varied, identifying patterns or optimal configurations for different granularity levels.

## Limitations

- **Hierarchical Pseudo-Label Quality**: The method's performance critically depends on the quality of hierarchical pseudo-labels generated by the BSSK and HSSK algorithms, with limited validation of pseudo-label accuracy across different dataset characteristics.
- **Hyperparameter Sensitivity**: The method relies on several hyperparameters (λ=0.35, α=0.5/0.1, number of hierarchical levels) that significantly impact performance, lacking comprehensive sensitivity analysis to demonstrate robustness.
- **Computational Complexity**: The paper does not provide detailed analysis of computational overhead, particularly for the hierarchical clustering and stable matching components, which is important for practical deployment considerations.

## Confidence

**High Confidence**: The core architectural components (ViT backbone, contrastive learning framework) are well-established and the paper provides clear implementation details for these elements.

**Medium Confidence**: The hierarchical pseudo-labeling approach and self-expertise mechanisms are novel but their effectiveness depends heavily on implementation details that are not fully specified.

**Low Confidence**: Claims about superior performance on coarse-grained datasets appear less substantiated, with limited experimental validation compared to the extensive fine-grained dataset analysis.

## Next Checks

1. **Pseudo-Label Quality Analysis**: Conduct detailed analysis of pseudo-label accuracy at different hierarchical levels across multiple datasets, including correlation between pseudo-label quality and final performance metrics.

2. **Computational Overhead Benchmarking**: Measure and report computational requirements (training time, memory usage) for each component, particularly focusing on the hierarchical clustering and stable matching operations.

3. **Hyperparameter Sensitivity Study**: Perform comprehensive grid search or random search across key hyperparameters (λ, α, number of hierarchical levels) to establish performance robustness and identify optimal configurations for different dataset characteristics.