---
ver: rpa2
title: Improving Steering Vectors by Targeting Sparse Autoencoder Features
arxiv_id: '2411.02193'
source_url: https://arxiv.org/abs/2411.02193
tags:
- steering
- feature
- effects
- features
- vectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to quantify and improve steering
  vector effectiveness in language models using sparse autoencoders (SAEs). The authors
  develop SAE-Targeted Steering (SAE-TS), which constructs steering vectors to target
  specific SAE features while minimizing side effects.
---

# Improving Steering Vectors by Targeting Sparse Autoencoder Features

## Quick Facts
- arXiv ID: 2411.02193
- Source URL: https://arxiv.org/abs/2411.02193
- Authors: Sviatoslav Chalnev; Matthew Siu; Arthur Conmy
- Reference count: 40
- Primary result: SAE-Targeted Steering (SAE-TS) outperforms existing methods on 7 of 9 steering tasks when evaluated on Gemma-2-2B

## Executive Summary
This paper introduces SAE-Targeted Steering (SAE-TS), a method that uses sparse autoencoders (SAEs) to construct steering vectors for language models. The key innovation is using SAEs to measure causal effects of steering interventions, enabling precise control over model behavior while maintaining text quality. The method outperforms existing approaches like Contrastive Activation Addition (CAA) and direct SAE feature steering on most tested steering tasks.

## Method Summary
The method trains a linear effect approximator to predict how steering vectors change SAE feature activations. For each target feature, it constructs a steering vector that maximizes activation of that feature while minimizing unintended side effects. The approach involves: 1) measuring feature effects of diverse steering vectors, 2) training a linear mapping from steering vectors to their effects, and 3) using this mapping to find optimal steering vectors for specific behavioral targets.

## Key Results
- SAE-TS achieves higher Behavioral*Coherence scores than CAA and direct SAE steering on 7 of 9 tested steering tasks
- The method maintains better text coherence compared to existing steering approaches
- SAE-TS outperforms baseline methods even when using fewer SAE features (1,024 vs 16,384)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAEs can measure the causal effects of steering interventions on model behavior
- Mechanism: By comparing SAE feature activations between steered and unsteered model outputs, we can quantify how steering vectors change the model's internal representations and predict the resulting behavioral changes
- Core assumption: The difference in SAE feature activations between steered and unsteered outputs accurately reflects the causal impact of the steering intervention on model behavior
- Evidence anchors: [abstract] "we address this issue by using SAEs to measure the effects of steering vectors", [section 3] "We use Sparse Autoencoders (SAEs) to measure the change in feature activations caused by steering interventions"

### Mechanism 2
- Claim: A linear relationship exists between steering vectors and their effects on SAE features
- Mechanism: The effect approximator learns a mapping from steering vectors to their measured effects, allowing prediction of feature changes for new steering vectors
- Core assumption: The relationship between steering vectors and their effects on SAE features is approximately linear within the range of steering vectors tested
- Evidence anchors: [section 4.1] "we construct the effect approximator function as a linear function", [section 4] "By learning the mapping from steering vectors to their effects on SAE features"

### Mechanism 3
- Claim: SAE-targeted steering vectors can achieve specific behavioral goals while maintaining coherence better than existing methods
- Mechanism: By using the linear effect approximator to find steering vectors that maximize target feature activation while minimizing other changes, we can achieve precise control over model behavior
- Core assumption: The linear effect approximator accurately captures the relationship between steering vectors and their behavioral effects, enabling effective optimization
- Evidence anchors: [abstract] "SAE-Targeted Steering (SAE-TS), which finds steering vectors to target specific SAE features while minimizing unintended side effects", [section 5] "Our evaluations demonstrate that SAE-TS outperforms existing methods"

## Foundational Learning

- Concept: Sparse Autoencoders (SAEs)
  - Why needed here: SAEs are the core tool for decomposing model activations into interpretable features and measuring steering effects
  - Quick check question: How do SAEs differ from traditional autoencoders, and why are they particularly useful for interpretability in LLMs?

- Concept: Steering vectors in transformer models
  - Why needed here: Understanding how steering vectors modify model behavior is essential for developing and evaluating SAE-TS
  - Quick check question: What is the mathematical operation for adding a steering vector to a transformer's hidden state, and at what point in the forward pass does this typically occur?

- Concept: Causal inference in neural networks
  - Why needed here: The method relies on measuring causal effects of interventions, which requires understanding the difference between correlation and causation in model behavior
  - Quick check question: Why is comparing steered vs. unsteered model outputs a valid approach for measuring causal effects of steering interventions?

## Architecture Onboarding

- Component map: SAE training -> Feature effect measurement -> Linear effect approximator training -> Steering vector generation -> Behavioral evaluation
- Critical path: 1) Train SAE on model activations, 2) Measure effects of diverse steering vectors on SAE features, 3) Train linear effect approximator, 4) Generate targeted steering vectors, 5) Evaluate on behavioral tasks
- Design tradeoffs: Linear vs. non-linear effect approximator (simplicity vs. accuracy), dataset size for training effect approximator (coverage vs. computational cost), choice of SAE architecture (feature quality vs. reconstruction fidelity)
- Failure signatures: Poor generalization of effect approximator to new steering vectors, steering vectors that achieve target behavior but destroy coherence, effect approximator that predicts effects poorly for certain feature directions
- First 3 experiments: 1) Verify that steering with a single SAE feature's decoder vector produces predictable effects on that feature, 2) Test whether the linear effect approximator can accurately predict effects of new steering vectors not in the training set, 3) Compare SAE-TS performance against baseline methods on a simple steering task with clear success criteria

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does SAE-TS sometimes achieve higher coherence scores than the unsteered baseline at optimal steering scales?
- Basis in paper: [explicit] The authors observe this phenomenon in Section 5 and Appendix A.3, noting that steering with the bias term increases proper noun frequency and appears to improve coherence scores
- Why unresolved: The paper provides empirical observations but lacks a mechanistic explanation for why steering would improve coherence rather than degrade it
- What evidence would resolve it: Detailed analysis of the semantic content and syntactic structure of outputs at different steering scales, comparing SAE-TS outputs to baseline outputs

### Open Question 2
- Question: How do feature effects measured at layer 12 SAE relate to downstream model behavior and feature interactions in later layers?
- Basis in paper: [inferred] The paper explicitly states their analysis is not about how early SAEs impact later layer SAEs, but this relationship could be crucial for understanding steering effectiveness
- Why unresolved: The paper focuses on layer 12 SAE effects without examining whether these local measurements predict global model behavior changes
- What evidence would resolve it: Experiments comparing steering effectiveness when measuring feature effects at different layers, or tracking how layer 12 SAE feature activations propagate through subsequent layers

### Open Question 3
- Question: Why does the pseudoinverse approach to targeted steering perform significantly worse than the SAE-TS method that normalizes the target feature column and subtracts normalized bias effects?
- Basis in paper: [explicit] Table 3 shows SAE-TS outperforms pseudoinverse across all tasks, but the paper only provides intuitive explanations about implicit bias handling rather than rigorous justification
- Why unresolved: The authors note the pseudoinverse approach "significantly underperforms" but don't provide thorough theoretical or empirical analysis of why this occurs
- What evidence would resolve it: Systematic ablation studies varying the pseudoinverse approach parameters, or theoretical analysis of the linear approximation properties under different training conditions

## Limitations

- The linear effect approximator assumption may break down for steering vectors that deviate significantly from the training distribution
- The behavioral evaluation methodology using GPT-4o-mini introduces potential subjectivity and variance in reported results
- The paper's claims about SAE-TS being a general framework for "understanding the causal effect of any steering vector intervention" may overstate the method's capabilities given the specific evaluation setup

## Confidence

- **High Confidence:** The core methodology of using SAEs to measure steering effects is technically sound and well-grounded in the literature
- **Medium Confidence:** The comparative performance claims (SAE-TS outperforming CAA and direct SAE steering on 7 of 9 tasks) are based on the presented evaluation but require validation on additional models and tasks
- **Low Confidence:** The claim that SAE-TS maintains semantic coherence better than baselines is based on LLM-as-a-judge evaluation which may not fully capture coherence in all contexts

## Next Checks

1. **Generalization Test:** Evaluate SAE-TS on steering tasks beyond the 9 used in the paper, particularly tasks that may stress the linear effect approximator assumption
2. **Model Transferability:** Test whether SAE-TS trained on Gemma-2-2B can effectively steer other models of similar size or whether the effect approximator requires retraining for each model
3. **Baseline Methodology Replication:** Independently implement and validate the CAA and direct SAE steering baselines to ensure the reported performance comparisons are fair and reproducible