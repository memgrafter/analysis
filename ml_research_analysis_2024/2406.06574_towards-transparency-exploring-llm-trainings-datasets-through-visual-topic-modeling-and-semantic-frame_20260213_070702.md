---
ver: rpa2
title: 'Towards Transparency: Exploring LLM Trainings Datasets through Visual Topic
  Modeling and Semantic Frame'
arxiv_id: '2406.06574'
source_url: https://arxiv.org/abs/2406.06574
tags:
- arxiv
- http
- data
- topic
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Bunka, a software tool for analyzing LLM training
  datasets using topic modeling and semantic framing. Bunka enables visual exploration
  of dataset content through 2D maps, revealing topic distributions and relationships.
---

# Towards Transparency: Exploring LLM Trainings Datasets through Visual Topic Modeling and Semantic Frame

## Quick Facts
- arXiv ID: 2406.06574
- Source URL: https://arxiv.org/abs/2406.06574
- Authors: Charles de Dampierre; Andrei Mogoutov; Nicolas Baumard
- Reference count: 32
- One-line primary result: Introduces Bunka, a tool for analyzing LLM training datasets through visual topic modeling and semantic framing to improve transparency and quality

## Executive Summary
This paper presents Bunka, a software tool designed to increase transparency in Large Language Model (LLM) training datasets through visual topic modeling and semantic framing analysis. Bunka transforms textual datasets into interactive 2D maps where topics are represented as clusters, enabling users to visually explore dataset content, relationships, and potential biases. The tool was validated through three use cases: summarizing a fine-tuning prompt dataset, accelerating DPO training through targeted filtering, and detecting conceptual biases in training data.

The authors demonstrate that visual topic modeling combined with semantic framing can reveal meaningful patterns in LLM training datasets that would be difficult to detect through traditional statistical analysis alone. By making dataset content more accessible and interpretable, Bunka aims to address the growing concern about transparency in AI systems, particularly regarding the data used to train foundation models.

## Method Summary
Bunka employs a pipeline that converts textual documents into vector embeddings using models like SentenceTransformers, then applies dimensionality reduction (UMAP/TSNE) to create 2D visualizations. Documents are clustered using algorithms like KMeans or DBSCAN to identify topics, with noun extraction and statistical analysis used to label each cluster. The semantic framing component calculates cosine similarities between document embeddings and predefined frame embeddings (e.g., future-past, work-leisure) to detect conceptual biases. The system provides both programmatic analysis and an interactive front-end for exploring results.

## Key Results
- Successfully summarized a fine-tuning prompt dataset, revealing 9 major topics including chat, summarization, and code generation
- Accelerated DPO fine-tuning by 6x while improving model performance across multiple benchmarks using targeted dataset filtering
- Quantified conceptual biases in training datasets, showing 85.8% bias toward future vs 14.2% toward past concepts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Topic Modeling combined with 2D Cartography enables visual exploration of dataset content and relationships
- Mechanism: Text documents are embedded into vector space, clustered, and mapped to 2D coordinates using UMAP/TSNE, with density visualization and noun-based topic labeling
- Core assumption: Human brains can effectively interpret spatial relationships and densities as proxies for semantic similarity and topic importance
- Evidence anchors:
  - [abstract] "Topic Modeling coupled with 2-dimensional Cartography can increase the transparency of datasets"
  - [section 2.1] "Cognitive science shows that 2D maps and diagrams are the easiest way to represent the multiple dimensions of an information"
  - [corpus] Weak - no direct citation, but reference to cognitive science literature and visualization tools like Wizmap
- Break condition: If embedding space doesn't preserve semantic relationships, or if 2D projection loses critical information

### Mechanism 2
- Claim: Filtering prompts based on unique GPT-4 topic distributions accelerates DPO fine-tuning
- Mechanism: Identify topics present in GPT-4 answers but not in LLaMA answers, then use only those prompts for fine-tuning
- Core assumption: Topics unique to GPT-4 responses represent the "knowledge gap" that DPO should fill, making training more efficient
- Evidence anchors:
  - [section 3.1] "We hypothesized that focusing the DPO process only on prompts that lead to GPT-4 specific responses, we could accelerate the DPO fine-tuning process"
  - [section 3.1] Results show improved performance across benchmarks with 1/6 of original data
  - [corpus] Weak - no comparative study with random sampling, assumption needs validation
- Break condition: If unique topics don't correlate with quality differences, or if filtering removes important learning signals

### Mechanism 3
- Claim: Semantic Framing Analysis can detect and quantify conceptual biases in training datasets
- Mechanism: Create 2D plots using cosine similarity between document embeddings and frame embeddings (e.g., future-past, work-leisure axes)
- Core assumption: Embedding models capture meaningful semantic relationships that can be used to measure bias along conceptual dimensions
- Evidence anchors:
  - [section 4.1] "we calculate the percentage of documents that have values greater than 0 in both frame 1 and frame 2, values less than 0 in frame 1 and greater than 0 in frame 2"
  - [section 4.1] Results show dataset bias toward future (85.8%) vs past (14.2%), work (76.8%) vs leisure (13.2%)
  - [corpus] Moderate - relies on UAE-Large-V1 model's ability to capture these semantic distinctions
- Break condition: If embedding model is itself biased, or if cosine similarity doesn't reflect human judgments of conceptual similarity

## Foundational Learning

- Concept: Topic Modeling fundamentals (LDA, NMF, BERTopic)
  - Why needed here: Understanding the evolution of topic modeling techniques and their limitations
  - Quick check question: What are the key differences between statistical (LDA/NMF) and embedding-based (BERTopic) topic modeling approaches?

- Concept: Vector embeddings and semantic similarity
  - Why needed here: Core to both topic modeling and semantic framing components of Bunka
  - Quick check question: How does cosine similarity between embeddings relate to semantic similarity in natural language?

- Concept: Dimensionality reduction techniques (UMAP, TSNE)
  - Why needed here: Essential for converting high-dimensional embeddings to interpretable 2D maps
  - Quick check question: What are the tradeoffs between UMAP and TSNE for preserving local vs global structure in embeddings?

## Architecture Onboarding

- Component map: Text → Embeddings → Dimensionality Reduction → Clustering → Topic Labeling → Visualization

- Critical path: Text → Embeddings → Dimensionality Reduction → Clustering → Topic Labeling → Visualization

- Design tradeoffs:
  - Embedding model choice affects semantic capture quality
  - Number of clusters balances granularity vs readability
  - Filtering threshold impacts uncertainty handling in semantic framing
  - Noun selection percentage (top 10%) trades specificity vs comprehensiveness

- Failure signatures:
  - Clusters don't make semantic sense → check embedding quality or number of clusters
  - Map is too crowded or sparse → adjust UMAP parameters or filtering
  - Semantic framing shows no clear patterns → verify frame sentences capture meaningful opposites
  - Performance degrades after filtering → check if unique topics actually represent quality differences

- First 3 experiments:
  1. Run BunkaTopics on a small, well-understood dataset (e.g., news articles) to verify topic coherence and map interpretability
  2. Compare results using different embedding models on the same dataset to understand sensitivity to embedding choices
  3. Apply semantic framing with simple, intuitive frames (e.g., positive-negative) on a sentiment-labeled dataset to validate bias detection capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of number of topics affect the interpretability and usefulness of the topic maps in BunkaTopics?
- Basis in paper: [explicit] The authors state that "Because there are no satisfying answers, we make it possible in our system for the user to iterate over different numbers of topics until the quality seems good enough."
- Why unresolved: The paper acknowledges that determining the optimal number of topics is an open problem in topic modeling, and does not provide a definitive method for selecting this parameter.
- What evidence would resolve it: Systematic experiments comparing the performance of BunkaTopics with different numbers of topics on various datasets, and a framework for automatically selecting the optimal number of topics based on dataset characteristics.

### Open Question 2
- Question: How does the size of documents affect the performance of Bunka's semantic framing analysis?
- Basis in paper: [inferred] The authors note that "we see a drop for the Future-Past categorization drops in the range [27-39] tokens" and that "there seems to be an optimum between 10 and 30 tokens where the Semantic Framing model and the Mistral-7B-Instruct-v0.1 converge towards the same answer."
- Why unresolved: While the authors observe some effects of document size, they do not provide a comprehensive analysis of how document length impacts the accuracy and reliability of semantic framing across different frame types.
- What evidence would resolve it: A thorough investigation of the relationship between document length and semantic framing accuracy across multiple frame types and datasets, including recommendations for optimal document lengths for different use cases.

### Open Question 3
- Question: How can BunkaTopics be optimized for domain-specific applications?
- Basis in paper: [explicit] The authors state that "as topics are often domain-specific, this approach must be optimized for different industries or areas of research."
- Why unresolved: While the authors acknowledge the need for domain-specific optimization, they do not provide concrete methods or guidelines for adapting BunkaTopics to different domains.
- What evidence would resolve it: Case studies demonstrating the application of BunkaTopics in various domains, along with a framework for customizing the tool's parameters and evaluation metrics for domain-specific use cases.

## Limitations
- Effectiveness heavily depends on embedding model quality, but comprehensive evaluation across different embeddings is lacking
- Semantic framing assumes embedding space meaningfully captures conceptual relationships without empirical validation
- Accelerated training claim lacks comparative studies with random sampling to confirm efficiency gains

## Confidence

- **High Confidence**: The basic architecture and implementation of Bunka's topic modeling pipeline (text → embeddings → dimensionality reduction → clustering → visualization) is technically sound and follows established practices in the field.

- **Medium Confidence**: The claim that Bunka can effectively summarize dataset content and reveal topic distributions is supported by the three use cases, but the evaluation relies heavily on qualitative observations rather than quantitative metrics.

- **Low Confidence**: The specific claims about accelerated DPO training and bias detection through semantic framing need more rigorous validation. The accelerated training claim lacks comparative studies, and the bias detection assumes embedding models capture meaningful semantic relationships without validation.

## Next Checks
1. Conduct a controlled experiment comparing dataset filtering based on unique topic distributions versus random sampling, measuring actual performance gains in DPO fine-tuning to validate the efficiency claim.

2. Perform human evaluation studies where annotators assess the semantic coherence of clusters and the validity of semantic framing results to verify that the tool's visualizations align with human understanding.

3. Test Bunka's robustness across different embedding models and parameter settings on the same datasets to establish how sensitive the results are to implementation choices and identify optimal configurations.