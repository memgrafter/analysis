---
ver: rpa2
title: 'Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt
  Tuning with Unlabeled Data'
arxiv_id: '2406.10502'
source_url: https://arxiv.org/abs/2406.10502
tags:
- candidate
- learning
- data
- unlabeled
- pseudolabels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a candidate pseudolabel learning (CPL) method
  to enhance vision-language models (VLMs) using abundant unlabeled data. Existing
  methods relying on hard pseudolabels suffer from inaccuracies when VLMs exhibit
  low zero-shot performance in downstream tasks.
---

# Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data

## Quick Facts
- arXiv ID: 2406.10502
- Source URL: https://arxiv.org/abs/2406.10502
- Authors: Jiahan Zhang; Qi Wei; Feng Liu; Lei Feng
- Reference count: 40
- Primary result: CPL method achieves state-of-the-art performance on nine benchmark datasets across three learning paradigms by using candidate pseudolabels instead of hard pseudolabels

## Executive Summary
This paper introduces Candidate Pseudolabel Learning (CPL), a method that enhances vision-language models (VLMs) using abundant unlabeled data. Traditional pseudolabeling methods suffer from inaccuracies when VLMs have low zero-shot performance, as hard pseudolabels often contain the wrong true label. CPL addresses this by generating refined candidate pseudolabels through simultaneous intra- and inter-instance label selection based on confidence score matrices. The method transforms the multiclass classification problem into learning with multiple candidate labels, allowing direct application of existing loss functions designed for partial-label learning.

The core innovation lies in recognizing that instances have varying identification difficulty and should not be treated uniformly when selecting candidate labels. CPL's intra-instance selection adapts the number of candidates per instance based on confidence thresholds, while inter-instance selection ensures class-balanced representation. Extensive experiments on nine benchmark datasets with three learning paradigms demonstrate CPL's effectiveness, consistently outperforming existing hard pseudolabel methods, particularly when VLMs have low initial zero-shot capability. The iterative refinement process creates a positive feedback loop where model training generates more confident predictions, which are used to update candidate pseudolabels, which in turn provide better supervision.

## Method Summary
CPL proposes a method to fine-tune vision-language models using abundant unlabeled data by generating refined candidate pseudolabels through simultaneous intra- and inter-instance label selection based on a confidence score matrix. The approach transforms the multiclass classification problem into learning with multiple candidate labels, allowing direct application of existing loss functions. The method involves computing confidence scores for all unlabeled data, generating candidate pseudolabels using both selection strategies, training the VLM using partial-label learning losses (e.g., Classifier-Consistent loss), and iteratively updating candidate pseudolabels after each training iteration.

## Key Results
- CPL consistently outperforms existing hard pseudolabel methods across nine benchmark datasets
- The method achieves state-of-the-art performance particularly when VLMs have low initial zero-shot capability
- CPL demonstrates effectiveness across three learning paradigms: unsupervised learning, semi-supervised learning, and transductive zero-shot learning
- The iterative refinement process creates a positive feedback loop between model training and candidate pseudolabel updates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Candidate pseudolabels improve label estimation accuracy by including the true label more often than hard pseudolabels.
- Mechanism: Intra-instance label selection adapts the number of candidates per instance based on confidence thresholds, ensuring comparable confidence levels across all candidate sets.
- Core assumption: Instances have varying identification difficulty and should not be treated uniformly when selecting candidate labels.
- Evidence anchors:
  - [abstract]: "CPL generates refined candidate pseudolabels by simultaneously considering intra- and inter-instance label selection, based on a confidence score matrix."
  - [section]: "The concept of intra-instance label selection originates from the idea of selecting the top-K confident labels as the most probable label candidates for each instance. However, we further consider that it may not be reasonable to select an equal number of top-K confident labels as the candidate set for each instance, because of the varying levels of identification difficulty associated with each instance."
- Break condition: If the confidence threshold is set too high, candidate sets may become too small and lose their advantage.

### Mechanism 2
- Claim: Inter-instance label selection balances class representation in the training set by preventing dominant classes from overwhelming the pseudolabel distribution.
- Mechanism: For each class, instances are selected based on relative confidence ranking within that class, ensuring proportional representation across all classes.
- Core assumption: Vision-language models exhibit class-imbalanced performance in zero-shot predictions, which propagates to hard pseudolabels.
- Evidence anchors:
  - [abstract]: "This strategy can result in better performance in true label inclusion and class-balanced instance selection."
  - [section]: "Since the predictions from CLIP exhibits class imbalance performance across various categories... we also employ an inter-instance label selection strategy to further refine the candidate pseudolabels."
- Break condition: If selection ratio is set too low, candidate sets may become empty for underrepresented classes.

### Mechanism 3
- Claim: The iterative refinement process progressively improves both the model and candidate pseudolabels, creating a positive feedback loop.
- Mechanism: Model training generates more confident predictions, which are used to update candidate pseudolabels, which in turn provide better supervision for the next training iteration.
- Core assumption: Model predictions improve with training, allowing for more refined candidate pseudolabel generation over time.
- Evidence anchors:
  - [abstract]: "In our CPL method, the fine-tuning of the model and the update of candidate pseudolabels are conducted iteratively, mutually benefiting each other."
  - [section]: "Throughout the training process, the candidate pseudolabels are progressively updated after each pre-defined iteration."
- Break condition: If the model converges too quickly or plateaus, the iterative improvement may stall.

## Foundational Learning

- Concept: Softmax confidence scores and their interpretation as probability distributions
  - Why needed here: CPL relies on confidence scores to rank and select candidate labels for each instance
  - Quick check question: What does a confidence score of 0.8 for a class indicate about the model's certainty?

- Concept: Partial-label learning and loss functions designed for candidate label sets
  - Why needed here: CPL transforms the multiclass problem into learning with multiple candidate labels, requiring appropriate loss functions
  - Quick check question: How does the Classifier-Consistent (CC) loss function handle multiple candidate labels differently from cross-entropy?

- Concept: Iterative training and pseudolabel update strategies
  - Why needed here: CPL updates candidate pseudolabels after each training iteration, requiring understanding of how to maintain consistency between model updates and label updates
  - Quick check question: What happens to the candidate pseudolabel set when the model's predictions change significantly between iterations?

## Architecture Onboarding

- Component map: Confidence score matrix generator -> Intra-instance label selector -> Inter-instance label selector -> Candidate set intersection module -> Loss function wrapper -> Iterative update controller

- Critical path: 1. Compute confidence scores for all unlabeled data 2. Generate candidate pseudolabels using both selection strategies 3. Train model on candidate-labeled data 4. Update confidence scores and repeat

- Design tradeoffs:
  - Larger candidate sets increase true label inclusion probability but introduce more ambiguity
  - More frequent updates improve adaptation but increase computational cost
  - Simpler selection strategies are faster but may produce less balanced results

- Failure signatures:
  - Empty candidate sets for many instances (thresholds too high or β too high)
  - Extreme class imbalance in selected candidates (β too low)
  - No improvement over iterations (learning rate too low or loss function incompatible)

- First 3 experiments:
  1. Verify confidence score computation matches expected softmax outputs
  2. Test intra-instance selection with fixed K on a small dataset to check candidate set sizes
  3. Run full CPL pipeline on EuroSAT with both selection strategies disabled to establish baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CPL scale with increasing dataset size and class diversity?
- Basis in paper: [inferred] The paper discusses performance on nine benchmark datasets but does not explicitly analyze scaling behavior.
- Why unresolved: The experiments focus on specific dataset benchmarks without systematically varying dataset size or class diversity.
- What evidence would resolve it: Systematic experiments varying dataset size (number of instances) and class diversity (number of classes) while measuring CPL performance compared to baseline methods.

### Open Question 2
- Question: What is the impact of hyperparameter selection (α and β) on CPL's performance across different learning paradigms?
- Basis in paper: [explicit] The paper mentions sensitivity analysis for α and β but does not provide comprehensive grid search results across all learning paradigms.
- Why unresolved: The ablation studies focus on specific tasks rather than providing a complete picture of hyperparameter sensitivity across all learning paradigms.
- What evidence would resolve it: Comprehensive grid search results for α and β across all learning paradigms (SSL, UL, TRZSL) with performance metrics.

### Open Question 3
- Question: How does CPL perform when integrated with other vision-language models beyond CLIP?
- Basis in paper: [inferred] The paper focuses on CLIP as the VLM but mentions the method's potential applicability to other VLMs.
- Why unresolved: All experiments use CLIP as the VLM, with no exploration of other vision-language models.
- What evidence would resolve it: Experiments applying CPL to other VLMs (e.g., ALBEF, BLIP) and comparing performance with their native pseudolabeling approaches.

## Limitations

- The paper does not specify how the confidence threshold τ is determined or updated during training iterations, which is critical for the adaptive intra-instance selection
- Computational overhead from iterative candidate pseudolabel updates is not analyzed, potentially limiting scalability for large-scale applications
- The method is only evaluated with CLIP as the VLM, leaving uncertainty about generalization to other vision-language models

## Confidence

- **High Confidence**: The general framework of using candidate pseudolabels instead of hard pseudolabels is well-founded and the empirical results demonstrate consistent improvements across multiple datasets and learning paradigms. The mechanisms of intra- and inter-instance selection are logically sound and address known issues with hard pseudolabel methods.

- **Medium Confidence**: The specific implementation details and hyperparameters (particularly τ and β) that govern the candidate pseudolabel generation process. While the overall approach is robust, the optimal settings for these parameters may vary across different datasets and VLMs, requiring careful tuning.

- **Low Confidence**: The scalability and computational efficiency of the method for very large-scale applications. The paper does not provide detailed analysis of runtime or memory requirements, which could be significant given the iterative nature of the algorithm and the need to compute confidence scores for all unlabeled data.

## Next Checks

1. **Parameter Sensitivity Analysis**: Conduct experiments to determine how different values of τ and β affect the quality of candidate pseudolabels and final model performance. This would involve systematically varying these hyperparameters and measuring their impact on label estimation accuracy, class balance, and test accuracy.

2. **Runtime and Scalability Benchmarking**: Measure the wall-clock time and memory usage of CPL compared to baseline methods across datasets of varying sizes. This would help quantify the computational overhead and identify potential bottlenecks, particularly the confidence score computation and candidate pseudolabel update steps.

3. **Cross-VLM Generalization**: Test CPL with different vision-language models beyond CLIP (e.g., Flamingo, BLIP) to verify that the method is not overly tuned to a specific VLM architecture. This would strengthen the claim that CPL is a general framework for enhancing VLMs rather than a CLIP-specific optimization.