---
ver: rpa2
title: Towards Improved Imbalance Robustness in Continual Multi-Label Learning with
  Dual Output Spiking Architecture (DOSA)
arxiv_id: '2402.04596'
source_url: https://arxiv.org/abs/2402.04596
tags:
- learning
- samples
- multi-label
- performance
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses continual multi-label learning (CMLL) from
  data streams using spiking neural networks (SNNs), which are computationally efficient
  but have not been widely applied to CMLL tasks. The proposed Dual Output Spiking
  Architecture (DOSA) uses two parallel output layers to accurately predict multi-label
  outputs.
---

# Towards Improved Imbalance Robustness in Continual Multi-Label Learning with Dual Output Spiking Architecture (DOSA)

## Quick Facts
- arXiv ID: 2402.04596
- Source URL: https://arxiv.org/abs/2402.04596
- Reference count: 40
- Key outcome: DOSA with Lf mm achieves better performance than previous state-of-the-art algorithms on several benchmark datasets for continual multi-label learning tasks.

## Executive Summary
This paper addresses continual multi-label learning (CMLL) from data streams using spiking neural networks (SNNs). The proposed Dual Output Spiking Architecture (DOSA) uses two parallel output layers to accurately predict multi-label outputs. A novel imbalance-aware focal loss function (Lf mm) with trainable class-specific margins is introduced to improve performance on imbalanced datasets. Experimental results show that Lf mm significantly improves multi-label classification performance over existing methods, particularly on imbalanced datasets. For CMLL tasks, DOSA with Lf mm achieves better performance than previous state-of-the-art algorithms on several benchmark datasets.

## Method Summary
The method combines a dual-output spiking neural network architecture with a novel focal maximum margin loss function that includes trainable class-specific margins. The architecture uses two parallel output layers (positive and negative) to handle multi-label classification, where the positive layer outputs high values for present labels while the negative layer outputs high values for absent labels. The Lf mm loss function incorporates classification confidence through an importance factor that downweights confident predictions and upweights uncertain ones, with a vector of trainable margins that adapts to varying levels of class imbalance across different datasets.

## Key Results
- Lf mm improves performance on the most imbalanced classes over Lmm
- DOSA with Lf mm achieves better performance than previous state-of-the-art algorithms on several benchmark datasets
- The trainable margin vector b adapts to data imbalance, with classes having fewer samples exhibiting larger margin values

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dual output structure allows simultaneous positive and negative label prediction, which is critical for multi-label classification.
- Mechanism: DOSA uses two parallel output layers (positive and negative) where inference is performed by comparing the averaged potentials element-wise to determine label presence/absence.
- Core assumption: The positive layer outputs high values for present labels while the negative layer outputs high values for absent labels, and their difference encodes confidence.
- Evidence anchors:
  - [abstract] "The proposed Dual Output Spiking Architecture (DOSA) uses two parallel output layers to accurately predict multi-label outputs."
  - [section II] "To predict the cth class in a multi-class scenario with an SNN, a single output neuron can produce c spikes... However, these approaches cannot be directly used for multi-label classification"
  - [corpus] Weak evidence - neighboring papers focus on single-output SNNs or temporal dynamics, not dual-output architectures
- Break condition: If the positive and negative layers cannot produce sufficiently separated outputs, the element-wise comparison will fail to distinguish labels.

### Mechanism 2
- Claim: The imbalance-aware focal loss (Lf mm) improves robustness by prioritizing learning from uncertain samples.
- Mechanism: Lf mm multiplies the maximum margin loss by an importance factor exp(-(ζk - b)) that downweights confident predictions and upweights uncertain ones.
- Core assumption: Samples with low ζk (classification confidence) are more informative for improving model robustness to imbalance.
- Evidence anchors:
  - [section III.C] "Lf mm incorporates the model’s classification confidence to improve robustness towards imbalance... the model needs to prioritize learning from samples on which it is less confident"
  - [section V.B] "On the datasets shown, Lf mm improves the performance on the most imbalanced classes over Lmm"
  - [corpus] No direct evidence - neighboring papers focus on other SNN learning strategies
- Break condition: If the margin vector b cannot adapt to class imbalance, the loss function may still favor majority classes.

### Mechanism 3
- Claim: Trainable class-specific margins allow the model to adapt to varying levels of imbalance across different classes.
- Mechanism: Lf mm uses a vector b of margins (one per class) rather than a fixed scalar, where classes with fewer samples get larger margins.
- Core assumption: Different classes have different levels of imbalance, and a fixed margin cannot handle this variation effectively.
- Evidence anchors:
  - [section III.C] "All the classes in a dataset are not imbalanced to the same extent... Hence, Lf mm uses a vector b of the same length as there are classes"
  - [section V.B] "Figure 3 shows the proportion of samples pk and the normalized margin values bk... classes having fewer samples exhibit larger values of margin"
  - [corpus] No direct evidence - neighboring papers don't discuss margin adaptation strategies
- Break condition: If the margin adaptation mechanism fails to converge or overfits to training data, class performance may degrade.

## Foundational Learning

- Concept: Spiking neural networks and leaky integrate-and-fire neurons
  - Why needed here: The entire architecture is built on SNNs, and understanding neuron dynamics is essential for grasping how DOSA works
  - Quick check question: How does a leaky integrate-and-fire neuron generate spikes, and why is this different from standard artificial neurons?

- Concept: Multi-label classification vs multi-class classification
  - Why needed here: The paper addresses a specific challenge in multi-label learning that doesn't exist in multi-class scenarios
  - Quick check question: What is the fundamental difference between predicting one label out of many (multi-class) versus predicting a subset of labels (multi-label)?

- Concept: Continual learning and catastrophic forgetting
  - Why needed here: The work addresses continual multi-label learning, where models must learn new tasks without forgetting previous ones
  - Quick check question: Why is catastrophic forgetting a particular challenge in continual learning, and how does the Sequential Learning with Model Adaptation (SEA) scheme attempt to address it?

## Architecture Onboarding

- Component map: Input -> Feature extractor (FC layers with parametric LIF neurons) -> Dual output layers (positive and negative) -> Output comparison -> Classification
- Critical path: Data flows through feature extractor, produces two output vectors, comparison determines final labels
- Design tradeoffs: Dual output increases parameter count but enables accurate multi-label prediction; trainable margins add complexity but improve imbalance handling
- Failure signatures: Poor performance on minority classes suggests margin adaptation failure; poor overall accuracy suggests issues with dual output comparison
- First 3 experiments:
  1. Verify dual output comparison works on a simple synthetic multi-label dataset
  2. Test Lf mm vs Lmm on an imbalanced multi-label dataset to confirm margin adaptation
  3. Validate SEA scheme by training on sequential tasks and measuring forgetting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed loss function (Lf mm) perform on continual multi-label learning tasks with non-stationary data distributions compared to stationary ones?
- Basis in paper: [inferred] The paper focuses on improving robustness to data imbalance, but does not explicitly compare performance under stationary vs non-stationary data distributions in continual learning scenarios.
- Why unresolved: The experimental setup and evaluation primarily focus on data imbalance and task-agnostic learning, without varying the stationarity of data distributions.
- What evidence would resolve it: Experiments comparing Lf mm performance on continual multi-label learning tasks with both stationary and non-stationary data distributions, showing differences in learning effectiveness and forgetting rates.

### Open Question 2
- Question: What is the impact of using different neuron models (e.g., other than parametric leaky integrate and fire) on the performance of DOSA in multi-label classification tasks?
- Basis in paper: [explicit] The paper mentions using parametric leaky integrate and fire neurons but does not explore the impact of other neuron models on DOSA's performance.
- Why unresolved: The experiments are conducted with a specific neuron model, and its performance relative to other models is not assessed.
- What evidence would resolve it: Comparative experiments using DOSA with different neuron models (e.g., standard leaky integrate and fire, adaptive exponential integrate and fire) on the same multi-label classification tasks, showing performance differences.

### Open Question 3
- Question: How does the trainable margin vector b in Lf mm adapt to varying levels of class imbalance across different datasets?
- Basis in paper: [explicit] The paper proposes a trainable margin vector b for Lf mm and shows that it adapts to data imbalance, but does not provide a detailed analysis of its adaptation mechanism across datasets with different imbalance levels.
- Why unresolved: The experimental results show improvements with Lf mm, but the specific adaptation behavior of the margin vector b across varying imbalance levels is not explored.
- What evidence would resolve it: Detailed analysis of the margin vector b values across multiple datasets with different imbalance levels, showing how the margins adjust to optimize performance for each class's imbalance.

## Limitations
- Experimental validation is limited to 10 datasets, lacking extensive ablation studies
- The CMLL evaluation uses a specific SEA scheme that may not generalize to other continual learning scenarios
- Paper doesn't discuss computational complexity or memory requirements compared to baseline methods

## Confidence
- **High confidence**: The mechanism of dual output layers for multi-label classification is well-supported by the paper's description and mathematical formulation.
- **Medium confidence**: The effectiveness of Lf mm loss with trainable margins is supported by experimental results but lacks extensive ablation studies.
- **Low confidence**: Claims about DOSA's superiority over all existing methods are based on limited experimental comparisons and may not generalize to all CMLL scenarios.

## Next Checks
1. Perform ablation study to isolate contribution of dual output architecture, Lf mm loss, and trainable margins
2. Evaluate DOSA on additional multi-label datasets and continual learning scenarios beyond the 10 datasets used
3. Compare memory and computational requirements of DOSA with baseline methods to assess practical deployment feasibility