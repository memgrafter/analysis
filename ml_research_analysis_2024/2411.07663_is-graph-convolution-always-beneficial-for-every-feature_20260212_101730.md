---
ver: rpa2
title: Is Graph Convolution Always Beneficial For Every Feature?
arxiv_id: '2411.07663'
source_url: https://arxiv.org/abs/2411.07663
tags:
- graph
- feature
- node
- features
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether graph convolution is equally beneficial
  for every feature dimension in Graph Neural Networks (GNNs). Existing feature homophily
  metrics fail to capture feature-level differences in GNN performance.
---

# Is Graph Convolution Always Beneficial For Every Feature?

## Quick Facts
- arXiv ID: 2411.07663
- Source URL: https://arxiv.org/abs/2411.07663
- Authors: Yilun Zheng; Xiang Li; Sitao Luan; Xiaojiang Peng; Lihui Chen
- Reference count: 40
- Key outcome: Graph Feature Selection (GFS) improves GNN performance in 83.75% of cases with 2.2% average accuracy increase

## Executive Summary
This paper challenges the assumption that graph convolution is equally beneficial for all feature dimensions in Graph Neural Networks. Through extensive experiments across 10 datasets and 8 GNN architectures, the authors demonstrate that different features respond differently to graph convolution - some benefit significantly while others are harmed. They introduce Topological Feature Informativeness (TFI), a mutual information-based metric that quantifies how well each feature aligns with graph topology, and propose Graph Feature Selection (GFS) to separately process GNN-favored and GNN-disfavored features for optimal performance.

## Method Summary
The authors propose a two-component framework: Topological Feature Informativeness (TFI) and Graph Feature Selection (GFS). TFI measures the mutual information between aggregated node features and labels to identify which features benefit from graph convolution. GFS then separates features based on their TFI scores, processing GNN-favored features through standard GNN layers and GNN-disfavored features through MLPs, with a final fusion layer combining both representations. This approach maintains comparable computational costs to standard GNNs while significantly improving performance across diverse graph structures.

## Key Results
- GFS improves performance in 83.75% (67/80) of tested cases across 10 datasets and 8 GNN architectures
- Average accuracy increase of 2.2% over baseline GNN models
- TFI outperforms existing feature selection metrics in identifying GNN-favored features
- GFS shows particular effectiveness for features encoded by Pretrained Language Models (PLMs)
- Performance improvements are robust to hyperparameter tuning

## Why This Works (Mechanism)

### Mechanism 1
Graph convolution is not equally beneficial for every feature dimension in GNNs. Different feature dimensions have varying levels of compatibility with graph topology - features with high Topological Feature Informativeness (TFI) align well with graph structure and benefit from convolution, while features with low TFI may be harmed by convolution. This occurs because features can be disentangled into topology-aware and topology-agnostic components.

### Mechanism 2
TFI effectively identifies GNN-favored and GNN-disfavored features by measuring mutual information between aggregated node features and labels. TFI measures how well aggregated features (after k-hop neighbor aggregation) capture label information - higher TFI indicates better alignment with graph structure and stronger performance gain from graph convolution. This works because mutual information between aggregated features and labels serves as a valid proxy for GNN performance on that feature.

### Mechanism 3
Separating features based on TFI and processing them with appropriate models improves overall performance. GFS processes GNN-favored features with GNNs to capture topological information and GNN-disfavored features with MLPs to preserve their original structure, then combines both representations. This works because features can be effectively separated and processed independently without losing information.

## Foundational Learning

- **Graph Neural Networks and message passing**: Understanding how GNNs aggregate neighbor information through graph convolution is fundamental to grasping why different features respond differently. Quick check: What is the key difference between GCN's aggregation formula and a standard MLP's operation?

- **Mutual Information and feature informativeness**: TFI is built on mutual information theory to measure how well aggregated features capture label information. Quick check: How does mutual information differ from correlation when measuring feature-label relationships?

- **Feature homophily vs topology-aware features**: Understanding the distinction between traditional feature homophily metrics and TFI's approach to identifying GNN-favored features is crucial. Quick check: Why might a feature show "good homophily" yet still benefit from graph convolution?

## Architecture Onboarding

- **Component map**: TFI calculation module -> Feature selection module -> GNN processing pipeline + MLP processing pipeline -> Fusion layer
- **Critical path**: 1) Calculate TFI for all features using mutual information estimation, 2) Sort features and determine split point (ratio r), 3) Process GNN-favored features through GNN, 4) Process MLP-favored features through MLP, 5) Concatenate and fuse representations for final output
- **Design tradeoffs**: Ratio r selection (higher r = more features through GNN), TFI calculation cost vs benefit, model complexity (adds MLP but maintains comparable computational cost)
- **Failure signatures**: Poor performance despite high TFI (inaccurate TFI calculation), performance degradation when using GFS (overly aggressive separation), inconsistent results across datasets (poor TFI generalization)
- **First 3 experiments**: 1) Baseline comparison: Run standard GCN vs GCN+GFS on Cora to verify improvement mechanism, 2) Feature ablation: Test GCN+GFS with different ratio r values to find optimal split point, 3) Pretrained embedding test: Compare GFS performance on original vs PLM features

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of GFS vary when applied to dynamically updated node embeddings during training? The paper mentions GFS could be extended to dynamically updated node embeddings in future research, but experiments only evaluate GFS on static node embeddings from pretrained models.

### Open Question 2
Can the ratio r in GFS be automatically selected without extensive hyperparameter tuning? The authors acknowledge that finding the optimal r value is challenging and suggest it as a future research direction, but don't propose a method for automatic selection.

### Open Question 3
How does GFS perform on other types of graph tasks beyond node classification, such as link prediction or graph classification? The experiments focus solely on node classification tasks, but GFS's feature selection approach could be applicable to other graph learning tasks.

## Limitations
- TFI computation adds overhead, particularly challenging for large-scale graphs with 100K+ nodes
- Performance depends on accurate mutual information estimation, which can be numerically unstable
- Limited evaluation on diverse graph types beyond standard node classification benchmarks

## Confidence
- **High confidence**: TFI's ability to identify GNN-favored features (supported by mathematical proofs and extensive experiments)
- **High confidence**: GFS's effectiveness in improving performance (verified across 10 datasets and 8 architectures)
- **Medium confidence**: PLM feature improvement claims (tested on fewer datasets)
- **Low confidence**: Generalizability to graph structures and feature distributions not represented in test set

## Next Checks
1. **Scalability test**: Evaluate TFI computation time and GFS performance on graphs with 100K+ nodes to verify practical applicability to large-scale problems.
2. **Cross-domain generalization**: Apply GFS to datasets from different domains (e.g., molecular graphs, social networks, knowledge graphs) to test robustness across graph types.
3. **Feature correlation analysis**: Investigate how correlated features affect TFI rankings and GFS performance, as real-world features often exhibit high correlation that may impact the separation strategy.