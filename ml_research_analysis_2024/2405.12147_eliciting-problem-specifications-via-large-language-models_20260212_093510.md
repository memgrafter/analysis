---
ver: rpa2
title: Eliciting Problem Specifications via Large Language Models
arxiv_id: '2405.12147'
source_url: https://arxiv.org/abs/2405.12147
tags:
- problem
- empty
- where
- agent
- amount
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that large language models can automatically
  generate formal problem-space specifications from natural language descriptions,
  enabling existing reasoning systems to solve multiple problem instances without
  human mediation. The authors implemented a multi-agent system using GPT-4 that applies
  domain-general problem-solving strategies to produce precise specifications for
  classic problems like the water jugs task.
---

# Eliciting Problem Specifications via Large Language Models

## Quick Facts
- arXiv ID: 2405.12147
- Source URL: https://arxiv.org/abs/2405.12147
- Reference count: 40
- Large language models can automatically generate formal problem-space specifications from natural language descriptions, enabling existing reasoning systems to solve multiple problem instances without human mediation

## Executive Summary
This paper demonstrates that large language models can automatically generate formal problem-space specifications from natural language descriptions, enabling existing reasoning systems to solve multiple problem instances without human mediation. The authors implemented a multi-agent system using GPT-4 that applies domain-general problem-solving strategies to produce precise specifications for classic problems like the water jugs task. The LLM-generated specifications were sufficiently accurate and detailed to allow a Soar agent to find optimal solutions, with learning reducing search space by up to two orders of magnitude compared to no-learning conditions. While results are preliminary, the work shows promise for accelerating cognitive systems research by automating the traditionally labor-intensive problem formulation process while maintaining core capabilities like robust inference and online learning.

## Method Summary
The authors developed a multi-agent LLM system using GPT-4 with domain-general problem-solving strategies to produce precise problem-space specifications from natural language descriptions. The system uses a fixed sequential analysis path through problem characterization, refinement, problem-space formulation, search control, and test case identification. They tested this approach on water jugs problems, creating variations including familiar problems, unit variations, extra jugs, and analogues. The LLM-generated specifications were then used by a Soar agent to find optimal solutions, with learning capabilities enabled to compare performance against no-learning conditions.

## Key Results
- LLM-generated specifications were sufficiently accurate and detailed to allow a Soar agent to find optimal solutions for water jugs problems
- Learning reduced search space by up to two orders of magnitude compared to no-learning conditions
- The multi-agent approach using fixed sequential analysis path successfully automated problem formulation across multiple water jugs variations

## Why This Works (Mechanism)
The approach works by leveraging LLMs' ability to parse natural language and apply structured reasoning to extract formal problem specifications. The multi-agent architecture breaks down the complex task of specification generation into sequential steps: understanding the problem, refining requirements, formulating the problem space, defining search control, and identifying test cases. Each agent specializes in one aspect, with the overall system maintaining consistency through the sequential flow. The use of domain-general problem-solving strategies allows the system to handle variations in problem descriptions while producing standardized formal specifications that reasoning systems can execute.

## Foundational Learning
- **Problem-space specification**: Formal representation of states, operators, and goals needed for automated reasoning (why needed: provides structured input for reasoning systems; quick check: can be executed by Soar agent)
- **Multi-agent LLM orchestration**: Sequential agent architecture where each agent handles one aspect of specification generation (why needed: breaks down complex task into manageable subtasks; quick check: produces consistent end-to-end specifications)
- **Search control formulation**: Rules and heuristics that guide the reasoning system's search process (why needed: improves efficiency by reducing search space; quick check: orders of magnitude reduction with learning)
- **Transfer operator definition**: Formal specification of state transitions in problem space (why needed: enables reasoning system to navigate between states; quick check: generates executable agent code)
- **Test case identification**: Generating concrete instances to validate specifications (why needed: ensures generated specifications work correctly; quick check: can solve generated test problems)

## Architecture Onboarding
- **Component map**: Problem Description -> CTA Agent (Sequential Analysis) -> Problem Space Specification -> Soar Agent -> Solution
- **Critical path**: Natural language input → Multi-agent analysis → Formal specification generation → Agent code generation → Solution search with learning
- **Design tradeoffs**: Fixed sequential analysis path provides consistency but may miss parallel opportunities; multi-agent approach enables specialization but requires careful prompt engineering
- **Failure signatures**: Incomplete transfer operator specifications prevent executable code generation; incorrect search control assumptions lead to inefficient or failed searches
- **First experiments**: 1) Run single water jugs problem through full pipeline, 2) Compare one-shot vs multi-agent specification generation, 3) Test Soar agent performance with and without learning enabled

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single problem domain (water jugs) with single target system (Soar)
- Claims about accelerating research are not quantified in terms of labor savings or scalability
- System robustness to ambiguous or noisy natural language inputs not tested

## Confidence
- Claims about LLM-generated specifications enabling cognitive systems to solve problems without human mediation: **Medium** confidence
- Claims about accelerating cognitive systems research by automating problem formulation: **Low** confidence
- Claims about maintaining core capabilities like robust inference and online learning: **Medium** confidence

## Next Checks
1. Test the multi-agent LLM system on at least three additional distinct problem domains (e.g., blocks world planning, cryptarithmetic puzzles, route finding) to assess generalizability
2. Compare specification generation time and accuracy against expert human performance on the same problem set
3. Evaluate system performance when given intentionally ambiguous or underspecified natural language descriptions to test robustness