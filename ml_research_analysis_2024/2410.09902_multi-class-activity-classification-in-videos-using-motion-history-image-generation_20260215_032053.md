---
ver: rpa2
title: Multi class activity classification in videos using Motion History Image generation
arxiv_id: '2410.09902'
source_url: https://arxiv.org/abs/2410.09902
tags:
- motion
- image
- action
- recognition
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents a supervised learning approach using Motion
  History Images (MHI) for human action recognition in video sequences. The method
  extracts temporal motion patterns by generating binary motion images through background
  subtraction, followed by morphological filtering and conversion to MHI.
---

# Multi class activity classification in videos using Motion History Image generation

## Quick Facts
- arXiv ID: 2410.09902
- Source URL: https://arxiv.org/abs/2410.09902
- Authors: Senthilkumar Gopal
- Reference count: 14
- Primary result: MLP classifier achieved significantly better accuracy than KNN for classifying six activities using MHI-based features

## Executive Summary
This study presents a supervised learning approach using Motion History Images (MHI) for human action recognition in video sequences. The method extracts temporal motion patterns by generating binary motion images through background subtraction, followed by morphological filtering and conversion to MHI. Seven Hu moment invariants and an additional third-order moment are computed from these images to form feature vectors. Two classifiers were evaluated: K-Nearest Neighbors (KNN) and Multi-layer Perceptron (MLP). KNN showed poor performance with high confusion between similar actions like walking and jogging. MLP demonstrated significantly better accuracy by learning subtle motion differences through hidden layers. The system successfully classified six different activities in a single multi-action video, though performance degraded when shadows were present or when τ values were not properly tuned.

## Method Summary
The method generates binary motion images from video frames using Gaussian filtering and background subtraction with a threshold. Morphological OPEN operator removes noise artifacts. Motion History Images are created using a time window τ=300, encoding recent motion with higher pixel intensities. Seven Hu moment invariants plus a third-order moment are extracted from each MHI as feature vectors. These 8-dimensional features are fed to both KNN and MLP classifiers for activity classification. The MLP uses backpropagation to adjust weights and minimize output error, while KNN relies on distance metrics that struggle with similar motion patterns.

## Key Results
- MLP classifier outperformed KNN significantly by learning subtle motion differences through hidden layers
- High confusion between walking and jogging classes due to similar motion patterns in MHI representations
- System performance degraded when shadows were present in video sequences
- Fixed τ=300 time window provided reasonable results but optimal values varied by activity type

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Motion History Images encode temporal motion patterns as spatial intensity gradients that capture the sequence and recency of movements
- Mechanism: The MHI algorithm accumulates binary motion detections over time τ, with recent motion assigned higher pixel intensities. This creates a temporal-to-spatial transformation where motion direction and speed become visible as intensity gradients across the image plane
- Core assumption: Motion patterns are sufficiently distinct between different activities when represented as intensity decay functions
- Evidence anchors:
  - [abstract] "Motion History image has been a well established framework to capture the temporal and activity information in multi dimensional detail"
  - [section] "MHI is represented as a pixel intensity function, where brighter values correspond to most recent motion"
  - [corpus] Weak evidence - no direct corpus support for MHI mechanism specifically
- Break condition: When motion patterns between activities are too similar (e.g., walking vs jogging), or when shadows create false motion signals that corrupt the intensity decay pattern

### Mechanism 2
- Claim: Hu moment invariants provide scale, rotation, and translation invariant shape descriptors that uniquely characterize MHI patterns
- Mechanism: The seven Hu moments and additional third-order moment are calculated from MHI intensity distributions. These moments remain constant under geometric transformations, making them robust feature vectors for activity classification
- Core assumption: The MHI intensity distributions for different activities produce sufficiently distinct moment values that can be separated by classification algorithms
- Evidence anchors:
  - [section] "We utilize the seven Hu moment invariants [10] which are known to provide reasonable shape discrimination in a translation, rotation and scale invariant manner"
  - [section] "The first seven parameters < v1, v2, v3, v4, v5, v6, v7 > are the Hu moments. We also add the third order independent moment invariant as determined in [11]"
  - [corpus] Weak evidence - no direct corpus support for moment extraction mechanism
- Break condition: When MHI patterns are corrupted by shadows or when τ is poorly tuned, producing moment values that fall within the overlap region of different activities

### Mechanism 3
- Claim: Multi-layer Perceptron classifiers learn non-linear decision boundaries that capture subtle motion differences missed by distance-based classifiers
- Mechanism: MLP uses backpropagation to adjust weights across hidden layers, learning complex feature representations from the moment vectors. This enables discrimination between activities with similar motion patterns by capturing higher-order interactions in the feature space
- Core assumption: The input moment features contain sufficient information about motion patterns for the network to learn meaningful discriminative features
- Evidence anchors:
  - [section] "MLP demonstrated significantly better accuracy by learning subtle motion differences through hidden layers"
  - [section] "This algorithm uses [12] Back-Propagation which continuously adjusts the weights of the network connections to minimize the training/testing output error"
  - [corpus] Weak evidence - no direct corpus support for MLP performance comparison
- Break condition: When the feature space is insufficiently discriminative due to poor MHI quality or when the training dataset is too small to learn the non-linear boundaries

## Foundational Learning

- Concept: Binary motion detection through background subtraction
  - Why needed here: Forms the foundation for detecting motion regions that are accumulated into MHIs
  - Quick check question: How does the Gaussian filter with kernel (3,3) affect the binary motion detection quality?

- Concept: Morphological filtering (OPEN operator)
  - Why needed here: Removes noise artifacts from binary motion images before MHI generation
  - Quick check question: What would happen to MHI quality if morphological filtering was skipped?

- Concept: Temporal window selection (τ parameter)
  - Why needed here: Controls the duration of motion history captured in each MHI, affecting temporal resolution
  - Quick check question: How would changing τ affect the ability to distinguish between fast and slow activities?

## Architecture Onboarding

- Component map: Video frames -> Gaussian filtering -> Background subtraction -> Binary motion detection -> Morphological filtering -> Motion Energy Image (MEI) -> Motion History Image (MHI) -> Hu moment extraction -> Classification (MLP/KNN)
- Critical path: MHI generation -> moment extraction -> classification prediction
- Design tradeoffs: Fixed τ provides simplicity but reduces adaptability; MLP provides better accuracy but requires more training data and computational resources compared to KNN
- Failure signatures: High confusion between similar activities (walking/jogging) indicates MHI quality issues; poor overall accuracy suggests feature extraction problems; shadows causing secondary MHI patterns indicate preprocessing needs
- First 3 experiments:
  1. Test MHI generation with different τ values on the same video sequence to observe temporal decay patterns
  2. Compare KNN vs MLP classification accuracy on a small subset of activities to validate classifier choice
  3. Introduce shadow in test videos to observe impact on MHI quality and classification performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of 3D Motion History Images (MHV) compare to 2D MHI when using the same classifier (MLP) for human action recognition across the six activity classes?
- Basis in paper: [explicit] The paper explicitly states that "3D Motion History Images computed as the eigenvector of body movements" and mentions using Extreme Learning Machines (ELM) for classification, suggesting that 3D MHI with ELM performs "exceptionally well in different lighting, background and occlusion conditions" compared to 2D MHI with traditional classifiers.
- Why unresolved: The paper only mentions this as future work and does not provide experimental results comparing 2D MHI+MLP versus 3D MHI+ELM on the same dataset.
- What evidence would resolve it: Direct experimental comparison of classification accuracy, confusion matrices, and processing time for both 2D MHI with MLP and 3D MHI with ELM on the same six-class activity dataset under identical conditions.

### Open Question 2
- Question: What is the optimal method for automatically determining the time-window parameter τ for each action class to achieve τ-invariant classification?
- Basis in paper: [explicit] The paper identifies that "the boundary conditions for the MHI generated for jogging was very close to the running and walking MHIs due to their similarities of motion action" and states "One way to help the classifier become more robust would be to introduce the time for τ as a factor which in turn can help the classifier be τ-invariant."
- Why unresolved: The paper uses a fixed τ value of 300 for all actions and does not explore methods for action-specific τ determination or incorporating τ as a feature vector.
- What evidence would resolve it: Experimental results showing classification accuracy improvements when using action-specific τ values versus fixed τ, or when incorporating τ as an additional feature dimension in the classifier input.

### Open Question 3
- Question: How effective would a sliding window approach be for real-time action recognition compared to the current frame-sequence processing method?
- Basis in paper: [explicit] The paper mentions as future work that "The algorithm can be improved to compute scores for different actions over a sliding window to provide more real-time recognition."
- Why unresolved: The current implementation processes predetermined frame sequences and does not evaluate real-time recognition capabilities or the trade-offs between window size, latency, and classification accuracy.
- What evidence would resolve it: Comparative analysis of classification accuracy and processing latency between the current frame-sequence approach and various sliding window configurations (different window sizes and overlap percentages) on the same multi-action video dataset.

## Limitations
- Limited dataset scope with only six activities tested, reducing generalizability
- Single time window τ=300 used without systematic exploration of optimal parameters
- Binary motion detection sensitive to shadows and background changes
- No real-time performance metrics or computational efficiency analysis

## Confidence
- **High**: MHI generation framework and feature extraction pipeline are well-established and correctly implemented
- **Medium**: MLP classifier outperforms KNN as claimed, but exact performance metrics not provided
- **Low**: Claims about future 3D MHI with ELM improvements remain theoretical without experimental validation

## Next Checks
1. Test MHI generation across a range of τ values (100-1000) on the same video sequence to identify optimal temporal resolution for different activity speeds
2. Implement ablation study removing morphological filtering to quantify its impact on binary motion image quality and downstream classification accuracy
3. Conduct controlled experiments introducing synthetic shadows and background variations to measure system robustness under realistic conditions