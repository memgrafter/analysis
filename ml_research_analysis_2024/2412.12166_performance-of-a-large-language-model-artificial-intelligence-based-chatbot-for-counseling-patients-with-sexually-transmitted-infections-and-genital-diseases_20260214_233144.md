---
ver: rpa2
title: Performance of a large language model-Artificial Intelligence based chatbot
  for counseling patients with sexually transmitted infections and genital diseases
arxiv_id: '2412.12166'
source_url: https://arxiv.org/abs/2412.12166
tags:
- health
- chatbot
- information
- otiz
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: An AI chatbot platform called Otiz was developed specifically for
  sexually transmitted infection (STI) counseling and diagnosis, using a multi-agent
  system architecture based on GPT4-0613 with modules for STI information, emotional
  recognition, Acute Stress Disorder detection, and psychotherapy. When evaluated
  by 23 venereologists on 30 patient-simulated prompts covering 4 STIs and 2 non-STIs,
  Otiz achieved high scores (4.1-4.7/5.0) on diagnostic accuracy, overall accuracy,
  correctness of information, comprehensibility, and empathy, though relevance scores
  were lower (2.9-3.6).
---

# Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases

## Quick Facts
- arXiv ID: 2412.12166
- Source URL: https://arxiv.org/abs/2412.12166
- Reference count: 0
- An AI chatbot called Otiz achieved high scores (4.1-4.7/5.0) on diagnostic accuracy, overall accuracy, correctness of information, comprehensibility, and empathy for STI counseling, evaluated by 23 venereologists on 30 simulated prompts.

## Executive Summary
This study presents Otiz, an AI chatbot platform designed for sexually transmitted infection (STI) counseling and diagnosis, leveraging a multi-agent system architecture based on GPT4-0613. The platform integrates specialized modules for STI information, emotional recognition, Acute Stress Disorder detection, and psychotherapy, utilizing Deterministic Finite Automaton principles to ensure contextually relevant and medically accurate interactions. Evaluated by 23 venereologists on 30 patient-simulated prompts covering 4 STIs and 2 non-STIs, Otiz demonstrated high performance in diagnostic accuracy, correctness of information, and empathy, though relevance scores were lower.

## Method Summary
The study developed Otiz, an AI chatbot using GPT4-0613 with a multi-agent architecture incorporating DFA principles. It includes modules for STI information, emotional recognition, ASD detection, and psychotherapy, guided by sophisticated, multi-layered prompt engineering to establish an expert venereologist persona. The chatbot was evaluated by 23 venereologists on 30 patient-simulated prompts, graded using a 6-point Numerical Rating Scale across six criteria: diagnostic accuracy, overall accuracy, relevance, correctness of information, comprehensibility, and empathy.

## Key Results
- Otiz achieved high scores (4.1-4.7/5.0) on diagnostic accuracy, overall accuracy, correctness of information, comprehensibility, and empathy.
- Diagnostic accuracy for non-STIs was significantly lower (p=0.038) compared to STIs.
- Inter-observer agreement was strong, with differences greater than 1 point in only 12.7% of paired evaluations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-agent architecture enables specialized STI counseling with context switching between modules.
- Mechanism: The Otiz system uses a DFA-based multi-agent framework with distinct modules for STI information, emotional recognition, ASD detection, and psychotherapy. Transitions between these modules are driven by user needs and DFA states, ensuring responses remain medically accurate and contextually relevant.
- Core assumption: Structured transitions prevent topic drift and maintain coherence in sensitive STI counseling conversations.
- Evidence anchors:
  - [abstract] "multi-agent system architecture based on GPT4-0613 with modules for STI information, emotional recognition, Acute Stress Disorder detection, and psychotherapy."
  - [section] "DFA is a computational model that defines systems through a limited set of states with predefined transitions, allowing for precise control over user interactions and chatbot responses."
  - [corpus] Weak/no direct evidence; related chatbots lack DFA-based structured transitions.
- Break condition: If DFA state logic is incomplete or user input mismatches expected states, the system may produce irrelevant or repetitive content.

### Mechanism 2
- Claim: Role-specific prompt engineering ensures responses are aligned with expert-level STI counseling.
- Mechanism: The prompt design explicitly defines Otiz as an "Expert venereologist physician" with character traits like professionalism, warmth, and wit. It embeds step-by-step diagnostic reasoning and adaptive communication instructions, enabling consistent medical accuracy and empathy.
- Core assumption: Persona-based prompts can reliably steer LLM outputs toward clinical best practices in STI counseling.
- Evidence anchors:
  - [abstract] "leveraging large language model (LLM) and Deterministic Finite Automaton principles to provide contextually relevant, medically accurate, and empathetic responses."
  - [section] "The system prompt begins by defining Otiz as an 'Expert venereologist physician.' This persona establishment is crucial as it sets the tone for all subsequent interactions and decision-making processes."
  - [corpus] Related works show similar persona-prompting but lack specific venereologist framing.
- Break condition: If prompts are too generic or miss edge-case handling, accuracy for non-STIs or complex presentations may degrade.

### Mechanism 3
- Claim: Venereologist evaluation by simulated patient interaction validates medical and empathetic performance.
- Mechanism: Twenty-three venereologists evaluated 30 simulated patient prompts across 4 STIs and 2 non-STIs, using a 6-point NRS for criteria like diagnostic accuracy, empathy, and relevance. High scores (4.1–4.7/5.0) indicate strong medical and empathetic performance, while low relevance scores (2.9–3.6) point to redundancy issues.
- Core assumption: Expert human evaluators can reliably assess AI-generated STI counseling quality in a simulated setting.
- Evidence anchors:
  - [abstract] "When evaluated by 23 venereologists on 30 patient-simulated prompts... Otiz achieved high scores (4.1-4.7/5.0) on diagnostic accuracy, overall accuracy, correctness of information, comprehensibility, and empathy."
  - [section] "Each venereologist was assigned a maximum of three prompts to evaluate... Each prompt was independently assessed by two different venereologists."
  - [corpus] Limited peer studies use similar expert-actor evaluation; novelty in STI-specific domain.
- Break condition: If evaluators have bias or prompts don't reflect real patient diversity, scores may overestimate real-world performance.

## Foundational Learning

- Deterministic Finite Automaton (DFA)
  - Why needed here: Provides precise control over conversational state transitions, ensuring contextually relevant and medically coherent interactions in multi-turn STI counseling.
  - Quick check question: How does DFA differ from a standard LLM conversation loop in handling topic transitions?

- Prompt Engineering with Persona Definition
  - Why needed here: Establishes expert-level behavior and communication style, critical for maintaining accuracy and empathy in STI-related discussions.
  - Quick check question: What specific traits are embedded in Otiz's persona prompt to guide LLM outputs?

- Multi-turn Diagnostic Reasoning
  - Why needed here: Enables systematic symptom analysis and differential diagnosis, mirroring expert venereologist workflows in an AI system.
  - Quick check question: Why is step-by-step symptom analysis essential in STI counseling chatbots?

## Architecture Onboarding

- Component map:
  - STI Information Module: Handles symptom-based detection and differential diagnosis.
  - Emotional Recognition Module: Analyzes user sentiment and adjusts tone.
  - ASD Detection Module: Screens for acute stress and offers coping resources.
  - Psychotherapy Module: Provides guided relaxation and cognitive strategies.
  - Question Suggestion Agent: Operates in parallel to guide conversation.
  - GPT4-0613 LLM Core: Powers all modules with context from prompt engineering.

- Critical path:
  1. User query → STI Information Module for diagnosis.
  2. Post-diagnosis → Emotional Recognition Module for empathy adjustment.
  3. If stress detected → ASD Detection → Psychotherapy Module.
  4. Question Suggestion Agent continuously guides topic flow.

- Design tradeoffs:
  - High accuracy vs. relevance: Structured DFA transitions reduce topic drift but may introduce redundancy.
  - Empathy vs. efficiency: Emotional and psychotherapy modules add depth but slow response time.
  - Generalization vs. specificity: STI-specific modules excel on STIs but underperform on non-STIs.

- Failure signatures:
  - Redundancy in responses (low relevance scores).
  - Slow response rate due to multiple module interactions.
  - Difficulty returning to medical topics after emotional support.

- First 3 experiments:
  1. Evaluate DFA state transition logic on edge-case inputs to reduce redundant outputs.
  2. Test prompt variations for non-STI conditions to improve diagnostic accuracy outside core domain.
  3. A/B test with and without Question Suggestion Agent to measure impact on conversation coherence.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation was conducted in a simulated environment, which may not fully capture real-world patient interactions.
- Diagnostic accuracy for non-STIs was significantly lower (p=0.038), indicating limitations in handling conditions outside the core STI domain.
- Relevance scores (2.9-3.6/5.0) suggest the chatbot may provide redundant or overly detailed responses, potentially impacting user experience.

## Confidence

- **High Confidence**: The multi-agent architecture based on GPT4-0613 with DFA principles effectively ensures contextually relevant and medically accurate responses in STI counseling, as evidenced by high scores (4.1-4.7/5.0) in diagnostic accuracy, correctness of information, and empathy.
- **Medium Confidence**: The role-specific prompt engineering reliably steers LLM outputs toward clinical best practices in STI counseling, though the lack of detailed prompt specifications limits full reproducibility.
- **Low Confidence**: The chatbot's performance in real-world settings with diverse patient populations remains uncertain, as the study is limited to simulated prompts and expert evaluations.

## Next Checks

1. Evaluate DFA state transition logic on edge-case inputs to reduce redundant outputs and improve relevance scores.
2. Test prompt variations for non-STI conditions to identify and address gaps in diagnostic accuracy outside the core STI domain.
3. A/B test with and without the Question Suggestion Agent to quantify its impact on conversation coherence and user satisfaction.