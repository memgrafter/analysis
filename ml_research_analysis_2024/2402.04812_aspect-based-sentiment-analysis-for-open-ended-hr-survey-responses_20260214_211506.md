---
ver: rpa2
title: Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses
arxiv_id: '2402.04812'
source_url: https://arxiv.org/abs/2402.04812
tags:
- sentiment
- classification
- responses
- data
- dutch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an aspect-based sentiment analysis (ABSA)
  approach for open-ended HR survey responses, addressing the need for detailed sentiment
  analysis in employee lifecycle management. Using a dataset of 1,458 Dutch survey
  responses, the study employs few-shot learning with Dutch BERT models, comparing
  their performance to bag-of-words and zero-shot baselines.
---

# Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses

## Quick Facts
- arXiv ID: 2402.04812
- Source URL: https://arxiv.org/abs/2402.04812
- Reference count: 17
- Key outcome: Dutch BERT models achieve macro F1 scores of 0.5219 for aspect classification and 0.8736 for sentiment classification in ABSA for HR survey responses

## Executive Summary
This paper introduces an aspect-based sentiment analysis (ABSA) approach for processing open-ended HR survey responses, addressing the challenge of extracting detailed sentiment information from employee feedback. The study focuses on Dutch language responses, employing few-shot learning with Dutch BERT models to classify both the aspects being discussed and the sentiment expressed toward them. The methodology demonstrates that Dutch-specific language models significantly outperform general approaches, providing a foundation for automated analysis of employee feedback across the employee lifecycle.

## Method Summary
The study employs a few-shot learning approach using Dutch BERT models (RobBERT and BERTje) to perform aspect-based sentiment analysis on open-ended HR survey responses. The methodology involves training models on a labeled dataset of 1,458 Dutch responses, comparing few-shot classification performance against bag-of-words and zero-shot baseline approaches. Data augmentation techniques are applied to assess their impact on model robustness, particularly for aspect classification tasks. The evaluation focuses on macro F1 scores to measure performance across different classes, providing a balanced assessment of model capabilities.

## Key Results
- Few-shot Dutch BERT models achieve macro F1 scores of 0.5219 for aspect classification
- Sentiment classification achieves higher performance with macro F1 scores of 0.8736
- Data augmentation improved aspect classification performance specifically for RobBERT model
- Dutch BERT models significantly outperform bag-of-words and zero-shot baselines

## Why This Works (Mechanism)
The success of this approach stems from leveraging language-specific pre-training on Dutch text data, which captures linguistic nuances critical for accurate sentiment and aspect detection. Few-shot learning allows the models to generalize effectively from limited labeled examples, which is particularly valuable given the time-intensive nature of annotating HR survey responses. The aspect-based approach enables granular analysis by identifying specific topics within responses and their associated sentiments, providing more actionable insights than document-level sentiment analysis.

## Foundational Learning
- **Aspect-based sentiment analysis**: Why needed - to extract detailed sentiment information about specific topics rather than overall document sentiment; Quick check - model can identify "salary" as aspect and "negative" as sentiment
- **Few-shot learning**: Why needed - to work effectively with limited labeled training data; Quick check - model performs well with minimal training examples per class
- **Dutch BERT models**: Why needed - to capture language-specific linguistic features and cultural context; Quick check - model understands Dutch idiomatic expressions and workplace terminology
- **Data augmentation**: Why needed - to increase training data diversity and improve model robustness; Quick check - performance improves on augmented training data
- **Macro F1 score**: Why needed - to provide balanced evaluation across classes, especially important for imbalanced datasets; Quick check - metric accounts for performance on minority classes
- **HR survey response processing**: Why needed - to automate analysis of employee feedback for organizational insights; Quick check - model extracts actionable insights from open-ended responses

## Architecture Onboarding
**Component Map:** Raw survey responses -> Preprocessing pipeline -> Aspect classification model -> Sentiment classification model -> Output: Aspect-sentiment pairs
**Critical Path:** Data preprocessing and tokenization → Aspect classification → Sentiment classification → Result aggregation
**Design Tradeoffs:** Few-shot learning vs. full supervised learning (efficiency vs. potential accuracy), Dutch-specific models vs. multilingual models (language specificity vs. broader applicability)
**Failure Signatures:** Poor performance on underrepresented aspects, confusion between similar sentiment categories, inability to handle complex linguistic structures
**First Experiments:** 1) Test baseline bag-of-words approach on sample data, 2) Evaluate zero-shot performance of Dutch BERT models, 3) Measure impact of data augmentation on aspect classification

## Open Questions the Paper Calls Out
None

## Limitations
- Limited generalizability due to single HR context and Dutch language specificity
- Aspect classification remains challenging with macro F1 scores around 0.52
- Data augmentation benefits only observed for RobBERT, not comprehensively explored

## Confidence
- High confidence in relative performance comparison between few-shot Dutch BERT and baseline approaches
- Medium confidence in generalizability to other HR contexts
- Low confidence in robustness of data augmentation improvements

## Next Checks
1. Validate model performance across multiple HR datasets from different organizations and industries
2. Conduct ablation studies to determine contribution of Dutch language pre-training vs. few-shot learning
3. Test models on translated English survey responses to evaluate cross-lingual performance consistency