---
ver: rpa2
title: Automated Fusion of Multimodal Electronic Health Records for Better Medical
  Predictions
arxiv_id: '2401.11252'
source_url: https://arxiv.org/abs/2401.11252
tags:
- search
- data
- fusion
- feature
- architecture
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AutoFM, a neural architecture search (NAS)
  framework designed to automate the fusion of multimodal electronic health records
  (EHR) for improved medical predictions. AutoFM addresses the challenges of heterogeneous
  EHR data by introducing a two-stage search space for modality-specific encoding
  and multimodal fusion.
---

# Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions

## Quick Facts
- arXiv ID: 2401.11252
- Source URL: https://arxiv.org/abs/2401.11252
- Reference count: 31
- Primary result: AutoFM outperforms state-of-the-art baselines across multiple medical prediction tasks using automated multimodal EHR fusion

## Executive Summary
This paper introduces AutoFM, a neural architecture search (NAS) framework designed to automate the fusion of multimodal electronic health records (EHR) for improved medical predictions. The framework addresses the challenges of heterogeneous EHR data by introducing a two-stage search space for modality-specific encoding and multimodal fusion. AutoFM employs a customized optimization loss and a pruning-based algorithm to derive optimal architectures. Experiments on real-world EHR data demonstrate that AutoFM significantly outperforms state-of-the-art baselines across various tasks, including acute respiratory failure prediction, shock prediction, mortality prediction, and diagnosis prediction.

## Method Summary
AutoFM is a neural architecture search framework that automates the fusion of multimodal electronic health records through a two-stage search process. The first stage searches for optimal encoding architectures for each modality (static demographics, clinical notes, continuous events, discrete events) using mixed operations that include feature interactions. The second stage performs multimodal fusion by first selecting which modalities to include at each fusion step, then searching for the optimal fusion operation (sum, MLP, or attentive sum). A customized optimization loss with a feature selection penalty encourages diversity in modality selection during fusion. The final architecture is derived through a pruning-based discretization algorithm that iteratively removes the least important operations based on validation performance.

## Key Results
- AutoFM outperforms state-of-the-art baselines across multiple medical prediction tasks including acute respiratory failure, shock, mortality, and diagnosis prediction
- The two-stage search space design enables effective exploration of modality-specific encoding and fusion strategies
- The pruning-based discretization algorithm preserves supernet performance better than traditional methods like DARTS

## Why This Works (Mechanism)

### Mechanism 1
The two-stage search space (modality-specific encoding + multimodal fusion) allows the model to separately optimize for modality-specific feature extraction and cross-modality integration, improving overall performance. In the first stage, AutoFM designs specialized encoding modules for each modality with feature interaction operations, enabling early fusion exploration. In the second stage, a feature selector determines which modalities to fuse, and a searchable fusion module identifies the optimal fusion strategy. This separation allows the model to explore diverse encoding and fusion strategies tailored to the heterogeneous nature of EHR data.

### Mechanism 2
The customized optimization loss with a feature selection penalty encourages diversity in modality selection during the fusion stage, leading to more robust architectures. AutoFM introduces a penalty term that maximizes the cross-entropy of feature selector weights across different fusion steps. This penalty discourages repetitive modality selection and encourages the model to explore diverse combinations of modalities at each fusion step.

### Mechanism 3
The pruning-based algorithm for deriving the final architecture preserves supernet performance better than traditional discretization methods like DARTS. After training the supernet, AutoFM gradually prunes operations by evaluating their contribution to validation performance. It removes the operation whose removal improves validation performance the most, then fine-tunes the remaining architecture. This iterative pruning continues until only one operation remains per mixed operation.

## Foundational Learning

- Concept: Neural Architecture Search (NAS)
  - Why needed here: AutoFM is a NAS framework, so understanding how NAS automates the design of neural network architectures is crucial for understanding the paper's contribution.
  - Quick check question: What are the main challenges that NAS aims to address compared to manual neural network design?

- Concept: Multimodal Data Fusion
  - Why needed here: AutoFM specifically addresses the challenge of fusing multimodal EHR data (static demographics, clinical notes, continuous events, discrete events). Understanding different fusion strategies and their trade-offs is essential for grasping the paper's approach.
  - Quick check question: What are the key differences between early fusion and late fusion strategies, and when might each be preferable?

- Concept: Differentiable Architecture Search (DARTS)
  - Why needed here: AutoFM builds upon DARTS by introducing a customized loss and pruning-based discretization. Understanding DARTS's core principles and limitations is necessary to appreciate AutoFM's innovations.
  - Quick check question: What are the main limitations of DARTS that AutoFM aims to address, and how does AutoFM's approach differ?

## Architecture Onboarding

- Component map:
  Input: Four modalities - static demographics (p), clinical notes (n), continuous events (M), discrete events (E)
  Modality-specific Search: K-layer networks with mixed operations (encoding + interaction) for each modality
  Multimodal Fusion Search: Feature selector (Identity/Zero operations) + Searchable fusion module (Sum, MLP, Attentive Sum)
  Prediction: Linear combination of fusion module outputs + Sigmoid (binary) or Softmax (multi-label)
  Optimization: Bi-level optimization with custom loss + Pruning-based discretization

- Critical path:
  1. Embed each modality into a common latent space
  2. Perform modality-specific search to obtain modality encodings
  3. Apply max pooling to sequence features to get same-shape encodings
  4. Perform multimodal fusion search to obtain final fused representation
  5. Generate predictions and optimize using custom loss
  6. Derive final architecture using pruning-based discretization

- Design tradeoffs:
  - Two-stage search vs. unified search: Two-stage allows separate optimization of encoding and fusion but increases complexity
  - Feature selection penalty: Encourages diversity but may force suboptimal modality selection if too strong
  - Pruning-based discretization vs. DARTS: Preserves performance better but requires more computation during derivation

- Failure signatures:
  - Poor performance on tasks requiring specific modalities: May indicate that the feature selection penalty is too strong or the modality-specific search space is too limited
  - Overfitting to validation set during pruning: May indicate that the pruning algorithm is not effectively identifying unimportant operations
  - Slow convergence during supernet training: May indicate that the custom loss is too complex or the search space is too large

- First 3 experiments:
  1. Ablation study: Remove each modality from input and observe performance drop to assess modality importance
  2. Comparison with DARTS: Derive architectures using DARTS and AutoFM's pruning method from the same supernet and compare performance
  3. Sensitivity analysis: Vary the penalty term weight Î» and observe its effect on feature selection diversity and overall performance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several remain unexplored based on the experimental design and discussion.

## Limitations
- Performance claims are evaluated on a single institutional dataset (MIMIC-III), which may limit generalizability across different healthcare systems
- Computational overhead of the two-stage NAS approach is not benchmarked against other automated approaches in terms of total GPU hours or energy consumption
- The feature selection penalty mechanism's effectiveness is demonstrated empirically but lacks theoretical justification for why maximizing cross-entropy of feature selector weights leads to optimal modality diversity

## Confidence
**High confidence**: The architectural framework design (two-stage search space, pruning-based discretization) is clearly specified and the performance improvements over multiple baselines are statistically significant.

**Medium confidence**: The claims about computational efficiency relative to manual design and the generalizability of results across different medical prediction tasks are supported but could benefit from additional validation.

**Low confidence**: The theoretical justification for the feature selection penalty mechanism and the claim that the two-stage search space is universally superior to unified search approaches for all multimodal EHR tasks lacks rigorous mathematical grounding.

## Next Checks
1. **Cross-institutional validation**: Evaluate AutoFM on at least two additional EHR datasets from different healthcare systems to assess generalizability and robustness to varying documentation practices and data distributions.

2. **Ablation study on search space design**: Compare the two-stage search approach against a unified search space with the same operations to determine if the separation of encoding and fusion stages provides significant benefits beyond computational convenience.

3. **Computational efficiency benchmarking**: Measure total GPU hours, memory usage, and energy consumption for AutoFM compared to both manual design and alternative NAS approaches across the full architecture search, training, and deployment pipeline.