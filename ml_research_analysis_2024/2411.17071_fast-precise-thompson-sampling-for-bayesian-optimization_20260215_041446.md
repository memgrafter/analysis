---
ver: rpa2
title: Fast, Precise Thompson Sampling for Bayesian Optimization
arxiv_id: '2411.17071'
source_url: https://arxiv.org/abs/2411.17071
tags:
- thompson
- arms
- sampling
- score
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Stagger Thompson Sampling (STS), a novel approach
  to Bayesian optimization that addresses the computational inefficiency of standard
  Thompson sampling in high-dimensional spaces. STS combines Hit-and-Run sampling
  with a Metropolis-Hastings acceptance criterion and a "stagger" perturbation strategy
  (log-uniform sampling of step sizes) to more efficiently locate the optimizer.
---

# Fast, Precise Thompson Sampling for Bayesian Optimization

## Quick Facts
- arXiv ID: 2411.17071
- Source URL: https://arxiv.org/abs/2411.17071
- Authors: David Sweet
- Reference count: 0
- Primary result: STS outperforms standard Thompson sampling and popular acquisition functions across multiple benchmark functions in dimensions ranging from 3 to 300

## Executive Summary
This paper presents Stagger Thompson Sampling (STS), a novel approach to Bayesian optimization that addresses the computational inefficiency of standard Thompson sampling in high-dimensional spaces. STS combines Hit-and-Run sampling with a Metropolis-Hastings acceptance criterion and a "stagger" perturbation strategy (log-uniform sampling of step sizes) to more efficiently locate the optimizer. The method demonstrates superior performance compared to standard Thompson sampling, P-Star Sampler, and other popular acquisition functions (EI, UCB) across multiple benchmark functions in dimensions ranging from 3 to 300. STS also matches the performance of P-Star Sampler when used as input to the Minimal Terminal Variance (MTV) batching algorithm.

## Method Summary
STS addresses the inefficiency of standard Thompson sampling in high-dimensional Bayesian optimization by introducing a novel perturbation strategy. Instead of uniform perturbations, STS samples step sizes from a log-uniform distribution (e^(-kU)), allowing more efficient exploration of regions with high posterior probability density. The algorithm uses Hit-and-Run sampling moves with a Metropolis-Hastings acceptance criterion to generate samples from the posterior distribution of the optimizer. This approach enables STS to locate the optimizer more precisely while requiring fewer computational resources than standard TS with large numbers of candidate arms. The method can be combined with the Minimal Terminal Variance batching algorithm for parallel optimization.

## Key Results
- STS outperforms standard Thompson sampling, P-Star Sampler, and acquisition functions (EI, UCB) across 9 benchmark functions in dimensions 3, 30, and 300
- STS requires fewer candidate arms than standard TS while achieving better precision in locating the optimizer
- STS-MTV combination matches the performance of PSS-MTV on multi-arm optimization problems
- Performance improvement is most pronounced in higher dimensions (30-300), with STS showing exponential efficiency gains over standard TS

## Why This Works (Mechanism)

### Mechanism 1
STS more precisely locates the maximizer than standard TS using less computation time. The log-uniform ("stagger") perturbation strategy combined with Hit-and-Run sampling and Metropolis-Hastings acceptance efficiently explores regions of high probability density in the posterior distribution. The core assumption is that the bulk of p*(x) lies in a small region that becomes exponentially harder to find as dimension increases with standard uniform sampling. This could break if the posterior distribution has multiple isolated modes or if the log-uniform step size range is inappropriate for the problem scale.

### Mechanism 2
STS samples from p*(x) more accurately than standard TS by reducing scale while maintaining unbiasedness. The log-uniform perturbation combined with Metropolis-Hastings acceptance criterion allows STS to adapt its step size dynamically, converging to p*(x) without requiring manual tuning of proposal distributions. The core assumption is that a symmetric log-uniform proposal distribution will generate a Markov chain that converges to p*(x). This could break if the Gaussian process model is misspecified or if the acceptance criterion based on single joint samples becomes too restrictive.

### Mechanism 3
STS outperforms other acquisition functions (EI, UCB) in high-dimensional Bayesian optimization. By sampling from p*(x) more efficiently, STS can identify promising regions without the computational overhead of maximizing acquisition functions like EI or UCB, which require gradient-based optimization. The core assumption is that the probability that an arm is optimal (p*(x)) contains sufficient information to guide optimization without explicitly computing acquisition functions. This could break if the objective function has very sharp, narrow optima where p*(x) becomes highly concentrated.

## Foundational Learning

- **Gaussian Process regression**: Why needed here: The paper uses GP as the surrogate model for the objective function, providing both mean predictions and uncertainty estimates needed for Thompson sampling. Quick check question: What are the two key components of a GP prediction that are used in Bayesian optimization acquisition functions?

- **Thompson sampling in Bayesian optimization**: Why needed here: The paper extends Thompson sampling from multi-armed bandits to continuous optimization by sampling from the posterior distribution of the optimizer. Quick check question: How does Thompson sampling differ from Upper Confidence Bound (UCB) in terms of exploration-exploitation trade-off?

- **Hit-and-Run sampling with Metropolis-Hastings**: Why needed here: The core sampling mechanism of STS relies on Hit-and-Run moves with a Metropolis-Hastings acceptance criterion to generate samples from p*(x). Quick check question: What is the acceptance probability for a proposed move in Metropolis-Hastings sampling?

## Architecture Onboarding

- **Component map**: GP surrogate model -> STS sampling algorithm -> log-uniform perturbation -> Metropolis-Hastings acceptance -> MTV batching (optional)
- **Critical path**: 1. Fit GP to observed data, 2. Initialize arm at GP mean maximum, 3. Iteratively perturb using log-uniform steps, 4. Accept/reject using joint GP samples, 5. Return accepted sample as optimization result
- **Design tradeoffs**: The paper trades off computational efficiency (fewer candidate arms) against sampling precision (log-uniform vs uniform perturbations), and simplicity (no trust regions or gradient information) against potential performance on extremely high-dimensional problems
- **Failure signatures**: 1. Slow convergence indicated by persistent high RMSE from optimum, 2. Poor exploration shown by samples clustering in one region, 3. Numerical instability when step sizes become too small
- **First 3 experiments**: 1. Compare STS to standard TS on a simple 1D test function (e.g., sphere function) with varying numbers of candidate arms. 2. Test the sensitivity of STS performance to the log-uniform perturbation parameter k by running on a 5D Ackley function. 3. Evaluate STS-MTV combination on a batch optimization problem with multiple arms per round.

## Open Questions the Paper Calls Out

- **High-dimensional scaling**: How does STS performance compare to other methods specifically designed for high-dimensional optimization, beyond turbo-1? This remains unresolved as the paper only compares STS to turbo-1 among methods specifically designed for high-dimensional optimization, without evaluating against other specialized high-dimensional optimization techniques referenced in turbo-1.

- **Optimal iteration count**: What is the optimal number of iterations M for STS in different optimization scenarios? While the ablation study shows performance asymptotes around M = 30, this may not be optimal for all scenarios, and the paper doesn't explore how M should be adapted based on problem characteristics.

- **Non-convex landscapes**: How does STS perform in non-convex optimization landscapes with multiple local optima? The test functions used may not fully capture the complexity of non-convex landscapes with many local optima typical in practical applications.

## Limitations

- Computational complexity analysis is limited to problems with limited curvature information, making it unclear how STS performs on functions with complex, high-curvature landscapes
- Limited discussion of how the method scales to real-world optimization problems with noisy, expensive-to-evaluate objectives
- The choice of perturbation parameter k â‰ˆ ln(10^-6) appears critical but sensitivity analysis is limited to only 3 values

## Confidence

- **High Confidence**: The theoretical foundation of STS as an unbiased sampler from p*(x) is well-established through the Metropolis-Hastings framework
- **Medium Confidence**: The empirical superiority of STS over standard TS and acquisition functions is demonstrated but relies on specific benchmark choices and parameters
- **Low Confidence**: The claims about STS-MTV integration matching PSS-MTV performance require further validation on problems where PSS is known to excel

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary the perturbation parameter k across several orders of magnitude to quantify its impact on convergence speed and solution quality
2. **High-Dimensional Scaling Test**: Evaluate STS performance on benchmark functions in dimensions >300 to verify the claimed exponential efficiency gains over standard TS
3. **Real-World Application**: Apply STS to an engineering optimization problem (e.g., hyperparameter tuning for a neural network) where the objective function has known challenging properties like local optima and noisy evaluations