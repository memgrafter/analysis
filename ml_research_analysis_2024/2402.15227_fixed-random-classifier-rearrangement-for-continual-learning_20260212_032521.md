---
ver: rpa2
title: Fixed Random Classifier Rearrangement for Continual Learning
arxiv_id: '2402.15227'
source_url: https://arxiv.org/abs/2402.15227
tags:
- classifier
- learning
- task
- tasks
- fixed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses catastrophic forgetting in continual learning
  by analyzing the role of classifiers alongside backbone models. It introduces Fixed
  Random Classifier Rearrangement (FRCR), a two-stage algorithm that first freezes
  random classifiers to constrain equivalent one-class classifier norms and then rearranges
  classifier entries to reduce interference between tasks.
---

# Fixed Random Classifier Rearrangement for Continual Learning

## Quick Facts
- arXiv ID: 2402.15227
- Source URL: https://arxiv.org/abs/2402.15227
- Authors: Shengyang Huang; Jianwen Mo
- Reference count: 28
- Primary result: FRCR achieves 98.84%, 97.99%, and 82.89% final accuracy on 5-Split-MNIST, 5-Split-FashionMNIST, and 5-Split-CIFAR10 respectively with minimal forgetting rates

## Executive Summary
This paper addresses catastrophic forgetting in continual learning by focusing on classifier design alongside backbone models. The authors introduce Fixed Random Classifier Rearrangement (FRCR), a two-stage algorithm that first freezes random classifiers to constrain equivalent one-class classifier norms, then rearranges classifier entries to reduce interference between tasks. The method demonstrates that controlling classifier norms and orthogonality effectively mitigates forgetting without requiring replay or parameter isolation mechanisms.

## Method Summary
FRCR operates through a two-stage process: (1) During training, random classifiers are frozen while the backbone model is trained, constraining equivalent one-class classifier norms to ensure stability across tasks. (2) After training, classifier entries are rearranged to minimize interference between tasks while maintaining the frozen classifier structure. This approach leverages the observation that classifier design significantly impacts forgetting, with proper norm constraints and orthogonality enabling effective knowledge retention across sequential tasks.

## Key Results
- Final average accuracy of 98.84% on 5-Split-MNIST with only 0.95% average maximum forgetting
- Final average accuracy of 97.99% on 5-Split-FashionMNIST with 2.10% average maximum forgetting
- Final average accuracy of 82.89% on 5-Split-CIFAR10 with 3.58% average maximum forgetting
- Outperforms baseline methods and stable-SGD across all tested datasets

## Why This Works (Mechanism)
The method works by controlling classifier norms and ensuring orthogonality between classifiers of different tasks. By freezing random classifiers during backbone training, the algorithm constrains the equivalent one-class classifier norms, preventing interference between tasks. The subsequent rearrangement stage optimizes classifier entries to minimize cross-task interference while maintaining the norm constraints established during training. This two-stage approach effectively decouples classifier design from backbone learning, allowing for more stable feature representations across tasks.

## Foundational Learning
- Catastrophic forgetting: The tendency of neural networks to forget previously learned tasks when trained on new ones - needed to understand the core problem being addressed
- Orthogonal classifiers: Classifiers designed to be orthogonal to each other to minimize interference - needed to understand how the rearrangement stage works
- Classifier norm constraints: The practice of constraining the magnitude of classifier weights - needed to understand the stability mechanism
- One-class classifier equivalence: The relationship between multi-class classifiers and their equivalent one-class formulations - needed to understand the theoretical framework

## Architecture Onboarding
Component map: Backbone model -> Frozen random classifiers -> Classifier rearrangement module -> Output layer
Critical path: Input -> Backbone -> Fixed classifiers -> Rearranged classifiers -> Classification output
Design tradeoffs: Sacrifices some classifier flexibility for stability vs. traditional approaches that allow full classifier adaptation
Failure signatures: Poor performance when classifier norms become unstable or when rearrangement doesn't sufficiently reduce interference
First experiments:
1. Test FRCR on 5-Split-MNIST to verify basic functionality
2. Compare with baseline methods on 5-Split-FashionMNIST
3. Evaluate performance degradation when classifier norms are not properly constrained

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes fixed classifier norms which may not hold as backbone features shift across tasks
- Limited to relatively simple datasets (MNIST, FashionMNIST, CIFAR10) without testing on more complex tasks
- Computational overhead from classifier rearrangement stage is not addressed
- Performance on imbalanced task streams or unknown task boundaries is not evaluated

## Confidence
High confidence: Experimental results on benchmark datasets, comparison with baseline methods, theoretical analysis of classifier norm constraints
Medium confidence: Generalizability to more complex datasets and real-world scenarios, scalability of the approach
Low confidence: Performance in task-agnostic settings, computational efficiency claims

## Next Checks
1. Evaluate FRCR on more complex datasets like CIFAR100 or ImageNet to assess scalability and performance on high-dimensional tasks
2. Test the method in task-agnostic continual learning settings where task boundaries are not provided during inference
3. Analyze the computational overhead and training time impact of the classifier rearrangement stage compared to standard continual learning approaches