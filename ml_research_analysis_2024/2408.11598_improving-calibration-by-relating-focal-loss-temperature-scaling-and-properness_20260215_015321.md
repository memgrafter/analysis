---
ver: rpa2
title: Improving Calibration by Relating Focal Loss, Temperature Scaling, and Properness
arxiv_id: '2408.11598'
source_url: https://arxiv.org/abs/2408.11598
tags:
- focal
- loss
- calibration
- temperature
- scaling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates why focal loss training leads to better
  calibration than cross-entropy by decomposing focal loss into a confidence-raising
  transformation (focal calibration map) and a proper loss. The authors prove this
  decomposition explains why focal loss produces under-confident predictions on training
  data, resulting in better calibration on test data due to the generalization gap.
---

# Improving Calibration by Relating Focal Loss, Temperature Scaling, and Properness

## Quick Facts
- arXiv ID: 2408.11598
- Source URL: https://arxiv.org/abs/2408.11598
- Reference count: 40
- Key outcome: Focal loss training improves calibration through decomposition into proper loss and confidence-raising transformation

## Executive Summary
This paper investigates why focal loss training leads to better calibration than cross-entropy loss by decomposing focal loss into a proper loss and a confidence-raising transformation (focal calibration map). The authors prove this decomposition explains why focal loss produces under-confident predictions on training data, resulting in better calibration on test data due to the generalization gap. They establish a strong connection between temperature scaling and focal loss through the focal calibration map, showing that focal calibration can be bounded by two temperature scaling transformations in the binary case, and behaves similarly to temperature scaling with T < 1 in the multiclass case. The proposed focal temperature scaling method, which composes focal calibration with temperature scaling, consistently improves calibration over standard temperature scaling on three image classification datasets while maintaining accuracy.

## Method Summary
The authors decompose focal loss into a confidence-raising transformation (focal calibration map) and a proper loss, then establish theoretical connections between focal calibration and temperature scaling. They implement standard temperature scaling and focal temperature scaling methods, optimizing parameters on validation sets to minimize ECE. The focal temperature scaling composes focal calibration (based on the focal loss parameter γ) with standard temperature scaling. Experiments are conducted on CIFAR-10, CIFAR-100, and TinyImageNet using ResNet-50 architecture, training models with cross-entropy and focal loss across various γ values, then applying both calibration methods to evaluate improvements in calibration metrics.

## Key Results
- Focal loss can be decomposed into a proper loss and focal calibration map, explaining its calibration benefits
- Focal calibration map behaves similarly to temperature scaling with T < 1, increasing model confidence
- Focal temperature scaling consistently outperforms standard temperature scaling on three image classification datasets
- The relationship between optimal focal loss parameter γ and temperature scaling parameter T is approximately linear across datasets and training methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Focal loss can be decomposed into a proper loss and a confidence-raising transformation (focal calibration map), which explains its improved calibration on test data.
- Mechanism: The focal calibration map increases model confidence by mapping predicted probabilities toward higher values, pushing predictions to be under-confident on training data. Due to the generalization gap, this under-confidence translates to better calibration on test data.
- Core assumption: The generalization gap causes models trained with proper losses like cross-entropy to be over-confident on test data.
- Evidence anchors:
  - [abstract] "We prove that focal loss can be decomposed into a confidence-raising transformation and a proper loss."
  - [section] "This decomposition suggests that training a focal loss is, in fact, equivalent to training a specific proper loss, which is applied on top of an additional fixed calibration layer in the network."
  - [corpus] Weak - no direct mention of this specific mechanism, but related work on calibration exists.
- Break condition: If the generalization gap does not exist or is negligible, the under-confidence mechanism would not lead to better test calibration.

### Mechanism 2
- Claim: The focal calibration map behaves similarly to temperature scaling with T < 1, effectively sharpening the predicted probability distribution.
- Mechanism: For multiclass cases, focal calibration increases the highest predicted probability while decreasing others, similar to temperature scaling with a temperature parameter less than one.
- Core assumption: The focal calibration map has a sigmoid-like shape that maps probabilities in a way that increases confidence.
- Evidence anchors:
  - [abstract] "we show that the focal calibration map for any γ > 0 increases the model confidence, similar to temperature scaling with T < 1 in the multiclass case."
  - [section] "Each arrow originates from a point representing an initial probability input and ends at a point corresponding to the output of the focal calibration... arrow directions are all from the centre towards corners, which implies that the predicted distribution becomes sharper."
  - [corpus] No direct evidence in corpus neighbors about this specific relationship.
- Break condition: If the focal calibration map does not have a sigmoid-like shape or does not increase confidence, this mechanism would not apply.

### Mechanism 3
- Claim: Focal temperature scaling, which composes focal calibration with temperature scaling, improves calibration compared to standard temperature scaling alone.
- Mechanism: The combination of focal calibration (γev) and temperature scaling (T) provides more flexible adjustment of predicted probabilities than either method alone, leading to better calibration.
- Core assumption: The focal calibration and temperature scaling transformations are sufficiently different to provide complementary benefits when composed.
- Evidence anchors:
  - [abstract] "Our experiments on three image classification datasets demonstrate that focal temperature scaling outperforms standard temperature scaling."
  - [section] "The goal is to produce predictions that minimize the metric of interest (e.g. ECE). As both transformations directly impact the model's confidence and are sufficiently different in a multiclass case, the focal temperature scaling should improve the model's calibration to a larger extent than standard temperature scaling."
  - [corpus] No direct evidence in corpus neighbors about this specific method.
- Break condition: If focal calibration and temperature scaling are too similar or redundant, their composition would not provide additional benefits.

## Foundational Learning

- Concept: Proper losses
  - Why needed here: Understanding proper losses is crucial because focal loss is improper, and the paper explains how focal loss achieves better calibration through decomposition into a proper loss and a confidence-raising transformation.
  - Quick check question: What is the defining property of a proper loss, and why does it lead to over-confidence on test data?

- Concept: Temperature scaling
  - Why needed here: Temperature scaling is a standard calibration method that focal temperature scaling builds upon, and understanding its mechanism is essential for grasping how focal temperature scaling works.
  - Quick check question: How does temperature scaling adjust predicted probabilities, and what does a temperature parameter T < 1 achieve?

- Concept: Generalization gap
  - Why needed here: The generalization gap explains why models trained with proper losses are over-confident on test data, which is the context in which focal loss's improved calibration is evaluated.
  - Quick check question: What is the generalization gap, and how does it affect model calibration on test versus training data?

## Architecture Onboarding

- Component map: Logits → Temperature scaling → Focal calibration → Calibrated probabilities

- Critical path: Logits → Temperature scaling → Focal calibration → Calibrated probabilities

- Design tradeoffs:
  - Single vs. composite calibration: Using focal temperature scaling provides more flexibility but requires tuning two parameters instead of one.
  - Training vs. post-hoc calibration: Focal loss during training vs. focal temperature scaling as a post-hoc method offer different approaches to achieving calibration.

- Failure signatures:
  - Poor calibration improvement: May indicate incorrect choice of γev or T parameters.
  - Over-correction: Calibration map may push probabilities too far, leading to under-confidence.
  - Computational overhead: 2D grid search for optimal parameters may be resource-intensive.

- First 3 experiments:
  1. Apply standard temperature scaling to a model trained with cross-entropy and evaluate ECE improvement.
  2. Apply focal temperature scaling with γev = 0.5 to the same model and compare calibration results.
  3. Vary γev parameter in focal temperature scaling to find optimal calibration for a focal loss-trained model.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the theoretical bounds for focal calibration in the binary case compare to empirical bounds for higher-dimensional cases?
- Basis in paper: [explicit] The paper derives theoretical bounds for binary focal calibration and conducts experiments to compare them with empirical bounds, finding that experimental bounds are considerably tighter than theoretical ones.
- Why unresolved: The paper only provides experimental results for three- and four-dimensional cases but does not establish theoretical bounds for these higher-dimensional scenarios.
- What evidence would resolve it: Deriving theoretical bounds for focal calibration in multiclass cases and comparing them with empirical results for dimensions higher than two.

### Open Question 2
- Question: What is the exact nature of the relationship between the optimal parameters γev and T for focal temperature scaling across different datasets and training methods?
- Basis in paper: [explicit] The paper observes a close to linear relationship between γev and T for different training methods and datasets but suggests that a full understanding of this phenomenon remains for future work.
- Why unresolved: The paper identifies the trend but does not provide a complete theoretical explanation or explore the optimized parameter search.
- What evidence would resolve it: A detailed theoretical analysis explaining the linear relationship and experimental validation of the optimized parameter search approach.

### Open Question 3
- Question: How does focal temperature scaling perform compared to other calibration methods like matrix and vector scaling in terms of both calibration and accuracy?
- Basis in paper: [explicit] The paper focuses on comparing focal temperature scaling with standard temperature scaling but does not directly compare it to other methods like matrix and vector scaling.
- Why unresolved: The paper's experiments are limited to focal temperature scaling versus standard temperature scaling, leaving a gap in understanding its performance relative to other methods.
- What evidence would resolve it: Conducting experiments that include comparisons of focal temperature scaling with matrix and vector scaling across various datasets and training methods.

### Open Question 4
- Question: What are the implications of the decomposition of focal loss into proper loss and focal calibration for understanding the generalization properties of models trained with focal loss?
- Basis in paper: [explicit] The paper provides a decomposition of focal loss but does not fully explore its implications for generalization.
- Why unresolved: The decomposition is presented, but its deeper implications for model generalization are not thoroughly investigated.
- What evidence would resolve it: Theoretical and empirical studies examining how the decomposition affects model generalization across different datasets and training scenarios.

## Limitations

- The experimental validation covers only three datasets with limited hyperparameter exploration for calibration methods
- The relationship between focal calibration and temperature scaling (T<1) is established theoretically but may not hold uniformly across all scenarios
- The decomposition proof for focal loss calibration is mathematically sound but its practical impact depends on specific dataset and model architecture

## Confidence

- Mathematical decomposition of focal loss: High confidence
- Generalization gap mechanism: Medium confidence
- Experimental results showing focal temperature scaling improvement: Medium confidence

## Next Checks

1. Test the focal calibration map behavior across different model architectures (beyond ResNet-50) to verify the T<1 temperature scaling relationship holds generally.
2. Conduct a systematic ablation study varying both γev and T parameters to map the complete calibration landscape and identify optimal combinations.
3. Evaluate calibration performance on out-of-distribution datasets to test whether the focal calibration mechanism generalizes beyond the training distribution.