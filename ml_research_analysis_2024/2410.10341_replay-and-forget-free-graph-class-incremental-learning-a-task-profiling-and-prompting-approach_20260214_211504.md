---
ver: rpa2
title: 'Replay-and-Forget-Free Graph Class-Incremental Learning: A Task Profiling
  and Prompting Approach'
arxiv_id: '2410.10341'
source_url: https://arxiv.org/abs/2410.10341
tags:
- task
- graph
- tasks
- learning
- gcil
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses class-incremental learning on graphs where
  task IDs are not available during inference, posing challenges in separating classes
  from different tasks. The authors propose a novel approach called Task Profiling
  and Prompting (TPP) that combines Laplacian smoothing-based task profiling with
  graph prompting.
---

# Replay-and-Forget-Free Graph Class-Incremental Learning: A Task Profiling and Prompting Approach

## Quick Facts
- arXiv ID: 2410.10341
- Source URL: https://arxiv.org/abs/2410.10341
- Reference count: 40
- Key outcome: Achieves 100% task ID prediction accuracy and at least 18% improvement in average CIL accuracy over state-of-the-art methods while being fully forget-free

## Executive Summary
This paper addresses the challenge of class-incremental learning on graphs where task IDs are not available during inference, a critical gap in existing GCIL research. The authors propose Task Profiling and Prompting (TPP), a novel approach that combines Laplacian smoothing-based task profiling with graph prompting. By constructing discriminative task prototypes and learning task-specific prompts with a frozen pre-trained GNN, TPP achieves both replay-free and forget-free learning. The method significantly outperforms existing approaches on four benchmark datasets while maintaining perfect task ID prediction accuracy.

## Method Summary
TPP addresses class-incremental learning on graphs without task ID information by first pre-training a GNN backbone on the initial task using contrastive learning. For each task, it constructs task prototypes using Laplacian smoothing and learns task-specific prompts and classifiers while keeping the GNN frozen. During inference, it predicts task IDs by matching test sample prototypes to stored task prototypes, then retrieves the corresponding prompt and classifier for classification. This approach eliminates the need for data replay and prevents catastrophic forgetting by maintaining separate task-specific models built on top of a frozen backbone.

## Key Results
- Achieves 100% task ID prediction accuracy across all four benchmark datasets
- Outperforms state-of-the-art methods by at least 18% in average CIL accuracy
- Demonstrates fully forget-free learning, even exceeding joint training performance
- Shows that small prompt sizes (3 tokens) are sufficient for effective task adaptation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Laplacian smoothing-based task profiling enables accurate task ID prediction by exploiting graph structure and node attributes.
- Mechanism: Laplacian smoothing propagates node information through graph structure, causing embeddings of nodes within the same task to converge to a common prototype while embeddings from different tasks diverge due to structural and attribute differences.
- Core assumption: Graphs for all tasks are not isolated and contain discriminative structural and attribute differences between tasks.
- Evidence anchors:
  - [abstract]: "We show theoretically that accurate task ID prediction on graph data can be achieved by a Laplacian smoothing-based graph task profiling approach"
  - [section]: "With the existence of edges between nodes, this task profiling method guarantees that the task prototypes of the same graph task are nearly the same with a large smoothing step, while those of different tasks are distinct due to differences in graph structure and node attributes"
  - [corpus]: No direct evidence found for Laplacian smoothing in graph continual learning
- Break condition: If graphs contain isolated nodes or tasks have very similar graph structures and node attributes, task prototypes may not be distinguishable.

### Mechanism 2
- Claim: Graph prompting enables task-specific knowledge absorption without catastrophic forgetting by learning small task-specific prompts while keeping the GNN backbone frozen.
- Mechanism: Each task-specific prompt is learned independently using a frozen pre-trained GNN, creating separate classification models for each task without model updating or data replay.
- Core assumption: A GNN backbone pre-trained on the first task can effectively transfer knowledge to subsequent tasks when combined with task-specific prompts.
- Evidence anchors:
  - [abstract]: "we propose a novel graph prompting approach for GCIL which learns a small discriminative graph prompt for each task, essentially resulting in a separate classification model for each task"
  - [section]: "The prompt learning requires the training of a single graph neural network (GNN) only once on the first task, and no data replay is required thereafter, thereby obtaining a GCIL model being both replay-free and forget-free"
  - [corpus]: No direct evidence found for graph prompting in continual learning
- Break condition: If the pre-trained GNN backbone cannot capture generic knowledge transferable to all tasks, task-specific prompts may not be effective.

### Mechanism 3
- Claim: Accurate task ID prediction eliminates inter-task class separation by confining classification to the predicted task's class space.
- Mechanism: Task ID prediction identifies which task a test sample belongs to, allowing the model to use only the classes from that specific task rather than all learned classes.
- Core assumption: Task ID prediction accuracy is sufficiently high to reliably identify the correct task for each test sample.
- Evidence anchors:
  - [abstract]: "Our task prototype-based method can achieve 100% task ID prediction accuracy on all four datasets"
  - [section]: "High task ID prediction accuracy helps confine the classification space of the test samples to the classes of the predicted task"
  - [corpus]: No direct evidence found for task ID prediction in graph continual learning
- Break condition: If task ID prediction accuracy drops below a threshold where incorrect task assignments significantly impact classification performance.

## Foundational Learning

- Concept: Laplacian smoothing on graphs
  - Why needed here: Provides theoretical foundation for task prototype construction and ensures task prototypes converge for same-task samples while diverging for different-task samples
  - Quick check question: How does the eigenvalue spectrum of the normalized Laplacian matrix affect the convergence behavior of node embeddings under Laplacian smoothing?

- Concept: Contrastive learning for GNNs
  - Why needed here: Enables pre-training of a GNN backbone on the first task that captures transferable knowledge for subsequent tasks
  - Quick check question: What graph augmentation techniques are most effective for contrastive learning on node classification tasks?

- Concept: Prompt learning in GNNs
  - Why needed here: Allows task-specific knowledge adaptation without updating the frozen backbone, enabling replay-free and forget-free learning
  - Quick check question: How does the size and initialization of graph prompts affect the ability to capture task-specific discriminative information?

## Architecture Onboarding

- Component map:
  - Task profiling module: Constructs task prototypes using Laplacian smoothing
  - Task ID prediction module: Matches test sample prototypes to stored task prototypes
  - Graph prompting module: Learns task-specific prompts using frozen GNN
  - Classification module: Performs within-task classification using retrieved task prompt and classifier

- Critical path:
  1. Pre-train GNN backbone on first task using contrastive learning
  2. For each task, construct task prototype and learn task-specific prompt and classifier
  3. At inference, construct test prototype, predict task ID, retrieve corresponding prompt and classifier, perform classification

- Design tradeoffs:
  - Small prompt size vs. task-specific information capacity
  - Number of Laplacian smoothing steps vs. computational cost and prototype distinguishability
  - Pre-training on first task vs. potential bias toward first task characteristics

- Failure signatures:
  - Low task ID prediction accuracy indicating insufficient prototype distinguishability
  - High forgetting rates suggesting pre-trained GNN lacks sufficient transferability
  - Poor within-task classification indicating prompts don't capture sufficient task-specific information

- First 3 experiments:
  1. Evaluate task ID prediction accuracy on validation set with varying Laplacian smoothing steps
  2. Test within-task classification accuracy with frozen GNN vs. learned prompts on first task
  3. Measure AA and AF on a single dataset with all components integrated

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the content, potential open questions include:

### Open Question 1
- Question: How does the Laplacian smoothing step size (s) affect the accuracy of task ID prediction in different graph datasets with varying node attribute distributions?
- Basis in paper: [explicit] The paper mentions that task prototypes of the same graph task are nearly the same with a large smoothing step, while those of different tasks are distinct. It also shows that the method achieves 100% prediction accuracy across all four datasets used.
- Why unresolved: The paper sets the number of steps s to 3 by default and shows results for this specific value, but does not explore the sensitivity of task ID prediction accuracy to different smoothing step sizes or analyze how this might vary with different types of graph data.
- What evidence would resolve it: Systematic experiments varying the smoothing step size across different datasets with different node attribute distributions, showing how prediction accuracy changes with s and identifying optimal values for different data characteristics.

### Open Question 2
- Question: Can the task profiling approach be extended to handle graph streams where the graph structure evolves over time, rather than static graphs in each task?
- Basis in paper: [inferred] The current method constructs task prototypes based on static graph structures and node attributes for each task. The paper focuses on class-incremental learning where each task is a static graph with unique classes.
- Why unresolved: The paper does not address scenarios where graph structures change dynamically over time or where nodes/edges can appear/disappear between tasks. The Laplacian smoothing-based approach assumes a fixed graph structure for prototype construction.
- What evidence would resolve it: Experimental results showing how the method performs on graph streams with evolving structures, and modifications to the task profiling approach to handle dynamic graph changes while maintaining accurate task ID prediction.

### Open Question 3
- Question: What is the impact of the graph prompt size (number of tokens k) on the model's ability to generalize to tasks with significantly different graph properties compared to the first task?
- Basis in paper: [explicit] The paper shows that TPP's performance increases quickly from k=1 to k=2 and remains stable when k>2, demonstrating effective adaptation to different tasks with small prompt sizes. It also mentions that the GNN backbone is learned only on the first task but can adapt to subsequent tasks through graph prompts.
- Why unresolved: The experiments use a fixed prompt size of k=3 across all datasets and do not explore how varying prompt sizes affect performance when subsequent tasks have significantly different graph properties (e.g., different graph densities, different node degree distributions) compared to the first task.
- What evidence would resolve it: Experiments varying the prompt size k across datasets with different graph characteristics, analyzing how prompt size affects the model's ability to adapt to tasks with varying degrees of similarity to the first task, and identifying whether larger prompts are needed for tasks with more divergent graph properties.

## Limitations
- The approach assumes graph structures and node attributes are sufficiently discriminative between tasks, which may not hold for all graph datasets
- The memory requirement grows linearly with the number of tasks due to storing task prototypes and prompts
- Performance relies heavily on the transferability of knowledge captured by the pre-trained GNN backbone

## Confidence
- **High confidence**: The theoretical foundation of Laplacian smoothing for task profiling and the experimental results showing 100% task ID prediction accuracy
- **Medium confidence**: The effectiveness of the graph prompting approach in enabling replay-free and forget-free learning, based on comparison with other methods
- **Low confidence**: The claim of being fully forget-free, as it depends heavily on the transferability of the pre-trained GNN backbone without sufficient ablation analysis

## Next Checks
1. **Ablation study on pre-training strategy**: Compare TPP performance when pre-training the GNN backbone on different tasks (not just the first) to validate the generality of the approach and identify potential biases.

2. **Robustness testing for task ID prediction**: Evaluate task ID prediction accuracy under varying levels of graph structure perturbation and attribute noise to assess real-world applicability.

3. **Memory and computational efficiency analysis**: Measure the memory footprint and inference time of TPP compared to baseline methods, particularly the overhead introduced by storing task prototypes and prompts for each task.