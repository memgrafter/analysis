---
ver: rpa2
title: Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation
arxiv_id: '2408.10642'
source_url: https://arxiv.org/abs/2408.10642
tags:
- training
- sample
- answer
- zhang
- optimized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a modified supervised fine-tuning (SFT) method
  called MinorSFT to improve LLM training effectiveness while reducing model deviation.
  The method introduces a sample-level dynamic coefficient based on the relative log
  probability between the optimized and reference models, which implicitly adjusts
  training data distribution to focus more on complex samples.
---

# Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation

## Quick Facts
- arXiv ID: 2408.10642
- Source URL: https://arxiv.org/abs/2408.10642
- Reference count: 3
- Introduces MinorSFT method to improve LLM fine-tuning by dynamically weighting samples based on model confidence

## Executive Summary
This paper proposes MinorSFT, a modified supervised fine-tuning approach that improves LLM training effectiveness while reducing model deviation. The method introduces a sample-level dynamic coefficient based on relative log probability between optimized and reference models, implicitly adjusting training data distribution to focus on complex samples. Experiments demonstrate that MinorSFT outperforms both standard SFT and SFT using DPO, achieving better performance with lower deviation, though at the cost of increased computation and requiring tuning of an additional hyperparameter.

## Method Summary
MinorSFT modifies standard supervised fine-tuning by introducing a dynamic coefficient for each training sample based on the relative log probability between the current optimized model and a reference model. This coefficient implicitly adjusts the effective training data distribution, giving higher weights to samples that the model finds more challenging. The authors also propose a normalized metric to measure LLM deviation during training, providing a quantitative way to monitor training stability. The method requires tuning an additional hyperparameter to control the influence of the dynamic coefficient.

## Key Results
- MinorSFT outperforms raw SFT and SFT with DPO on FinanceIQ, fineval, and ceval-exam datasets
- Achieved better performance metrics while maintaining lower model deviation
- Demonstrated effectiveness using Qwen2-7B-Instruct model architecture

## Why This Works (Mechanism)
MinorSFT works by introducing a dynamic weighting mechanism that adapts to the model's learning progress. By comparing the relative log probabilities between the optimized and reference models for each sample, the method identifies which samples are more challenging for the current model state. These challenging samples receive higher weights during training, allowing the model to focus more on difficult cases rather than spending equal effort on all samples. This adaptive approach helps the model learn more efficiently while preventing excessive deviation from the reference model, which could lead to instability or loss of useful knowledge.

## Foundational Learning

**Relative log probability** - Measures the confidence difference between two models on the same input. Needed to quantify how well the optimized model is performing compared to the reference. Quick check: Compute for sample pairs and verify larger values indicate more challenging samples.

**Dynamic sample weighting** - Technique to assign different importance levels to training samples based on their characteristics or the model's current state. Needed to focus training on samples that provide the most learning value. Quick check: Monitor weight distribution over training epochs.

**Model deviation measurement** - Quantifies how much an optimized model differs from its reference model during training. Needed to ensure training stability and prevent catastrophic forgetting. Quick check: Track deviation metric across training steps to identify instability patterns.

## Architecture Onboarding

Component map: Data -> Reference Model -> Optimized Model -> Dynamic Coefficient Calculator -> Weighted Loss Function -> Updated Model

Critical path: Training data flows through the reference model to establish baseline predictions, then through the optimized model where relative log probabilities are computed. These probabilities feed into the dynamic coefficient calculator, which generates sample weights that modify the loss function. The updated model parameters are then computed and the cycle repeats.

Design tradeoffs: The method trades increased computational overhead for improved sample efficiency and reduced model deviation. The additional hyperparameter provides flexibility but requires careful tuning. The dynamic coefficient approach is more adaptive than static weighting but may introduce training instability if not properly constrained.

Failure signatures: Excessive deviation from the reference model, training instability indicated by oscillating loss values, or convergence to suboptimal solutions if the dynamic coefficient becomes too aggressive. Monitoring the normalized deviation metric helps detect these issues early.

First experiments: 1) Run baseline SFT without dynamic coefficients to establish performance floor. 2) Implement static sample weighting to compare against dynamic approach. 3) Test different hyperparameter values for the dynamic coefficient to find optimal settings.

## Open Questions the Paper Calls Out
None identified in the paper.

## Limitations
- Limited evaluation scope to single model architecture (Qwen2-7B-Instruct) and specific domains
- Computational overhead implications not fully characterized across different hardware configurations
- Hyperparameter sensitivity analysis remains incomplete, lacking guidance on optimal tuning strategies

## Confidence
- High confidence: Normalized LLM deviation metric provides reliable training stability monitoring
- Medium confidence: Computational overhead claims are reasonable but lack detailed benchmarking
- Medium confidence: Experimental results demonstrate clear improvements but limited generalizability

## Next Checks
1. Conduct systematic ablation studies removing each component of MinorSFT to quantify individual contributions
2. Test across multiple model families beyond Qwen2-7B and diverse domains to assess generalizability
3. Benchmark computational overhead on different hardware configurations and compare against wall-clock time impact in production scenarios