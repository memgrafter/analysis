---
ver: rpa2
title: 'Sub-Adjacent Transformer: Improving Time Series Anomaly Detection with Reconstruction
  Error from Sub-Adjacent Neighborhoods'
arxiv_id: '2404.18948'
source_url: https://arxiv.org/abs/2404.18948
tags:
- attention
- anomaly
- time
- sub-adjacent
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the Sub-Adjacent Transformer, a novel attention\
  \ mechanism for unsupervised time series anomaly detection. The key idea is to restrict\
  \ attention to sub-adjacent neighborhoods\u2014regions not immediately adjacent\
  \ to the target point\u2014under the observation that anomalies typically differ\
  \ more from their sub-adjacent neighborhoods than from immediate vicinities."
---

# Sub-Adjacent Transformer: Improving Time Series Anomaly Detection with Reconstruction Error from Sub-Adjacent Neighborhoods

## Quick Facts
- arXiv ID: 2404.18948
- Source URL: https://arxiv.org/abs/2404.18948
- Authors: Wenzhen Yue; Xianghua Ying; Ruohao Guo; DongDong Chen; Ji Shi; Bowei Xing; Yuqing Zhu; Taiyan Chen
- Reference count: 24
- Primary result: State-of-the-art F1 scores up to 99.0% on six real-world benchmarks using sub-adjacent attention mechanism

## Executive Summary
This paper introduces the Sub-Adjacent Transformer, a novel attention mechanism for unsupervised time series anomaly detection. The key innovation restricts attention to sub-adjacent neighborhoodsâ€”regions not immediately adjacent to the target pointâ€”under the observation that anomalies differ more from their sub-adjacent neighborhoods than from immediate vicinities. This design increases reconstruction error for anomalies, making them more detectable. The method combines linear attention with a learnable mapping function for flexible attention matrix shaping and achieves state-of-the-art performance across six real-world benchmarks and a synthetic dataset.

## Method Summary
The Sub-Adjacent Transformer modifies standard transformer attention by focusing on sub-adjacent neighborhoods (regions between K1 and K2 distances from the target point) rather than immediate neighbors. The model uses linear attention with a learnable mapping function (row-wise Softmax with temperature) instead of vanilla self-attention to provide greater flexibility in attention matrix shaping. The anomaly score combines normalized attention contribution from sub-adjacent regions with reconstruction error, weighted by reconstruction loss. The model is trained using a combined loss of reconstruction error and attention loss, with early stopping and hyperparameter optimization for K1, K2, and lambda values.

## Key Results
- Achieves state-of-the-art F1 scores up to 99.0% on six real-world benchmarks (SWaT, WADI, PSM, MSL, SMAP, SMD)
- Superior performance on synthetic NeurIPS-TS dataset with five anomaly types (global, contextual, shapelet, seasonal, trend)
- Demonstrates robustness to training set size and parameter choices, maintaining high performance across different configurations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Focusing attention on sub-adjacent neighborhoods increases reconstruction error for anomalies more than for normal points.
- Mechanism: Anomalies have less correlation with their non-immediate neighbors than normal points. By restricting attention to these sub-adjacent regions, reconstruction becomes more difficult for anomalies, making them easier to detect through higher reconstruction error.
- Core assumption: Anomalies are less related to their non-immediate neighborhoods compared to normal points.
- Evidence anchors:
  - [abstract]: "our method restricts the attention to regions not immediately adjacent to the target points, termed sub-adjacent neighborhoods. Our key observation is that owing to the rarity of anomalies, they typically exhibit more pronounced differences from their sub-adjacent neighborhoods than from their immediate vicinities."
  - [section 3.2]: "Time points usually have stronger connections with their neighbors and fewer connections with distant points. This characteristic is more pronounced for anomalies."
- Break condition: If anomalies show similar patterns to normal points in sub-adjacent regions, or if the reconstruction error distribution between anomalies and normal points doesn't differ significantly in these regions.

### Mechanism 2
- Claim: Linear attention with learnable mapping function provides more flexibility in shaping the attention matrix than vanilla self-attention.
- Mechanism: Traditional softmax-based self-attention creates competition among values in the same row, limiting attention distribution patterns. Linear attention with a learnable mapping function allows more flexible attention patterns that can better emphasize sub-adjacent regions.
- Core assumption: The traditional softmax operation impedes the formation of desired attention matrix patterns where sub-adjacent regions are dominant.
- Evidence anchors:
  - [section 3.2]: "The traditional Softmax operation used in standard self-attention impedes the formation of the desired attention matrix, where the predefined non-diagonal stripes are dominant. In response, we adopt linear attention for its greater flexibility in attention matrix configurations."
  - [section 3.2]: "As shown in Figure 3, linear attention demonstrates better attention matrix shaping capabilities."
- Break condition: If the learnable mapping function fails to learn an effective pattern or if vanilla self-attention with appropriate modifications can achieve similar results.

### Mechanism 3
- Claim: The combination of sub-adjacent attention contribution and reconstruction error provides a more discriminative anomaly score than using either alone.
- Mechanism: Anomalies typically have lower attention contribution in sub-adjacent regions and higher reconstruction errors. By combining these two signals (with softmax normalization on the attention contribution), the resulting anomaly score better distinguishes anomalies from normal points.
- Core assumption: Anomalies exhibit less attention contribution and higher reconstruction errors compared to normal points.
- Evidence anchors:
  - [section 3.2]: "Moreover, it assists in anomaly detection. This is due to its incorporation into the anomaly score calculation, where anomalies typically show a lower attention contribution than normal points."
  - [section 3.3]: "AnomalyScore (X) = Softmax (âˆ’SACon (A)) âŠ™ h X:,ð‘– âˆ’ Ë†X:,ð‘– 2 ð¹ ið‘–=1,Â·Â·Â·ð‘‡"
- Break condition: If anomalies don't consistently show lower attention contribution or if reconstruction error alone is sufficient for detection.

## Foundational Learning

- Concept: Transformer attention mechanisms
  - Why needed here: The paper builds on transformer architecture but modifies the attention mechanism specifically for time series anomaly detection.
  - Quick check question: How does standard self-attention work, and what are its limitations for time series anomaly detection?

- Concept: Linear attention mechanisms
  - Why needed here: The paper uses linear attention instead of vanilla self-attention to achieve the desired attention matrix pattern.
  - Quick check question: What is the difference between linear attention and vanilla self-attention, and why does linear attention provide more flexibility?

- Concept: Time series anomaly detection fundamentals
  - Why needed here: Understanding the problem domain is crucial for appreciating why the sub-adjacent attention approach is effective.
  - Quick check question: What are the main challenges in unsupervised time series anomaly detection, and how do reconstruction-based methods typically work?

## Architecture Onboarding

- Component map:
  - Input data (X) -> StandardScaler normalization -> Conv1d positional encoding -> 3-layer Sub-Adjacent Transformer with linear attention -> Reconstructed output (Ë†X) -> Combined loss (reconstruction + attention) -> Anomaly score (attention contribution + reconstruction error)

- Critical path:
  1. Preprocess input data with StandardScaler
  2. Apply positional encoding
  3. Pass through 3-layer Sub-Adjacent Transformer
  4. Compute reconstruction loss and attention loss
  5. Calculate anomaly score using both attention contribution and reconstruction error
  6. Apply dynamic Gaussian scoring for final anomaly detection

- Design tradeoffs:
  - Window size: Affects the temporal context captured (100 used in experiments)
  - K1 and K2 parameters: Define the sub-adjacent region boundaries (20 and 30 used in experiments)
  - Lambda parameter: Balances reconstruction and attention losses (10 used in experiments)
  - Linear vs. vanilla attention: Linear provides more flexibility but may be less efficient for small windows

- Failure signatures:
  - Poor performance on datasets with different characteristics: May indicate suboptimal K1/K2 parameters
  - High GPU memory usage: Could suggest issues with linear attention implementation
  - Inconsistent results across runs: May indicate sensitivity to initialization or learning rate

- First 3 experiments:
  1. Verify the attention matrix pattern: Visualize the attention matrix to ensure sub-adjacent regions are being emphasized
  2. Test different K1/K2 values: Evaluate performance with various sub-adjacent region definitions
  3. Compare linear vs. vanilla attention: Measure the impact of the attention mechanism choice on detection performance

## Open Questions the Paper Calls Out
- The paper does not explicitly call out open questions, but the following areas remain unexplored:
  - How does the Sub-Adjacent Transformer's performance scale with increasing window sizes, and what are the computational trade-offs of using larger windows?
  - How does the model's performance compare across datasets with different anomaly rates and types when using the same hyperparameter settings?
  - How does the choice of the mapping function in linear attention affect performance, and are there other potential mapping functions that could further improve the model's effectiveness?

## Limitations
- The core assumption that anomalies differ more from sub-adjacent neighborhoods than normal points is not directly validated through ablation studies or controlled experiments
- The optimal parameterization of K1 and K2 values is not clearly defined and may vary significantly across different datasets
- Computational efficiency claims are based on window size 100, and performance at larger scales remains unexplored

## Confidence
- **Mechanism 1**: Medium - supported by author observations but lacking direct experimental validation
- **Mechanism 2**: Medium - shows improvement over baseline but ablation studies are limited
- **Mechanism 3**: High - consistent performance across benchmarks, though weighting is not thoroughly explored

## Next Checks
1. **Ablation study on attention mechanism**: Compare sub-adjacent attention with standard self-attention, adjacent attention, and random attention patterns to isolate the specific benefit of the sub-adjacent approach.

2. **Parameter sensitivity analysis**: Systematically vary K1 and K2 parameters across a wider range to determine optimal values for different dataset characteristics and identify patterns in parameter selection.

3. **Cross-dataset generalization test**: Evaluate model performance when trained on one dataset type and tested on another (e.g., train on SMAP, test on SWaT) to assess the generality of the sub-adjacent attention mechanism beyond dataset-specific patterns.