---
ver: rpa2
title: Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models
  for Text-to-Code Generation
arxiv_id: '2409.04164'
source_url: https://arxiv.org/abs/2409.04164
tags:
- code
- tasks
- chatgpt
- error
- llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates five large language models (ChatGPT, BingChat,
  Bard, Llama2, and Code Llama) for their ability to generate Python code from natural
  language problem descriptions sourced from LeetCode. The models are tested on 89
  tasks across three difficulty levels, with their outputs assessed using LeetCode's
  automated testing system.
---

# Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation

## Quick Facts
- arXiv ID: 2409.04164
- Source URL: https://arxiv.org/abs/2409.04164
- Reference count: 40
- Primary result: ChatGPT solved 58% of LeetCode tasks correctly, outperforming other LLMs including code-specialized models

## Executive Summary
This study evaluates five large language models (ChatGPT, BingChat, Bard, Llama2, and Code Llama) for their ability to generate Python code from natural language problem descriptions sourced from LeetCode. The models are tested on 89 tasks across three difficulty levels, with their outputs assessed using LeetCode's automated testing system. Results show significant performance differences: ChatGPT solves 58% of tasks correctly, far outperforming others, including code-specialized models like Code Llama (9%). Code Llama also requires manual indentation fixes before execution. Across correct solutions, LLM-generated code often outperforms human submissions in runtime and memory efficiency. Shorter prompts correlate with higher success rates. Error analysis reveals "wrong answer" as the most frequent failure mode (>50%), suggesting partial correctness in many cases. While ChatGPT proves highly effective, all models still require critical review before deployment.

## Method Summary
The study evaluates five large language models on their ability to generate Python code from LeetCode problem descriptions. The evaluation uses 89 problems spanning easy, medium, and hard difficulty levels. Models are tested using LeetCode's automated testing system, which provides pass/fail outcomes. Code Llama required manual indentation fixes before execution. Performance is measured by the percentage of tasks solved correctly, with additional analysis of runtime and memory efficiency compared to human submissions. Prompt length is also examined for correlation with success rates.

## Key Results
- ChatGPT achieved 58% correct solutions, significantly outperforming other models
- Code Llama, despite being code-specialized, only achieved 9% correctness and required manual fixes
- LLM-generated correct code typically outperformed human submissions in runtime and memory efficiency
- Shorter prompts correlated with higher success rates across models
- "Wrong answer" was the most frequent failure mode (>50%), suggesting partial correctness in many cases

## Why This Works (Mechanism)
Assumption: ChatGPT's superior performance likely stems from its general-purpose training on diverse web data combined with reinforcement learning from human feedback, which may have exposed it to a broader range of programming patterns and problem-solving approaches than specialized code models trained primarily on code repositories.

## Foundational Learning
Unknown: The paper doesn't explicitly detail the foundational learning approaches or training methodologies that enabled these models to perform text-to-code generation tasks.

## Architecture Onboarding
Component Map: Problem Description -> LLM Model -> Code Generation -> LeetCode Test Suite -> Pass/Fail Result
Critical Path: Natural language input → Model inference → Code output → Automated testing → Performance evaluation
Design Tradeoffs: Specialized code models vs general LLMs, prompt length vs performance, automated testing vs human review
Failure Signatures: "Wrong answer" >50% of failures, requiring manual indentation fixes for Code Llama, limited generalizability beyond LeetCode
First Experiments:
1. Test models on non-LeetCode programming tasks to assess generalizability
2. Implement human expert review of incorrect solutions to identify partial correctness
3. Experiment with prompt engineering techniques to improve performance

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly call out specific open questions for further research.

## Limitations
- Exclusive use of LeetCode problems limits generalizability to real-world programming tasks
- Automated test suite provides only pass/fail outcomes without insight into partial correctness
- Lack of human expert review leaves uncertainty about the nature of incorrect solutions
- Study doesn't explore prompt engineering strategies that might improve model performance

## Confidence
High confidence: ChatGPT's superior performance, correlation between prompt length and success, comparative efficiency of LLM-generated code
Medium confidence: Performance ranking of BingChat and Bard, generalizability to non-LeetCode tasks
Low confidence: Specific failure modes beyond "wrong answer," absolute quality of incorrect solutions without expert evaluation

## Next Checks
1. Replicate the study using a broader corpus of real-world programming problems from diverse sources to assess generalizability
2. Conduct human expert code reviews of a representative sample of both correct and incorrect model outputs to identify nuanced patterns in model reasoning
3. Test the impact of prompt engineering strategies on model performance across all evaluated LLMs to determine if current results reflect model capability or prompt sensitivity