---
ver: rpa2
title: 'Smart Multi-Modal Search: Contextual Sparse and Dense Embedding Integration
  in Adobe Express'
arxiv_id: '2408.14698'
source_url: https://arxiv.org/abs/2408.14698
tags:
- search
- embeddings
- multi-modal
- queries
- clip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper describes a series of AB tests to optimize multi-modal
  search for Adobe Express templates. The approach integrates sparse, dense, and contextual
  features using CLIP-style embeddings (AdobeCLIP) and a domain-specific intent model
  (MM-CKG).
---

# Smart Multi-Modal Search: Contextual Sparse and Dense Embedding Integration in Adobe Express

## Quick Facts
- **arXiv ID:** 2408.14698
- **Source URL:** https://arxiv.org/abs/2408.14698
- **Reference count:** 19
- **Key outcome:** Integration of sparse, dense, and contextual features using AdobeCLIP and MM-CKG models significantly improved multi-modal search performance, reducing null rates by over 70% and increasing click-through rates by up to 17%.

## Executive Summary
This paper presents a novel multi-modal search system for Adobe Express templates that integrates sparse, dense, and contextual embeddings. The approach uses AdobeCLIP embeddings for sparse matching and dense reranking, combined with a domain-specific intent model (MM-CKG) for contextual understanding. The system shows significant improvements in search performance, particularly for complex queries, demonstrating the effectiveness of combining multiple embedding types for enhanced retrieval accuracy.

## Method Summary
The method employs a hybrid approach combining sparse and dense embeddings with contextual features. Sparse AdobeCLIP embeddings are used for initial matching to improve recall, while dense embeddings handle reranking. For queries with four or more words, MM-CKG embeddings are used for both matching and ranking. The system also incorporates symbolic CKG intents to handle null and low recovery cases. This multi-stage pipeline leverages different embedding types based on query complexity to optimize both recall and precision in template retrieval.

## Key Results
- Null rates reduced by over 70% through the integrated embedding approach
- Click-through rates increased by up to 17% compared to baseline methods
- Significant performance improvements for complex multi-modal search queries

## Why This Works (Mechanism)
The system works by leveraging the complementary strengths of different embedding types. Sparse embeddings capture broad semantic relationships and improve recall by matching relevant templates that might be missed by exact matching. Dense embeddings provide fine-grained semantic understanding for precise reranking. The MM-CKG model adds contextual awareness for complex queries, while symbolic intents handle edge cases. This multi-layered approach ensures both broad coverage and precise matching across varying query complexities.

## Foundational Learning
- **Sparse vs Dense Embeddings**: Why needed - Sparse embeddings capture broad semantic relationships while dense embeddings provide precise semantic matching. Quick check - Compare retrieval performance using only sparse vs only dense embeddings.
- **Multi-stage Retrieval**: Why needed - Different stages optimize for recall and precision separately. Quick check - Measure improvement in precision@K after reranking stage.
- **Contextual Embeddings**: Why needed - Long queries require understanding of complex user intent. Quick check - Evaluate performance difference for queries â‰¥4 words vs shorter queries.
- **Hybrid Search Systems**: Why needed - Combining multiple approaches addresses different failure modes. Quick check - Perform ablation studies removing each component.
- **Domain-specific Intent Models**: Why needed - Template search has unique requirements and vocabulary. Quick check - Compare performance against general-purpose language models.
- **Embedding Dimensionality Trade-offs**: Why needed - Higher dimensions improve accuracy but increase computational cost. Quick check - Benchmark performance vs latency across different embedding sizes.

## Architecture Onboarding
- **Component Map**: User Query -> AdobeCLIP Sparse Matching -> AdobeCLIP Dense Reranking -> MM-CKG Contextual Processing -> Result Ranking -> Display
- **Critical Path**: Query processing through embedding generation, retrieval, and ranking stages
- **Design Tradeoffs**: Balance between retrieval recall and ranking precision, computational cost vs accuracy, complexity of multi-stage pipeline vs performance gains
- **Failure Signatures**: High null rates indicate sparse matching issues, poor ranking suggests dense embedding problems, context misunderstanding points to MM-CKG limitations
- **First Experiments**: (1) Baseline performance measurement with single embedding type, (2) A/B testing of sparse vs dense only approaches, (3) Evaluation of query length impact on different embedding strategies

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Domain-specific evaluation limits generalizability to other product types
- Computational costs and latency implications of multi-stage pipeline not addressed
- Limited discussion of edge cases and ambiguous query handling
- Lack of detailed statistical significance metrics beyond reported percentages

## Confidence
- **High** confidence in sparse and dense embedding combination effectiveness
- **Medium** confidence in MM-CKG integration for long queries
- **Low** confidence in overall approach generalization to other domains

## Next Checks
1. Conduct cross-domain experiments to validate the approach on non-Adobe Express template datasets
2. Perform ablation studies to quantify individual contributions of sparse, dense, and contextual embeddings
3. Evaluate computational efficiency and latency impact of the multi-stage pipeline in production settings