---
ver: rpa2
title: 'Modular addition without black-boxes: Compressing explanations of MLPs that
  compute numerical integration'
arxiv_id: '2412.03773'
source_url: https://arxiv.org/abs/2412.03773
tags:
- frequency
- relu
- error
- neurons
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work provides the first rigorous case study in compressing
  nonlinear feature-maps in mechanistic interpretability. The authors analyze the
  MLP layer in modular addition transformers, which had previously been treated as
  a black box despite the rest of the model being well-understood.
---

# Modular addition without black-boxes: Compressing explanations of MLPs that compute numerical integration

## Quick Facts
- **arXiv ID**: 2412.03773
- **Source URL**: https://arxiv.org/abs/2412.03773
- **Reference count**: 40
- **Primary result**: First rigorous case study in compressing nonlinear feature-maps in mechanistic interpretability, interpreting MLPs as numerical integration schemes

## Executive Summary
This work provides the first rigorous case study in compressing nonlinear feature-maps in mechanistic interpretability. The authors analyze the MLP layer in modular addition transformers, which had previously been treated as a black box despite the rest of the model being well-understood. The key insight is interpreting the MLP as performing numerical integration: each neuron computes the area of a rectangle under a trigonometric curve. Specifically, the MLP can be understood as evaluating a quadrature scheme for integrals of the form ∫ReLU[cos(k(a+b)/2 + ϕ)] cos(kc + 2ϕ)dϕ. To validate this interpretation, the authors derive non-vacuous error bounds on the MLP's output in time linear in the parameter count - achieving the theoretical minimum complexity.

## Method Summary
The authors develop a framework for interpreting MLP layers as numerical integration schemes, specifically quadrature methods for evaluating integrals involving trigonometric functions. They analyze the modular addition transformer architecture by decomposing the MLP's computation into a series of rectangular area calculations under ReLU-activated cosine curves. The validation approach involves deriving mathematical error bounds that are provably non-vacuous (achieved in linear time complexity) and comparing these theoretical bounds against empirical measurements of the actual model error (0.03-0.05 vs theoretical bound of 0.48-0.70). The methodology combines mechanistic interpretability techniques with numerical analysis to create compressed explanations of the MLP's functionality.

## Key Results
- First rigorous case study in compressing nonlinear feature-maps in mechanistic interpretability
- MLP interpreted as numerical integration scheme with provable non-vacuous error bounds
- Actual error (0.03-0.05) significantly lower than theoretical bounds (0.48-0.70), confirming practical utility
- Explains why modular addition model logits resemble Nanda et al.'s "clock" algorithm rather than Zhong et al.'s "pizza" algorithm

## Why This Works (Mechanism)
The MLP layer functions as a numerical integration scheme where each neuron computes the area of a rectangle under a ReLU-activated trigonometric curve. This interpretation works because the modular addition task can be expressed as integrals of the form ∫ReLU[cos(k(a+b)/2 + ϕ)] cos(kc + 2ϕ)dϕ, where k is a frequency parameter and ϕ represents phase. The ReLU activation creates piecewise linear segments that approximate the integral using rectangular quadrature. The use of secondary frequencies (twice the primary) compensates when the primary frequency's contribution becomes small, explaining why the model's logits resemble the "clock" algorithm rather than the "pizza" algorithm.

## Foundational Learning
- **Numerical Integration (Quadrature)**: Methods for approximating definite integrals using discrete samples - needed to understand how the MLP computes trigonometric integrals; quick check: verify that rectangular area approximation converges to true integral as sample count increases
- **Mechanistic Interpretability**: Techniques for reverse-engineering neural network computations - needed to connect MLP weights to mathematical operations; quick check: trace how individual neuron activations contribute to final output
- **ReLU Activation Function**: Piecewise linear function that outputs max(0, x) - needed to understand the piecewise structure of the integration scheme; quick check: confirm that ReLU creates the sharp transitions in the integration regions
- **Modular Arithmetic**: Operations on integers where values wrap around at a certain point - needed to understand the problem domain being solved; quick check: verify that cos(2π(a+b)/N) correctly represents modular addition in the frequency domain
- **Trigonometric Integrals**: Integrals involving sine and cosine functions - needed to derive the analytical form of what the MLP is computing; quick check: confirm that the integral of cos² over a period equals π
- **Error Bounds in Numerical Analysis**: Mathematical guarantees on approximation accuracy - needed to validate the compression quality; quick check: verify that the derived bound is non-vacuous (tighter than trivial bounds)

## Architecture Onboarding

Component Map:
Input Embeddings -> Attention Layer -> MLP Layer -> Output Layer

Critical Path:
The MLP layer is the critical component being analyzed, positioned after the attention mechanism and before the output projection. It performs the numerical integration that computes the final logits.

Design Tradeoffs:
The architecture trades computational efficiency for interpretability - using a simple MLP structure that enables mathematical analysis while maintaining sufficient capacity for accurate modular addition computation. The choice of ReLU activation and specific frequency patterns enables the quadrature interpretation while balancing expressivity and analyzability.

Failure Signatures:
When the quadrature interpretation fails, the model would show systematic errors in regions where the rectangular approximation poorly matches the true integral, particularly near phase boundaries where ReLU creates discontinuities. The error bounds would become vacuous (exceeding trivial bounds) and the actual error would deviate significantly from the theoretical predictions.

First Experiments:
1. Measure actual vs predicted error across different input ranges to verify the quadrature interpretation holds uniformly
2. Visualize individual neuron activations as rectangles under the ReLU curve to confirm the area interpretation
3. Perform frequency analysis on the learned weights to verify the secondary frequency compensation mechanism

## Open Questions the Paper Calls Out
None

## Limitations
- Focuses on a single, relatively simple model architecture (modular addition transformers), limiting generalizability
- Error bounds (0.48-0.70) are notably looser than actual errors (0.03-0.05), suggesting potential for refinement
- The claim that this approach could extend to other architectures remains speculative without additional empirical validation

## Confidence

| Claim | Confidence |
|-------|------------|
| Numerical integration interpretation of MLP layer | Medium |
| Error bound validity | High |
| Secondary frequency compensation explanation | Medium |

## Next Checks

1. Apply the numerical integration interpretation framework to other small transformer tasks with known analytical solutions (e.g., modular multiplication, or different algebraic operations) to test generalizability.

2. Experimentally manipulate the MLP architecture (width, depth, activation functions) to determine which components are essential for the numerical integration interpretation versus incidental to the modular addition task.

3. Conduct ablation studies that systematically disable or modify specific neurons to verify whether the quadrature scheme interpretation correctly predicts which neurons are critical for accurate computation.