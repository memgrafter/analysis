---
ver: rpa2
title: 'MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities'
arxiv_id: '2405.17419'
source_url: https://arxiv.org/abs/2405.17419
tags:
- detection
- training
- np-mix
- classes
- video
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting out-of-distribution
  (OOD) samples in multimodal settings, which is critical for safety-critical applications.
  The authors introduce MultiOOD, a novel benchmark for multimodal OOD detection,
  comprising diverse datasets and modality combinations.
---

# MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities

## Quick Facts
- arXiv ID: 2405.17419
- Source URL: https://arxiv.org/abs/2405.17419
- Reference count: 40
- Key outcome: MultiOOD benchmark + A2D algorithm + NP-Mix method achieve 21.46% absolute FPR95 improvement on UCF101

## Executive Summary
This paper addresses the critical problem of detecting out-of-distribution (OOD) samples in multimodal settings, which is essential for safety-critical applications. The authors introduce MultiOOD, a comprehensive benchmark for multimodal OOD detection spanning five action recognition datasets with video, optical flow, and audio modalities. They propose the Agree-to-Disagree (A2D) algorithm that amplifies modality prediction discrepancies during training, and NP-Mix, a novel outlier synthesis method that explores broader feature spaces. Extensive experiments demonstrate that training with A2D and NP-Mix significantly improves existing OOD detection algorithms, reducing FPR95 from 32.14% to 10.68% on UCF101 for the ASH method.

## Method Summary
The method combines A2D training with NP-Mix outlier synthesis. A2D encourages modalities to agree on ground-truth predictions while disagreeing on all other classes, amplifying the Modality Prediction Discrepancy phenomenon where ID samples produce similar softmax predictions across modalities but OOD samples yield divergent predictions. NP-Mix synthesizes outliers by convexly combining embeddings from a target class with embeddings from its nearest neighbor classes, creating synthetic samples that span class boundaries rather than clustering near ID samples. The approach is evaluated on the MultiOOD benchmark using multiple OOD detection algorithms with and without A2D/NP-Mix training.

## Key Results
- FPR95 reduced from 32.14% to 10.68% on UCF101 for ASH method (21.46% absolute improvement)
- NP-Mix explores broader feature spaces by leveraging nearest neighbor classes for outlier synthesis
- Combining A2D training with NP-Mix yields multiplicative improvements in OOD detection performance
- MultiOOD benchmark enables comprehensive evaluation across Near-OOD and Far-OOD scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Modality Prediction Discrepancy drives OOD detection improvement
- **Mechanism**: A2D amplifies the inherent difference where ID samples produce similar predictions across modalities while OOD samples yield divergent predictions
- **Core assumption**: OOD samples naturally produce larger prediction discrepancies across modalities than ID samples
- **Evidence anchors**: Strong empirical support in the paper, but relies on core assumption validation across diverse datasets
- **Confidence**: Medium

### Mechanism 2
- **Claim**: NP-Mix improves OOD detection by generating boundary-spanning outliers
- **Mechanism**: Synthesizes outliers by combining embeddings from target classes with nearest neighbor classes
- **Core assumption**: Boundary-spanning outliers are more effective than ID-near outliers for training OOD detection
- **Evidence anchors**: Novel approach with good results, but effectiveness depends on dataset characteristics
- **Confidence**: Medium

### Mechanism 3
- **Claim**: A2D + NP-Mix combination yields multiplicative rather than additive improvements
- **Mechanism**: A2D creates disagreement patterns while NP-Mix tests them in challenging scenarios
- **Core assumption**: Effects are complementary rather than simply additive
- **Evidence anchors**: Empirical results promising but theoretical understanding limited
- **Confidence**: Low-Medium

## Foundational Learning

- **Concept**: Modality fusion and multimodal representation learning
  - Why needed here: Understanding how video, audio, and optical flow modalities combine effectively
  - Quick check question: What are the advantages and disadvantages of early fusion vs late fusion in multimodal learning?

- **Concept**: Outlier synthesis and data augmentation techniques
  - Why needed here: NP-Mix is a novel outlier synthesis method requiring understanding of synthetic data use
  - Quick check question: How does Mixup differ from traditional data augmentation techniques, and what are its theoretical underpinnings?

- **Concept**: OOD detection metrics and evaluation protocols
  - Why needed here: Understanding FPR95, AUROC, and Near-OOD vs Far-OOD evaluation
  - Quick check question: What is the difference between Near-OOD and Far-OOD setups, and why is this distinction important?

## Architecture Onboarding

- **Component map**: MultiOOD Benchmark -> Feature extractors (SlowFast, ResNet-18) -> Classifiers -> Training pipeline (CE + A2D + NP-Mix) -> Evaluation

- **Critical path**: 
  1. Load multimodal data and extract features from each modality
  2. Compute predictions from combined and individual modality embeddings
  3. Calculate A2D discrepancy loss between modality predictions (excluding ground-truth)
  4. Synthesize outliers using NP-Mix and compute additional losses
  5. Backpropagate combined loss through the network
  6. Evaluate OOD detection performance using standard metrics

- **Design tradeoffs**:
  - Training complexity vs performance: A2D and NP-Mix add overhead but significantly improve OOD detection
  - Modality selection: More modalities improve performance but increase computational cost and potential imbalance
  - Distance metric selection: Hellinger works well but alternatives could be explored

- **Failure signatures**:
  - Poor OOD detection despite A2D/NP-Mix: Modality Prediction Discrepancy assumption may not hold
  - Overfitting to synthesized outliers: NP-Mix may generate outliers too close to ID distribution
  - Modality collapse: A2D may force modalities to become too similar

- **First 3 experiments**:
  1. Implement A2D on HMDB51 with video and optical flow, verify increased prediction discrepancy for OOD samples
  2. Implement NP-Mix and visualize synthesized outliers to confirm boundary-spanning behavior
  3. Combine A2D and NP-Mix, evaluate FPR95 improvement vs baseline unimodal methods

## Open Questions the Paper Calls Out
- How does A2D perform on datasets with 1000+ classes? (Untested on MultiOOD benchmark)
- How does NP-Mix perform with different distance metrics for outlier synthesis?
- Can A2D and NP-Mix be effectively applied to multimodal settings beyond video, audio, and optical flow (e.g., LiDAR and radar data)?

## Limitations
- Modality Prediction Discrepancy assumption may not hold for highly correlated modalities
- NP-Mix effectiveness depends on meaningful semantic boundaries between classes
- Multiplicative improvement claims lack theoretical justification for complementarity

## Confidence
- Mechanism 1 (Modality Prediction Discrepancy): Medium - Strong empirical support but relies on core assumption
- Mechanism 2 (NP-Mix): Medium - Novel approach with good results, but dataset-dependent
- Mechanism 3 (Combined effect): Low-Medium - Empirical results promising but theoretical understanding limited

## Next Checks
1. Test Modality Prediction Discrepancy assumption on datasets with highly correlated modalities
2. Evaluate NP-Mix performance on datasets with ambiguous class boundaries
3. Conduct ablation studies to quantify individual vs combined contributions of A2D and NP-Mix