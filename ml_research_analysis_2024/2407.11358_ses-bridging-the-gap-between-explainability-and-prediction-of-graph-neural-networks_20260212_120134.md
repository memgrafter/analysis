---
ver: rpa2
title: 'SES: Bridging the Gap Between Explainability and Prediction of Graph Neural
  Networks'
arxiv_id: '2407.11358'
source_url: https://arxiv.org/abs/2407.11358
tags:
- graph
- node
- learning
- explanations
- gnns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving both high prediction
  accuracy and interpretability in Graph Neural Networks (GNNs). The authors propose
  SES, a self-explained and self-supervised GNN that bridges the gap between explainability
  and prediction.
---

# SES: Bridging the Gap Between Explainability and Prediction of Graph Neural Networks

## Quick Facts
- arXiv ID: 2407.11358
- Source URL: https://arxiv.org/abs/2407.11358
- Authors: Zhenhua Huang; Kunhao Li; Shaojie Wang; Zhaohong Jia; Wentao Zhu; Sharad Mehrotra
- Reference count: 40
- Primary result: Proposed SES achieves state-of-the-art performance in both explanation and prediction tasks, outperforming baselines by up to 2.59% in node classification accuracy and up to 3.0% in explanation tasks.

## Executive Summary
This paper addresses the challenge of achieving both high prediction accuracy and interpretability in Graph Neural Networks (GNNs). The authors propose SES, a self-explained and self-supervised GNN that bridges the gap between explainability and prediction. SES consists of two phases: explainable training and enhanced predictive learning. During explainable training, a global mask generator is co-trained with a graph encoder to produce crucial structure and feature masks, providing node feature and subgraph explanations. In the enhanced predictive learning phase, mask-based positive-negative pairs are constructed to compute a triplet loss and enhance node representations through contrastive learning. Experimental results demonstrate that SES achieves state-of-the-art performance in both explanation and prediction tasks on real-world and synthetic datasets.

## Method Summary
SES (Self-Explained and Self-Supervised) is a GNN model designed to achieve both high prediction accuracy and interpretability. It consists of two main phases: explainable training and enhanced predictive learning. In the explainable training phase, a global mask generator is co-trained with a graph encoder to produce feature and structure masks that highlight important node features and substructures. These masks are used to provide explanations for the model's predictions. In the enhanced predictive learning phase, mask-based positive-negative pairs are constructed to compute a triplet loss, which enhances node representations through contrastive learning. The model is trained using a combination of cross-entropy loss for supervised learning, subgraph loss for explanation quality, and triplet loss for contrastive learning.

## Key Results
- SES outperforms baseline models by up to 2.59% in node classification accuracy on real-world datasets.
- SES achieves up to 3.0% improvement in explanation quality compared to state-of-the-art post-hoc explainers.
- SES demonstrates faster training and explanation generating times compared to post-hoc methods like GNNExplainer.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SES achieves high prediction accuracy and interpretability by co-training a global mask generator with a graph encoder during explainable training.
- Mechanism: The mask generator produces feature and structure masks that directly align with the graph encoder's aggregation process, eliminating the need for computationally expensive subgraph searches.
- Core assumption: The masks generated by the mask generator are meaningful and accurately capture the most relevant features and substructures for each node.
- Evidence anchors:
  - [abstract]: "SES employs a global mask generator co-trained with a graph encoder and directly produces crucial structure and feature masks, reducing time consumption and providing node feature and subgraph explanations."
  - [section]: "During explainable training, SES employs a global mask generator co-trained with a graph encoder and directly produces crucial structure and feature masks, reducing time consumption and providing node feature and subgraph explanations."
- Break condition: If the mask generator fails to produce meaningful masks, the explanations and prediction accuracy will be compromised.

### Mechanism 2
- Claim: SES improves prediction performance by utilizing the generated masks to construct positive-negative node pairs for contrastive learning.
- Mechanism: Mask-based positive-negative pairs are created to compute a triplet loss, ensuring nodes with similar structures are closely situated and discriminating nodes with dissimilar structural attributes.
- Core assumption: The positive-negative node pairs constructed from the masks effectively capture the structural similarities and differences between nodes.
- Evidence anchors:
  - [abstract]: "In the enhanced predictive learning phase, mask-based positive-negative pairs are constructed utilizing the explanations to compute a triplet loss and enhance the node representations by contrastive learning."
  - [section]: "To utilize these explanations and improve prediction performance, inspired by contrastive learning (a self-supervised method), mask-based positive and negative pairs are created to compute a triplet loss that ensures nodes with similar structures are closely situated and discriminates nodes with dissimilar structural attributes."
- Break condition: If the positive-negative node pairs fail to capture meaningful structural relationships, the contrastive learning will not effectively enhance the node representations.

### Mechanism 3
- Claim: SES provides more coherent explanations than post-hoc methods by co-training the masks with the graph encoder.
- Mechanism: The feature and structure masks are co-trained with the graph encoder using a dedicated loss, ensuring consistency between the explanations and the model's decision-making process.
- Core assumption: The co-training process ensures that the masks accurately reflect the graph encoder's aggregation and decision process.
- Evidence anchors:
  - [abstract]: "SES provides more coherent explanations on real-world datasets, has a fourfold increase in Fidelity+ score for explanation quality, and demonstrates faster training and explanation generating times."
  - [section]: "The feature and structure masks in SES directly work on the feature and adjacency matrices, respectively, and they are co-trained with the backbone GNN by Eq. (8). It ensures feature and structure masks are consistent with the backbone GNN's aggregation and decision process."
- Break condition: If the co-training process fails to align the masks with the graph encoder's decision-making process, the explanations will be less coherent and potentially misleading.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: SES is a GNN-based model that leverages the graph structure and node features for prediction and explanation tasks.
  - Quick check question: What is the main idea behind GNNs, and how do they differ from traditional neural networks?

- Concept: Self-Supervised Learning
  - Why needed here: SES uses self-supervised learning techniques, such as contrastive learning, to enhance the node representations and improve prediction accuracy.
  - Quick check question: What is the main goal of self-supervised learning, and how does it differ from supervised and unsupervised learning?

- Concept: Model Explainability
  - Why needed here: SES aims to provide both accurate predictions and interpretable explanations, which is crucial for building trust and understanding in the model's decision-making process.
  - Quick check question: What are the main challenges in achieving model explainability, and why is it important in the context of GNNs?

## Architecture Onboarding

- Component map: Graph encoder -> Mask generator -> Contrastive learning module -> Supervised learning module

- Critical path:
  1. Explainable training phase: Co-train the graph encoder and mask generator to generate feature and structure masks.
  2. Enhanced predictive learning phase: Construct positive-negative node pairs from the masks and apply contrastive learning to improve node representations.

- Design tradeoffs:
  - Tradeoff between prediction accuracy and explainability: SES aims to achieve both, but there may be cases where improving one comes at the cost of the other.
  - Computational complexity: The mask generator and contrastive learning modules add computational overhead, which may impact training and inference time.

- Failure signatures:
  - Poor prediction accuracy: If the model fails to achieve high accuracy on node classification tasks, it may indicate issues with the graph encoder, mask generator, or contrastive learning module.
  - Unreliable explanations: If the generated explanations do not align with the model's decision-making process or fail to capture important features and substructures, it may suggest problems with the mask generator or co-training process.

- First 3 experiments:
  1. Validate the performance of SES on a small synthetic dataset (e.g., BAShapes) to ensure the model can generate accurate explanations and achieve high prediction accuracy.
  2. Compare the time consumption of SES with post-hoc explainers (e.g., GNNExplainer) on a real-world dataset (e.g., Cora) to demonstrate the efficiency gains of SES.
  3. Perform an ablation study by removing the mask generator or contrastive learning module to quantify their contributions to the overall performance of SES.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions. However, based on the limitations and future work mentioned, some potential open questions include:

- How does SES's performance scale with increasing graph size and complexity beyond the datasets studied?
- Can SES be effectively adapted for graph-level tasks beyond node classification, such as graph classification or link prediction?
- How robust is SES to adversarial attacks targeting the explanation component, and what defenses can be implemented?

## Limitations
- Computational overhead: The mask generator and contrastive learning modules add computational complexity, potentially impacting training and inference time.
- Sensitivity to hyperparameters: The performance of SES may be sensitive to the choice of hyperparameters, such as learning rates, mask generator architecture, and triplet loss margin.

## Confidence
- Mechanism 1 (Co-training masks with graph encoder): Medium
- Mechanism 2 (Contrastive learning with mask-based pairs): Medium
- Mechanism 3 (Coherent explanations through co-training): Medium

## Next Checks
1. Conduct a comprehensive ablation study to quantify the individual contributions of the mask generator and contrastive learning module to the overall performance of SES.
2. Investigate the sensitivity of SES to hyperparameters and identify optimal configurations for different datasets and tasks.
3. Compare the runtime efficiency of SES with state-of-the-art post-hoc explainers on large-scale graph datasets to demonstrate the practical benefits of SES.