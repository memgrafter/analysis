---
ver: rpa2
title: CLIP-driven Outliers Synthesis for few-shot OOD detection
arxiv_id: '2404.00323'
source_url: https://arxiv.org/abs/2404.00323
tags:
- detection
- data
- methods
- learning
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of few-shot out-of-distribution
  (OOD) detection, where the goal is to recognize OOD images that belong to classes
  unseen during training, using only a small number of labeled in-distribution (ID)
  images. The authors propose CLIP-driven Outliers Synthesis (CLIP-OS), a method that
  synthesizes reliable OOD data for training.
---

# CLIP-driven Outliers Synthesis for few-shot OOD detection

## Quick Facts
- arXiv ID: 2404.00323
- Source URL: https://arxiv.org/abs/2404.00323
- Authors: Hao Sun; Rundong He; Zhongyi Han; Zhicong Lin; Yongshun Gong; Yilong Yin
- Reference count: 11
- Primary result: CLIP-OS achieves superior few-shot OOD detection, outperforming existing methods by a substantial margin on CIFAR-100 with 78.24 average AUROC

## Executive Summary
This paper addresses the challenge of few-shot out-of-distribution (OOD) detection, where the goal is to recognize OOD images that belong to classes unseen during training, using only a small number of labeled in-distribution (ID) images. The authors propose CLIP-driven Outliers Synthesis (CLIP-OS), a method that synthesizes reliable OOD data for training. CLIP-OS works in three main steps: (1) it obtains ID-relevant features by enhancing patch-level perception and adaptively separating ID-relevant from ID-irrelevant features, (2) it synthesizes reliable OOD data by mixing up ID-relevant features from different ID classes, and (3) it regularizes the ID/OOD boundary using the synthetic OOD samples with unknown-aware prompt learning. Experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that CLIP-OS significantly outperforms existing methods, achieving superior few-shot OOD detection capability.

## Method Summary
CLIP-OS is a few-shot OOD detection method that leverages CLIP models and synthetic OOD data generation. It enhances patch-level features using patch-context incorporating (3x3 uniform convolution), adaptively separates ID-relevant from ID-irrelevant features using CLIP-surgery-discrepancy masking, and synthesizes reliable OOD data by mixing up ID-relevant features from different classes. The method then regularizes the ID/OOD boundary using the synthetic OOD samples with unknown-aware prompt learning, which aligns OOD supervised signals with the text embedding of the "unknown" prompt. CLIP-OS is evaluated on few-shot OOD detection tasks using CIFAR-10, CIFAR-100, and ImageNet as ID datasets, and Textures, Places365, LSUN-Crop/Resize, and iSUN as OOD datasets.

## Key Results
- CLIP-OS achieves superior few-shot OOD detection performance, significantly outperforming existing methods on CIFAR-10, CIFAR-100, and ImageNet datasets.
- On CIFAR-100, CLIP-OS achieves an average AUROC of 78.24, surpassing other methods by a substantial margin.
- The method demonstrates robust performance across different OOD datasets, including Textures, Places365, LSUN-Crop/Resize, and iSUN.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Patch-context incorporating improves discrimination of patch embeddings by including neighboring patch information.
- Mechanism: Uses a fixed 3x3 convolution kernel with uniform weights (1/9 each) to average surrounding patch embeddings into the current patch's embedding, enhancing local context awareness.
- Core assumption: Surrounding patch information is relevant to the current patch's semantic content and improves classification accuracy.
- Evidence anchors:
  - [abstract] "CLIP-OS enhances patch-level features' perception by newly proposed patch uniform convolution"
  - [section] "We incorporate the patch-context's embedding into the current patch's embedding" and "each patch in the Attention module, we pass it through a convolution operation to incorporate the average information of the surrounding eight patches"
  - [corpus] Weak evidence - no direct citations in related papers about patch-context convolution for OOD detection
- Break condition: If surrounding patches contain unrelated or noisy information, the averaged context could degrade rather than improve patch discrimination.

### Mechanism 2
- Claim: CLIP-surgery-discrepancy masking separates ID-relevant from ID-irrelevant features by leveraging CLIP's known opposite visualization behavior.
- Mechanism: Replaces standard self-attention with vision-to-vision (v-v) self-attention to generate a similarity map, then calculates the difference between this map and CLIP's original map to enhance foreground-background distinction at boundaries.
- Core assumption: CLIP's opposite visualization behavior (background regions having higher similarity to class text embeddings than foreground regions) can be exploited to improve boundary detection between ID-relevant and ID-irrelevant regions.
- Evidence anchors:
  - [abstract] "CLIP-OS enhances patch-level perception by newly proposed patch uniform convolution, and adaptively obtains the proportion of ID-relevant information by employing CLIP-surgery-discrepancy"
  - [section] "Li et al. [2023] discovers that the major cause of opposite visualization is the parameters (query and key) in the self-attention module" and "By calculating the difference between the our SM ap and CLIP's SM apclip, we can enhance the score of the foreground at the boundaries"
  - [corpus] Weak evidence - no direct citations in related papers about exploiting CLIP's opposite visualization for OOD detection
- Break condition: If the assumption about CLIP's opposite visualization behavior doesn't hold for the specific dataset or model version, the discrepancy calculation may not improve boundary detection.

### Mechanism 3
- Claim: Unknown-aware prompt learning regularizes ID/OOD boundaries by aligning synthetic OOD samples with an "unknown" prompt, avoiding uniform distribution regularization.
- Mechanism: Uses cross-entropy loss with a special "unknown" text embedding for OOD samples, allowing the model to classify OOD as "unknown" without affecting ID classification performance.
- Core assumption: Synthetic OOD samples can be effectively aligned with an "unknown" prompt to create meaningful supervision signals that regularize the ID/OOD boundary.
- Evidence anchors:
  - [abstract] "CLIP-OS leverages synthetic OOD samples by unknown-aware prompt learning to enhance the separability of ID and OOD"
  - [section] "The OOD loss in LoCoOp is achieved by maximizing the entropy of OOD samples... We propose unknown-aware prompt learning for regularizing the boundary between ID and OOD, which aligns the OOD supervised signals with the text embedding of the 'unknown' prompt"
  - [corpus] Weak evidence - no direct citations in related papers about unknown-aware prompt learning for OOD detection
- Break condition: If the "unknown" prompt doesn't capture the semantic space of OOD samples well, the regularization may not effectively separate ID and OOD distributions.

## Foundational Learning

- Concept: Vision-language models (VLMs) like CLIP
  - Why needed here: CLIP provides strong feature extraction capabilities and the ability to generate text embeddings for prompts, which are essential for both feature extraction and the unknown-aware prompt learning mechanism
  - Quick check question: What are the two main components of CLIP and how do they interact?

- Concept: Few-shot learning scenarios
  - Why needed here: The method specifically addresses cases where only 1-2 samples per class are available, requiring techniques that can work with minimal supervision
  - Quick check question: How does few-shot learning differ from zero-shot and fully supervised learning in terms of data requirements?

- Concept: Out-of-distribution detection fundamentals
  - Why needed here: Understanding the core problem of distinguishing between ID and OOD samples is essential for grasping why synthetic OOD data generation and boundary regularization are important
  - Quick check question: What is the key challenge in OOD detection that makes synthetic OOD data generation valuable?

## Architecture Onboarding

- Component map:
  - Input layer: Raw images from few-shot ID dataset
  - Patch-context incorporating: 3x3 uniform convolution applied to patch embeddings
  - CLIP-surgery-discrepancy masking: v-v self-attention + similarity map difference calculation
  - Feature extraction: ID-relevant features separated from ID-irrelevant features
  - OOD synthesis: Mixup of ID-relevant features from different classes
  - Unknown-aware prompt learning: Cross-entropy loss with "unknown" prompt for OOD samples
  - Output layer: Classification scores for ID classes + OOD detection score

- Critical path: Input → Patch-context incorporating → CLIP-surgery-discrepancy masking → OOD synthesis → Unknown-aware prompt learning → Output
- Design tradeoffs: The method trades increased computational complexity (additional convolution and similarity map calculations) for improved OOD detection performance in few-shot scenarios
- Failure signatures: Poor performance on ID classification, failure to detect OOD samples, sensitivity to hyperparameter β in patch-context incorporating
- First 3 experiments:
  1. Verify patch-context incorporating improves patch discrimination by comparing classification accuracy with and without this component on a validation set
  2. Test CLIP-surgery-discrepancy masking effectiveness by visualizing extracted ID-relevant regions and measuring boundary accuracy
  3. Evaluate unknown-aware prompt learning by comparing OOD detection performance against entropy maximization baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CLIP-OS change with different patch sizes in the patch uniform convolution?
- Basis in paper: [explicit] The paper mentions using a 14x14 patch design in CLIP and proposes patch-context incorporating using a 3x3 convolution kernel, but does not explore the impact of varying patch sizes.
- Why unresolved: The paper only evaluates one patch size (14x14) and does not provide ablation studies or analysis of how different patch sizes might affect the performance of CLIP-OS.
- What evidence would resolve it: Conducting experiments with different patch sizes (e.g., 7x7, 10x10, 16x16) and comparing the OOD detection performance (AUROC) of CLIP-OS for each patch size would provide evidence to answer this question.

### Open Question 2
- Question: How does CLIP-OS perform when trained on datasets with significantly different characteristics (e.g., medical images, satellite imagery)?
- Basis in paper: [inferred] The paper evaluates CLIP-OS on CIFAR-10, CIFAR-100, and ImageNet-100, which are general image datasets. However, it does not test the method's performance on datasets with different characteristics or domains.
- Why unresolved: The paper focuses on evaluating CLIP-OS on standard image classification datasets, but does not explore its performance on datasets with different characteristics or domains.
- What evidence would resolve it: Evaluating CLIP-OS on datasets from different domains (e.g., medical images, satellite imagery, hyperspectral images) and comparing its performance to existing methods would provide evidence to answer this question.

### Open Question 3
- Question: How does the choice of OOD loss function affect the performance of CLIP-OS?
- Basis in paper: [explicit] The paper proposes using cross-entropy loss with an "unknown" prompt for OOD regularization, but does not explore alternative OOD loss functions.
- Why unresolved: The paper only evaluates one OOD loss function (cross-entropy with "unknown" prompt) and does not provide ablation studies or analysis of how different OOD loss functions might affect the performance of CLIP-OS.
- What evidence would resolve it: Conducting experiments with different OOD loss functions (e.g., maximum entropy, KL divergence, focal loss) and comparing the OOD detection performance (AUROC) of CLIP-OS for each loss function would provide evidence to answer this question.

## Limitations
- The paper relies on weak external citations for the three novel mechanisms, which may limit the confidence in their effectiveness.
- The method's performance is evaluated on general image datasets (CIFAR-10, CIFAR-100, ImageNet-100), and its generalizability to other domains remains untested.
- The paper does not explore the impact of different patch sizes or alternative OOD loss functions on the performance of CLIP-OS.

## Confidence
- **High Confidence**: Overall experimental methodology and evaluation metrics (AUROC on standard OOD benchmarks)
- **Medium Confidence**: Individual mechanism implementations and their specific contributions to performance gains
- **Low Confidence**: Generalizability claims beyond the three tested datasets (CIFAR-10, CIFAR-100, ImageNet-100)

## Next Checks
1. **Mechanism Isolation Test**: Run ablations removing each mechanism (patch-context, discrepancy masking, unknown-aware learning) individually to quantify their independent contributions to the reported AUROC improvements.

2. **Cross-Domain Generalization**: Evaluate CLIP-OS on OOD detection tasks from different domains (medical imaging, satellite imagery) to assess whether the method's performance transfers beyond natural image datasets.

3. **Hyperparameter Sensitivity Analysis**: Systematically vary the patch-context convolution parameters (kernel size, weighting scheme) and the mixup interpolation coefficient β to identify whether reported performance is robust to hyperparameter choices or represents an optimal configuration on specific data.