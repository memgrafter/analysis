---
ver: rpa2
title: Improvement in Facial Emotion Recognition using Synthetic Data Generated by
  Diffusion Model
arxiv_id: '2411.10863'
source_url: https://arxiv.org/abs/2411.10863
tags:
- facial
- data
- fer2013
- recognition
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of class imbalance in facial\
  \ emotion recognition (FER) datasets, which hinders model performance and generalization.\
  \ The authors propose a method combining ResEmoteNet\u2014a CNN architecture with\
  \ Residual and Squeeze-and-Excitation blocks\u2014with synthetic data augmentation\
  \ using Stable Diffusion models (SD2 and SD3-Medium)."
---

# Improvement in Facial Emotion Recognition using Synthetic Data Generated by Diffusion Model

## Quick Facts
- arXiv ID: 2411.10863
- Source URL: https://arxiv.org/abs/2411.10863
- Authors: Arnab Kumar Roy; Hemant Kumar Kathania; Adhitiya Sharma
- Reference count: 28
- Primary result: 96.47% accuracy on FER2013 and 99.23% on RAF-DB using synthetic data augmentation

## Executive Summary
This paper addresses class imbalance in facial emotion recognition (FER) datasets by combining ResEmoteNet—a CNN with Residual and Squeeze-and-Excitation blocks—with synthetic data augmentation using Stable Diffusion models. The approach generates synthetic facial images for underrepresented emotion classes, balancing the training data distribution. Experiments on FER2013 and RAF-DB datasets show substantial accuracy improvements, with FER2013 accuracy increasing from 79.79% to 96.47% and RAF-DB from 94.76% to 99.23%.

## Method Summary
The method combines ResEmoteNet architecture with synthetic data augmentation using Stable Diffusion 2 and SD3-Medium models. ResEmoteNet uses residual connections to prevent vanishing gradients and SE blocks to recalibrate channel-wise feature responses. Synthetic images are generated using emotion-specific text prompts and added to the training set to balance class distributions. The model is trained with SGD (lr=1e-3, batch size=16) on augmented datasets, achieving significant improvements in both overall accuracy and per-class recognition.

## Key Results
- FER2013 accuracy improved from 79.79% to 96.47% (16.68% absolute improvement)
- RAF-DB accuracy improved from 94.76% to 99.23% (4.47% absolute improvement)
- Synthetic data augmentation significantly improved recognition of underrepresented classes (Disgust, Fear)
- ResEmoteNet outperformed existing state-of-the-art approaches on both benchmark datasets

## Why This Works (Mechanism)

### Mechanism 1
Diffusion-based synthetic data augmentation improves class balance and thus recognition accuracy by increasing sample counts for underrepresented emotion classes, reducing statistical bias in the training distribution.

### Mechanism 2
Residual and Squeeze-and-Excitation blocks enable deeper networks to learn better facial emotion features without vanishing gradients through skip connections and channel-wise feature recalibration.

### Mechanism 3
Using two diffusion models (Stable Diffusion 2 and SD3-Medium) diversifies synthetic data and reduces overfitting to a single generative distribution by producing complementary synthetic samples.

## Foundational Learning

- **Class imbalance and its impact on classifier performance**: Why needed here - The datasets FER2013 and RAF-DB have skewed class distributions, leading to biased models. Quick check: What is the ratio of Happy to Disgust samples in FER2013? (Answer: ~16:1)

- **Convolutional neural network architecture basics (residual and SE blocks)**: Why needed here - ResEmoteNet uses residual connections and squeeze-and-excitation mechanisms. Quick check: What problem do residual connections solve in deep networks? (Answer: Vanishing gradients)

- **Generative models and diffusion processes**: Why needed here - Stable Diffusion models iteratively denoise random noise into realistic images guided by text prompts. Quick check: What is the core iterative step in a diffusion model? (Answer: Gradual denoising of a noisy image)

## Architecture Onboarding

- **Component map**: Input (64x64 grayscale/RGB) → Initial conv+BN → Max pooling → SE block → 3 residual blocks → AAP → Output (Softmax over 7 emotion classes)

- **Critical path**: 1) Load and preprocess image (resize to 64x64) 2) Forward pass through CNN backbone 3) SE block recalibration 4) Residual block feature extraction 5) AAP and classification head 6) Loss computation (cross-entropy) 7) Backward pass with SGD + LR scheduler

- **Design tradeoffs**: Using two diffusion models increases diversity but also computational cost. Larger synthetic class sizes improve balance but risk overfitting to synthetic data. Residual/SENet blocks improve accuracy but increase parameter count and inference time.

- **Failure signatures**: High training accuracy but low validation accuracy → overfitting, likely from synthetic data or insufficient regularization. Class-wise accuracy highly skewed despite augmentation → synthetic images may not represent true emotion distributions. Very slow convergence → learning rate too low or model too deep for given data.

- **First 3 experiments**:
  1. Train baseline ResEmoteNet on original FER2013 without augmentation; record per-class accuracy
  2. Generate synthetic images for the two smallest classes (Disgust, Fear) only; retrain and compare performance
  3. Use Augmentation 4 (15k samples/class); train and verify that overall accuracy improves and class balance is achieved

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal ratio of synthetic to real data for maximizing FER model performance without overfitting? The paper shows significant improvements with synthetic data augmentation but does not explore the saturation point where additional synthetic data stops improving or begins degrading performance.

### Open Question 2
How does the quality of synthetic images affect FER model generalization across different datasets and real-world conditions? The paper uses Stable Diffusion models but doesn't analyze how image quality, artifacts, or prompt variations impact model robustness to real-world variations.

### Open Question 3
Can synthetic data augmentation improve FER model performance on emotion classes beyond the seven basic emotions? The experiments are limited to the seven basic emotions without exploring whether the approach generalizes to more nuanced or compound emotional states.

## Limitations
- Exact ResEmoteNet architecture details (layer dimensions, SE block parameters) are not fully specified, making precise replication difficult
- Complete set of Stable Diffusion text prompts for each emotion class is not provided, which may affect synthetic data quality and reproducibility
- No quantitative evidence is provided showing the degree of class imbalance in the original datasets or the exact sample counts after augmentation

## Confidence
- **High confidence**: The overall approach of using diffusion models for synthetic data augmentation in FER is valid and has shown significant accuracy gains
- **Medium confidence**: The specific architecture design choices (Residual + SE blocks) and their contributions to performance are plausible but not independently verified
- **Low confidence**: The exact mechanism by which dual diffusion models improve generalization over a single model is not demonstrated or discussed in detail

## Next Checks
1. Recreate the per-class sample distribution in FER2013 and RAF-DB before and after augmentation to verify the stated class imbalance and balancing effects
2. Implement a minimal ResEmoteNet variant and test it on the original datasets to establish a baseline before applying synthetic augmentation
3. Generate a small set of synthetic images using the provided prompts and evaluate them qualitatively and quantitatively to confirm they preserve emotion-relevant features