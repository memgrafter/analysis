---
ver: rpa2
title: Representation Learning of Daily Movement Data Using Text Encoders
arxiv_id: '2405.04494'
source_url: https://arxiv.org/abs/2405.04494
tags:
- days
- participant
- data
- learning
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method for representation learning of daily
  movement data in dementia care, converting time-series activity data into text strings
  that can be encoded using a language model. The approach fine-tunes a sentence embedding
  model (SE-MiniLM) to generate similar embeddings for the same participants within
  a 30-day window, enabling clustering, vector search, and identification of activity
  deviations.
---

# Representation Learning of Daily Movement Data Using Text Encoders

## Quick Facts
- arXiv ID: 2405.04494
- Source URL: https://arxiv.org/abs/2405.04494
- Reference count: 40
- The method converts daily movement time-series into text strings for language model encoding, enabling clustering and similarity search for dementia patient monitoring

## Executive Summary
This paper presents a novel approach for representation learning of daily movement data in dementia care by converting time-series activity data into text strings that can be encoded using language models. The method fine-tunes a sentence embedding model (SE-MiniLM) to generate similar embeddings for the same participants within a 30-day window, enabling clustering, vector search, and identification of activity deviations. Experiments on a dataset of 65,962 days from 134 dementia patients demonstrate the method can identify meaningful clusters of daily activity patterns and detect changes in behavior.

## Method Summary
The approach converts time-series activity sensor data into text strings representing daily activity patterns, then uses a pre-trained sentence embedding model (SE-MiniLM) fine-tuned with triplet loss to learn representations where days from the same participant within 30 days are close in embedding space. The method employs 20-minute modal aggregation of sensor events, converts these into text strings, and fine-tunes the encoder to maximize similarity between embeddings of the same participant while minimizing similarity across participants. This enables downstream analysis through k-means clustering and cosine similarity search to identify behavioral patterns and changes.

## Key Results
- The method successfully identifies clusters of daily activity patterns, with one cluster (cluster 1) characterized by low activity potentially indicating adverse health conditions
- Cosine similarity analysis reveals participants with consistent activity patterns versus those with frequent changes, enabling identification of behavioral transitions
- The approach allows finding similar days of activity across participants and tracking changes in daily routines over time

## Why This Works (Mechanism)

### Mechanism 1
Language models encode meaningful semantic relationships between activity location tokens (e.g., "Kitchen" vs "Bedroom"). Pre-trained text encoders learn contextual embeddings that capture semantic similarity between words, so semantically related locations produce similar vector representations. The core assumption is that the pre-trained language model has learned meaningful relationships between activity-related terms during training.

### Mechanism 2
Triplet loss fine-tuning aligns embeddings of similar days (same participant within 30-day window) while pushing apart dissimilar days. The triplet loss objective forces the model to learn a metric space where days from the same participant are closer together, enabling clustering and similarity search. The core assumption is that days from the same participant within 30 days are semantically similar enough to serve as positive pairs.

### Mechanism 3
Clustering and cosine similarity over learned embeddings reveal meaningful behavioral patterns and changes. Once embeddings are learned, unsupervised methods like k-means and cosine similarity can identify distinct activity patterns and track changes over time. The core assumption is that the learned embedding space preserves meaningful structure that reflects real behavioral differences.

## Foundational Learning

- **Time series representation learning**: Needed because raw time series of activity events are high-dimensional and irregular; we need compact, meaningful vector representations for downstream analysis. Quick check: What is the dimensionality of the original activity data vs. the learned embeddings?

- **Self-supervised learning via triplet loss**: Needed because labeled data is scarce in healthcare; we use temporal proximity and participant identity as weak supervision. Quick check: How are positive and negative pairs defined in this triplet setup?

- **Vector similarity and clustering**: Needed to group similar days and find nearest neighbors to identify patterns and anomalies. Quick check: What similarity metric is used to compare daily embeddings?

## Architecture Onboarding

- **Component map**: Raw sensor data → 20-minute modal aggregation → Text string conversion → SE-MiniLM encoder → Fine-tuning with triplet loss → Embedded vectors → Clustering / similarity search
- **Critical path**: Text encoding and fine-tuning steps are critical; errors here propagate to all downstream analysis
- **Design tradeoffs**: Modal aggregation loses temporal detail but ensures fixed-length input; 30-day window for positive pairs balances capturing routine vs. detecting change
- **Failure signatures**: Clusters not semantically meaningful → check fine-tuning data quality; High variance in similarity scores → check embedding normalization or aggregation method
- **First 3 experiments**: 1) Train with different aggregation granularities (10 min vs 30 min) and compare cluster coherence; 2) Vary the positive pair window size (7, 15, 30 days) and evaluate embedding stability; 3) Compare k-means clustering vs. DBSCAN to see if density-based clustering reveals different patterns

## Open Questions the Paper Calls Out

### Open Question 1
How does replacing location synonyms (e.g., "lounge" with "living room") during model training affect the learned embeddings and their clinical utility? This remains an open question because the authors only mention this as a future research direction without conducting experiments. The impact of synonym usage on embedding quality and cross-environment applicability is unknown.

### Open Question 2
What alternative methods for clustering activity patterns could incorporate domain knowledge from clinicians to improve clinical utility? The current k-means clustering approach may not capture clinically meaningful patterns. Domain experts could provide insights on what constitutes meaningful activity clusters that differ from purely statistical approaches.

### Open Question 3
How do the learned embeddings perform on classification tasks for predicting adverse health conditions or behavioral changes? While the paper demonstrates clustering and similarity search capabilities, it doesn't evaluate whether the embeddings can effectively predict specific clinical outcomes or behavioral changes.

## Limitations
- The method relies on 30-minute interval aggregation, discarding fine-grained temporal patterns that might be clinically relevant
- Assumes temporal proximity (within 30 days) implies semantic similarity, which may not hold for participants with irregular routines
- Evaluation is limited to unsupervised analysis without direct clinical validation of discovered clusters or identified behavioral changes
- Small dataset (134 participants) limits generalizability and qualitative interpretation may not be reproducible

## Confidence

- **High Confidence**: Technical feasibility of converting time-series data to text and encoding with language models; basic mechanics of triplet loss fine-tuning are sound
- **Medium Confidence**: Claim that learned embeddings can identify meaningful clusters of daily activity patterns; needs clinical validation for real-world relevance
- **Low Confidence**: Assertion that the method can reliably identify health-related behavioral changes; current evidence is primarily observational correlations

## Next Checks

1. **Clinical Validation Study**: Conduct a study where clinicians review and validate whether the identified clusters and detected changes correspond to actual health events or care needs, establishing ground truth for evaluation.

2. **Temporal Resolution Experiment**: Re-run the analysis with different temporal aggregation windows (15-minute vs 60-minute intervals) to assess sensitivity to temporal granularity and determine optimal resolution for clinical utility.

3. **Temporal Stability Analysis**: Track the consistency of learned embeddings for participants over extended periods (6+ months) to evaluate whether the method maintains stability for routine monitoring while still detecting meaningful changes.