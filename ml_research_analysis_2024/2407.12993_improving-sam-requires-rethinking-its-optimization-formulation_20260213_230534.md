---
ver: rpa2
title: Improving SAM Requires Rethinking its Optimization Formulation
arxiv_id: '2407.12993'
source_url: https://arxiv.org/abs/2407.12993
tags:
- bisam
- loss
- optimization
- bound
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that Sharpness-Aware Minimization (SAM) is fundamentally
  flawed because it maximizes an upper bound of the 0-1 loss, which doesn't guarantee
  maximizing the misclassification error. To address this, the authors reformulate
  SAM as a bilevel optimization problem, called BiSAM, where the minimizer uses an
  upper bound of the 0-1 loss while the maximizer uses a lower bound.
---

# Improving SAM Requires Rethinking its Optimization Formulation

## Quick Facts
- arXiv ID: 2407.12993
- Source URL: https://arxiv.org/abs/2407.12993
- Reference count: 26
- This paper argues that SAM's use of cross-entropy for both players leads to weaker perturbations, proposing BiSAM with a bilevel formulation that consistently improves accuracy by 0.1-0.8% across diverse tasks.

## Executive Summary
This paper identifies a fundamental flaw in Sharpness-Aware Minimization (SAM): maximizing cross-entropy doesn't guarantee maximizing misclassification error because cross-entropy is merely an upper bound of the 0-1 loss. The authors propose BiSAM, a bilevel optimization reformulation where the minimizer uses an upper bound (cross-entropy) while the maximizer uses a lower bound surrogate of the 0-1 loss. This approach leads to stronger adversarial perturbations that actually increase misclassification error. BiSAM consistently outperforms SAM and its variants across image classification, fine-tuning, and NLP tasks while maintaining similar computational complexity.

## Method Summary
BiSAM reformulates SAM as a bilevel optimization problem where the minimizer and maximizer have different objectives. The minimizer uses cross-entropy (upper bound of 0-1 loss) while the maximizer uses a newly designed lower-bound surrogate loss based on log-sum-exp to approximate the maximum over data points. The method computes perturbations using this lower-bound objective, then updates weights using gradients from the perturbed model. The algorithm maintains computational complexity comparable to SAM by reusing most of its infrastructure while only modifying the perturbation computation step. The authors provide theoretical justification for why this bilevel formulation leads to stronger adversarial perturbations that better align with the ultimate goal of minimizing misclassification error.

## Key Results
- BiSAM improves test accuracy by 0.3-0.8% on CIFAR-10 and CIFAR-100
- BiSAM achieves 0.1-0.2% improvement on ImageNet-1K
- Consistently outperforms SAM and its variants across 6 independent runs on multiple architectures (VGG, ResNet, DenseNet, WideResNet)
- Maintains similar computational complexity to SAM while providing better performance on fine-tuning and NLP tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Maximizing cross-entropy does not guarantee maximizing misclassification error because cross-entropy is an upper bound of the 0-1 loss.
- Mechanism: When the adversary maximizes cross-entropy, it can find perturbations that increase cross-entropy without changing the predicted class, thus not increasing misclassification error.
- Core assumption: The cross-entropy loss is a continuous upper bound of the 0-1 loss, and maximizing it doesn't necessarily increase the 0-1 loss.
- Evidence anchors:
  - [abstract] "We argue that SAM should instead be reformulated using the 0-1 loss. As a continuous relaxation, we follow the simple conventional approach where the minimizing (maximizing) player uses an upper bound (lower bound) surrogate to the 0-1 loss."
  - [section 2.2] "This means that any ϵ⋆ obtained by Equation (4) has no guarantee to increase the classification error."
  - [corpus] Weak evidence - corpus neighbors focus on SAM variants but don't address the 0-1 loss reformulation directly.
- Break condition: If the upper bound relationship between cross-entropy and 0-1 loss is broken or if the perturbation doesn't affect the predicted class.

### Mechanism 2
- Claim: BiSAM's bilevel formulation with different objectives for minimizer and maximizer leads to stronger perturbations.
- Mechanism: The minimizer uses cross-entropy (upper bound) while the maximizer uses a lower-bound surrogate of 0-1 loss, creating adversarial perturbations that actually increase misclassification.
- Core assumption: The lower-bound surrogate loss used by the maximizer will find perturbations that increase misclassification error when cross-entropy alone cannot.
- Evidence anchors:
  - [abstract] "We argue that the original SAM with surrogate loss suffers from a fundamental flaw that leads to a weaker perturbation."
  - [section 3] "As a consequence of Lemma 3.1 we conclude that a valid approach for the maximization player is to solve the differentiable problem..."
  - [corpus] Weak evidence - corpus neighbors don't discuss the bilevel formulation or different objectives for players.
- Break condition: If the lower-bound surrogate doesn't actually lead to misclassification or if the bilevel optimization becomes intractable.

### Mechanism 3
- Claim: The log-sum-exp lower bound construction allows differentiable maximization while maintaining theoretical guarantees.
- Mechanism: The lower bound uses log-sum-exp to replace the non-differentiable max operator, creating a differentiable objective that still provides a valid lower bound on misclassification error.
- Core assumption: The log-sum-exp approximation maintains the lower bound property while being differentiable enough for optimization.
- Evidence anchors:
  - [section 3] "Using Equation (10) in Equation (9) yields the desired bound" and the subsequent derivation.
  - [section 3] "Note that both upper and lower objective functions in Equation (12) are aligned with the ultimate goal of the 0-1 loss."
  - [corpus] No direct evidence - corpus neighbors don't discuss the log-sum-exp construction.
- Break condition: If the log-sum-exp approximation becomes too loose or if the gradient vanishes in practical scenarios.

## Foundational Learning

- Concept: 0-1 loss vs surrogate losses
  - Why needed here: Understanding why cross-entropy alone is insufficient for the maximization player requires grasping the difference between 0-1 loss and its continuous surrogates.
  - Quick check question: If a perturbation increases cross-entropy but the predicted class remains the same, did it increase the 0-1 loss?

- Concept: Bilevel optimization
  - Why needed here: BiSAM reformulates SAM as a bilevel problem where the minimizer and maximizer have different objectives, requiring understanding of nested optimization.
  - Quick check question: In bilevel optimization, what is the relationship between the outer problem's solution and the inner problem's solution?

- Concept: Lower-bound vs upper-bound surrogates
  - Why needed here: The key innovation is using an upper bound for minimization and a lower bound for maximization, requiring understanding of when each type is appropriate.
  - Quick check question: Why would you use a lower bound for a maximization problem and an upper bound for a minimization problem?

## Architecture Onboarding

- Component map: Base optimizer (SGD with momentum) -> SAM perturbation computation -> BiSAM perturbation loss (log-sum-exp of lower-bound surrogates) -> Validation accuracy monitoring -> Hyperparameter tuning (ρ, µ, α)

- Critical path:
  1. Compute perturbation loss Qϕ,µ(w) using lower-bound surrogate
  2. Compute perturbation: ϵ = ρ∇wQ(w)/||∇wQ(w)||
  3. Compute gradient on perturbed weights: g = ∇wLB(w + ϵ)
  4. Update weights: w = w - ηg

- Design tradeoffs:
  - Using log-sum-exp vs tanh for lower bound: log-sum-exp provides better gradients but is computationally heavier
  - Perturbation radius ρ: Larger values create stronger perturbations but may destabilize training
  - Batch size: Larger batches provide more stable gradients but increase memory usage

- Failure signatures:
  - No improvement over SAM: Check if the lower-bound surrogate is too loose or if gradients are vanishing
  - Training instability: Reduce perturbation radius ρ or increase batch size
  - Slow convergence: Verify that the log-sum-exp computation is properly optimized

- First 3 experiments:
  1. Reproduce SAM baseline on CIFAR-10 with ResNet-56 to establish baseline performance
  2. Implement BiSAM with tanh lower bound and compare performance on same setup
  3. Compare BiSAM with log-sum-exp lower bound against both SAM and tanh variant to evaluate the impact of lower-bound choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the bilevel formulation in BiSAM truly guarantee improved generalization performance compared to SAM across all neural network architectures and datasets?
- Basis in paper: [inferred] The paper demonstrates improved performance on several models and datasets but does not provide a theoretical guarantee for all architectures and datasets.
- Why unresolved: The paper only provides empirical evidence on a limited set of models and datasets. Theoretical analysis of generalization bounds specific to BiSAM is not provided.
- What evidence would resolve it: Extensive empirical testing across a wide range of neural network architectures and diverse datasets, coupled with theoretical analysis of generalization bounds for BiSAM.

### Open Question 2
- Question: What is the impact of the choice of lower-bound surrogate loss function (e.g., tanh vs. -log) on the performance of BiSAM?
- Basis in paper: [explicit] The paper presents two options for the lower-bound surrogate loss function and shows that BiSAM (-log) generally performs better or comparably to BiSAM (tanh).
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of different lower-bound surrogate loss functions on BiSAM's performance.
- What evidence would resolve it: Systematic comparison of BiSAM's performance using various lower-bound surrogate loss functions across different models and datasets.

### Open Question 3
- Question: Can the bilevel optimization formulation of BiSAM be extended to other domains beyond image classification, such as reinforcement learning or graph neural networks?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of BiSAM on image classification tasks and fine-tuning, but does not explore its applicability to other domains.
- Why unresolved: The paper focuses primarily on image classification tasks and does not investigate the potential of BiSAM in other domains.
- What evidence would resolve it: Empirical testing of BiSAM on reinforcement learning tasks, graph neural networks, and other domains to assess its effectiveness and potential benefits.

## Limitations

- The theoretical claim that SAM has a "fundamental flaw" is primarily supported by abstract arguments rather than empirical demonstrations of SAM failing in specific scenarios.
- The computational complexity claim of "comparable" overhead to SAM needs more rigorous benchmarking across different hardware setups and model scales.
- The paper doesn't explore alternative lower-bound surrogates beyond log-sum-exp and tanh, leaving open questions about whether the specific mathematical construction drives the improvements.

## Confidence

- **High Confidence**: The empirical results showing BiSAM outperforming SAM across diverse tasks (image classification, fine-tuning, NLP) with consistent accuracy improvements of 0.1-0.8%.
- **Medium Confidence**: The theoretical justification for using different objectives (upper vs lower bound) for minimizer and maximizer, as this relies on specific assumptions about the relationship between cross-entropy and 0-1 loss.
- **Low Confidence**: The claim that this is a "fundamental flaw" in SAM's original formulation, as alternative interpretations of SAM's behavior exist in the literature.

## Next Checks

1. **Ablation Study**: Systematically test BiSAM with different lower-bound surrogates (beyond log-sum-exp and tanh) to isolate whether the improvement stems from the bilevel formulation or the specific mathematical construction.

2. **Failure Mode Analysis**: Design experiments where SAM's original formulation demonstrably fails to find useful perturbations (e.g., cases where cross-entropy increases but accuracy doesn't decrease) to provide empirical support for the theoretical claims.

3. **Scalability Assessment**: Benchmark BiSAM on larger models (Vision Transformers, LLMs) and datasets to verify that the computational complexity remains "comparable" to SAM as claimed, measuring wall-clock time and memory usage across different hardware configurations.