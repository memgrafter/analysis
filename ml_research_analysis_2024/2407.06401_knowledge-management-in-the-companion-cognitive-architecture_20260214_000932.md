---
ver: rpa2
title: Knowledge Management in the Companion Cognitive Architecture
arxiv_id: '2407.06401'
source_url: https://arxiv.org/abs/2407.06401
tags:
- knowledge
- companion
- provenance
- facts
- forbus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper documents challenges in scaling the Companion cognitive
  architecture''s knowledge management system, which handles over 700,000 facts across
  1,300 microtheories. Three main challenges are addressed: knowledge representation
  using CycL language and microtheories for logical consistency, efficient access
  via PlanB with AllegroCache database and mentions map for retrieval, and knowledge
  management through provenance tracking.'
---

# Knowledge Management in the Companion Cognitive Architecture

## Quick Facts
- arXiv ID: 2407.06401
- Source URL: https://arxiv.org/abs/2407.06401
- Reference count: 4
- Knowledge base handles over 700,000 facts across 1,300 microtheories

## Executive Summary
The Companion cognitive architecture's knowledge management system scales to handle a large knowledge base through three key innovations: an epistemic layer for tracking knowledge sources and provenance, efficient retrieval using a mentions map and PlanB reasoning engine, and logical compartmentalization via microtheories. The system automatically updates knowledge through provenance tracking, achieving 71.4% precision in extracting commonsense facts from Simple English Wikipedia. Future work includes extending provenance tracking to hierarchical events and implementing trust assessment using Dempster-Shafer Theory.

## Method Summary
The Companion architecture uses a three-tier knowledge stack: physical storage in KRF3 files, logical organization via CycL microtheories connected through genlMt inheritance, and an epistemic layer tracking provenance events. PlanB, the knowledge base module, uses AllegroCache database with persistent-classes and map-ranges for efficient storage and retrieval. The mentions map provides coarse-coded indexing of entity mentions for fast retrieval, while the provenance cache enables automatic KRF file updates by tracking which facts depend on which sources.

## Key Results
- Knowledge base handles over 700,000 facts across 1,300 microtheories
- 71.4% precision extracting 976 commonsense facts from 2,679 Simple English Wikipedia articles
- Automatic KRF file updates through provenance tracking without manual intervention
- Efficient retrieval using mentions map with coarse coding of entity mentions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The epistemic layer enables automatic updating of knowledge by tracking provenance events.
- Mechanism: When a KRF file is reloaded, PlanB creates a new provenance event with a new timestamp. The system automatically forgets facts no longer supported by the current provenance event, ensuring knowledge stays consistent without manual intervention.
- Core assumption: Every fact in the KB can be uniquely associated with its source provenance event.
- Evidence anchors:
  - [abstract] "The provenance cache enables automatic updating of KRF files by tracking which facts depend on which sources."
  - [section 5.1] "The epistemic layer is organized by provenance. Every fact that is loaded into the KB is tagged with metadata recording where it came from, namely the provenance event that caused the fact to be known."
  - [corpus] Weak - no direct corpus evidence found for this specific provenance mechanism.

### Mechanism 2
- Claim: The mentions map provides efficient retrieval through coarse coding of entity mentions.
- Mechanism: Each fact is indexed by the entities it mentions in specific positions, stored as entity-location-fact triples. During retrieval, PlanB intersects fact sets that share mentions with the query pattern, then filters by microtheory.
- Core assumption: Coarsely coded mentions (ignoring nested structure within positions) provide sufficient selectivity for efficient retrieval without missing relevant facts.
- Evidence anchors:
  - [section 4.3] "Mentions are compressed into integer keys using the entity and fact IDs, so that mentions for the same entity are stored adjacently. This makes it efficient to look up all mentions of an entity, or all mentions of the entity in a particular position, using map-range's cursor mechanism."
  - [section 4.3] "During retrieval, PlanB breaks down the query pattern to mentions the same way. Variables are ignored. For each entity mention in the query, PlanB uses the mentions map to retrieve a bucket of facts that mention the same entity in the same location."
  - [corpus] Weak - no direct corpus evidence found for this specific mentions map implementation.

### Mechanism 3
- Claim: Microtheories provide logical compartmentalization that prevents contradictions and improves reasoning efficiency.
- Mechanism: Knowledge is organized into logically consistent microtheories connected via genlMt inheritance. Queries are contextualized within specific microtheories, limiting the scope of reasoning to relevant facts and rules.
- Core assumption: Logical consistency within microtheories can be maintained as knowledge scales, and genlMt inheritance correctly propagates relevant facts without introducing contradictions.
- Evidence anchors:
  - [section 3.2] "Microtheories are connected using genlMt statements. (genlMt MT1 MT2) means that MT1 inherits the contents of MT2. Any query made in MT1 will see the facts stored in both MT1 and MT2."
  - [section 3.2] "Microtheories are invaluable from the perspective of both reasoning and ontologizing. In addition to keeping contradictory facts separate, microtheories greatly reduce the amount of work required for deduction."
  - [corpus] Weak - no direct corpus evidence found for this specific microtheory implementation.

## Foundational Learning

- Concept: Higher-order predicate calculus and CycL syntax
  - Why needed here: Companions use CycL language to represent knowledge assertions as s-expressions, which is fundamental to understanding how knowledge is encoded and manipulated in the system.
  - Quick check question: What is the difference between an individual entity and a collection in CycL, and how are they linked?

- Concept: Knowledge representation formats (KRF files, microtheories)
  - Why needed here: Understanding how knowledge is physically stored (KRF files) and logically organized (microtheories) is essential for working with the knowledge stack.
  - Quick check question: How does the in-microtheory directive work, and what is its relationship to genlMt statements?

- Concept: Database systems and Lisp data types
  - Why needed here: PlanB uses AllegroCache database with persistent-classes and map-ranges, requiring understanding of how Lisp objects are stored and retrieved efficiently.
  - Quick check question: What are the trade-offs between using persistent-classes versus map-ranges for storing facts in PlanB?

## Architecture Onboarding

- Component map:
  - Companion cognitive architecture (agents with FIRE reasoning engines)
  - PlanB knowledge base module (AllegroCache database, mentions map, provenance cache)
  - NextKB knowledge base (derived from OpenCyc, extended with Companion knowledge)
  - KRF3 files (physical storage format)
  - Microtheories (logical organization)
  - Archivist agent (persistent storage and knowledge serving)

- Critical path: Knowledge retrieval during reasoning
  1. FIRE reasoning engine queries PlanB
  2. PlanB retrieves facts using mentions map and microtheory context
  3. Special facts and indexed facts are retrieved via custom handlers
  4. Retrieved knowledge is returned to FIRE for reasoning

- Design tradeoffs:
  - Persistent-classes vs map-ranges: convenience vs efficiency
  - Microtheories vs unified knowledge base: logical consistency vs retrieval simplicity
  - Coarse coding in mentions map vs fine-grained indexing: speed vs precision

- Failure signatures:
  - Slow retrieval: mentions map indexing may be ineffective or microtheory context too broad
  - Inconsistent knowledge: provenance tracking may be failing or microtheory boundaries may be violated
  - Memory bloat: KRF files may not be properly managed or provenance events may accumulate excessively

- First 3 experiments:
  1. Test knowledge retrieval performance with different query patterns and microtheory contexts
  2. Verify provenance cache functionality by updating a KRF file and checking automatic fact forgetting
  3. Measure the impact of different indexing strategies (persistent-classes vs map-ranges) on retrieval speed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the provenance cache handle conflicting knowledge from multiple sources with different trust levels?
- Basis in paper: [explicit] Mentioned as a potential next step in Section 6.2 regarding trust assessment and knowledge integration
- Why unresolved: The paper outlines the need for trust assessment using Dempster-Shafer Theory but doesn't detail how this would be implemented or what factors would determine trust levels
- What evidence would resolve it: Implementation details showing how provenance events are weighted based on source reliability, examples of conflicting knowledge resolution, and evaluation metrics for trust assessment accuracy

### Open Question 2
- Question: What are the specific performance impacts of transitioning from persistent-classes to map-ranges in PlanB?
- Basis in paper: [explicit] Section 4.2 states that testing showed map-ranges are more efficient than persistent-classes and mentions a planned transition
- Why unresolved: The paper doesn't provide specific benchmarks or quantitative comparisons between the two storage approaches
- What evidence would resolve it: Comparative performance metrics (retrieval times, memory usage) for both storage methods under various workload conditions

### Open Question 3
- Question: How would the distribution layer for knowledge organization function in practice, and what criteria would determine which KRF files belong to specific KB builds?
- Basis in paper: [explicit] Section 6.1 mentions the need for a distribution layer but doesn't provide implementation details
- Why unresolved: The paper only conceptualizes the need for this layer without explaining how it would be structured or what factors would influence KB configuration decisions
- What evidence would resolve it: Design specifications for the distribution layer, examples of KB builds for different applications, and evaluation of the flexibility and maintainability of this approach

## Limitations

- Limited empirical validation of performance characteristics at scale
- No quantitative comparison between persistent-classes and map-ranges storage approaches
- Provenance cache mechanism not fully specified for complex dependency scenarios

## Confidence

This analysis has **Medium confidence** in the core mechanisms described, as the paper provides detailed architectural descriptions but limited empirical validation. The provenance tracking and mentions map implementations are well-specified conceptually, but their actual performance characteristics and scalability limits are not thoroughly tested.

## Next Checks

1. Measure retrieval latency and accuracy as knowledge base scales beyond 700k facts with varying microtheory complexity
2. Test provenance cache behavior under concurrent updates and partial KRF file modifications
3. Evaluate Dempster-Shafer Theory integration for trust assessment across heterogeneous knowledge sources