---
ver: rpa2
title: Learning Human-Aligned Representations with Contrastive Learning and Generative
  Similarity
arxiv_id: '2405.19420'
source_url: https://arxiv.org/abs/2405.19420
tags:
- line
- similarity
- learning
- generative
- circle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a method to learn human-aligned representations
  by integrating a Bayesian notion of generative similarity with contrastive learning.
  Generative similarity is defined as the probability that two samples came from the
  same distribution relative to them coming from different distributions, and it is
  used as the basis for a contrastive loss function.
---

# Learning Human-Aligned Representations with Contrastive Learning and Generative Similarity

## Quick Facts
- **arXiv ID**: 2405.19420
- **Source URL**: https://arxiv.org/abs/2405.19420
- **Reference count**: 40
- **Primary result**: Proposed method integrates generative similarity with contrastive learning to align machine representations with human cognition, outperforming baselines in shape regularity, abstract concepts, and hierarchical image categorization tasks.

## Executive Summary
This paper introduces a novel approach to learning human-aligned representations by combining contrastive learning with a Bayesian notion of generative similarity. The method defines similarity between data points based on the probability they came from the same distribution relative to different distributions, capturing human-like hierarchical structure and graded relationships. Evaluated across three domains - shape regularity, abstract geometric concepts, and hierarchical image categories - the approach demonstrates improved alignment with human behavior compared to standard contrastive learning methods. The framework provides a scalable procedure for aligning machine intelligence with human cognition by leveraging Bayesian models of cognition within a contrastive learning framework.

## Method Summary
The proposed method learns human-aligned representations by integrating generative similarity into contrastive learning. Generative similarity is defined as the probability that two samples came from the same distribution relative to them coming from different distributions. This similarity measure can be directly computed when tractable or approximated using Monte Carlo sampling from a generative model. The generative similarity is then incorporated into a contrastive loss function, typically using a triplet loss formulation where the similarity score replaces the standard distance metric. The method requires a domain-specific generative model that captures the underlying structure of the data, such as hierarchical relationships or distributional properties.

## Key Results
- Captured human-like shape regularity biases, with model performance correlating with human error rates
- Improved few-shot generalization of abstract geometric concepts compared to baseline approaches
- Encoded hierarchical image categories effectively, matching human performance across WordNet tree levels
- Outperformed supervised contrastive learning and standard contrastive learning in aligning with human behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generative similarity encodes human-like hierarchical structure by modeling data distributions rather than flat categories.
- Mechanism: Instead of training on independent class labels, the method uses Bayesian generative models to define similarity as the probability two samples came from the same distribution relative to different distributions. This creates embeddings where semantic relationships (like WordNet hierarchy) are preserved.
- Core assumption: Human cognitive representations are naturally organized in hierarchical, distributional structures rather than flat categorical boundaries.
- Evidence anchors:
  - [abstract] "we define the generative similarity between a pair of samples to be their probability of having been sampled from the same distribution relative to that of them being sampled from two independently-drawn distributions"
  - [section 3.3] "We derived a measure of generative similarity using the WordNet hierarchy as a part of a generative model...Our measure of generative similarity between the two images is as follows"
  - [corpus] "Weak" (corpus lacks direct evidence of hierarchical modeling; references focus on general contrastive learning)
- Break condition: If the underlying generative model poorly matches human cognitive structure, the learned representations will fail to capture human-like abstractions.

### Mechanism 2
- Claim: Integrating Bayesian generative models with contrastive learning enables scalable alignment without requiring large-scale human similarity judgments.
- Mechanism: The framework uses a Bayesian definition of similarity (Equation 1) that can be incorporated into a contrastive loss. When direct computation is intractable, Monte Carlo sampling from the generative model approximates the similarity for triplet-based training.
- Core assumption: Bayesian models of human similarity can be approximated efficiently enough for large-scale contrastive learning.
- Evidence anchors:
  - [abstract] "we address this challenge by leveraging a Bayesian notion of generative similarity whereby two data points are considered similar if they are likely to have been sampled from the same distribution"
  - [section 2] "Given the definition of generative similarity, we next distinguish between two scenarios. When sgen can be directly computed, then its incorporation in a contrastive loss function is straightforward"
  - [corpus] "Weak" (corpus neighbors focus on contrastive learning generally but don't specifically address Bayesian integration)
- Break condition: If Monte Carlo approximation becomes computationally prohibitive or introduces too much variance, the method loses scalability advantage.

### Mechanism 3
- Claim: Generative similarity captures graded relationships between concepts, not just binary category membership.
- Mechanism: By defining similarity over distributions rather than discrete labels, the method can represent nuanced relationships (e.g., a spider is more similar to an insect than to a mammal, reflecting hierarchical distance).
- Core assumption: Human similarity judgments are inherently graded and reflect underlying distributional relationships rather than discrete category boundaries.
- Evidence anchors:
  - [abstract] "Generative similarity is defined as the probability that two samples came from the same distribution relative to them coming from different distributions"
  - [section 3.3] "The Levels Dataset of Muttenthaler et al. (2024b)...humans perform an odd-one-out judgment on image triplets that are sampled at three different levels of abstraction"
  - [corpus] "Weak" (corpus doesn't provide evidence about graded similarity relationships)
- Break condition: If human judgments are actually better modeled by discrete categories for the domain, the graded approach may introduce unnecessary complexity.

## Foundational Learning

- Concept: Bayesian inference and posterior computation
  - Why needed here: The method fundamentally relies on Bayesian definitions of similarity (Equation 1) and posterior probabilities over distribution parameters
  - Quick check question: Given two samples and a generative model, can you write the formula for computing the posterior probability they came from the same distribution?

- Concept: Contrastive learning objectives and triplet loss
  - Why needed here: The method integrates generative similarity into a contrastive learning framework using triplet-based losses (Equation 2)
  - Quick check question: What is the difference between the InfoNCE loss used in standard contrastive learning and the triplet loss formulation used here?

- Concept: Probabilistic programs and context-free grammars
  - Why needed here: For the Geoclidean experiment, the method uses probabilistic programs that can be parsed into parse trees, with generative similarity computed via shared substructures
  - Quick check question: How would you define a context-free grammar that can parse a simple probabilistic program into a parse tree?

## Architecture Onboarding

- Component map: Data pipeline -> Generative model module -> Contrastive learning module -> Evaluation module
- Critical path: Data → Generative similarity computation → Contrastive loss → Embedding update → Human alignment evaluation
- Design tradeoffs:
  - Computational cost vs. accuracy: Direct generative similarity computation vs. Monte Carlo approximation
  - Model complexity vs. generalization: Richer generative models capture more structure but may overfit
  - Domain specificity vs. scalability: Task-specific generative models vs. domain-agnostic approaches
- Failure signatures:
  - Poor alignment with human behavior despite high downstream task performance
  - Computational bottleneck during Monte Carlo sampling phase
  - Embeddings collapse to trivial solutions (all points same distance apart)
- First 3 experiments:
  1. Implement the Gaussian mixture example from Appendix F to verify the basic mechanism works
  2. Apply the quadrilateral shape regularity experiment to test human alignment in a vision domain
  3. Test the WordNet hierarchy experiment to verify the method captures hierarchical structure in natural images

## Open Questions the Paper Calls Out
None explicitly identified in the paper.

## Limitations
- Method's performance depends heavily on quality of underlying generative model, which may not generalize across domains
- Computational cost of Monte Carlo sampling for generative similarity approximation may limit scalability
- Approach requires domain-specific generative models, reducing applicability to problems where such models can be defined

## Confidence
- High confidence in theoretical framework and mathematical formulation of generative similarity
- Medium confidence in empirical results across all three domains, given limited comparison baselines
- Low confidence in method's scalability to very large datasets or complex generative models

## Next Checks
1. Test the method on a new domain with a different type of generative model (e.g., continuous distributions instead of discrete hierarchies)
2. Compare against additional baseline methods, particularly those that incorporate human behavioral data directly
3. Conduct ablation studies to quantify contribution of generative similarity component versus standard contrastive learning