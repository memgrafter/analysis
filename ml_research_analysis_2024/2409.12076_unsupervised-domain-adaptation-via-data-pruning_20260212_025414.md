---
ver: rpa2
title: Unsupervised Domain Adaptation Via Data Pruning
arxiv_id: '2409.12076'
source_url: https://arxiv.org/abs/2409.12076
tags:
- training
- data
- domain
- pruning
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AdaPrune, a novel method for unsupervised
  domain adaptation (UDA) that improves model robustness by removing irrelevant examples
  from the training data. The method formulates data pruning as an integer quadratic
  program that minimizes the Maximum Mean Discrepancy (MMD) between the pruned training
  set and the target distribution.
---

# Unsupervised Domain Adaptation Via Data Pruning
## Quick Facts
- arXiv ID: 2409.12076
- Source URL: https://arxiv.org/abs/2409.12076
- Authors: Andrea Napoli; Paul White
- Reference count: 0
- Primary result: AdaPrune achieves up to 14% accuracy improvement in bioacoustic UDA tasks

## Executive Summary
This paper introduces AdaPrune, a novel method for unsupervised domain adaptation (UDA) that improves model robustness by removing irrelevant examples from the training data. The method formulates data pruning as an integer quadratic program that minimizes the Maximum Mean Discrepancy (MMD) between the pruned training set and the target distribution. Using RBF mixture kernels and branch-and-bound optimization, AdaPrune selects the most relevant examples for training. Evaluated on a real-world bioacoustic event detection task, AdaPrune achieves up to 14% improvement in accuracy over non-adaptive training, outperforming related UDA algorithms like KMM.

## Method Summary
AdaPrune addresses unsupervised domain adaptation by formulating data pruning as an integer quadratic program. The approach minimizes the Maximum Mean Discrepancy (MMD) between the pruned source dataset and the target distribution using RBF mixture kernels. Branch-and-bound optimization is employed to efficiently select the most relevant training examples. The method is evaluated on a bioacoustic event detection task, where it demonstrates significant improvements in accuracy by removing examples that are far from the target distribution. AdaPrune also shows complementary effects when combined with CORAL, suggesting potential for hybrid UDA approaches.

## Key Results
- AdaPrune achieves up to 14% accuracy improvement over non-adaptive training on bioacoustic event detection
- Outperforms related UDA algorithms like KMM in the evaluated task
- Demonstrates particularly strong performance when combined with CORAL
- t-SNE visualizations and correlation analysis confirm that removing examples far from the target distribution enhances generalization

## Why This Works (Mechanism)
AdaPrune works by identifying and removing source domain examples that are dissimilar to the target domain, thereby reducing domain shift. The MMD metric quantifies distributional differences, and minimizing it through selective pruning ensures the training data better represents the target distribution. The RBF mixture kernel captures complex similarity structures, while branch-and-bound optimization efficiently solves the combinatorial selection problem. This data-centric approach complements model-centric adaptation methods like CORAL, explaining the observed performance gains when combined.

## Foundational Learning
- Maximum Mean Discrepancy (MMD): Measures distributional similarity between source and target domains; needed to quantify domain shift for pruning decisions; quick check: verify MMD decreases after pruning
- RBF Mixture Kernels: Capture complex similarity structures between domains; needed to accurately estimate MMD with multiple similarity scales; quick check: test different kernel configurations on validation data
- Branch-and-Bound Optimization: Efficiently solves the combinatorial pruning problem; needed to handle the discrete nature of example selection; quick check: compare solution quality and runtime against greedy alternatives
- Integer Quadratic Programming: Formalizes the pruning problem with discrete constraints; needed to maintain exact selection of examples; quick check: validate integrality constraints are satisfied
- Domain Adaptation Metrics: Accuracy and MMD serve as evaluation criteria; needed to measure both task performance and distributional alignment; quick check: correlate MMD reduction with accuracy improvement

## Architecture Onboarding
Component map: Raw Data -> MMD Calculation -> Branch-and-Bound Pruning -> Selected Examples -> Model Training -> Evaluation
Critical path: The MMD calculation and branch-and-bound optimization are the most computationally intensive components, directly determining pruning quality and runtime
Design tradeoffs: Exact integer optimization ensures optimal pruning but may be slow; approximation could improve scalability but risk suboptimal selection
Failure signatures: Poor MMD estimation leads to ineffective pruning; computational complexity becomes prohibitive for large datasets
First experiments: 1) Verify MMD reduction on a small toy dataset, 2) Test pruning effectiveness on a simple binary classification task, 3) Evaluate computational scalability on increasing dataset sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Computational scalability concerns for large datasets due to integer quadratic programming complexity
- Limited evaluation scope restricted to bioacoustic event detection tasks
- Sensitivity to RBF kernel parameter choices not thoroughly analyzed

## Confidence
High: Core methodology of MMD-based data pruning and demonstrated performance improvements
Medium: General effectiveness across different UDA scenarios and scalability claims
Low: Theoretical guarantees of branch-and-bound optimization and universality of CORAL complementarity

## Next Checks
1. Evaluate AdaPrune on standard computer vision UDA benchmarks (e.g., Office-31, VisDA) to assess cross-domain generalization
2. Conduct extensive ablation studies on kernel parameter sensitivity and analyze the impact on pruning decisions
3. Test the scalability by applying AdaPrune to datasets with 10x more examples and measure computational overhead and performance degradation