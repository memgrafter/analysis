---
ver: rpa2
title: Loss Landscape Degeneracy and Stagewise Development in Transformers
arxiv_id: '2402.02364'
source_url: https://arxiv.org/abs/2402.02364
tags:
- loss
- learning
- training
- attention
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the link between loss landscape degeneracy\
  \ and developmental stages in transformers by tracking the local learning coefficient\
  \ (LLC) throughout training. The authors train two transformer models\u2014a language\
  \ model and an in-context linear regression model\u2014and monitor how the LLC changes\
  \ over time."
---

# Loss Landscape Degeneracy and Stagewise Development in Transformers

## Quick Facts
- arXiv ID: 2402.02364
- Source URL: https://arxiv.org/abs/2402.02364
- Authors: Jesse Hoogland; George Wang; Matthew Farrugia-Roberts; Liam Carroll; Susan Wei; Daniel Murfet
- Reference count: 40
- One-line primary result: This paper investigates the link between loss landscape degeneracy and developmental stages in transformers by tracking the local learning coefficient (LLC) throughout training.

## Executive Summary
This paper investigates the link between loss landscape degeneracy and developmental stages in transformers by tracking the local learning coefficient (LLC) throughout training. The authors train two transformer models—a language model and an in-context linear regression model—and monitor how the LLC changes over time. They identify plateaus in the LLC curve as stage boundaries and validate these divisions by examining structural and behavioral changes in the models. The results show that most developmental stages identified by changes in degeneracy coincide with significant, interpretable shifts in the internal computational structure and input/output behavior of the transformers, suggesting that degeneracy and development are fundamentally linked in deep learning.

## Method Summary
The authors train two transformer models—a language model on the Pile dataset and an in-context linear regression model on synthetic data—and estimate the local learning coefficient (LLC) at regular intervals throughout training using stochastic gradient Langevin dynamics (SGLD). They identify plateaus in the LLC curve as stage boundaries and analyze structural and behavioral changes within each stage using metrics such as bigram scores, n-gram scores, in-context learning scores, attention entropy, and attention variability. The method combines empirical training with theoretical analysis from singular learning theory to establish a connection between loss landscape geometry and model development.

## Key Results
- LLC plateaus reliably identify distinct developmental stages in both transformer models
- Most identified stages correspond to interpretable shifts in internal structure and behavior
- Developmental changes include learning of bigram statistics, positional information, induction circuits, and in-context learning capabilities
- LLC decreases in some stages indicate model simplification, challenging existing theories of neural network development

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Changes in loss landscape degeneracy, as measured by the local learning coefficient (LLC), reveal stage boundaries in transformer training.
- **Mechanism:** The LLC quantifies degeneracy by measuring how volume in parameter space scales near a local minimum. As training progresses, sudden changes in this scaling indicate shifts in the effective dimensionality of the model, which correspond to qualitative changes in internal structure and behavior.
- **Core assumption:** The LLC estimator using SGLD provides reliable estimates of degeneracy throughout training, even when parameters are not exact local minima.
- **Evidence anchors:**
  - [abstract] "We track loss landscape degeneracy throughout training, as quantified by the local learning coefficient"
  - [section 4] "We quantify loss landscape degeneracy throughout training by estimating the local learning coefficient"
  - [corpus] No direct evidence for LLC reliability during training; assumption stated as "precedent in prior work"
- **Break condition:** If SGLD chains escape to distant optima or fail to converge, LLC estimates become unreliable and stage boundaries cannot be identified.

### Mechanism 2
- **Claim:** LLC plateaus delineate developmental stages where internal computational structures form and behavioral capabilities emerge.
- **Mechanism:** Critical points in the LLC curve indicate brief pauses in degeneracy changes, marking boundaries between distinct developmental periods. These periods coincide with interpretable shifts in model behavior and structure.
- **Core assumption:** Changes in degeneracy are linked to changes in internal structure and behavior through the singular learning process framework.
- **Evidence anchors:**
  - [abstract] "We show that training can be divided into distinct periods of change in loss landscape degeneracy"
  - [section 5] "we use critical points in the LLC curve to define stage boundaries"
  - [corpus] No direct evidence for singular learning process applying to SGD training
- **Break condition:** If developmental changes occur without corresponding LLC changes, the degeneracy-based stage division fails to capture meaningful model development.

### Mechanism 3
- **Claim:** Specific developmental stages correspond to identifiable structural and behavioral changes in transformers.
- **Mechanism:** Each stage identified by LLC plateaus coincides with measurable changes: LM1 learns bigram statistics, LM2 uses positional information and learns n-grams, LM3-4 forms induction circuits, LR1 learns context-independent prediction, LR2 acquires in-context learning, LR3-4 shows reduced robustness to outliers.
- **Core assumption:** The metrics used to track behavior and structure are sensitive enough to detect meaningful developmental changes.
- **Evidence anchors:**
  - [abstract] "most of the developmental stages identified by changes in degeneracy coincide with significant, interpretable shifts in the internal computational structure"
  - [section 6] "In LM1 the model learns to predict according to bigram statistics"
  - [corpus] No direct evidence for metric sensitivity across diverse transformer architectures
- **Break condition:** If developmental changes occur that don't affect the measured metrics, they may be missed by the analysis.

## Foundational Learning

- **Concept:** Singular Learning Theory (SLT)
  - Why needed here: Provides theoretical foundation linking degeneracy in loss landscape to developmental stages
  - Quick check question: How does SLT explain the relationship between loss landscape geometry and model complexity?

- **Concept:** Bayesian inference and the singular learning process
  - Why needed here: Motivates the use of LLC plateaus as stage boundaries through the concept of posterior transitions between neighborhoods of different degeneracy
  - Quick check question: What role does the local learning coefficient play in the singular learning process?

- **Concept:** Nonlinear dynamics and bifurcation theory
  - Why needed here: Provides additional theoretical motivation for how degeneracy in a potential can give rise to stagewise development
  - Quick check question: How does degeneracy in a potential function relate to structural changes in a dynamical system?

## Architecture Onboarding

- **Component map:** Transformer models with attention-only layers (no MLPs for language models), positional embeddings, layer normalization, and unembedding layers. Two learning settings: language modeling and in-context linear regression.

- **Critical path:** 1) Train transformer models with saved checkpoints, 2) Estimate LLC at each checkpoint using SGLD, 3) Identify plateaus in LLC curve to define stages, 4) Analyze behavioral and structural changes within each stage.

- **Design tradeoffs:** Language models use attention-only architecture for comparability with prior work but may miss developmental insights from MLP layers. Linear regression setting provides theoretical clarity but may not capture full complexity of real-world tasks.

- **Failure signatures:** LLC estimates fail to converge or show excessive variance, LLC curve lacks clear plateaus, identified stages don't correspond to interpretable behavioral or structural changes.

- **First 3 experiments:**
  1. Train a simple one-layer attention-only transformer on synthetic data and verify LLC estimation works
  2. Apply LLC estimation to a pre-trained language model checkpoint and check for stable estimates
  3. Train a two-layer transformer on in-context linear regression and identify initial LLC-based stages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed link between loss landscape degeneracy and developmental stages hold across more diverse transformer architectures, data distributions, and learning algorithms?
- Basis in paper: [explicit] The authors state that their analysis is limited to two specific settings and that verifying the connection across a more diverse range of emergent model structures and behaviors is necessary.
- Why unresolved: The study only examined two-layer attention-only transformers in language modeling and in-context linear regression settings. Different architectures (e.g., with MLP layers), data distributions, and training algorithms may exhibit different developmental patterns that could either strengthen or weaken the observed link.
- What evidence would resolve it: Systematic studies examining LLC-based stage identification across various transformer architectures (varying depth, attention patterns, activation functions), data types (images, code, multimodal), and training procedures (different optimizers, learning rate schedules, regularization methods) would provide conclusive evidence.

### Open Question 2
- Question: What is the mechanistic explanation for stages where the local learning coefficient decreases, indicating a simplification of the model's computational structure?
- Basis in paper: [explicit] The authors observe LLC decreases during certain stages and note that this phenomenon is not accounted for by existing theories of neural network development, which typically predict increasing complexity.
- Why unresolved: While the authors provide examples of weight and attention pattern collapses that might explain LLC decreases, they cannot definitively establish a causal relationship or explain why simpler structures would be favored during certain developmental stages.
- What evidence would resolve it: Detailed mechanistic interpretability studies tracing how parameter changes during LLC-decreasing stages lead to simpler computational pathways, combined with theoretical work on why SGD might favor such simplifications, would provide clarity.

### Open Question 3
- Question: What is the precise relationship between the singular learning process in Bayesian inference and the development observed in stochastic gradient descent-trained neural networks?
- Basis in paper: [inferred] The authors draw analogies between stage divisions in their experiments and the singular learning process, but acknowledge that fully accounting for the observed LLC decreases requires theoretical progress in relating Bayesian inference to SGD.
- Why unresolved: While both Bayesian inference and SGD show stagewise development, the theoretical conditions under which LLC estimation works away from local minima are not well understood, and the connection between free energy minimization and gradient-based optimization remains unclear.
- What evidence would resolve it: Mathematical frameworks establishing rigorous connections between the free energy landscape of Bayesian inference and the empirical loss landscape traversed by SGD, potentially through analyzing the implicit regularization properties of SGD, would provide answers.

## Limitations
- LLC estimation relies on SGLD chains that may not converge to true local minima during training, potentially affecting stage boundary identification
- The singular learning theory framework connecting degeneracy to development is not directly validated for SGD-trained transformers
- Stage boundaries are identified through heuristic smoothing and tolerance parameters, making them somewhat subjective

## Confidence

- **High confidence**: The LLC curves show clear plateaus during training and correlate with interpretable behavioral changes in both transformer models
- **Medium confidence**: The LLC plateaus meaningfully divide training into stages with distinct internal structures, though some developmental changes may occur between identified boundaries
- **Medium confidence**: The metrics used to track behavior and structure are sensitive to developmental changes, but may miss subtler transitions

## Next Checks

1. Perform ablation studies varying SGLD hyperparameters (step size, chain count, steps per chain) to assess robustness of LLC estimates and stage boundaries
2. Compare LLC-based stage identification with alternative methods (e.g., mutual information between layers, PCA of activation patterns) to validate the degeneracy-based approach
3. Test whether artificially modifying loss landscape degeneracy through regularization affects the timing and nature of developmental stages