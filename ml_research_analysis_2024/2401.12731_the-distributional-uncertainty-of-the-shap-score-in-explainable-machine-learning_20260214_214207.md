---
ver: rpa2
title: The Distributional Uncertainty of the SHAP score in Explainable Machine Learning
arxiv_id: '2401.12731'
source_url: https://arxiv.org/abs/2401.12731
tags:
- shap
- shapm
- feature
- features
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how Shapley Additive Explanations (SHAP)
  scores, a popular method for interpreting machine learning models, are affected
  by uncertainty in the underlying probability distribution of the data. The authors
  propose a framework for reasoning about SHAP scores under distributional uncertainty,
  treating the SHAP score as a polynomial function over an uncertainty region of probability
  distributions.
---

# The Distributional Uncertainty of the SHAP score in Explainable Machine Learning

## Quick Facts
- arXiv ID: 2401.12731
- Source URL: https://arxiv.org/abs/2401.12731
- Authors: Santiago Cifuentes; Leopoldo Bertossi; Nina Pardal; Sergio Abriola; Maria Vanina Martinez; Miguel Romero
- Reference count: 31
- Primary result: SHAP scores under distributional uncertainty form multilinear polynomials over hyperrectangles, with NP-complete complexity for finding extrema

## Executive Summary
This paper introduces a framework for analyzing SHAP scores under distributional uncertainty, treating SHAP as a polynomial function over regions of probability distributions. The authors establish that finding maximum and minimum SHAP scores within uncertainty regions is NP-complete, even for simple decision trees. Experiments on the California Housing dataset demonstrate that considering uncertainty leads to different feature rankings and provides more robust insights into feature importance.

## Method Summary
The framework converts machine learning models into SHAP polynomials over probability distributions, defines uncertainty regions as hyperrectangles around empirical distributions, and finds extrema by evaluating the polynomial at all vertices. The method is applied to a binarized version of the California Housing dataset using decision trees, computing SHAP intervals for random entities across varying sampling percentages to analyze ranking sensitivity.

## Key Results
- SHAP scores under uncertainty form multilinear polynomials over hyperrectangle uncertainty regions
- Finding max/min SHAP scores and related problems (ambiguity, irrelevance) are NP-complete for decision trees
- SHAP intervals provide insights into feature importance robustness under distributional uncertainty
- Real-world experiments show uncertainty-aware analysis can change feature rankings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SHAP polynomial formulation allows uncertainty analysis by treating SHAP score as a function over a hyperrectangle of probability distributions
- Mechanism: By representing SHAP score as a multilinear polynomial in probability variables (px), the framework can find max/min values over uncertainty regions using vertex analysis
- Core assumption: The SHAP polynomial is multilinear and its extrema occur at vertices of the hyperrectangle
- Evidence anchors:
  - [abstract] "we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region"
  - [section] "Proposition 4. Let f be a multilinear polynomial over n variables. Let I ⊆ [0, 1]^n be a hyperrectangle. Then the maximum and minimum of f restricted to I is attained in the vertices of I."
  - [corpus] Weak - no direct mention of polynomial formulation in neighbor papers

### Mechanism 2
- Claim: NP-completeness results provide theoretical foundation for computational complexity of uncertainty-aware SHAP analysis
- Mechanism: By proving that finding max/min SHAP scores over uncertainty regions is NP-complete (even for decision trees), the framework establishes that uncertainty-aware SHAP analysis is computationally hard but still in NP class
- Core assumption: The hardness results hold for practical model classes like decision trees where SHAP is normally tractable
- Evidence anchors:
  - [section] "we establish that determining these extrema, as well as related problems like checking for ambiguity or irrelevance of features, are NP-complete, even for simple models like decision trees"
  - [section] "Theorem 7. The problem REGION-MAX-SAP is NP-hard for decomposable and deterministic Boolean circuits. The result holds even when restricted to decision trees."
  - [corpus] No direct mention of NP-completeness in neighbor papers

### Mechanism 3
- Claim: SHAP intervals provide robust feature importance rankings that are invariant to distributional uncertainty
- Mechanism: By computing the range of possible SHAP scores over uncertainty regions, the framework can identify when feature rankings are stable versus when they depend on the specific distribution choice
- Core assumption: The length and overlap of SHAP intervals correlate with robustness of feature importance rankings
- Evidence anchors:
  - [abstract] "experiments on a real-world dataset demonstrate that considering uncertainty can lead to different feature rankings and provide more robust insights into feature importance"
  - [section] "SHAP intervals may provide useful insights. For instance, obtaining smaller SHAP intervals for a feature suggests its SHAP score is more robust against uncertainty"
  - [corpus] Weak - no direct mention of SHAP intervals in neighbor papers

## Foundational Learning

- Concept: Multilinear polynomials and their properties
  - Why needed here: The SHAP polynomial is multilinear, and understanding its properties (like extrema at vertices) is crucial for the framework's analysis
  - Quick check question: Why do multilinear polynomials attain their maximum and minimum at vertices of hyperrectangles?

- Concept: Computational complexity classes (NP, NP-complete)
  - Why needed here: The framework's complexity results rely on understanding what it means for a problem to be NP-complete
  - Quick check question: What is the difference between a problem being in NP versus being NP-complete?

- Concept: Shapley values and coalition game theory
  - Why needed here: SHAP scores are based on Shapley values, so understanding this foundation is necessary to grasp why the framework works
  - Quick check question: How does the Shapley value formula compute feature importance in coalition games?

## Architecture Onboarding

- Component map: Model → Polynomial Generation → Hyperrectangle Definition → Optimization → Interval Computation → Visualization

- Critical path: Model → Polynomial → Hyperrectangle → Optimization → Intervals → Analysis

- Design tradeoffs:
  - Accuracy vs. tractability: Using vertex analysis is exact but exponential in feature count
  - Generality vs. efficiency: Framework works for many models but may be slow for high-dimensional cases
  - Precision vs. computational cost: Tighter uncertainty bounds give more precise results but require more computation

- Failure signatures:
  - Very large SHAP intervals indicate high sensitivity to distributional uncertainty
  - NP-hard problems becoming intractable for realistic model sizes
  - Non-multilinear behavior in SHAP polynomial indicating model class limitations

- First 3 experiments:
  1. Simple linear model with 2-3 features: Verify polynomial generation and vertex analysis
  2. Decision tree with known optimal solution: Test NP-hardness claims and algorithm correctness
  3. Real dataset with varying sample sizes: Validate interval computation and robustness analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the complexity of finding SHAP score maxima/minima change when moving beyond product distributions to more general probability distributions?
- Basis in paper: [explicit] The paper explicitly states that "going beyond the case of product distributions is a natural next step" and that their current results focus on product distributions and hyperrectangles
- Why unresolved: The paper only establishes NP-completeness for the product distribution case, leaving open whether similar complexity results hold for more general distributions
- What evidence would resolve it: A formal proof showing whether the NP-completeness results extend to other distribution families (e.g., multivariate Gaussian, mixture models) or demonstrating that different complexity classes apply

### Open Question 2
- Question: What is the relationship between distributional robustness of SHAP scores and input-level robustness of the classifier itself?
- Basis in paper: [explicit] The paper notes this is "a different problem from the most common one of robustness with respect to the perturbation of an input entity" and suggests analyzing "how a local perturbation of a given distribution in the uncertainty region affects the SHAP scores."
- Why unresolved: While the paper establishes complexity bounds for SHAP variation over entire uncertainty regions, it doesn't investigate how small perturbations affect SHAP scores or how this relates to input-level robustness properties
- What evidence would resolve it: Empirical studies showing the correlation between classifier robustness measures and SHAP score stability under distributional perturbations, or theoretical bounds connecting these two forms of robustness

### Open Question 3
- Question: How does the computational complexity of SHAP analysis under distributional uncertainty scale with the dimensionality of the feature space?
- Basis in paper: [inferred] The paper shows NP-completeness results but doesn't provide detailed empirical scaling analysis, particularly noting that their algorithm evaluates vertices of hyperrectangles (2^n evaluations for n features)
- Why unresolved: The theoretical NP-completeness results don't specify how practical computation time grows with feature dimensionality, which is crucial for real-world applications
- What evidence would resolve it: Systematic experiments measuring computation time as a function of feature dimensionality, or approximation algorithms with provable error bounds that scale better with dimensionality

### Open Question 4
- Question: How do the proposed distributional uncertainty methods apply to non-binary features and labels?
- Basis in paper: [explicit] The paper states "It would be interesting to know how a local perturbation of a given distribution in the uncertainty region affects the SHAP scores" and mentions that their framework is "defined for binary features," suggesting extension to non-binary cases
- Why unresolved: The paper's framework and complexity results are all derived for binary features, but real-world data often contains continuous or categorical features with multiple levels
- What evidence would resolve it: Formal extensions of the polynomial framework to handle multi-valued features, along with corresponding complexity analysis and experimental validation on datasets with non-binary features

## Limitations
- Vertex enumeration approach has exponential computational complexity in feature count, limiting scalability
- Framework currently restricted to binary features and labels, limiting applicability to real-world data
- NP-completeness results, while theoretically important, may not reflect practical performance at typical problem scales

## Confidence

- **High Confidence**: The multilinear polynomial formulation and vertex optimization mechanism - directly supported by Proposition 4 and fundamental properties of multilinear functions
- **Medium Confidence**: The NP-completeness results - theoretically sound but computational complexity may not manifest at practical problem scales
- **Medium Confidence**: The robustness claims via SHAP intervals - experimental results show promise but the relationship between interval properties and ranking stability needs more rigorous validation

## Next Checks

1. **Scalability Benchmark**: Test the vertex enumeration approach on synthetic decision trees with increasing feature counts (5, 10, 15, 20 features) to empirically measure computational scaling and identify practical limits.

2. **Interval-Robustness Correlation**: Conduct controlled experiments where the true data distribution is varied systematically, measuring how well SHAP interval width predicts changes in feature ranking stability across multiple runs.

3. **Alternative Optimization Methods**: Compare the vertex enumeration approach against approximation methods (sampling-based optimization, convex relaxations) to evaluate the tradeoff between exactness and computational efficiency for larger problems.