---
ver: rpa2
title: 'LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context
  QA'
arxiv_id: '2409.02897'
source_url: https://arxiv.org/abs/2409.02897
tags:
- citations
- citation
- statement
- answer
- cite
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of enabling large language models
  (LLMs) to generate fine-grained sentence-level citations in long-context question
  answering (QA) scenarios, improving trustworthiness and verifiability. The authors
  propose CoF, a pipeline that uses off-the-shelf LLMs to automatically construct
  high-quality long-context QA instances with precise citations.
---

# LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA

## Quick Facts
- arXiv ID: 2409.02897
- Source URL: https://arxiv.org/abs/2409.02897
- Reference count: 40
- LongCite models outperform GPT-4o in citation F1 scores by up to 6.4%, generating finer-grained sentence-level citations in long-context QA.

## Executive Summary
This paper addresses the challenge of generating fine-grained sentence-level citations in long-context question answering using large language models. The authors propose CoF, an automated pipeline that constructs high-quality QA instances with precise citations, resulting in the LongCite-45k dataset. By fine-tuning models on this dataset, LongCite-8B and LongCite-9B achieve superior citation quality compared to larger proprietary models like GPT-4o, enabling more trustworthy and verifiable long-context QA responses.

## Method Summary
The authors introduce CoF, a pipeline that leverages off-the-shelf LLMs to generate long-context QA instances with fine-grained citations. The process involves using Self-Instruct to generate questions and answers, adding coarse-grained chunk-level citations, extracting fine-grained sentence-level citations, and filtering low-quality instances. This pipeline is used to construct the LongCite-45k dataset, which is then used to fine-tune LongCite-8B and LongCite-9B models for single-pass citation generation.

## Key Results
- LongCite models achieve citation F1 scores up to 6.4% higher than GPT-4o.
- The models generate finer-grained sentence-level citations compared to baseline approaches.
- LongCite-8B and LongCite-9B outperform even much larger proprietary models in citation quality.

## Why This Works (Mechanism)
The CoF pipeline automates the creation of high-quality long-context QA instances with precise citations by combining LLM-based question generation, coarse-to-fine citation extraction, and quality filtering. This ensures the fine-tuning dataset captures both accurate answers and precise sentence-level references, enabling models to learn the mapping from content to citation in a single pass.

## Foundational Learning
- **Long-context QA**: Processing and answering questions over extensive text passages; needed to handle real-world documents; quick check: input length > 8k tokens.
- **Sentence-level citation**: Referencing specific sentences as evidence; improves verifiability; quick check: citation granularity < sentence level.
- **Self-Instruct**: LLM-driven instruction generation; creates diverse QA pairs; quick check: question-answer diversity > baseline.
- **Citation F1 score**: Metric for citation accuracy; evaluates both precision and recall; quick check: higher F1 = better citation quality.
- **Fine-tuning**: Adapting pre-trained models to specific tasks; improves task-specific performance; quick check: compare pre-trained vs. fine-tuned results.
- **Dataset filtering**: Removing low-quality instances; ensures training data reliability; quick check: filtered data quality > unfiltered.

## Architecture Onboarding
- **Component map**: Input documents -> CoF pipeline (question generation, coarse citation, fine citation, filtering) -> LongCite-45k dataset -> Fine-tuning -> LongCite models (8B, 9B) -> QA with citations.
- **Critical path**: CoF pipeline construction of LongCite-45k dataset → fine-tuning LongCite models → single-pass citation generation.
- **Design tradeoffs**: Automated pipeline enables large-scale dataset creation but may introduce bias; single-pass inference trades complexity for speed; sentence-level citations increase precision but require more granular extraction.
- **Failure signatures**: Low citation recall indicates missed evidence; coarse citations suggest insufficient fine-grained extraction; poor QA accuracy points to weak fine-tuning data or model capacity.
- **First 3 experiments**: 1) Ablation of CoF components to measure impact on citation F1. 2) Evaluation on out-of-domain datasets to test generalization. 3) Error analysis on filtering mechanisms to quantify bias.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on CoF pipeline quality raises concerns about potential biases in LongCite-45k dataset.
- Evaluation focuses on citation accuracy, not correctness of underlying answers.
- Limited baseline comparisons and proprietary model constraints restrict reproducibility.
- Generalizability to other domains or languages remains untested.

## Confidence
- **High Confidence**: The reported citation F1 score improvements and the effectiveness of the CoF pipeline in generating fine-grained citations are well-supported by the experimental results.
- **Medium Confidence**: The superiority of LongCite models over GPT-4o in citation quality is credible but based on limited baseline comparisons and proprietary model constraints.
- **Low Confidence**: The long-term generalizability of the approach to other domains or languages and the robustness of the filtering mechanisms for dataset quality are uncertain due to lack of extensive validation.

## Next Checks
1. Conduct ablation studies to assess the impact of each component in the CoF pipeline on the final citation quality and dataset diversity.
2. Evaluate the LongCite models on out-of-domain datasets to test robustness and generalizability beyond the constructed LongCite-45k corpus.
3. Perform a detailed error analysis on the filtering mechanisms to quantify and mitigate potential biases introduced during dataset construction.