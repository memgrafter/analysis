---
ver: rpa2
title: 'ChartKG: A Knowledge-Graph-Based Representation for Chart Images'
arxiv_id: '2410.09761'
source_url: https://arxiv.org/abs/2410.09761
tags:
- chart
- visual
- data
- charts
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ChartKG proposes a knowledge graph-based representation for chart
  images that models visual elements and their semantic relationships in a unified
  manner. The approach extracts five entity types (visual elements, visual element
  property values, data variables, data variable values, visual insights) and four
  relationship types (visual property correspondences, data variable correspondences,
  visual encoding mappings, visual insight correspondences).
---

# ChartKG: A Knowledge-Graph-Based Representation for Chart Images

## Quick Facts
- **arXiv ID**: 2410.09761
- **Source URL**: https://arxiv.org/abs/2410.09761
- **Reference count**: 40
- **Key outcome**: ChartKG proposes a knowledge graph-based representation for chart images that models visual elements and their semantic relationships in a unified manner.

## Executive Summary
ChartKG introduces a novel knowledge graph (KG) based representation for chart images that unifies visual elements, data variables, and visual insights in a structured, machine-interpretable form. The approach defines five entity types and four relationship types to capture both the raw visual structure and semantic meaning of charts. A general framework converts chart images to KG representation using CNNs for classification, YOLOv5 and OCR for parsing, and rule-based methods for graph construction. The method demonstrates strong performance on object recognition (mAP50 above 0.7 for all chart types) and OCR accuracy (exceeding 70% for most text categories), enabling effective semantic-aware chart retrieval and chart question answering that outperform keyword-based and deep learning-only approaches.

## Method Summary
ChartKG converts chart images into knowledge graph representations by first classifying the chart type using a pre-trained ResNet50 model, then parsing visual elements and text using YOLOv5 for object detection and Tesseract OCR for text extraction. The extracted elements are classified into five entity types (visual elements, visual element property values, data variables, data variable values, visual insights) and four relationship types (visual property correspondences, data variable correspondences, visual encoding mappings, visual insight correspondences) using rule-based methods. This structured representation enables downstream tasks like semantic-aware chart retrieval and chart question answering by matching entities and relationships rather than raw visual features.

## Key Results
- Object recognition achieves mAP50 above 0.7 for all chart types, with most categories exceeding 0.9
- OCR accuracy exceeds 70% for most text categories
- ChartKG-powered retrieval achieves average user ratings above 4.0, outperforming keyword-based methods
- KG-based question answering outperforms both T5 and KG-T5 baselines in accuracy while being more time-efficient

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The knowledge graph representation unifies visual elements, data variables, and visual insights in a structured, machine-interpretable form.
- Mechanism: By defining five entity types and four relationship types, the approach captures both the raw visual structure and semantic meaning of charts.
- Core assumption: Standard charts can be decomposed into these five entity types and four relationship types without loss of essential information for downstream tasks.
- Evidence anchors: [abstract] "ChartKG... can model the visual elements in a chart image and semantic relations among them including visual encodings and visual insights in a unified manner." [section III] "By investigating and summarizing common visual elements of charts and the semantic relations among them, we categorize the involved entities of charts into five types..."

### Mechanism 2
- Claim: The chart-to-KG conversion framework achieves high accuracy in object recognition and OCR, enabling reliable KG construction.
- Mechanism: The framework uses pre-trained CNNs for chart classification, YOLOv5 for object detection, and Tesseract OCR for text extraction, achieving mAP50 above 0.7 for all chart types and OCR accuracy above 70% for most text categories.
- Core assumption: State-of-the-art computer vision models pre-trained on general datasets can be fine-tuned to achieve high accuracy on chart-specific tasks.
- Evidence anchors: [section V-B] "The results indicate that our framework performs well in terms of the metrics. Across various object categories, the majority of them exhibit excellent recognition rates, with mAP50, Precision, and Recall scores consistently exceeding 0.9..." [section V-C] "Most categories of text OCR accuracy are above 70%."

### Mechanism 3
- Claim: The KG-based representation enables semantic-aware chart retrieval and chart question answering that outperform keyword-based and deep learning-only approaches.
- Mechanism: By structuring chart content as a knowledge graph, the approach enables entity and relationship matching for retrieval and template-based question answering, achieving higher accuracy and interpretability than T5 and KG-T5 baselines.
- Core assumption: Structured semantic relationships in charts are more effective for matching user queries than raw visual or textual features alone.
- Evidence anchors: [section VII-A] "Our average rating exceeds 4.0, which is much higher than the keyword-based method. Moreover, our time consumption is only slightly increased..." [section VII-B] "KG-T5 achieved higher accuracy with minimal differences in time efficiency... our method excels in both time efficiency and question-answering accuracy compared to deep learning-based methods."

## Foundational Learning

- **Concept**: Knowledge graphs as structured representations of entities and relationships
  - Why needed here: ChartKG relies on representing chart content as entities and relationships to enable machine understanding and downstream tasks
  - Quick check question: Can you explain the difference between entities and relationships in a knowledge graph?

- **Concept**: Object detection and recognition in computer vision
  - Why needed here: The chart-to-KG framework uses YOLOv5 to detect visual elements like bars, lines, and text in charts
  - Quick check question: What is the difference between object detection and image classification?

- **Concept**: Optical character recognition (OCR) for text extraction
  - Why needed here: Tesseract OCR is used to extract text from chart elements like titles, labels, and legends
  - Quick check question: What are the main challenges in OCR for chart images compared to natural images?

## Architecture Onboarding

- **Component map**: Chart → Classification → Object Detection → OCR → Entity Classification → Relationship Construction → Knowledge Graph
- **Critical path**: Chart image flows through classification, parsing, entity extraction, and relationship construction to produce the final knowledge graph
- **Design tradeoffs**: The approach trades off between representation expressiveness (using KG) and extraction accuracy (using pre-trained models), balancing between comprehensive semantic capture and practical implementation feasibility
- **Failure signatures**: Low object recognition accuracy, OCR errors, incorrect chart classification, and failure to capture non-standard visual encodings are key failure points
- **First 3 experiments**:
  1. Evaluate chart classification accuracy on a small set of diverse chart images
  2. Test object detection and OCR on a subset of charts to measure accuracy and identify failure modes
  3. Construct a simple knowledge graph for a single chart type and validate the entity and relationship extraction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would ChartKG's accuracy change when applied to complex visualizations like network graphs or arc diagrams?
- Basis in paper: [explicit] "For more complex charts, such as arc diagrams and packed circles, our evaluation does not cover."
- Why unresolved: The paper only evaluated ChartKG on four basic chart types (bar, line, pie, scatter) and acknowledges it would need extensions for complex visualizations.
- What evidence would resolve it: Systematic evaluation of ChartKG on various complex chart types with performance metrics compared to baseline methods.

### Open Question 2
- Question: What is the impact of OCR errors on downstream tasks, and how can these errors be systematically corrected?
- Basis in paper: [explicit] "OCR accuracy can be further enhanced with the introduction of more comprehensive training data and models" and "we plan to develop a human-machine interaction system for manual correction of errors."
- Why unresolved: While the paper acknowledges OCR limitations and plans for future work, it doesn't quantify the impact of OCR errors on task performance or validate any correction mechanisms.
- What evidence would resolve it: Empirical study measuring task performance degradation due to OCR errors and evaluation of error correction systems.

### Open Question 3
- Question: How does the knowledge graph representation compare to other structured representations (like JSON or XML) for chart understanding tasks?
- Basis in paper: [inferred] The paper compares ChartKG to end-to-end deep learning methods and data-extraction methods but doesn't compare to other structured representations.
- Why unresolved: The paper establishes ChartKG's advantages over black-box methods but doesn't position it against other interpretable, structured chart representations.
- What evidence would resolve it: Head-to-head comparison of ChartKG against alternative structured representations across multiple chart understanding tasks with quantitative metrics.

## Limitations
- The framework relies on pre-trained models that may struggle with highly stylized or low-quality chart images
- Rule-based KG construction may not generalize well to non-standard chart types or complex visual encodings
- Template-based question answering is limited to predefined visual insights and may fail on queries requiring deeper reasoning

## Confidence
- Chart-to-KG conversion framework effectiveness: **High** (supported by quantitative metrics and case studies)
- KG-based chart retrieval superiority: **Medium** (based on user ratings, but limited to specific query types)
- KG-based question answering accuracy: **Medium** (outperforms baselines but uses template-based approach with limited reasoning)

## Next Checks
1. Test the framework on a diverse set of real-world charts with varying quality, styles, and complexity to evaluate robustness beyond the reported results
2. Conduct user studies comparing ChartKG-based retrieval with more sophisticated semantic search methods on a wider range of query types and chart categories
3. Evaluate the question answering system on charts requiring multi-step reasoning or non-standard visual encodings to assess the limitations of the template-based approach