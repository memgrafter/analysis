---
ver: rpa2
title: Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language
  Models
arxiv_id: '2409.16220'
source_url: https://arxiv.org/abs/2409.16220
tags:
- llms
- data
- queries
- accuracy
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates integrating Large Language Models (LLMs)
  into conversational user interfaces (UIs) to enhance entity extraction and RDF reasoning
  over linked data systems without requiring model retraining. By embedding RDF schema
  data into LLM prompts and using optimized templates, the approach improves the accuracy
  and expressivity of queries in conversational UIs.
---

# Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models

## Quick Facts
- arXiv ID: 2409.16220
- Source URL: https://arxiv.org/abs/2409.16220
- Reference count: 25
- Key result: Integrating LLMs into conversational UIs improves entity extraction and RDF reasoning without model retraining.

## Executive Summary
This study explores using Large Language Models (LLMs) to enhance entity extraction and RDF reasoning in conversational user interfaces (UIs) over linked data systems. By embedding RDF schema data directly into LLM prompts and employing optimized templates, the approach enables accurate query processing without requiring model retraining. Experiments with multiple state-of-the-art LLMs demonstrate significant improvements in accuracy for both entity extraction and RDF schema querying, enabling more context-aware interactions in conversational UIs.

## Method Summary
The method involves embedding RDF schema data into LLM prompts using optimized templates to guide accurate JSON output generation. RDF triples are converted to vector embeddings for scalable semantic retrieval, enabling focused subgraph generation for arbitrary user queries. Experiments compare zero-shot and few-shot performance across multiple LLMs, using structural and semantic evaluation metrics to assess output quality. The approach leverages existing ontologies and linked data endpoints without model fine-tuning.

## Key Results
- GPT-4-turbo achieved 68.3% accuracy in zero-shot entity extraction, rising to 89.2% in few-shot scenarios.
- GPT-4-turbo reached 100% accuracy in RDF schema querying tasks.
- Optimized prompt templates improved output accuracy by up to 42.86% compared to simpler prompts.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM integration improves entity extraction in conversational UIs without requiring retraining by embedding RDF schema data directly into LLM prompts.
- Mechanism: RDF schema definitions (sensors, properties, monitored values) are embedded into prompts, enabling the LLM to reason over structured data and generate accurate JSON outputs mapping user queries to SPARQL entities.
- Core assumption: LLMs can parse and reason over structured RDF triples and schema when embedded in prompts, producing correct mappings without fine-tuning.
- Evidence anchors:
  - [abstract] "embedding RDF schema data into LLM prompts and using optimized templates"
  - [section] "The definitions of sensors, their properties, and the corresponding properties each sensor monitors are the essential data for the LLM to identify entities and understand their relationships"
- Break condition: If the RDF schema is too large to fit into the prompt or if the LLM fails to preserve structural integrity of the schema mapping in outputs.

### Mechanism 2
- Claim: Vector embeddings of RDF triples combined with subgraph generation allow scalable and accurate retrieval of relevant RDF data for arbitrary user queries.
- Mechanism: RDF triples are embedded as vectors; for each query, the closest triples are found, subgraphs are merged, and the result is injected into the LLM prompt to provide focused context.
- Core assumption: Semantic similarity between query embeddings and RDF triple embeddings reliably retrieves contextually relevant triples for accurate entity extraction.
- Evidence anchors:
  - [section] "We utilised the ‘paraphrase-TinyBERT-L6-v2’, a pre-trained model capable of capturing semantic similarities within textual data [19], to represent each triple as a vector."
  - [section] "When a user query is received, it is similarly encoded, and a cosine similarity search is performed in Qdrant to identify the most closely related triple."
- Break condition: If the embedding model fails to capture domain-specific semantics or if query ambiguity leads to incorrect subgraph selection.

### Mechanism 3
- Claim: Optimized prompt templates significantly improve LLM output accuracy for structured JSON generation in entity extraction tasks.
- Mechanism: Detailed prompts with explicit instructions and JSON templates guide the LLM to generate syntactically correct, semantically accurate JSON outputs mapping queries to RDF entities and filters.
- Core assumption: LLMs are highly sensitive to prompt structure and detail, and providing clear JSON scaffolding reduces hallucinations and improves compliance.
- Evidence anchors:
  - [section] "Recent studies have demonstrated the high sensitivity of LLMs to the specificity of prompts"
  - [section] "Table 2, the results indicated a 42.86% improvement in the outputs generated by the more detailed second prompt compared to the first."
- Break condition: If prompts become too long relative to context limits, or if LLM output generation becomes inconsistent under different template formats.

## Foundational Learning

- Concept: RDF and SPARQL fundamentals
  - Why needed here: Understanding how RDF triples, SPARQL queries, and ontology schemas work is critical to embedding and reasoning over linked data in prompts.
  - Quick check question: What are the three components of an RDF triple and how do they map to SPARQL SELECT clauses?

- Concept: Vector embeddings and semantic similarity
  - Why needed here: RDF triples are converted to vectors for retrieval; understanding cosine similarity and embedding models is key to evaluating subgraph generation accuracy.
  - Quick check question: How does cosine similarity between RDF triple embeddings help retrieve contextually relevant data for a user query?

- Concept: LLM prompt engineering and few-shot learning
  - Why needed here: Accurate JSON generation depends on prompt structure and the use of few-shot examples to guide model behavior without retraining.
  - Quick check question: Why does providing a JSON template in the prompt improve the likelihood of correct structured output?

## Architecture Onboarding

- Component map:
  - User query → Query encoder → Qdrant vector DB → RDF subgraph retrieval → LLM prompt assembly → LLM output → JSON validation → SPARQL query builder
  - RDF store (SPARQL endpoint) ↔ RDF embedding pipeline ↔ LLM integration layer ↔ UI interface
- Critical path:
  - Query encoding → RDF subgraph retrieval → LLM response generation → JSON validation
- Design tradeoffs:
  - Prompt size vs. RDF context richness: embedding too much RDF risks exceeding LLM context limits.
  - Semantic accuracy vs. retrieval speed: using vector embeddings trades exactness for scalability.
  - Few-shot examples vs. prompt simplicity: more examples improve accuracy but consume token budget.
- Failure signatures:
  - JSON structure mismatches or missing keys in LLM output.
  - Incorrect RDF entity mapping due to poor semantic retrieval.
  - LLM hallucinations when RDF context is insufficient or ambiguous.
- First 3 experiments:
  1. Encode a set of simple user queries and retrieve top-1 RDF triple embeddings; validate correct mapping manually.
  2. Expand to top-2 triple retrieval, merge subgraphs, and assess accuracy improvement over top-1.
  3. Compare few-shot vs. zero-shot performance using the same query set, measuring JSON accuracy and structure.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMs in entity extraction and RDF reasoning vary across different types of linked data ontologies beyond SOSA?
- Basis in paper: [inferred] The paper tests LLMs with a specific SOSA ontology dataset, but does not explore performance across diverse ontologies.
- Why unresolved: The study focuses on a single dataset and does not provide comparative analysis across different ontological structures.
- What evidence would resolve it: Experiments testing LLM performance on multiple ontologies with varying complexity and structure.

### Open Question 2
- Question: What are the long-term implications of using RDF embeddings versus full RDF data inclusion in LLM prompts for system scalability and cost?
- Basis in paper: [explicit] The paper discusses challenges of embedding large RDF datasets and uses selective data inclusion, but does not evaluate long-term scalability or cost.
- Why unresolved: The paper acknowledges the limitations of RDF embeddings but does not provide a detailed analysis of long-term trade-offs.
- What evidence would resolve it: Longitudinal studies comparing system performance and costs using different RDF data inclusion strategies.

### Open Question 3
- Question: How can the issue of LLM hallucinations in RDF reasoning be further mitigated without relying solely on fine-tuning?
- Basis in paper: [explicit] The paper mentions LLM hallucinations as a limitation and discusses fine-tuning as a mitigation strategy.
- Why unresolved: The paper identifies hallucinations as a problem but does not explore alternative strategies beyond fine-tuning.
- What evidence would resolve it: Research into additional methods such as prompt engineering, hybrid systems, or external validation mechanisms.

## Limitations

- Reliance on prompt engineering limits performance on highly domain-specific or complex queries.
- RDF embedding approach depends on embedding quality and may degrade with ambiguous queries or complex schemas.
- Manual evaluation introduces subjectivity, and experiments are limited to a single private SPARQL endpoint, reducing generalizability.

## Confidence

- **High confidence** in the core mechanism: embedding RDF schema data into LLM prompts improves entity extraction accuracy, supported by direct experimental results and manual validation.
- **Medium confidence** in the RDF subgraph retrieval via vector embeddings: while the approach is well-grounded, its performance depends on embedding quality and may degrade with ambiguous queries or complex schemas.
- **Low confidence** in broad generalizability: the evaluation is limited to one dataset and prompt template set, and the reliance on private endpoints limits reproducibility.

## Next Checks

1. Replicate the subgraph retrieval accuracy using a public RDF dataset (e.g., DBpedia) and a standard embedding model, measuring semantic similarity and query accuracy.
2. Conduct a user study with real conversational queries to assess practical accuracy and hallucination rates in diverse domains.
3. Compare prompt-based entity extraction with fine-tuned model performance on the same dataset to quantify the trade-off between prompt engineering and model adaptation.